{"anchor": "Nine things I learned in ninety years. It feels reassuring that none of these surprised me, and I strive towards a lot of these views/learnings already.  Hopefully a good sign!  Packard's writings help give me a little more clarity too, especially when written in such a thoughtful way.  Very cool  <3 I still have my first edition Cave of Time. I don't think it's a first printing though but still, when they came out it was simply awesome. I got the first 6 books in a pack for my birthday, I shared them later on with my children and they loved them too when they were young. Love these. This quote stuck out to me: > It follows, I think, that the luckier you\u2019ve been, the more humility and generous spiritedness you need, and the unluckier you\u2019ve been, the more compassion for yourself you need, and unfair as it may seem, the more you need irrepressible resolve. a completely different topic & question on this post.\nhow is his blog made? I like the style (simple yet clear and beautiful). Anyone know what direction i should look at? It is the simple things that is the hardest. If anything, having children revealed many of the mentioned. To me, having children is enlightenment > what an outsized role is played by luck This speaks to me. So much of our life circumstances are beyond our control (parents, genetics, geography, society, wider economy, etc.) It's humbling, how much of our success or failure is influenced by pure chance. Since he might not be known to most (especially a younger audience), the author is a writer best known for many of the Choose Your Own Adventure books that were hugely successful in the 80s. Jimmy Maher wrote about them recently  https://www.filfre.net/2025/09/choose-your-own-adventure/  ...and use LaTeX Thanks for sharing this <3 Thank you, Kevin, for sharing this, and thank you for your insights, Edward. As a young man without a father anymore, it's always a pleasure learning about people's life experiences to help me be my best self without years", "positive": "\u201cThe closer to the train station, the worse the kebab\u201d \u2013 a \u201cstudy\u201d. Anecdotally, it's the same for coffee. Office lobby coffee shops are invariably terrible. The decent ones are always at least a 5-10 minute walk away. This makes intuitive sense. High mass-transit corridor real-estate (rail, air, road) leases come at a premium so those higher fixed-costs and must be balanced against a higher-volume of less-breadth of service with the same fixed (or even slightly higher) labor costs. In food service, high-volume is (mostly) inversely correlated with quality. Looking at their actual results ( https://preview.redd.it/znmnejgab5je1.png?width=1000&format=... ), I don't see any positive or negative correlation. Although I can subjectively confirm the hypothesis. I've observed the following: 1) An alarming number of regions in the world have a pizza joint called \"New York Pizza\", \"Manhattan Pizza\", or similar. 2) The similarity of the pizza therein to the actual thin, greasy slices served up in pizza joints from actual New York is inversely proportional to the location's distance from New York. So, the New York Pizza in Boston -- pretty close. The New York Pizza in Brisbane, QLD is alien by comparison and I think they consider \"pepperoni\" and \"salami\" interchangeable down there. He didn't find a correlation, or rather found that there is no correlation, between proximity to a railway station and how the kebab is reviewed. It's a nice study for a statistics class! The only place this isn't true is Japan. Always like reading the Best Kebab reviews on trip advisor. It\u2019s right next to Queen Street railway station so fits with the study.  https://www.tripadvisor.co.uk/Restaurant_Review-g186534-d125...  > Not only was my food uncooked but I also discovered a pubic hair in my chips and cheese, then when I proceeded to report the problem, I was chased with a knife. Down Dundas Street.Absolutely scandalous LOL we may need to update the title of this post, half the top level comment", "negative": "\u201cLet people help\u201d \u2013 Advice that made a big difference to a grieving widow. Rabbi Haim once ascended to the firmaments to see the difference between the worlds. He first visited Gehenna (Hell). He saw a vast hall with long tables covered in the most magnificent foods. But the people sitting there were skeletal and wailing in agony. As the Rabbi looked closer, he saw that every person had wooden slats splinted to their arms, stretching from their shoulders to their wrists. Their arms were perfectly straight and stiff; they could pick up a spoon, but they could not bend their elbows to bring the food to their own mouths. They sat in front of a feast, starving in bitterness. The Rabbi then visited Gan Eden (Heaven). To his surprise, he saw the exact same hall, the same tables, and the same magnificent food. Even more shocking, the people there also had wooden slats splinted to their arms, keeping them from bending their elbows.\n But here, the hall was filled with laughter and song. The people were well-fed and glowing. As the Rabbi watched, he saw a man fill his spoon and reach across the table, placing the food into the mouth of the man sitting opposite him. That man, in turn, filled his spoon and fed his friend. The Rabbi returned to Hell and whispered to one of the starving men, \"You do not have to starve! Reach across and feed your neighbor, and he will feed you.\"\n The man in Hell looked at him with spite and replied, \"What? You expect me to feed that fool across from me? I would rather starve than give him the pleasure of a full belly!\" Text-based alt:  https://text.npr.org/2026/01/20/nx-s1-5683170/let-them-the-s...  When someone's spouse has died, a very helpful thing to do is to cook and package and deliver meals that the surviving spouse can simply place in the fridge and warm up as needed. When you are grieving, to actually prepare a meal is a terribly, terribly difficult thing to do. The end of this article leaves me hanging. Did she manage to find the previou"}
{"anchor": "NanoChat \u2013 The best ChatGPT that $100 can buy. Wow, how do we sign up for the Eurekalabs course and how much does it cost? I've always thought about the best way to contribute to humanity: number of people you help x how much you help them. I think what Karpathy is doing is one of the highest leverage ways to achieve that. Our current world is build on top of open source projects. This is possible because there are a lot of free resources to learn to code so anyone from anywhere in the world can learn and make a great piece of software. I just hope the same will happen with the AI/LLM wave. Eureka Labs:  https://github.com/EurekaLabsAI  What a prolific person Andrej is. It's been more than amazing to follow along! Here's the announcement post [0] from Karpathy, which provides a bit of additional context. [0]  https://x.com/karpathy/status/1977755427569111362  > Thank you to chief LLM whisperer   Alec Radford for advice/guidance. oh man an Alec x Andrej podcast would BREAK THE INTERNET... just saying... going from glory days of GPT1 to now building GPT3? in 4 hours Should be \"that you can train for $100\" Curios to try it someday on a set of specialized documents. Though as I understand the cost of running this is whatever GPU you can rent with 80GB of VRAM. Which kind of leaves hobbyists and students out. Unless some cloud is donating gpu compute capacity. >If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for --device_batch_size in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. That sounds like it could run on a 24gb GPU. Batch size of 8 would imply 20gb mem, no? ...presumably just takes forever This weekend I just cracked into nanoGPT ( https://github.com/karpathy/nanoGPT ), an older but fabulous learning exercise where you build and train a crappy shakespeare GPT with ~0.8M parameters on a cpu. Results are about what you'd expect from that, they", "positive": "Waymo granted permit to begin testing in New York City. I saw one of these on Chambers Street just yesterday afternoon, but it must have been in manual mode, of course. It's fascinating seeing all the comments elsewhere anytime Waymo starts testing in another city along the lines of, \"ah, but how will they handle X, Y, and Z here?? Checkmate, robots!\" despite having already launched service in several other cities. Granted, NYC is the biggest city in the US, so maybe that sort of reaction is more reasonable there than when people in Dallas or Boston do it. Very cool. I wonder what scale it has to hit for this to become a profitable line item for Google and what their revenue targets are for it. Man I love Waymo everytime I'm in SF. Truly feel like I'm living in the future when I sit in one I'm cautiously optimistic about this self-driving thing. Waymo at least seems to have figured out a lot of it. Would it be way better to make walkable neighborhoods, mixed-use developments, and reliable and frequent public transit? Yes. Yes it would. But, in lieu of that, self-driving has a lot of advantages in the long run, even if the technology isn't 100% perfect right now. It's insane that they need permits for 8 cars that have humans driving them in 2025, when they're already fully automated in SF. > We\u2019re a tech-friendly administration Clearly not. Is this the first time Waymo is doing winter / snow testing at scale? I think some of the Pittsburgh-based self-driving firms may have tried this, but unaware how far they got. I\u2019m curious if autonomous cars will become targets for aggressive drivers. Like a driver isn\u2019t going to be as scared cutting off a Waymo or tailgating one because the AI isn\u2019t gonna get road rage or honk like hell. In some places I could see the Waymo\u2019s getting severely bullied if that\u2019s the case. The game-theoretic aspect of this is interesting to me. A lawful robot will never make progress in Manhattan because the people will just walk across its path con", "negative": "We Do Not Support Opt-Out Forms (2025). That site doesn't seem to support pages loading either. edit: I feel their pain - I've spent the past week fighting AI scrapers on multiple sites hitting routes that somehow bypass Cloudflare's cache. Thousands of requests per minute, often to URLs that have  never  even existed. Baidu and OpenAI, I'm looking at you. Archive link:  https://web.archive.org/web/20251009081648/https://conscious...  | Since emails are sent from the individual\u2019s email account, they are already verified. This is not how email works, though.  https://archive.ph/QCMjJ  if it helps The irony of a site about AI opt-outs getting hammered by AI scrapers is almost too on the nose. trollbridge's point about scrapers using residential IPs and targeting authentication endpoints matches what we've seen. The scrapers have gotten sophisticated. They're not just crawling, they're probing. The economics are broken. Running a small site used to cost almost nothing. Now you need to either pay for CDN/protection or spend time playing whack-a-mole with bad actors. ronsor hosting a front-page HN project on 32MB RAM is impressive and also highlights how much bloat we've normalized. The scraper problem is real, but so is the software efficiency problem. It\u2019s wild when I read a professional looking website like this and Conscious Digital misspells their own org name as \u201cConsious Digital\u201d in the first paragraph. I\u2019m glad they\u2019re fighting against email spam but it just raises all sorts of red flags in my mind, or at least it used to. Funny enough, these days it indicates the article was written by a human. I had a dev join my team and made a few typos and it gave me a chuckle, as it\u2019s a whole class of mistake I hadn\u2019t seen in awhile. The \"required login\" pattern is particularly a problem. I seem to have namesakes around the US and UK that use my email address as their own when signing up for various services (mobile phone services, Shopify, Uber, various banks and investmen"}
{"anchor": "The Prophet of Parking: A eulogy for the great Donald Shoup. Oregon eliminated burdensome parking regulations in most larger cities and: it's fine. Many home builders still add parking to new projects because there is market demand for it - and they are also competing for tenants or buyers against existing housing which has parking. But there is now the flexibility to do some projects without parking, which really helps at the affordable end of the spectrum, and is a good fit for more walkable locations. BTW, Nolan Gray, cited as the author, has a book out himself that's really approachable and good reading if you're interested in cities:  https://islandpress.org/books/arbitrary-lines  Shoup passed away on February 6: *  https://parkingreform.org/donald-shoup/  *  https://cal.streetsblog.org/2025/02/08/streetsblog-mourns-th...  *  https://news.ycombinator.com/item?id=43004881  His book: *  https://en.wikipedia.org/wiki/The_High_Cost_of_Free_Parking  * EconTalk podcast episode:  https://www.youtube.com/watch?v=8Sgmw3jQcyc  > Nor are minimum parking requirements even needed: developers have the knowledge and incentives to provide the appropriate amount of off-street parking. If a developer builds too little parking, she will struggle to attract tenants and command lower rents. This isn't entirely true. In cities where parking requirements are eliminated, many new businesses move into locations that would have previously been illegal, showing that many commercial tenants view parking requirements as excessive. In my city, judging by public comment, support for parking requirements comes not from business owners or developers but from voters who fear a lack of parking at the businesses they frequent and who fear that parking for nearby businesses or apartment buildings will overflow into their neighborhood (the horror.) > One survey of the literature suggests that drivers in the typical American city spend an average of eight minutes looking for parking at the end of ea", "positive": "Danish pension fund divesting US Treasuries. What happens when USD stops becoming the the reserve currency for the world?  And who takes its place? A sensible response, indeed. Investing is about finding the right balance of risk vs reward. When a country becomes less reliable, it becomes a less attractive investment, until the interest they pay rises enough to compensate for the additional risk. Edit: Yes, I am being sarcastic. > $100 million Is that a lot? Seems relatively inconsequential in the grand scheme of things, but perhaps a warning of larger moves to come. Let's see how Norway will react The US keeps voting to raise its debt cieling. Theres not end in sight to endless taxation by both parties. Nobody is reducing spending and delivery continues to go down. > \"The decision is rooted in the poor U.S. government finances,  which make us think that we  need to make an effort to find an  alternative  way of conducting our liquidity and risk management,\" Investment Director Anders Schelde said in a written statement. Not a political decision. Still a bad sign for the US, but not really unexpected. This divestment is so little and with so little aim. The whole situation is been caused by a single guy and 400 enablers, whereas the US is a 400 million people country. The correct form of reaction is a punch in the face during a bilateral meeting, Zelensky came close to doing it but unfortunately he resisted his impulse , that's where the epicenter of all newly generated global problems in the last 10 years lies, in that octogenarian brian of his. When I actually look at the data, a lot of US deficit growth came from several specific shocks, with inconsistent years of recovery. - 9/11 - Iraq War - Covid The US did recover a bit deficit-wise in Obama years, but have not reset the fiscal picture from Covid.  https://fred.stlouisfed.org/series/FYFSD  So much of the way the United States works is having a nearly limitless source of borrowing at low rates in the form of s", "negative": "Notes on starting to use Django. Claude Code is also very good at building basic CRUD apps with Django. Thanks for this! I wish there were more cross-comparisons like this out there of what it is actually like to use some of these frameworks, the note on Django being a little less magic than Rails makes me genuinely interested in it. I always return to Django for any project. It's fantastic. Enough batteries are included with it that it is very powerful. Django is objectively the most productive \"boring technology\" I've ever worked with for developing web applications. They don't regularly add too many bells and whistles on every release, but they keep it stable and reasonably backwards compatible. Django aside, I think this is a really important point:     Being able to abandon a project for months or years and then come back\n  to it is really important to me (that\u2019s how all my projects work!) ...\n  \nIt's perhaps especially true for a hobbyist situation, but even in a bigger environment, there is a cost to keeping people on hand who understand how XYZ works, getting new people up to speed, etc. I, too, have found found that my interactions with past versions of myself across decades has been a nice way to learn good habits that also benefit me professionally. After spending a lot of my time on Django, it's fine for simple to moderately complex things.  The ORM mostly good.  DRF is fine for APIs.  And the admin is super nice as well. But once something gets significantly complex, the ORM starts to fall down, and DRF becomes more of a hindrance. But if you're just doing simple CRUD apps, Django is perfectly serviceable. > I love being able to backup by just doing a VACUUM INTO and then copying the resulting single file. Naively, I would probably just copy the sqlite file. Is that a bad idea? The Django ORM / migrations are still basically unmatched in happiness factor. I much prefer Python but am not really seeing any point to doing anything other than JavaScript for"}
{"anchor": "50 Years of Travel Tips. I don't agree with all of this though I do think most of it  can  be good advice. I did a huge amount of travel, mostly of particular styles, latterly when I was working. Still do a fair bit though I'm trying to spend less time on flights and more on destinations. The main thing I didn't see in there although I may have missed it or it may have been implied is travel light. You can't always go with carry-on pack of some sort if you have varied trips, e.g. smart clothing plus hiking kit. But you can probably go lighter than you think. I know I'm mostly at lightweight travel than I used to be. > If you hire a driver, or use a taxi, offer to pay the driver to take you to visit their mother. Uhh, I really can't imagine this one working well in a Western country. I spent 9 months traveling from Mexico to Buenos Aires with a backpack eighteen years ago.  Spent most nights in hostels in shared rooms for a few dollars a night. It was a great experience. Carried a MacBook Pro and a digital Nikon D70.  Actually had the first iPhone but hardly used it. Do have a selfie of myself on a bus somewhere in Central America. These days I\u2019m taking more expensive vacations in cheaper countries. You can go to the Caribbean and stay for $2000 a night or go to places like Morocco or Panama on a  luxury  vacation for 1/3 the price. Wow, that's actually a really good list. I'd add if a journalist has done it, you can do it. Search HN for you location (which also has most of Atlas Obscura in it) This is great advice. On his 'laser out' approach, I often find after travel I am tired and I _really_ don't want to spend hours more getting to where I'm really going, so I usually stop in the city that I landed in. But I have a policy: never go to sleep without going to walk in the city. That is: never land and sleep. _Always_ absorb some of the local environment. Then when your brain knows it's somewhere else, then go to sleep. This has worked to varying degrees. I always w", "positive": "History LLMs: Models trained exclusively on pre-1913 texts. smbc did a comic about this:  http://smbc-comics.com/comic/copyright  The punchline is that the moral and ethical norms of pre-1913 texts are not exactly compatible with modern norms. \u201cTime-locked models don't roleplay; they embody their training data. Ranke-4B-1913 doesn't know about WWI because WWI hasn't happened in its textual universe. It can be surprised by your questions in ways modern LLMs cannot.\u201d \u201cModern LLMs suffer from hindsight contamination. GPT-5 knows how the story ends\u2014WWI, the League's failure, the Spanish flu.\u201d This is really fascinating. As someone who reads a lot of history and historical fiction I think this is really intriguing. Imagine having a conversation with someone genuinely from the period, where they don\u2019t know the \u201cend of the story\u201d. The sample responses given are fascinating. It seems more difficult than normal to even tell that they were generated by an LLM, since most of us (terminally online) people have been training our brains' AI-generated text detection on output from models trained with a recent cutoff date. Some of the sample responses seem so unlike anything an LLM would say, obviously due to its apparent beliefs on certain concepts, though also perhaps less obviously due to its word choice and sentence structure making the responses feel slightly 'old-fashioned'. This is a neat idea.  I've been wondering for a while now about using these kinds of models to compare architectures. I'd love to see the output from different models trained on pre-1905 about special/general relativity ideas.  It would be interesting to see what kind of evidence would persuade them of new kinds of science, or to see if you could have them 'prove' it be devising experiments and then giving them simulated data from the experiments to lead them along the correct sequence of steps to come to a novel (to them) conclusion. I\u2019d like to know how they chat-tuned it. Getting the base model is one ", "negative": "The guide to real-world EV battery health. Tesla does their own with real world data. It\u2019s a non-issue. Save the planet. Stop making excuses and get an EV. > How long do electric car batteries last? The article never answers the question. But if you assume 70% end-of-life threshold with 2.3% loss per year - then we're looking at 13 years. Hopefully, in coming years, we will see more practically designed EVs that are more affordable.  A practical car doesn't need neck-snapping acceleration, every bell-and-whistle and room for a family of six with a dog.  I'd like to believe that as batteries cost drop, the incentive to justify the extra cost will drop.  Then we can get back to \"just basic transportation\" rather than a luxury product for the rich.   While $31k isn't exactly cheap, the base new Leaf is heading the right direction. 81% of original capacity for many cars means when driving at highway speeds you will get like 250 miles or less range per charge. Still dramatically less than gas cars. Important to note that this article is geared toward  Fleet Managers , so terms like \u201caverage service life\u201d may not apply.  For example the average car in the us survives 12.6 years before being junked, totaled, etc.  which is far longer than a car would be in fleet service at a company. While buying an EV is a greener choice than buying an ICE, a better option still is to use the vehicle you already have for as long as reasonable. This also overlooks the fact that EVs are prohibitively expensive for the vast majority of the population. It isn't the case that people aren't buying them because of preference. Nearly everyone would buy a car that's cheaper to run and maintain if they could afford it. \"Save the planet\" by making giant lithium strip mining operations great again. (Safely hidden out of sight in rural China or West Virginia, of course.) City slicker \"logic.\" No thanks. I will instead  actually  do something to help the planet by continuing to drive decades year old v"}
{"anchor": "My favorite cult sci-fi and fantasy books you may not have heard of before. Anyone got some favs to share? I need to read the new Peter Hamilton book (book 2 due out soon). And I am ashamed to admit I haven't read any Greg Egan yet, need to get on that :) Of these I've only read  The Worm Ouroboros , and I cannot recommend it enough.  The structure is a bit weird at first\u2014you gotta get past the first chapter\u2014but after that it settles and is astounding.  If you have any passing interest in Lord of the Rings, you'll likely love it. I read sci-fi but not fantasy, why do people insist on lumping these together? John C Wright wrote a nice short story set in William Hope Hodgson's \"The Night Land\"  Awake in the Night   https://web.archive.org/web/20090524012412/http://www.thenig...  In the side panels are users/readers who drew up their own maps on what they think the Nightscape is. It has all the romantic mystery of a fantasy tale, whilst still being firmly grounded in reality. I remember when London's Shard was going up, and I'd see it lit up slightly at night, glowing and ominous and thinking, \"this is it: this is the last holdout of humanity.\" Am I missing something, or is \u201cLove And Chocolate\u201d a romance novel that was included as a joke? Seems pretty incongruous in this list. One of the effects of passing of time is that even some of the greats of yore are now obscure and cultish. Like the whole golden age I have met very few people under 50 that have read the early Schekley short stories. That are probably one of the sci fi peaks. But in cult and unknown works - Ticket to tranai. One of the best (anti) utopias written. I'd like to recommend one as well: The City & the City, by China Mi\u00e9ville. A delightful, unique experience! Fresh and original, \u201cfantasy science fiction\u201d. Not a big fan of detective stories and noir, but this is something else. I would like to recommend The Wandering Inn by Pirateaba. You won't read anything else for years. If you like these books -- e", "positive": "I built my own CityMapper. Before Citymapper existed, there was OneBusAway, a Ph.D. student project at the University of Washington. It still exists and powers millions of transit rider trips every day all around the world in Seattle, Washington DC, New York City, Poznan Poland, Buenos Aires Argentina, Adelaide Australia, and who knows where else. If you\u2019re interested in hacking on something like Citymapper, or setting up an OBA server for your own city, you can find everything you need on our GitHub organization:  https://github.com/OneBusAway  That includes docker images, an iOS app and a trip planner framework, android app, Sveltekit web app, and even a next generation OBA server written in Go. As far as the data to power this, you can get GTFS for every US transit agency from  https://mobilitydatabase.org/  (nb I\u2019ve been involved in the OBA project since 2012) Why are the table and the description of the RAPTOR algorithm in the article images rather than text? During university, we've built OptiTravel ( https://github.com/denysvitali/optitravel ) to do something similar. We couldn't use Google Maps APIs (project requirement), so we wrote a custom routing algorithm based on A* and I've created a Rust server to host GTFS data ( https://github.com/denysvitali/gtfs-server ) \u00e0 la Transitland ( https://transit.land/ ). Performance wasn't great since everything had to run locally and do network roundtrips, but it found routes in my hometown that Google Maps didn't show. Pretty cool discovering hidden connections in the transit network and being able to customize your own params ( https://github.com/denysvitali/optitravel/blob/master/src/ma... ) I am involved with the OpenTripPlanner project, which is a Java trip planning application that also uses the RAPTOR algorithm! It\u2019s used in cities all over the world, with the biggest deployment being ENTUR\u2019s in Norway, which covers the entire country. I believe all trip planning apps in Norway use this deployment. It supports m", "negative": "I built a light that reacts to radio waves [video]. I love your poetry on a phone project so muchhhh Very cool, was there a conversion or look up table to convert db to gamma for more accurate human visualization? Incredibly cool. I was really hoping to see the more \u2018edge\u2019 cases - take the light out to the middle of nowhere, walk towards it and away from it with just your phone or a Bluetooth speaker, see it react to your approach. The bit at the end about it shifting over the course of the day is cool, but I wish the effect was more visually apparent - it mostly just looked like random noise the whole time to me. This is fantastic. But the idea where you use a camera that can only see the wifi signals in the room like visible light is even more stunning. It would be even better if you could block out all light from the visible spectrum and only see the GHz band. This is such a neat project. The idea of translating invisible radio waves into visible light is mesmerizing \u2014 it feels like giving your surroundings a new sensory dimension. It\u2019s beautiful. I think I\u2019ve seen something similar in a Ukraine war video where they use a device that lights up on specific frequencies that drones use. FANTASTIC!! I was just thinking about this the other day, and wondering about directionality... For example, if you had a camera facing a space, and the receiving antenna was within that space... and you were able to (somehow?) from the antennas perspective, see the \"direction\" the frequency was coming from.. And then map the different specific frequencies within the desired bandwidth to colors... and of course intensity map like you have in the slit device.. And then \"look through the camera\"... you would see a live three dimensional overlay of all signals within range (colored!) \"interacting\" with the antenna... but kind of more the \"looking through the camera\" sort of view, like you could \"see\" how those waves were interacting.. And then wouldn't it be interesting to put a tin-foi"}
{"anchor": "AGI fantasy is a blocker to actual engineering. Many big names in the industry have long advocated for the idea that LLM-s are a fundamental dead end. Many have also gone on and started companies to look for a new way forward. However, if you're hip deep in stock options, along with your reputation, you'll hardly want to break the mirage. So here we are. Okay, so come up with an alternative, it's math, you can also write algorithms. Elon thinking Demis is the evil supervillain is hilariously backward and a mirror image of the reality. \"As a technologist I want to solve problems effectively (by bringing about the desired, correct result), efficiently (with minimal waste) and without harm (to people or the environment).\" As a businessman, I want to make money. E.g. by automating away technologists and their pesky need for excellence and ethics. On a less cynical note, I am not sure that selling quality is sustainable in the long term, because then you'd be selling less and earning less. You'd get outcompeted by cheap slop that's acceptable by the general population. I like the conclusion; like for me, Whisper has radically improved CC on my video content. I used to spend a few hours translating my scripts into CCs, and tooling was poor. Now I run it through whisper in a couple minutes, give one quick pass to correct a few small hallucinations and misspellings, and I'm done. There are big wins in AI. But those don't pump the bubble once they're solved. And the thing that made Whisper more approachable for me was when someone spent the time to refine a great UI for it (MacWhisper). I'm surprised the companies fascinated with AGI don't devote some resources to neuroscience - it seems really difficult to develop a true artificial intelligence when we don't know much about how our own works. Like it's not even clear if LLMs/Transformers are even theoretically capable of AGI, LeCun is famously sceptical of this. I think we still lack decades of basic research before we can ", "positive": "Deciphering language processing in the human brain through LLM representations. ok, that pretty cool research from Google, hope this leads to even more discoveries around the brain, hopefully it's time we get a better understanding of our brains and how to hack them. I view this as compelling evidence that current models are more than \"stochastic parrots,\" because as the OP shows, they are learning to model the world in ways that are similar (up to a linear transformation) to those exhibited by the human brain. The OP's findings, in short: * A linear transformation of a speech encoder's embeddings closely aligns them with patterns of neural activity in the brain's speech areas in response to the same speech sample. * A linear transformation of a language decoder's embeddings closely aligns them with patterns of neural activity in the brain's language areas in response to the same language sample. Could this lead us to being able to upload our brains onto computers? To kill death. Very cool. It is somewhat ironic that they had to use an OpenAI model for this research. At the same time, this gives nice continuity from earlier works that demonstrated similar, smaller scale, results using GPT-2. This is interesting. The blog post links several papers, and I recommend reading them. Responses here however seem not commensurate with the evidence presented. Two of the papers[0][1] that provide the sources for the illustration in the blog post are about research conducted on a very small group of subjects. They measure neural activity when listening to a 30 minutes podcast (5000 words). Participants tried to guess next words. All the talk about \"brain embedding\" is derived from interpreting neuronal activity and sensor data geometrically. It is all very contrived. Very interesting stuff from a neuroscience, linguistics and machine learning perspective. But I will quote from the conclusion of one of the papers[1]: \"Unlike humans, DLMs (deep language models) cannot think, unde", "negative": "There's only one Woz, but we can all learn from him. Woz is by far the person in computing history for whom I have the most respect. Dude is an absolute  legend , and from everything I have heard is humble and kind on top of his crazy skills. If I could get to the point where I had even 10% of his skill and generosity of spirit, I would consider myself to have done pretty well. It\u2019s a stark contrast to today's mindset where we often just throw more resources at the problem.  His obsession with elegance over features is something I try to keep in mind, even if it's harder in modern web dev. \" Let's make it shorter and punchier.  \"Woz's floppy disk controller design is still the gold standard for doing in software what competitors needed a whole board of chips to do.  That kind of obsession with elegance over brute force is exactly what's missing in modern engineering. Only one Woz? What about Scott? Coincidentally one of the earliest Apple I prototypes ends its auction tomorrow if you have over $500K to spare:  https://news.ycombinator.com/item?id=46605420  For me, anyone who is involved in FOSDEM in any way deserves more respect (regarding revolutionary things we can learn) I learned some very bad jokes from him. It's kinda funny... In '89 a friend and I were talking about starting a startup like the two Steve's (we didn't know about Ron Wayne back then.)  We both knew exactly what Woz did, but were a bit sketchy on Jobs role in the early days.  Don't get me wrong, I'm not saying Jobs was a layabout, only that the strengths he brought to the table were more abstract. So I would also say... the kinds of things we learn from Woz are concrete and we get immediate feedback if we learned them wrong. Everyone chooses the wrong Steve to worship. I can't think of a single person who embodies the spirit of this site more than Woz. dang could replace the guidelines with a picture of Woz and we'd all know what it meant. modern engineering is launching an electron to-do list ap"}
{"anchor": "How Google Maps allocates survival across London's restaurants. Interesting work, but ultimately silly: of course google maps ranks results.  No one (yes, yes, I'm sure like 3 people) want a list of all results, unordered or ordered by something useless like name, when they type in restaurant.  And I cannot put into words how uneager I am to have the city or state government manage what comes up when I put indian or burrito into a map. The other commenter thought the work was silly, but I think it's brilliant. Keep at this!! You're making me hungry :) super interesting project. I would love to generate a similar list for my own neighbourhood I love the idea! And I want to have it for my city :) Is there a project on GitHub or somewhere that I could clone??  (smiling face with halo)  Very interesting. But I wonder how much Google (and other) Maps can actually shape the scene. For tourist hotspots with a lot of visitors, it IS clearly the driving force. But for locals, I don\u2019t think it has an overwhelming effect. Locals know their restaurants and they visit them based on their own rating. They could explore total strange and new ones, but then they will form their own rating and memory immediately and will not get fooled/guided by algorithm (the next time) Google maps is doing the same thing to local business success that social media algorithms are doing to political success. The algorithm controls what you perceive as the consensus of others. It is a dangerous world to have such power so highly concentrated. At least in central London, the \"underrated gems\" feature does not seem to be very good at finding underrated gems. That might just be a feature of the area though. I have gotten so sick of Google Maps that I've done the unthinkable, and have started walking around the city trying establishments at random. It has yielded quite good results basically immediately. People (myself included) have gotten too used to living In The Box. Putting aside the time to just go", "positive": "Is liberal democracy in terminal decline?. The pendulum is swinging back slightly, but I wouldn\u2019t pronounce it dead just yet. We are seeing a decline of American hegemony, accelerated by this current regime. And the ascendancy of a non-democratic superpower. However, the largest chunk of GDP and growth still sits firmly in democratic countries and very consequential American elections are happening this year, and in 2028. The real question is, will Europe find its spine? Terminal velocity achieved ... The only question is whether it'll hit the ground before the next US election. Any emergency 'chute's available? I can\u2019t access the article\u2026 but honestly, I\u2019ve been asking myself the same question for the past ten years.\nThe best answer I\u2019ve found is: not yet \u2014 but the current backlash and drift toward authoritarianism in many democracies is actually the sign that something real is shifting.\nIn a way, the situation looks weirdly similar to Europe before WWII. Democracies were starting to integrate some of the socialist ideas that had emerged in the 19th century, and the dominant forces of capitalism pushed back hard. They let fascists rise, sometimes even supported them. That led to a war, millions of deaths, and then a massive change of mindset: after WWII, every European country implemented strong social protection and regulation.\nToday, the shift is less about social security and more about cultural transformation \u2014 the end of patriarchy, and with it the decline of imperialism and Western dominance. Those foundations started being seriously questioned in the 60s. The dominant forces are resisting because, deep down, they\u2019ve already lost \u2014 there\u2019s no going back. But as always, they can still cause immense damage on the way out. And yes, if they refuse to let go peacefully, it could lead to conflict, and a lot of casualties.\nBut after, democracy will make a come back. I may be too optimist. Unfortunately I suspect yes - for practical reasons not directly linked to dem", "negative": "Emissary, a fast open-source Java messaging library. Emissary is a simple-to-use, no dependency, yet BLAZING FAST messaging library for decoupling messages (requests and events) and message handlers. Emissary aims to take advantage of the simplicity of using the annotations for handlers (e.g. @RequestHandler/@EventHandler) without the drawbacks of reflection (slow). What differentiates Emissary from other messaging/dispatch libraries? It takes advantage of java.lang.invoke.LambdaMetafactory to avoid the cost of invoking methods reflectively. This results in performance close to directly invoking the request handler and event handler methods. ~ 1000% more throughput compared to other similar libraries (Spring's ApplicationEventPublisher, Pipelinr, EventBus)\n~ 90% faster compared to other similar libraries (Spring's ApplicationEventPublisher, Pipelinr, EventBus) Benchmarks found on the GitHub repository:  https://github.com/joel-jeremy/emissary?tab=readme-ov-file#p...  Naming collision with an ActivityPub server  https://emissary.dev/  I'm a big fan of Guava's EventBus. Easy to implement and straightforward to understand. This library does seem to require more setup and I don't see the immediate advantages, also why does it require an instanceProvider? I don't understand what that does. Assuming that you are the author of Emissary, this could be a Show HN, I think.  https://news.ycombinator.com/showhn.html  Are you planning to add persistent events as well, so that events are not lost due to crashes And i2p rust router  https://github.com/altonen/emissary  Emissary really shines if performance is a top priority. The setup is more or less similar, you register a bunch of event handlers when initializing the library. The main difference is that, in addition to events, Emissary also supports \"request\" messages. Requests enforce the invariant that only one handler should handle it - if there are multiple handlers registered for a given request, Emissary will throw an erro"}
{"anchor": "A few random notes from Claude coding quite a bit last few weeks. The section on IDEs/agent swarms/fallibility resonated a lot for me; I haven't gone quite as far as Karpathy in terms of power usage of Claude Code, but some of the shifts in mistakes (and reality vs. hype) analysis he shared seems spot on in my (caveat: more limited) experience. > \"IDEs/agent swarms/fallability. Both the \"no need for IDE anymore\" hype and the \"agent swarm\" hype is imo too much for right now. The models definitely still make mistakes and if you have any code you actually care about I would watch them like a hawk, in a nice large IDE on the side. The mistakes have changed a lot - they are not simple syntax errors anymore, they are subtle conceptual errors that a slightly sloppy, hasty junior dev might do. The most common category is that the models make wrong assumptions on your behalf and just run along with them without checking. They also don't manage their confusion, they don't seek clarifications, they don't surface inconsistencies, they don't present tradeoffs, they don't push back when they should, and they are still a little too sycophantic. Things get better in plan mode, but there is some need for a lightweight inline plan mode. They also really like to overcomplicate code and APIs, they bloat abstractions, they don't clean up dead code after themselves, etc. They will implement an inefficient, bloated, brittle construction over 1000 lines of code and it's up to you to be like \"umm couldn't you just do this instead?\" and they will be like \"of course!\" and immediately cut it down to 100 lines. They still sometimes change/remove comments and code they don't like or don't sufficiently understand as side effects, even if it is orthogonal to the task at hand. All of this happens despite a few simple attempts to fix it via instructions in CLAUDE . md. Despite all these issues, it is still a net huge improvement and it's very difficult to imagine going back to manual coding. TLDR ev", "positive": "My stages of learning to be a socially normal person. I don't have much to add to this right now other than to say this is really fantastic writing. I don't normally enjoy \"my journey\" kind of blog posts, but this one feels full of valuable insights, and I'm grateful to the author for sharing. It's also just nice to read something written by a skilled writer. I wish I had the drive to do as much work as the author has. Instead I will live more or less where I am now, stably in social mediocrity, perpetually somewhat impedance mismatched with the people around me. really identify. especially with the early yearning to connect and not having the skills. Learned sooo much over the years by being brutally rejected and eventually taking stock of what happened and extracting a rule or two. but then, yeah, next phase, rules don't matter (except when they do) and change moment to moment anyway. funny to read this here on hacker news of all places, where I let my carefully managed, almost always inhibited, childhood nerd self fly free in the comments. OP has definitely gone beyond me in many ways, with his talk about embodiment, and being able to be so empathic that he has elicited tears of gratitude. Enviable. >  I was probably the most severely bullied kid at my school. >  I was demonstrating my erudition Those two things might have been linked. I wasn't there, but I'm suspicious. Fortunately the author learns better by the end of the article, but it stuck out to me because LLMs have made people suspicious of five dollar words like delve so to use the word erudition in this day and age is a choice. Appreciate the writing and the author's fortitude in achieving their goals. While I never had friends, neither online nor in person, I cannot identify with this at all - it reads like a strange, obsessive seeking of external validation which I have never felt myself. Maybe I am just disinterested in people in general. I eat at Chinese restaurants where my waiter is a QR code. Pl", "negative": "ICE using Palantir tool that feeds on Medicaid data. Any time I see people say \"I don't see why I should care about my privacy, I've got nothing to hide\" I think about how badly things can go if the wrong people end up in positions of power. The classic example here is what happens when someone is being stalked by an abusive ex-partner who works in law enforcement and has access to those databases. This ICE stuff is that scaled up to a multi-billion dollar federal agency with, apparently, no accountability for following the law at all. Wishful thinking but it would be real great if a future leader destroyed this infrastructure. I'm sure they'll run on not using it but when systems like this exist they tend to find applications Why would Medicaid have the data of anyone who is at risk of immigration enforcement? The reported connection seems tenuous: > The tool \u2013 dubbed Enhanced Leads Identification & Targeting for Enforcement (ELITE) \u2013 receives peoples\u2019 addresses from the Department of Health and Human Services (which includes Medicaid) and other sources, 404 Media reports based on court testimony in Oregon by law enforcement agents, among other sources. So, they have a tool that sucks up data from a bunch of different sources, including Medicaid.  But there's no actual nexus between Medicaid and illegal immigrants in this reporting. Edit: In the link to their earlier filings, EFF claims that some states enroll illegal immigrants in Medicaid:  https://www.eff.org/deeplinks/2025/07/eff-court-protect-our-...  This current administration and their policies have definitely influenced my opinion on the 2018 debate around citizenship questions on the US census. (For more context:  https://www.tbf.org/blog/2018/march/understanding-the-census... ) Glad to see this post didn't get flagged like the one that was posted yesterday on a similar topic about ICE data mining and user tracking.  https://news.ycombinator.com/item?id=46748336  \"ICE Budget Now Bigger Than Most of the Wo"}
{"anchor": "Map To Poster \u2013 Create Art of your favourite city. Why are big chunks of Sam Francisco missing (eg around the bridge) missing from the example? It says there are examples but I can't see them? I believe (from a quick code check on my phone) it should be possible to output the images to SVG with a little tweak, thanks to your use of matplotlib? Is there a reason you\u2019ve defaulted to PNG that I\u2019m missing? That's splendid. I've long wanted to make a jigsaw puzzle out of Sydney's road map, so I can familiarise myself with the layout of roads while having fun. That way I can reduce my reliance on nav app and become one of those old-school drivers. The map of Venice seems to be the only one whose image is \"squeezed\" horizontally. Wondering why. I tried it in a python3 venv, but the download data step is stuck at 0% unfortunately. Three random themes for anyone who's Czech or likes Prague and doesn't want to set up the script locally:  https://imgur.com/a/Ovg8mDW  Also check out prettymapp  https://prettymapp.streamlit.app/  This repo is fantastic. The README should be the gold standard for OSS. Not to mention how stunning the outputs are. Thanks for sharing. Pretty cool! It would be great if there was a way to set coordinates manually, since Nominatim can sometimes produce mediocre results. Also, would be nice to have a way to render the same map in all themes, not just one. what are the blue dots? (not water bodies i think?) San Francisco looks nice, but there seems to be a problem with the projection in some of the sample images. It looks as if it isn't UTM but a global sphere projection, which isn't suitable for local renders. It's suspicious that the word 'projection' isn't mentioned in the Readme. Does anyone have recommendations for how to actually print a poster from images like these? Very cool, thanks for sharing!! Looks amazing !\nIn my free time, i play with my laser cutting machine.\nIt will save me some design time.\nThanks What happens if there are multiple citi", "positive": "High air pollution could diminish exercise benefits by half \u2013 study. It sounds terrible . What will happend in the future?! The research doesn't differentiate between seasons , and every one knows how polluted the air is in the winter when everyone is heating their home and apartament. I look at the PM2.5 data for my city every day, and at this point (Nov) in the winter season, the only acceptable time to exercise is between 2PM-4PM after vertical mixing kicked in. Outside that duration, particulates are elevated after morning rush our, after evening rush hour, or during overnight inversion trapping evening rush hour + wood burning smoke until the next morning rush hour. This is one the main reasons why I would prefer working remote, it is hard to utilize this time well (for exercise) if you are in the office. At least with PM you can wear a mask, although I am still searching for the best one that works during intense exercise. Also wanted to point out\n\"Trump EPA moves to abandon rule that sets tough standards for deadly soot pollution\"  https://apnews.com/article/epa-soot-air-pollution-trump-zeld...  If only you could see it. In the big cities the air quality has improved, however, I am not sure if it really has, or if we are now just burning hydrocarbons more efficiently so that the particle sizes have become invisible. Put it this way, although cars are allegedly better than they were, fuel consumption hasn't dropped considerably. The cars are more numerous than ever, and, although there are EVs, there are still more ICE cars than there were in the good old days when petrol came with lead in it. I am not sure that most people in urban areas even know what good air tastes and smells like. I take a canal path through lush countryside, far from any cars for most of the way. This canal has an aqueduct (or is it a viaduct?) over a motorway and the contrast is incredible. You go from basically smelling flowers to air pollution and back to clean air again quite quickly", "negative": "Cloudflare claimed they implemented Matrix on Cloudflare workers. They didn't. Days after the fake story about Cursor building a web browser from scratch with GPT-5.2 was debunked. Disbelief should be the default reaction to stories like this. I've never thought someone should be fired based on a blog post but man, this comes real close. Honestly I like Cloudflare's CDN and DNS but beyond that I don't really trust much else from them. In the past though their blog has been one of the best in the space and the information has been pretty useful, almost being a gold standard for postmortems, but this seems especially bad. Definitely out of line compared to the rest of their posts. And with the recent Cursor debacle this doesn't help. I also don't really get their current obsession with porting every piece of software on Earth to Workers recently... I found the source code Jade was referring to, and it looks like the author just noticed this thread:  https://github.com/nkuntz1934/matrix-workers/commit/0823b47c...  Technical blogs from infrastructure companies used to serve two purposes: demonstrate expertise and build trust. When the posts start overpromising, you lose both. I don't know enough about this specific implementation to say whether \"implemented Matrix\" is accurate or marketing stretch. But the pattern of \"we did X\" blog posts that turn out to be \"we did a demo of part of X\" is getting tiresome across the industry. The fix is boring: just be precise about what you built. \"We prototyped a Matrix homeserver on Workers with these limitations\" is less exciting but doesn't erode trust. The developer just \"cleaned up the code comments\", i.e. they removed all TODOs from the code:  https://github.com/nkuntz1934/matrix-workers/commit/2d3969dd...  Professionalism at its finest! It\u2019s not a  working  or  complete  implementation, but\u2026 It is worrying to see a major vendor release code that does not actually work just to sell a new product. When companies pretend that com"}
{"anchor": "alphaXiv: Open research discussion on top of arXiv. I remember seeing this idea some years ago. I think it was called qrxiv.org or something like that, but can't find it anymore. I hope this one has better luck, getting the users in the fragmented space of preprints can be a challenge. Hey alphaxiv, you won\u2019t let me claim some of my preprints, because there\u2019s no match with the email address. Which there can\u2019t be, as we\u2019re only listing a generic first.last@org addresses in the papers. Tried the claiming process twice, nothing happened. Not all papers are on Orcid, so that doesn\u2019t help. I think it\u2019ll be hard growing a discussion platform, if there\u2019s barriers of entry like that to even populate your profile. hnews tries to say one positive thing challenge impossible i always love any idea for curating high iq internet community This seems like a horrible idea. I know we need an alternative to peer review but an online comment section feels like something worse than that. This is great. Already loving the discussions/comments I see there. I believe this site is missing a very important thing, direct links to the different categories with a list of papers.\nThis is at least how I (and I believe many others) browse arXiv. I open it up in the morning, scroll through a few categories and open a few papers that look interesting to me. I could see myself using alphaxiv for that, and then, if there's a comment section, I might even read it, and, who knows, leave a comment. But there's no way I'm going to be changing the address or going to some other site to search for papers just to see whether there are some comments. ps: I see the extension adds a \"discussion\" link to arxiv, it is a pity that it is only available for Chrome. What's the main thing that this new website adds over scirate? Great idea. - The frontpage should directly show the list of papers, like with HN. You shouldn't have to click on \"trending\" first. (When you are logged in, you see a list of featured papers ", "positive": "Broken legs and ankles heal better if you walk on them within weeks. It was ~20 years ago, so my memory is a little foggy, but I gave myself a \"dancer's fracture\" in one foot. After many months, it was looking like a non-union. The podiatrist was worried any pin would split the broken bone even more. It wasn't looking good. I had read something along these lines even back then, so with my crazy immobilizer boot on, I head to the gym and started doing light squats several times per week. Next x-ray: healed. The pathology for broken collar bones was changing right as I took up mountain biking, and subsequently shattered my collarbone. It was hotly debated at the hospital, if my specific case should be operated on or not. Each time I had a checkup, one doctor would say \"wait and see\" while the other was saying \"I can't believe we didn't operate on this\". At any rate, the outcome was as good as if they had operated on it, according to the doc anyway. Nice of them to test it out on me! More related to this though, I have broken both my collarbones, the first time I had little direction and just held my arm still for 2-3 months. It took forever to heal, and my arm atrophied significantly. The second time, similar severity. I was guided through rehab and I was back using my arm within the first month, very little atrophy. I fractured my elbow mountain biking, the tip of my radius. The urgent care doctor gave me a sling and suggested months of immobility. The orthopaedic said to throw away the sling and start exercising the elbow as soon as I could, and prescribed PT. Turns out that was the right move, there are some permanent changes to mobility but it's about 97% what it was before the crash. Immobilizing joints can apparently cause the muscles, tendons, and nerves to seize up and lose significant range of movement permanently. If anyone's heard of RICE (Rest, Ice, Compression, Elevation) for healing joints, the new guidance is called POLICE: Protect, Optimal Load, Ice, C", "negative": "\u201cLet people help\u201d \u2013 Advice that made a big difference to a grieving widow. Rabbi Haim once ascended to the firmaments to see the difference between the worlds. He first visited Gehenna (Hell). He saw a vast hall with long tables covered in the most magnificent foods. But the people sitting there were skeletal and wailing in agony. As the Rabbi looked closer, he saw that every person had wooden slats splinted to their arms, stretching from their shoulders to their wrists. Their arms were perfectly straight and stiff; they could pick up a spoon, but they could not bend their elbows to bring the food to their own mouths. They sat in front of a feast, starving in bitterness. The Rabbi then visited Gan Eden (Heaven). To his surprise, he saw the exact same hall, the same tables, and the same magnificent food. Even more shocking, the people there also had wooden slats splinted to their arms, keeping them from bending their elbows.\n But here, the hall was filled with laughter and song. The people were well-fed and glowing. As the Rabbi watched, he saw a man fill his spoon and reach across the table, placing the food into the mouth of the man sitting opposite him. That man, in turn, filled his spoon and fed his friend. The Rabbi returned to Hell and whispered to one of the starving men, \"You do not have to starve! Reach across and feed your neighbor, and he will feed you.\"\n The man in Hell looked at him with spite and replied, \"What? You expect me to feed that fool across from me? I would rather starve than give him the pleasure of a full belly!\" Text-based alt:  https://text.npr.org/2026/01/20/nx-s1-5683170/let-them-the-s...  When someone's spouse has died, a very helpful thing to do is to cook and package and deliver meals that the surviving spouse can simply place in the fridge and warm up as needed. When you are grieving, to actually prepare a meal is a terribly, terribly difficult thing to do. The end of this article leaves me hanging. Did she manage to find the previou"}
{"anchor": "Canada. So you say the highs aren\u2019t as high and the lows certainly aren\u2019t as low as in the US.  Given that few really experience the highs, I think the Canadian choice is correct.  It\u2019s a stereotype, but the people do tend to be friendlier and the pace is slower.  But I\u2019ve found that the quality of work is a function of one\u2019s inner makeup not the external environment.  We\u2019ll see what the next 5-10 years looks like in N America. I was not born in Canada, but I chose to immigrate here and it's one of the top 5 best choices I've ever made. I have access to so much that in other places would be wildly expensive. My life is richer due to the diversity of the people I am surrounded by, if I bought every book I borrowed from the library last year it would have cost $3000 or more, and even after moving away from a large city I have access to public transit good enough to cover most of my needs. It's actually really wild to think I spent a couple of years working in Boston more than a decade ago, and I used my zipcar subscription way more often than I've ever had to use a communauto in fake london (a city no one would mistake for having good urban planning). The Canada the author refers to is gone. Canada is far from perfect but there is no other country in the world I would ever consider leaving it behind for. I grew up in Canada and live in the US now with kids. The US is not one country. It's two that are radically different. There's wealthy America. The top 5% to 10% that have healthcare, have their own safety nets, don't need to worry about money, their kids go to select schools that they can buy into (mostly by buying into the right neighborhoods), an amazing pension plan, etc. My kids go to a fancy library with reading time, puppets and classical music. All the things I love about Canada and more. That country is amazing and the quality of life is unparalleled unless you're obscenely wealthy. The bottom 80 to 90% percent of Americans live a life that is far inferior t", "positive": "10 years of personal finances in plain text files. This seems to be, in effect, advertising for a book about how to use the underlying FOSS software to do this. I would be okay with that as a monetization model, except that the book author despite being a self-described FOSS dev doesn't seem to have anything to do with the project ( https://github.com/beancount/beancount/graphs/contributors ). Ah, not quite true. The author fixed a typo in a docstring once ( https://github.com/beancount/beancount/commit/8584763b618f76... ). Plain text files are appreciated. I started storing all my notes (500+ by today) in markdown files locally. It's easy to search and navigate with grep and ag/rg. It's easy to edit in Vim or your favorite editor. It's easy to append all sorts of informations. I add some flags and properties in metadata, like last_reviewed, some tags, etc. The versioning and sync is solved by git + a private github repo. I have 14 years of personal (and 2 years of sole proprietorship) finance data in beancount. I tried all the available personal finance apps there are, from cloud/online offerings to offline apps. Eventually, I settled on beancount because it is the most versatile file format. In addition to tracking finances, I can track stocks, unvested RSU grants, vacation hours, and even personal training I have paid for but yet to use. It's cumbersome at times, and I do miss the (G)UI of entering transactions, but with (neo)vim I got used to it and I breeze trough my finances in 15-20 minutes once a week. > 30-45 minutes every single month That's 6\u20139 hours every year! 5 years: 30\u201345 hours 10 years: 60\u201390 hours I've been beancount'ing for years now As we've crossed into the new year I've switched to a similar directory setup as the OP with 1 file per year. Previously I just had one file that was from 2022 which ended up being like 2 million lines of text, which was starting to bog down the emacs plugin. What I appreciate the most about this approach to personal ", "negative": "'Active' sitting is better for brain health: review of studies. I'm confused by this... It seems to me like the relevant part is \"playing computer games is good\" not \"the type of sitting you do matters\". Playing computer games while standing might be even better Original source:  https://news.uq.edu.au/2026-01-not-all-sitting-same-when-it-...  > \"...Passive activities such as watching television have been linked to worse memory and cognitive skills, while \u2018active sitting\u2019 like playing cards or reading correlate with better brain health, researchers have found.\" ...Do these researchers even read this to themselves aloud before hitting publish? It's confounding that they would find \"sitting\" to be the active ingredient pushing the outcome differential. Obviously, if you remove the bodily posture from the action that the user is engaging in, you would observe the same outcome the researchers did\u2014meaning sitting was not operative here (..duh). Breaking news at 11: the brain works best when it\u2019s actually used. Breaking news! Using the brain is better for brain health than not using it. Next: Playing chess on one leg is better for brain health than sitting. \"Passively watching TV\" feels like a common target for brain health/strength/etc discussions. I'm curious if there's been any studies into the differences that engagement with television programs can have on the brain. There's been a whole breadth of television programming over the decades. I think it would be wrong to treat it all as equal in regards to how it impacts your brain. Maybe in the future people will focus on solving problems some AGI can solve better to keep themselves in shape, like how exercise is a modern invention This article has nothing to do with sitting. That this is the state of \"science\" is very disappointing, and whenever I see the domain sciencealert, am pretty much trained that it is going to be nonsense. Sadly, other science publications seem to be following a not dissimilar trend.  https://j"}
{"anchor": "Don't fall into the anti-AI hype. > As a programmer, I want to write more open source than ever, now. I want to write less, just knowing that LLM models are going to be trained on my code is making me feel more strongly than ever that my open source contributions will simply be stolen. Am I wrong to feel this? Is anyone else concerned about this? We've already seen some pretty strong evidence of this with Tailwind. \"Die a hero or live long enough to see yourself become the villain\" AI is both a near-perfect propaganda machine and, in the programming front, a self-fulfilling prophecy: yes, AI will be better at coding than human. Mostly because humans are made worse by using AI. The \u201canti-AU hype\u201d phrase oversimplifies what\u2019s playing out at the moment. On the tech side, while things are a bit rough around the edges still the tech is very useful and isn\u2019t going away. I honestly don\u2019t see much disagreement there. The concern mostly comes from the business side\u2026 that for all the usefulness on the tech there is no clearly viable path that financially supports everything that\u2019s going on. It\u2019s a nice set of useful features but without products with sufficient revenue flowing in to pay for it all. That paints a picture of the tech sticking around but a general implosion of the startups and business models betting on making all this work. The later isn\u2019t really \u201canti-AI hype\u201d but more folks just calling out the reality that there\u2019s not a lot of evidence and data to support the amount of money invested and committed. And if you\u2019ve been around the tech and business scene a while you\u2019ve seen that movie before and know what comes next. In 5 years time I expect to be using AI more than I do now. I also expect most of the AI companies and startups won\u2019t exist anymore. What I don't understand about this whole \"get on board the AI train or get left behind\" narrative, what advantage does an early adopter have for AI tools? The way I see it, I can just start using AI once they get good", "positive": "Ratatui \u2013 App Showcase. the title of this post is odd? it\u2019s a showcase of TUI applications built with this Rust crate \u2014 which I am hearing about for the first time, and am interested in. I was expecting a blog post on why Rust is experiencing a TUI revolution or something I've seen lots of TUIs lately, why is that? What is the renewed interest? The only places I know of is Awesome TUIs [0] and terminaltrove [1] I can also see that Ratatui has an awesome list too [2]. [0]  https://github.com/rothgar/awesome-tuis  [1]  https://terminaltrove.com/  [2]  https://github.com/ratatui-org/awesome-ratatui  Some of the most interesting projects here have the worst installation stories.It's sort of tilting at windmills to not acknowledge that people are going to mostly install through package managers for their platform by advertising it as such. I'm not suggesting there's anything wrong with building from source. On the contrary, I think it's fantastic as many targets are supported here as there are! I think it's a shame more people aren't discovering them is all. Very dope. I really like dua as my mac only has 256 GB. What is the best / most popular / user friendly terminal http client I can replace postman with. Has a history I can search, save favorites, secure etc. Ratatui is neat but the way it's architected, you need to take on third party dependencies for each individual widget. And we're talking basic things like spinners, checkboxes, text areas, etc. -- there aren't too many widgets built into ratatui itself. I didn't like the idea of taking all that on so instead I went with something more handrolled. Ratatui is awesome! Just built a little chat client with it, tons of fun.  https://terma.mattmay.dev/  I'm really waiting for the TUI web browser. That would let me live completely in the terminal. Is anyone working on this? With the speed terminals are and support for graphics through things like sixel and shaders I'd love to have a browser even if I couldn't do videos", "negative": "Judge order bars feds from altering or destroying evidence in Pretti shooting. The original title is: > Judge grants order barring feds from altering or destroying evidence in Pretti shooting Well that is reassuring. This administration has demonstrated an excellent track record of respecting and following judicial orders. Why is that even needed, honestly? Like is \"destroying or altering evidence\" usually legitimate or what? Not sure why anyone thinks a judges order is worth anything in the USA anymore. I am not reassured at all. Why was such an order needed? Seems like this should be the default and if you are caught tampering, straight to jail. I don\u2019t think this belongs on HN. There isn\u2019t a compelling technical angle and there are plenty of other venues to discuss politics. These judges can spend the rest of eternity issuing these orders but there is no mechanism to enforce it since the current administration has shown a complete disregard for precedence and mores. Currently doing the rounds of non US but allied special forces and commando chat groups is the blunt response of US General Tony Thomas, former head of the Special Operations Command (2016 to 2019) to each and every one of the senior Trump administration pushing the domestic terrorist line. Stephen Miller (for one of many) tweeted:     A would-be assassin tried to murder federal law enforcement and the official Democrat account sides with the terrorists.\n  \nGeneral Tony Thomas responded with a high resolution image of the first shot taken, from the rear, execution style:  https://x.com/TonyT2Thomas/status/2015629593265250810  I hope the US population can reign in Hegseth, Miller, Bondi, et al clown car. It's obvious to all across the globe what's going here. For reference:  https://en.wikipedia.org/wiki/Raymond_A._Thomas  can be compared to the bio of the day drinking weekend warrior currently heading the US DoD. Given Trump folks' previous behavior surrounding court orders of documents, I'm sure this"}
{"anchor": "Ask HN: What's the Point Anymore?. No point, buy tinned food and head for the darkest part of the forest. Do you read a book just so you know what happens at the end, or because you like the journey there too? Do you read blog posts \"just to know\" or because you like reading? Sure, if you don't like reading, then it's great you don't have to. But personally I like to read, and be taken on an adventure by writers, that's why I read, I don't read just so I \"know what happened\". So everything remains the same, nothing has changed. Nothing been destroyed by AI, it only seems to have destroyed your own perspective. The point is to cultivate the ability to distinguish between real and fake.  Soon enough, that ability will be extremely rare, and for the people who really need it, nothing else will do. Sounds like you're getting burned out by too much hype-chasing. Follow your interests, and you'll always discover something that AI hasn't solved by itself. And keep in mind that people have always had these concerns whenever something new came along - photography, computers, etc. > Why read a blog post, when Google AI Summary can just give you the summary? Because the summary is often wrong, and the summary might not even be the point? > Why read a book, when you can just get AI summary of it? You've been able to read a good summary by a human for most books on Wikipedia for decades now. Going to the example used thousands of times, maybe the horse drivers thought the same way, but guess what? now we have cars, race cars, super cars, flying cars. The engine kept changing, car markets kept evolving. \nPeople kept adapting. \nAdapting is the only way or the Penguin way :P Imho there are still tasks that can't be done by AI good enough. Wouldn't let clawbot handle my personal relationships. Not even scheduling a football [or dota2] game. Yet alone navigate job. So, maybe level up the goal post? Try do something not-easily-done by AI? Select from your fringe interests [if core is ", "positive": "Is OpenAI Dead Yet?. Tracking the demise of OpenAI through the news cycle No, they are not dead.  However, they face incredible competition in a brutally commoditized product space. As a retail investor mostly invested into broad ETFs (All World), is there any way I can get short exposure to OpenAI? Being short Oracle/Nvidia/Microsoft? Relevant, I would definitely be sleeping uneasy if I was at \u201cOpen\u201dAI. Some insist that Chinese models are a few generations behind, how many probably depends more on patriotism rather than fact. Those people typically also insist that Chinese models are just distillations and often neglect to see how many of these companies contribute to the theory of designing efficient and capable models.\nIt is somehow thought that they will always trail US models. Well. i would say look at recent history. China worked up the ladder of manufacturing from simple, bad stuff to highly complex things - exactly what westerners then claimed they\u2019d never be able to.\nThen as that was conquered, westerners comforted themselves by insisting that China could copy, but trail-blazing would always still be our thing. Well, Baidu and Alibaba face scaling issues few western companies do and BYD seems to match Tesla or VW just fine. I am unsure why anyone would think US models are destined to remain in the lead forever. At \u201cbest\u201d, I see a fragmented world where each major region (yes also Europe) will eventually have their own models - exactly because no one wants to give any competitive power a chokehold over their society. But beyond that, models will largely be so good that this \u201cgeneration\u201d/universal superiority idea becomes completely obsolete. Is OpenAI profitable yet? Will it be in time to recoop capex. It will be the first application of the 'curse of Open company' rule: any for-profit entity that has the name Open in it is destined to go bankrupt. Keep in mind that the \"news cycle\" isn't of much use in this field. For 2025, almost all \"mainstream\" media was", "negative": "JRR Tolkien reads from The Hobbit for 30 Minutes (1952). This is so good.  You can tell that Andy Serkis based his gollum voice off of this. I wonder what Tolkien would say of so much of the symbolism from his novels being used to bootstrap a horrible dystopian control grid? Would he approve or disapprove? The way that orcs are dehumanized you have to wonder. Is there a version minus the music? This is the most magnificent audio version ever recorded of The Hobbit - by Nicol Williamson in the early 1970's. Zip file with mp3 in it:  https://drive.google.com/file/d/1b2aPKgVVguOKMOOqWskaliOviYr...  Best enjoyed on a rainy afternoon in an armchair with a cup of tea. Of course he didn't live to see the Peter Jackson movies but I think I've heard his son didn't like them My favorite recent LotR media: There is a Lord of the Rings MMO (like World of Warcraft) and a guy made a video recording a walk from the Shire to Mordor. Like you can just walk from the Shire to Mordor in the game. And it's almost 10 hours long in real world time to do that! But on top of that the whole journey is narrated by the Lord of the Rings audio book, with the relevant parts of the journey.  https://youtu.be/LYipECdYpXc  Incredibly relaxing People who don't like \"On The Road\" should listen to Jack read it in his own voice. It is amazing how Lord of the Rings persists in the world. Christopher Lee reading the Children of Hurin is also fantastic. tangential comment, but if anyone is interested in one of the best (imo \"legendary\") audio books on LOTR look no further than Phil Dragash :  https://archive.org/details/tlotrunabridged . Okay who\u2019s going to clone this using AI and have it read the entire book? Anyone?! I drink in his old local. A bit weird in there I would imagine if you're an American. Although I am a bit American and it is a bit weird in there. Ranged Touch's Shelved By Genre podcast is doing an entire year on The Hobbit + Lord of the Rings.\n https://rangedtouch.com/2026/01/02/the-hobbi"}
{"anchor": "Mathematical Foundations of Reinforcement Learning. The best lectures on Reinforcement Learning and related topics are by Dimitris Bertsekas:  https://web.mit.edu/dimitrib/www/home.html  Another great resource on RL is Mykel Kochenderfer's suite of textbooks: \n https://algorithmsbook.com/  Also worth mentioning Murphy's WIP textbook[0] focused entirely on RL, which is an outgrowth of his excellent ML textbooks. [0]:  https://arxiv.org/abs/2412.05265  Awesome resource, in case someone is interested I implemented most of suttons book here  https://github.com/ivanbelenky/RL  I don't know how to go from understanding this material to having a job in the field. Just stuck as a SWE for now. Highly recommended .. even the main contents diagram is a great visual overview of RL in general, as is the 30 minute intro YT video. Im expecting to see a lot of hyper growth startups using RL to solve a realworld problem in engineering / logistics / medicine LLMs currently attract all the hype for good reasons, but Im surprised VCs dont seem to be looking at RL companies specifically. 6-lecture series on the Foundations of Deep RL by Pieter Abbeel is also very recommended. gives very good overview and intuition\n https://youtu.be/2GwBez0D20A  And if you want to understand the theory of Skinner's Verbal Behavior check out  https://bfskinner.org/wp-content/uploads/2020/11/978_0_99645...  During the openai gym era of RL, one of the great selling pts was that RL was very approachable for a new comer as the gym environments were small and tractable that a hobbyist could learn a little bit of RL, try it out on cartpole and see how it'd perform. Are there similarly tractable RL tasks/learning environments with LLMs? From the outside, my impression is that you need some insane GPU access to even start to mess around with these models. Is there something one can do on a normal MacBook air for instance in this LLM x RL domain? > This book, however, requires the reader to have some knowledge of ", "positive": "Eat Real Food. Makes sense to me! And poor diet is probably one of the biggest problems in the United States Makes sense. Now make protein affordable. And 100 years from now, will we still call it the New Pyramid? :) I guess we still call it New York... Great!  How will the reductions in consumer protection, health, FDA, etc. - by this current administration impact that?  https://www.food-safety.com/articles/11004-a-2025-timeline-o...  This website is far too complicated, just show a clear, labeled image of the new pyramid.  This is designed to scare people, not inform them. Lol good one. Anything matching . real .\\.gov$ can be discarded as BS these days... Edit: Actually make that simply .*\\.gov$ It's unbelievable to which point this clown show has permanently dismantled US soft power. Guess they think they have enough hard power to compensate. What with all that good raw milk and meat they're eating... Ironic that a steak is one of the three things showing up on the landing page. Is that the beef lobby money coming in? I enjoy an occasional steak but if the goal is to improve diet of masses, it\u2019s not the food I\u2019d put at the center. \"In February 2010, Michelle Obama launched \u201cLet\u2019s Move!\u201d with a wide-ranging plan to curb childhood obesity. The campaign took aim at processed foods, flagged concerns about sugary drinks, and called for children to spend more time playing outside and less time staring at screens. The campaign was roundly skewered by conservatives... But the strategy that Kennedy\u2019s HHS is using to address the problem so far\u2014pressuring food companies to alter their products instead of introducing new regulations\u2014is the same one that Obama relied on, and will likely fall short for the same reason hers did a decade ago.\"  https://www.theatlantic.com/health/archive/2025/09/maha-lets...  Meta comment: The design aesthetic gives me a real \"Cards Against Humanity\" feel. > Whole grains are encouraged. Refined carbohydrates are not. Prioritize fiber-rich whole g", "negative": "Krak\u00f3w, Poland in top 5 worst air quality worldwide. The air in Krak\u00f3w is fine once you give it a good chew. I don't know why people are complaining. Warsaw is top 15, Krakow and Warsaw are the only European cities in the top 15. For some added context, it's around -10 degrees celcius there right now. I don't know why Poland stands out here, but I know that older residential areas burn wood (in other Eastern European countries as well), because that's just how you heat an old house: these neigbourhoods are horrible to walk through in winter, because the air just stinks of smoke. I've been living there for 15years and it's the reason I've moved away. Frankly I love the city enough that I would sabotage my health for it. Not my kids health though. Asthma related problems in kids are widespreada and of course bad air quality is related to tons of other negative consequences. I wonder though how do they compute the number (is it average across points measured in the city?). Because within city borders air quality varies wildly. There are some regions where it is actually pretty good. Few years ago Krak\u00f3w has forbidden the use of solid fuels which improved the situation significantly. Days like today are happening much less often since then. Moreover, Krak\u00f3w has probably one of the densest network of pollution sensors in the world, which is why we talk about it at all. There are places in Poland that are much worse off, but there's not that much data to back it up. Fossil fuel heating is _extremely_ polluting, and really costing the population months, up to years of their life. But it's a silent killer, so let's dramatize fantasy nuclear accidents instead. I used to live in Gdansk, and later Gdynia, and let me tell you - as soon as it's cold outside, people burn all kinds of shit at home, the air's so thick you can practically cut it with a knife. We theorized that the smog's mainly from residential burning of coal, but of course who know's what's in the stove. All I kno"}
{"anchor": "I built my own CityMapper. Before Citymapper existed, there was OneBusAway, a Ph.D. student project at the University of Washington. It still exists and powers millions of transit rider trips every day all around the world in Seattle, Washington DC, New York City, Poznan Poland, Buenos Aires Argentina, Adelaide Australia, and who knows where else. If you\u2019re interested in hacking on something like Citymapper, or setting up an OBA server for your own city, you can find everything you need on our GitHub organization:  https://github.com/OneBusAway  That includes docker images, an iOS app and a trip planner framework, android app, Sveltekit web app, and even a next generation OBA server written in Go. As far as the data to power this, you can get GTFS for every US transit agency from  https://mobilitydatabase.org/  (nb I\u2019ve been involved in the OBA project since 2012) Why are the table and the description of the RAPTOR algorithm in the article images rather than text? During university, we've built OptiTravel ( https://github.com/denysvitali/optitravel ) to do something similar. We couldn't use Google Maps APIs (project requirement), so we wrote a custom routing algorithm based on A* and I've created a Rust server to host GTFS data ( https://github.com/denysvitali/gtfs-server ) \u00e0 la Transitland ( https://transit.land/ ). Performance wasn't great since everything had to run locally and do network roundtrips, but it found routes in my hometown that Google Maps didn't show. Pretty cool discovering hidden connections in the transit network and being able to customize your own params ( https://github.com/denysvitali/optitravel/blob/master/src/ma... ) I am involved with the OpenTripPlanner project, which is a Java trip planning application that also uses the RAPTOR algorithm! It\u2019s used in cities all over the world, with the biggest deployment being ENTUR\u2019s in Norway, which covers the entire country. I believe all trip planning apps in Norway use this deployment. It supports m", "positive": "Show HN: Books mentioned on Hacker News in 2025. Affiliate marketing is such a mixed bag. I absolutely love it when people can monetize their writing by adding some affiliate links that are relevant to the audience - win/win for all sides. Yet it is as slimy as anything else when the sole purpose of creating content is to publish affiliate links. Great books listed here! Added some to my TBR list. Thanks! I'm a little surprised the numbers aren't higher across the board. The fact that Mein Kampf was mentioned so often in 2025 is saying something about the political climate lol.. Nice website though, I like it. Neat. I'm seeing a lot of overlap with books mentioned on r/reddit. I didn't realize, until know, how demographically similar hacker news and reddit are. The top 3 programming books mentioned this year were 1. Structure and Interpretation of Computer Programs\n2. Clean Code\n3. Crafting Interpreters Also, it\u2019s quite fascinating how often fiction books were recommended! I wouldn\u2019t\u2019ve expected that on HN. Have you seen  https://hackernewsbooks.com  ? The recent novel Abundance seems to be agressibley grouped with the John Green novel An Abundance of Katherines - which I think is a humorous retelling of 2025 but also maybe needs some matching work Hitchhikers guide to the universe having 42 mentions is a cosmic level coincidence great project! how did you do tokenization and alignment of the titles to their ISBN / Amazon ID Would love to learn more about how this is built. I remember a similar project from 4 years ago[0] that used a classic BERT model for NER on HN comments. I assume this one uses a few-shot LLM approach instead, which is slower and more expensive at inference, but so much faster to build since there's no tedious labeling needed. [0]  https://news.ycombinator.com/item?id=28596207  The Book of Dragons by Edith Nesbit is listed instead of \"the Dragon book\" The 6 first books reflect the quality comments I often see here on HN. No offense intended towa", "negative": "Web-based image editor modeled after Deluxe Paint. Is it simple to adapt file open/save in order to embed it in  https://exaequos.com  ? Nice. Vanilla js with a pretty clean code. From a quick look there is some components architecture and they are decoupled via an events bus. I used to implement evented architectures in winform apps in the past. On the one hand it may seem insane but in practice it was a really good choice. Nice! The code looks pretty neat! And also somehow clean. I like those projects, without all those boring constraints you have in \"enterprise\" or even worse start-up code. Source code is very readable and very comfortable to use application. This is surprising given it's a web application in modern age, did not expect that. Steffest was just showing off his entry for the color cycling competition at GERP 2026 which uses a few of his tools to produce including DPaint.  https://www.youtube.com/watch?v=VyB5cvA6f78  EDIT: I see he posted a link at the bottom of the Readme.md I guess I should have scrolled to the bottom first. I've been following this app for a while. Worth noting that the author is also a very talented graphic artist and demoscener. Works created with this tool frequently appear in various demoscene compos. I appreciate the nostalgia of it but DPII was a light themed tool, this one is dark themed, difficult for me to read. I run DPII in DoxBox on Linux like this: dosbox DP.EXE Something I don't see in your app is the Perspective tool. This is neat, some years ago i also thought of making a simple DPaint clone (though much simpler than what this project seems to do) and started by... painting the tool icons, then losing interest :-P. I did end up reusing them for a pixelart editing component for Lazarus though[0] (and put the icons in my \"Bad-Common-Icons\" icon set[1] that i use for my GUI programs). But i do want to, at some point, tackle making something like Paint Shop Pro 7 (for desktop, not web) because i think it has the best U"}
{"anchor": "Douglas Adams on the English\u2013American cultural divide over \"heroes\". Stephen Fry made the same remarks in a Q&A session some years ago:  https://www.youtube.com/watch?v=8k2AbqTBxao  As a Brit I can't agree more with both, I find American humour so hard to relate to but I guess it's just a culture thing What a great response by Adams! I think the acceptance, and even the celebration of failure is present among the \u201cmaker\u201d community in the USA to some extent, which has really drawn me to it. I wonder if there\u2019s the same outlook on failure among other creatives, would be interesting to compare the hobby communities opinions between the USA and UK. I call this take pseudo-intellectual indulgence form, so called, academic intelectuais. Lord of the Rings is very much English Literature, and the biggest epic form the 20th century and has none of that. Ditto for Harry Poter (I\u2019m not saying Harry Potter is on the same level of literary grandeur as LOTR, but it\u2019s still an important epic series for newer generations). You can always find examples for one side or the other of the argument. But, of course, only \u201csocial\u201d scientists would be tick enough to claim some clear divide here as it suits their argument. Explains why Sir Keir Starmer is so relatable. Although I have very little experience with British humor, I find it interesting to compare British fiction I read as a child/teenager that became popular hits in the US (Harry Potter, Alex Rider). From this article's perspective, those protagonists are the epitome of American heroes (autonomy, mastery, purpose). No wonder they garnered such acclaim in the US. Curious if these stories are the exception rather than the rule in British YA fiction? Is the comparison unfair, since these stories were not written with the comedic genre in mind? I feel like the divide is very evident of each countries version of the show \"The Office\". Probably a common trope at this point, but not even the dialogue, already the aesthetic tells you a ", "positive": "Where can you go in Europe by train in 8h?. If you now could just book a train between these cities on a common european platform (or local transportation provider...)... one could dream... just booking a train and getting a quote crossing multiple borders (without interrail) is just a nightmare :( Title shared on HN left me somewhat disappointed.  The actual time appears to be \"Where can you go by train in 8h?\", though that's somewhat less clear.  It only seems to include central stations of larger cities, though I was hoping for a list of shortest travel times between stations in Europe, as more of a thought/data experiment.  Or put another way; which two train stations in Europe have the least distance between them? Anyway, the shared feature is neat, but seems to be somewhat iffy once you get out of the bigger cities.  If a route has 2 or more connections, it seems to struggle to show them.  While true to its message, I still feel the restriction of 8 hours misses sleeper trains, where travel time is less essential compared to daytime trains. It's cute for discoverability, but for a specific train search, I would definitely defer to bahn.de, which basically includes all train stations in Europe. There is a website I love for seeing how to get almost everywhere in Europe by train:  https://www.seat61.com/  I don't understand how it works. First time clicking on Poland, it showed a kind of a heat map around some city. Then I click on another location and nothing happens. OK, there's a \"back\" button, I go back, click on the map again in a different place and... nothing happens. No heat map. At some point in frustration I accidentally move the mouse while clicking and the map rotates upside down. Don't know, is it me, my browser, or there's something about the UI. Since train fans always like to point this out when it comes to flying: this is how far you can get in 8 hours  on the train . It doesn\u2019t include the time to get to the station, the buffer time you need (i", "negative": "Doom has been ported to an earbud. Hi, I ported DOOM to the Pinebuds Pro earbuds.\nIt's accessible over the internet, so you can join the queue and play DOOM on my earbuds from your PC!\nMore info as well as links to the github repos can be found on the site. This is awesome! the amount of devices doom has not been run on shrinks by the day haha How are the PineBuds Pro, anyone have them? The Pine64 IRC network doesn't have a channel for PineBuds discussion so I haven't had an easy opportunity to ask. At first I thought you found a way to control/view the game acoustically and I was very curious how that worked. But, this probably makes more sense. Do we have Doom on a USB-C plug microcontroller yet? List of Doom ports:  https://en.wikipedia.org/wiki/List_of_Doom_ports  Im waiting for the post \"Doom ported to disposable Vape chip\" :-D can we run doom on water pump? Whenever I see another supposedly menial device including enough general purpose hardware to run Doom, I wonder whether I should think of that as a triumph of software over hardware or an economic failure to build cheaper purpose-built hardware for things like sending audio over a radio. The standalone viewer (connected directly to the earbuds) also works on mobile:  https://files.catbox.moe/pdvphj.mp4  No touch controls though, it just plays the intro loop On a tangent: I remember reading John Carmak saying that as game engines became more complex, he had to relinquish the idea of writing all the (engine) code himself, and start to rely on other folks contributions as well (this was in an interview after the release of Doom 3). I wonder what his feelings are in this age of AI. Relevant SMBC, \"Computer scientist vs computer engineer\":  https://www.smbc-comics.com/comic/2011-02-17  I am a bit said that it is always Doom. Now ... I played the game when I was young. It was addictive. I don't\nthink it was a good game but it was addictive. And somewhat simple. So what is the problem then? Well ... games have got"}
{"anchor": "Claude Code gets native LSP support. My favourite agent crush[0] has lsp support for a while. I\u2019ve not noticed the agent deciding to use it all that much. [0]  https://github.com/charmbracelet/crush  It's strangely difficult to find official information about this, but here's what I've learned: \u2022 Use `/plugin` to open Claude Code's plug-in manager \u2022 In the Discover tab, enter `lsp` in the search box \u2022 Use `spacebar` to enable the ones you want, then `i` to install Hope that helps! This is an ignorant question, but, what is the benefit of this if you also have your project open in an editor or IDE (presuming they integrate language server?) If you're vibe coding without an editor, would this have any benefits to code quality over a test suite and the standard linter for a language? It\u2019s breathtaking how fast Anthropic / Claude Code team ships. They are definitely coding in a LLM maximalist way, in a good way. I am super bullish on claude code / codex cli + LSP and other deterministic codemod and code intelligence tools. I was playing around with codex this weekend and honestly having a great time (my opinion of it has 180'd since gpt-5.2(-codex) came out) but I was getting annoyed at it because it kept missing references when I asked it to rename or move symbols. So I built a skill that teaches it to use rope for mechanical python codebase refactors:  https://github.com/brian-yu/python-rope-refactor  Been pretty happy with it so far! What does the terminal integration mentioned do? I haven't come across a case where it has used the LSP yet. Opus 4.5 is fairly consistent in running QA at proper times. Lint checks and all are already incorporated into a standard & native processes outside of IDE. I think lookup can be useful when definitions are hidden deep in hard to reach places on my disk... hasn't been a problem though the agent usually finds what it needs. Anyway, here is what it stated it could do:       > Do you have access to an lsp tool?\n\n     Yes, I have an L", "positive": "Challenges and Research Directions for Large Language Model Inference Hardware. >  To address these challenges, we highlight four architecture research opportunities:  High Bandwidth Flash  for 10X memory capacity with HBM-like bandwidth;  Processing-Near-Memory  and  3D memory-logic stacking  for high memory bandwidth; and  low-latency interconnect  to speedup communication.  High Bandwidth Flash (HBF) got submitted 6 hours ago! It's a  great  article, fantastic coverage of a wide section of the rapidly moving industry.  https://news.ycombinator.com/item?id=46700384   https://blocksandfiles.com/2026/01/19/a-window-into-hbf-prog...  HBF is about having many dozens or hundreds of channels of flash memory. The idea of having Processing Near HBF, spread out, perhaps in mixed 3d design, would be not at all surprising to me. One of the main challenges for HBF is building improved vias, improved stacking, and if that tech advanced the idea of more mixed NAND and compute layers rather than just NAND stacks perhaps opens up too. This is all really exciting possible next steps. Related too  https://www.sdxcentral.com/news/ai-inference-crisis-google-e...  David Patterson is such a legend! From RAID to RISC and one of the best books in computer architecture, he's on my personal hall of fame. Several years ago I was at one of the Berkley AMP Lab retreats at Asilomar, and as I was hanging out, I couldn't figure how I know this person in front of me, until an hour later when I saw his name during a panel :)). It was always the network. And David Patterson, after RISC, started working on iRAM, that was tackling a related problem. NVIDIA bought Mellanox/Infiniband, but Google has historically excelled at networking, and the TPU seems to be designed to scale out in the best possible way. Can\u2019t we credit the first author in the title too? Come on. That appendix of memory prices looks interesting, but misses the recent trend. Weird to see no mention in this paper of persistent memory ", "negative": "I'm 34. Here's 34 things I wish I knew at 21. The days are long, but the years are short Congrats, you're half way there to publish your first self-help book! > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. It really seems quite difficult for straight men to succeed at this. > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. You must succeed. I'm not sure I like the framing of this Sex and violence intersect and interweave. It's not realistic to avoid any hurt. > One day \u2013 probably somewhere between 28 and 38 \u2013 you'll wake up and just feel 'off'. A bit sore. A bit tired. That feeling will never leave you. Be grateful for your youth while you have it. This happened when I was 20. I don't know what else to say other than, it fucking sucks. 35. Women can be as horny and lonely as men and all you need to do is talk to them to meet them. This was a revelation to me in my early-thirties. > Eating meat is quite clearly immoral. Unless it will be detrimental to your health, eat as little as possible. Carnivorous animals, are they immoral? >If you're a man, one of your hardest battles may be not giving in to sexual urges that cause harm to others. What the ... Some great life lessons here, but also some I don't agree with: - The lazy person works twice as hard.\nOften I found you can save a lot of time just trying to the minimal possible and gain a lot of insights of why something is minimal vs not -The opinion of the person who rarely offers it is listened to more closely.\nI found the opposite to be true, those who don't offer their thoughts frequently are often dismissed when they do want to share something Anyway, many of the points are great.. I would also add to k"}
{"anchor": "Ask HN: What are the best engineering blogs with real-world depth?. Encountered one specific example about a month ago here on HackerNews - All about automotive lidar.\n https://news.ycombinator.com/item?id=46110395  Blog posts where I find quality really shows are usually about something I know next to nothing about how it works. A badly written article usually either goes really shallow or skips some facts when going into depth and requires catchup elsewhere to actually understand it. The lidar article from Main Street Autonomy goes beyond basics and explained everything from the ground up in such a connected way that it was a real pleasure reading it. Sounds like you look for an intersection of academic papers (1.), tech blogs (2.), text books (3.), and confidential business strategies (4.)? A very high ambition. Maybe  https://projectzero.google/archive.html   https://netflixtechblog.medium.com/   https://www.uber.com/en-US/blog/engineering/  You're probably looking for something that is more focused on specific software decisions/implementations, but  https://infrequently.org  is the best web development blog out there. It's not \"technical\" so much as it just educates you on how to be a good web developer/run a team. There's zero fluff and considerable detail (footnotes are practically blog posts themselves).  http://highscalability.squarespace.com/all-time-favorites/  There are no such blogs. Usually companies, or individuals, will write these after they implement some feature into their products. Which makes them inherently little pieces of information scattered all over the internet and there is no one blog that is just about this. Cloudflare, google project zero. > especially from tech company blogs,  https://engineering.fb.com/   https://netflixtechblog.com/   https://stripe.com/blog/engineering   https://eng.uber.com   https://engineering.linkedin.com/   https://engineering.atspotify.com/   https://tailscale.com/blog   https://careersatdoordash.com/enginee", "positive": "Roam 50GB is now Roam 100GB. Nice that instead of completely cutting you off at the cap they put it in super slow 500 kbits. That is actually usable and used to be the fastest speed you could get at home. That's not bad for the cheap plan. Even the slow mode is fast enough for video conferencing and doing basic remote work. They still have a separate unlimited plan for anyone who needs more. I\u2019ve kept it on the backup service for 10 GB at $10 or whatever and it\u2019s pretty cool. Used it off my balcony in SF when Google Fiber had a 1 hr outage, take it on road trips, and stuff like that. Totally worth it. I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff. Aside from the fact it allows you to work with Starlink to buy more fast speed, it also allows core stuff to continue to function (e.g. basic notifications, non-streaming web traffic, etc). They could make it 1000GB for US$10/month and I still wouldn't give any money to a company associated with that man. Finally I can use Codex/OpenCode even out in the woods. No work-life balance; just vibing everywhere I go. I had a \u201chit\u201d post on bsky [0] (90 likes, big numbers for me) asking whether people would want an unlimited mobile plan throttled at 256kbps for $2/month. Seems like yes? There\u2019s lots to say about how useable it is (I often get throttled when traveling and it\u2019s really not that bad + it helps curb any desire to scroll videos!) But mainly I want to ask - I looked into it for a minute and it seems like you couldn\u2019t start an mvno because carriers wouldn\u2019t let you cannibalize them? You can get very cheap IoT plans but if you tried reselling IoT as esims for consumers, the carriers would kill it? So yeah - Starlink to mobile is actually the only viable way that routes around this problem? (((email in profile if you\u2019re cuckoo enough like me and want to start a self service\u2019d throttled mvno))) [0]  https://bsky.app/profile/greg.technology/post/3mbmwsytnyc23  I want the old plan back. If ", "negative": "The C-Shaped Hole in Package Management. Please don't.  C packaging in distros is working fine and doesn't need to turn into crap like the other language-specific package managers.  If you don't know how to use pkgconf then that's your problem. very related:  https://michael.orlitzky.com/articles/motherfuckers_need_pac...  >  Conan and vcpkg exist now and are actively maintained I am not sure if it is just me, but I seem to constantly run into broken vcpkg packages with bad security patches that keep them from compiling, cmake scripts that can't find the binaries, missing headers and other fun issues. I don't trust any language that fundamentally becomes reliant on package managers.  Once package managers become normalized and pervasively used, people become less thoughtful and investigative into what libraries they use.  Instead of learning about who created it, who manages it, what its philosophy is, people increasingly just let'er rip and install it then use a few snippets to try it.  If it works, great.  Maybe it's a little bloated and that causes them to give it a side-eye, but they can replace it later....which never comes. That would be fine if it only effected that first layer, of a basic library and a basic app, but it becomes multiple layers of this kind of habit that then ends up in multiple layers of software used by many people. Not sure that I would go so far as to suggest these kinds of languages with runaway dependency cultures shouldn't exist, but I will go so far as to say any languages that don't already have that culture need to be preserved with respect like uncontacted tribes in the Amazon.  You aren't just managing a language, you are also managing process and mind.  Some seemingly inefficient and seemingly less powerful processes and ways of thinking have value that isn't always immediately obvious to people. Missing in this discussion is that package management is tightly coupled to module resolution in nearly every language. It is not enoug"}
{"anchor": "Deciphering language processing in the human brain through LLM representations. ok, that pretty cool research from Google, hope this leads to even more discoveries around the brain, hopefully it's time we get a better understanding of our brains and how to hack them. I view this as compelling evidence that current models are more than \"stochastic parrots,\" because as the OP shows, they are learning to model the world in ways that are similar (up to a linear transformation) to those exhibited by the human brain. The OP's findings, in short: * A linear transformation of a speech encoder's embeddings closely aligns them with patterns of neural activity in the brain's speech areas in response to the same speech sample. * A linear transformation of a language decoder's embeddings closely aligns them with patterns of neural activity in the brain's language areas in response to the same language sample. Could this lead us to being able to upload our brains onto computers? To kill death. Very cool. It is somewhat ironic that they had to use an OpenAI model for this research. At the same time, this gives nice continuity from earlier works that demonstrated similar, smaller scale, results using GPT-2. This is interesting. The blog post links several papers, and I recommend reading them. Responses here however seem not commensurate with the evidence presented. Two of the papers[0][1] that provide the sources for the illustration in the blog post are about research conducted on a very small group of subjects. They measure neural activity when listening to a 30 minutes podcast (5000 words). Participants tried to guess next words. All the talk about \"brain embedding\" is derived from interpreting neuronal activity and sensor data geometrically. It is all very contrived. Very interesting stuff from a neuroscience, linguistics and machine learning perspective. But I will quote from the conclusion of one of the papers[1]: \"Unlike humans, DLMs (deep language models) cannot think, unde", "positive": "Ask HN: What non-fiction do you read?. Jaws: The Story of a Hidden Epidemic Modern environments and lifestyles have changed our jaw development dramatically, contributing to the high prevalence of sleep-disordered breathing (snoring through to obstructive sleep apnea), chronic tension, jaw joint problems, and orthodontic need. \"The Molecule of More\" by Daniel Z. Lieberman and Michael E. Long. A bit naive but fascinating narrative about how dopamine controls our feelings, addictions, and, basically, happiness. \"Future Noir: The Making of Blade Runner\" by Paul Sammon A deep history of the making of the movie \"Blade Runner\". Very enjoyable if you liked the movie. Pilgrim at Tinker Creek by Annie Dillard Your Inner Fish: A Journey Into the 3.5-Billion-Year History of the Human Body\n - Really cool account of human evolutionary history Stolen Focus (Johann Hari)\n - About how we've lost (and can regain) the ability to focus due to technological distraction (currently social media, etc. but hasn't always been) Chip War\n - History and geopolitical significance of the semiconductor industry Plato's works surrounding Socrates' death: Phaedo, Crito, Euthyphro, The Apology. Its fascinating to discover how many thoughts and ideas they had which are still relevant in our societies today. Also, they are incredibly readable, its like taking part in on a conversation among friends. I only read non-fiction; mostly philosophy. Here are some books off the top of my head: * The Inner Citadel/Philosophy as a Way of Life by Pierre Hadot * Plato's dialogues (someone already mentioned a few of them, but the Republic was missing from their list). * Epictetus (Discourses and Enchiridion) * The various essays/letters of Seneca * Matter and Consciousness by Churchland (older, but fascinating) * The Mediations of Marcus Aurelius * (mostly) any Buddhist texts * What a Plant Knows * Moonwalking with Einstein There are tons of fascinating books, way too many to list. All Pulitzer price winning non-f", "negative": "Apple, What Have You Done?. Specifically this System Data issue is big problem but I read online about it and tried stupid fix: set time to far future. Supposedly will expire this system data caches. Nonsense, I said. It is foolish to make cache so big it does not allow update to download. But I did it nonetheless and system data reduced! So crazy is real. I am glad at least that Apple has not forced me to update my iPhone 13 and 2023 Macbook, as Windows would have by now. I am hoping to ride this out, and that a later bundled update will remedy the worst complaints. The most alarming thought in TFA, though, was that the iPhone update might have at least a secondary mission of nudging the user to buy a new phone - certainly not an unknown tactic in tech. > \"My iPhone 14 Pro has 35Gb of \"system data\" which has basically filled up the entire storage I had left\" I occasionally use a macbook pro at \u00a3WORK for a few apple specific processes, and it currently has 188.67gb of \"system data\" that I have no idea how to clean up or remove. It's marked separately from the 11.01gb of macOS in the storage settings, and it constantly complains about the disk almost being full. Updating and restarting don't clear it, I wish I could just rm -rf it all. Does anyone know how I can at least see what it is, and potentially even clean it up? EDIT: Thanks for the CleanMyMac recommendations, the 57.6gb of xcode caches that didn't show up in the \"developer\" section of the storage settings might have had something to do with it At this point I\u2019m going to hold out on updating MacOS for a year. If things don\u2019t improve or the direction doesn\u2019t change significantly I\u2019m going to seriously consider paying the switching costs. My days of not believing people's gushing praise about \"just works\" about any proprietary technology are certainly coming to a middle I have 70GB of \"Messages\" on my Mac because iMessage \"in the cloud\" still stores all your attachments locally on every device. Yes, I can set t"}
{"anchor": "Anna's Archive loses .org domain after surprise suspension.  https://annas-archive.se/  Works still > We recommend checking our Wikipedia page for the latest domains. I wonder how wikipedia feels being used as DNS? EDIT: Apparently this is a well known practice. Some interesting discussion here:  https://news.ycombinator.com/item?id=40008383  Seems like great publicity for Anna's Archive. I've heard an increasing amount about Anna's Archive over the last 12 months. It has popped up a lot. I wonder if they've seen their traffic spike a lot. They could always use Yggdrasil. yeah no shit, this is what happens when you agitate the major music record labels - it's going to get worse And that's why helping torrenting and seeding the content of AA is vital: they can take down a domain name but not block everyone who seeds. I said this before but if you've got some spare GB/TB on a computer/server, consider \"donating\" it for culture preservation purposes: https://annas-archive.se/torre  nts Is this an abuse of the ServerHold status? Was this the same mechanism used to delist a Gaza video archive recently? > This status code is set by your domain's Registry Operator. Your domain is not activated in the DNS. > If you provided delegation information (name servers), this status may indicate an issue with your domain that needs resolution. If so, you should contact your registrar to request more information. If your domain does not have any issues, but you need it to resolve in the DNS, you must first contact your registrar in order to provide the necessary delegation information.  https://www.icann.org/resources/pages/epp-status-codes-2014-...  I recommend Anna's Archive get a Nostr account. Once they finally have a solid court order to seize domains, generally the rate at which they get seized accelerates greatly. Nostr is the only decentralized manner (no, Mastodon/fediverse is dependent on domain names, which are getting seized by courts in relation to this -- it is not dece", "positive": "Functors, Applicatives, and Monads. This reminds me of  https://www.adit.io/posts/2013-04-17-functors,_applicatives,...  I think over the recent years, there's been a rise in typed languages that support functional programming like TypeScript and Rust. It will be interesting to see if this trend continues in the context of AI assistant programming. My guess is that it will become easier for beginners, and the type systems will help to build more robust programs in cooperation with AI. the bit at the end is quite rude of the haskeller responding but I also think they're largely right; another monads explained through boxes tutorial is not gonna help anyone. In fact it's really a step in the wrong direction. Using a few different monads is where to start. Unfortunately, while you may not have appreciated the tone of the Haskell interaction, they are correct in their assessment from a factual perspective. This explanation propagates a number of misunderstandings of the topics well known to be endemic to beginners. In particular, I observed the common belief that functors apply to \"containers\", when in fact they apply to things that are not containers as well, most notably functions themselves, and it also contains the common belief that a monad has \"a\" value, rather than any number of values. For instance, the \"list monad\" will confuse someone operating on this description because when the monad \"takes the value out of the list\", it actually does it once  per value  in the list. This is the common \"monad as burrito\" metaphor, basically, which isn't just bad, but is actually wrong. I'm not limiting it to these errors either, these are just the ones that leap out at me. Coming from non-Haskell background, it took me a good while to undestand that `Just` is a constructor specific to the `Maybe` type. Found this for a quite nice answer:  https://stackoverflow.com/a/18809252  For some reason everyone likes to talk about Monads, but really the other types here are just as in", "negative": "Gathering Linux Syscall Numbers in a C Table. I've been thinking about doing this for a little side project for some time.  Looking forward to the eventual conclusion :) There is an existing project that tracks and gather syscalls in the linux kernel, for all ABIs:  https://github.com/mebeim/systrack  . The author maintains a table here, which is incredibly useful:  https://syscalls.mebeim.net/?table=x86/64/x64/latest  > In an ideal world, there would be a header-only C library provided by the Linux kernel; we would include that file and be done with it. As it turns out, there is no such file, and interfacing with syscalls is complicated. Because Linux is the exception, UNIX public API is the C library as defined later by POSIX. The goal to create C and rewrite UNIX V4 into C was exactly to move away from this kind of platform details. Also UNIX can be seen as C's runtime, in a way, thus traditionally the C compiler was the same of the platform vendor, there were not pick and chose among C compilers and standard libraries, that was left for non-UNIX platforms. > In an ideal world, there would be a header-only C library provided by the Linux kernel; we would include that file and be done with it. As it turns out, there is no such file, and interfacing with syscalls is complicated. Isn't that nolibc.h? > I was expecting a unified interface across all architectures, with perhaps one or two architecture-specific syscalls to access architecture-specific capabilities; but Linux syscalls are more like Swiss cheese. There's lots of historical weirdness, mostly around stuff where the kernel went \"oops, we need 64-bit time_t or off_t or whatever\" and added, for example, getdents64 to old platforms, but new platforms never got the broken 32-bit version. There are some more interesting cases, though, like how until fairly recently (i.e. about a decade ago for the mainline kernel), on x86 (and maybe other platforms?) there weren't individual syscalls for each socket syscall, the"}
{"anchor": "Show HN: I visualized the entire history of Citi Bike in the browser. How was the data gathered? They just publicly show the bike's locations? I've seen many visualizations of the citibike data over the years, this is one of the most charismatic for sure! Interesting that citibike publishes trip level data.  The bike share schemes in Dublin only publish station counts or free bike locations.  So you can see the overall pattern of bike motion, but there\u2019s no way to see how many north side trips go to the docks vs Heuston station vs the city center. This is just so cool! Not much more to add. Thanks a lot for sharing!! Great work :) How is MapBox going for this free tool? Is it costing you money? It's often interesting to observe the different ways that privacy is approached in the US and Europe. In Europe we often accept pretty grave restrictions of our liberty like the UK's Online Safety Act, which would never fly in the US, and we do so without much public comment. On the other side of things, organisations in the US happily expose datasets like this one, which would give a most EU Data Protection Officers a heart attack, and nobody bats an eyelid. Relevant callout from  https://bikemap.nyc/about : * Limitations * The data only contains the start and end station for each trip, but does not contain the full path. Route geometries are computed for each (start station, end station) pair using the shortest path from OSRM. This means that the computed routes are directionally correct but inexact. Trips that start and end at the same station are filtered out since the route geometry is ambiguous. non corrupted github link:  https://github.com/freeman-jiang/bikemap.nyc  Cool visualization. Do you find the OSRM shortest path routes probable for bikes? Not living in NYC, I expected pretty different paths. Say the \"Hudson River Greenway\" or whatever that's called. I really wish Lyft invested in maintenance. I used Citibike this week for the first time in about a year, and th", "positive": "Advanced Python Features. TFA's use-case for for/else does not convince me:       for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    else:\n        primary_server = backup_server\n    deploy_application(primary_server)\n  \nAs it is shorter to do this:       primary_server = backup_server\n    for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    deploy_application(primary_server)   The way the language is evolving, it seems likely to me that people in the applications camp (ML, simple web-dev, etc.) will soon need a \"simple Python\" fork or at least an agreed-upon subset of the language that doesn't have most of these complications (f-strings are a major success, though). Here is another one, list and expression comprehensions shared with ML languages (not that AI one), apparently many aren't aware of them. The itertools package. I would argue that most of these features (basically everything except metaclasses) are not advanced features. These are simple, but for some reason less well known or less used features. Metaclasses are however quite complex (or at least lead to complex behavior) and I mostly avoid them for this reason. And 'Proxy Properties' are not really a feature at all. Just a specific usage of dunder methods. This is all fun and games unless you have to debug someone elses code and they use a new feature that you didnt know about.\nSpeaking for myself, I would be glad if there were a python_light version of the interpreter that has a simple syntax only like the early 3.x versions. just my 2 ct If context managers are considered advanced I despair at the code you're writing. Nice! I would add assert_never to the pattern matching section for exhaustiveness checks:  https://typing.python.org/en/latest/guides/unreachable.html#...  This is a nice list of \"things you might not know\" that is worth skimming to add to your too", "negative": "Google confirms 'high-friction' sideloading flow is coming to Android. TBH this doesn't seem a particularly high friction change. It seems very like what we have to do already, or like what we do on OSX. How does this relate to the announcement from a while back about introducing signatures that tie back to Google? (IE trusted developer program or whatever they're calling that horse shit.) Google's long term strategy with Android is baffling to me. Apple has had better mobile hardware for years. Apple has higher consumer trust. Apple has better app selection (for most people). Apple has been increasingly implementing the core features that differentiate Android devices, like USB-C and RCS. Every Android user lost to the increasing iOS market share is another customer Google has to pay exorbitant fees to a competitor to access. And Google's strategy is to continue removing differentiating features from Android that  also  help them mitigate the threat of antitrust? Surely the marginal revenue from the inconsequential number of sideloading users isn't attractive enough to justify that kind of strategic blunder. > Matthew Forsyth, Director of Product Management, Google Play Developer Experience & Chief Product Explainer, said the system isn\u2019t a sideloading restriction, but an \u201cAccountability Layer.\u201d And... What about accountability for hosting distributing spyware, malware loaded apps from Google Playstore and hundreds of copy cat, misleading apps? Why can't they pose a question when the phone is setup? - Yes, I want to sideload - No I dont want If the user says NO then to later enable it to allow sideload Yes, the user needs to factory reset phone. Done. When this whole thing got announced, I purchased a new Pixel 9 and flashed it with GrapheneOS. I am hoping that in about 6-8 years (when I realistically need to update) the landscape might be a bit better. Or who knows, maybe I'll just continue using GrapheneOS. So far I have not had a single issues with it. Apps the "}
{"anchor": "The highest quality codebase. > I like Rust's result-handling system, I don't think it works very well if you try to bring it to the entire ecosystem that already is standardized on error throwing. I disagree, it's very useful even in languages that have exception throwing conventions. It's good enough for the return type for Promise.allSettled api. The problem is when I don't have the result type I end up approximating it anyway through other ways. For a quick project I'd stick with exceptions but depending on my codebase I usually use the Go style ok, err tuple (it's usually clunkier in ts though) or a rust style result type ok err enum. Yeah. I noticed Claud suffers when it reaches context overload - its too opinionated, so it shortens its own context with decisions I would not ever make, yet I see it telling itself that the shortcuts are a good idea because the project is complex...then it gets into a loop where it second guesses its own decisions and forgets the context and then continues to spiral uncontrollably into deeper and deeper failures - often missing the obvious glitch and instead looking into imaginary land for answers - constantly diverting the solution from patching to completely rewriting... I think it suffers from performance anxiety... ---- The only solution I have found is to - rewrite the prompt from scratch, change the context myself, and then clear any \"history or memories\" and then try again. I have even gone so far as to open nested folders in separate windows to \"lock in\" scope better. As soon as I see the agent say \"Wait, that doesnt make sense, let me review the code again\" its cooked This is a great example of there being no intelligence under the hood. you gotta be strategic about it. so for example for tests, tell it to use equivalence testing and to prove it, e.g. create a graph of permutations of arguments and their equivalences from the underlying code, and then use such thing to generate the tests. telling it to do better without", "positive": "Douglas Adams on the English\u2013American cultural divide over \"heroes\". Stephen Fry made the same remarks in a Q&A session some years ago:  https://www.youtube.com/watch?v=8k2AbqTBxao  As a Brit I can't agree more with both, I find American humour so hard to relate to but I guess it's just a culture thing What a great response by Adams! I think the acceptance, and even the celebration of failure is present among the \u201cmaker\u201d community in the USA to some extent, which has really drawn me to it. I wonder if there\u2019s the same outlook on failure among other creatives, would be interesting to compare the hobby communities opinions between the USA and UK. I call this take pseudo-intellectual indulgence form, so called, academic intelectuais. Lord of the Rings is very much English Literature, and the biggest epic form the 20th century and has none of that. Ditto for Harry Poter (I\u2019m not saying Harry Potter is on the same level of literary grandeur as LOTR, but it\u2019s still an important epic series for newer generations). You can always find examples for one side or the other of the argument. But, of course, only \u201csocial\u201d scientists would be tick enough to claim some clear divide here as it suits their argument. Explains why Sir Keir Starmer is so relatable. Although I have very little experience with British humor, I find it interesting to compare British fiction I read as a child/teenager that became popular hits in the US (Harry Potter, Alex Rider). From this article's perspective, those protagonists are the epitome of American heroes (autonomy, mastery, purpose). No wonder they garnered such acclaim in the US. Curious if these stories are the exception rather than the rule in British YA fiction? Is the comparison unfair, since these stories were not written with the comedic genre in mind? I feel like the divide is very evident of each countries version of the show \"The Office\". Probably a common trope at this point, but not even the dialogue, already the aesthetic tells you a ", "negative": "Hands-On Introduction to Unikernels. I've found the idea of unikernels interesting for several years now, is there a tl;dr on why they don't seem to have taken off, like at all? Or is it all happening behind some doors I don't have access to? This is really well written, thanks for sharing. I didn't understand the point of using Unikraft though, if you can boot linux in much less than 150ms, with a far less exotic environment the missing piece of unikernel is debuggability & observability - it need to be easy to replicate on dev machine & easy to debug\n- it needs to integrate well with current obs stack. easy to debug in production. without clear debuggability & observability, i would never put it into production I would like to follow the tutorial but it mentions a playground. Am I missing something as I cannot find a link or instructions for the playground. So, if I understand correctly, a \"unikernel\" is what we used to call an \"executive\" except it is intended to be run as a guest on a virtual machine provided by a full-fledged traditional kernel/userspace OS instead of on bare metal. The article does reintroduce some concepts that were commonplace when I was first learning computers and it gives them some new names. I like that good ideas can still be useful after years of not being the latest fad, and it's great that someone can get new credit for an old idea with just a little bit of marketing spin. I think that part of it is that relatively few people use bare-metal servers these days, and nested virtualisation isn't universally supported. I also found this technical critique [0] compelling, but I have no idea if any of it is accurate or not. [0]:  https://www.tritondatacenter.com/blog/unikernels-are-unfit-f...  They kind of did, that is basically how serverless works. Managed runtimes on top of hypervisors. Security, it isn't only memory footprint. Which architecture can boot it in 150ms ?! Hey! Co-founder of Unikraft here. Unikraft aims to offer a Linux-com"}
{"anchor": "Is OpenAI Dead Yet?. Tracking the demise of OpenAI through the news cycle No, they are not dead.  However, they face incredible competition in a brutally commoditized product space. As a retail investor mostly invested into broad ETFs (All World), is there any way I can get short exposure to OpenAI? Being short Oracle/Nvidia/Microsoft? Relevant, I would definitely be sleeping uneasy if I was at \u201cOpen\u201dAI. Some insist that Chinese models are a few generations behind, how many probably depends more on patriotism rather than fact. Those people typically also insist that Chinese models are just distillations and often neglect to see how many of these companies contribute to the theory of designing efficient and capable models.\nIt is somehow thought that they will always trail US models. Well. i would say look at recent history. China worked up the ladder of manufacturing from simple, bad stuff to highly complex things - exactly what westerners then claimed they\u2019d never be able to.\nThen as that was conquered, westerners comforted themselves by insisting that China could copy, but trail-blazing would always still be our thing. Well, Baidu and Alibaba face scaling issues few western companies do and BYD seems to match Tesla or VW just fine. I am unsure why anyone would think US models are destined to remain in the lead forever. At \u201cbest\u201d, I see a fragmented world where each major region (yes also Europe) will eventually have their own models - exactly because no one wants to give any competitive power a chokehold over their society. But beyond that, models will largely be so good that this \u201cgeneration\u201d/universal superiority idea becomes completely obsolete. Is OpenAI profitable yet? Will it be in time to recoop capex. It will be the first application of the 'curse of Open company' rule: any for-profit entity that has the name Open in it is destined to go bankrupt. Keep in mind that the \"news cycle\" isn't of much use in this field. For 2025, almost all \"mainstream\" media was", "positive": "Resistance training load does not determine hypertrophy. tldr appears to be that if you work to fatigue it doesn't matter if you fatigue out with high weights vs low weights I know it's practically de rigeur to jump into the comments and immediately complain about methodology for any study that makes it to the front page, and I want to emphasize I don't distrust their findings, but I would like to see an equivalent study go out longer than 10 weeks. When I've been taking weightlifting seriously I feel like I don't even start to notice hypertrophy until 8-10 weeks. I feel like 6 months is the actual period where results would matter, to me, but I assume \"subject compliance\" is pretty difficult to get for such a timeframe, if you're really watching dietary intake and ensuring subjects go to failure (which, to its credit, this study did). I thought it was already well understood/researched that it's not the weights that matter, but effectively taking your sets to muscular failure. While one might think \"I can do 50 reps with low weights\" there is practical aspects to this - you don't wand to spend hours at the gym, and doing heavy weights at 5-7 reps is sufficient as long as you are close or at muscular failure. If I read this correctly the gist is that it does not matter if you use heavy weights with few reps (common body builder wisdom) or lighter weights with more reps. As long as you always exercise to\ncomplete muscle fatigue you'll\nget the maximum for your genetics (which itself varies a lot). The group that did lower reps with higher weight, had the better one rep max at the end of the study, but they didn\u2019t measure if the higher rep group had greater endurance. Which seems a bit odd, considering their conclusion is both groups grew the same amount of muscle which fine but if the muscle is adapted for something different in each group, you would want to capture that. > Twenty healthy young male participants completed thrice-weekly resistance exercise sessions for", "negative": "Tesla unsupervised Robotaxis are nowhere to be found. I don't think actual unsupervised robotaxis exist, given the reports that they're just having the supervisor follow in a chase car[1]. [1]  https://futurism.com/advanced-transport/car-following-tesla-...  This should not be surprising to anyone who pays any attention to Elon Musk's  \u0336l\u0336i\u0336e\u0336s\u0336 , er... \"predictions\" And yet TSLA sits comfortably at ~$450. If someone knowledgeable can explain this to me, I'd be very grateful. Maintaining a meme stock is hard, really hard.  You do have to hand it to the bloke that he is working hard on this. Back in the day, the term \"snake oil salesman\" was used and it is as fresh today as it always was. There\u2019s no consequences to Musk not delivering and simply making up bullshit. I just saw a LinkedIn post from someone totally unrelated to Musk, or Tesla fawning about how amazing the Tesla Optimus robots are, how they are going to operate in space and how he would prefer one to give him surgery over a doctor. 100s of positive interactions followed Humans seem to need some fiction to believe to get them through their day. So as long as people don\u2019t demand that reality is the driver of their future they will continue to live in whatever fantasy world that makes them the main character There are only around 50[0] unique vehicles operating in Austin (not all operating at the same time) and initially only about 3 are operating \"with no safety monitor in the car.\" Based on social media posts it seems they all have chaser vehicles. [0]  https://robotaxitracker.com  JerryRigEverything randomly started dissing Tesla's FSD system two days before he posts a sponsored video for Ford's self-driving feature. It's probably a good thing they are doing this ultra-conservative rollout of robotaxi. No amount of failed promises, missed deadlines or just plain lies is going to dampen the stock, it\u2019s just the way it is with this. Staying away is the best one can do. HN is so fucked at this point. For th"}
{"anchor": "Advanced Python Features. TFA's use-case for for/else does not convince me:       for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    else:\n        primary_server = backup_server\n    deploy_application(primary_server)\n  \nAs it is shorter to do this:       primary_server = backup_server\n    for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    deploy_application(primary_server)   The way the language is evolving, it seems likely to me that people in the applications camp (ML, simple web-dev, etc.) will soon need a \"simple Python\" fork or at least an agreed-upon subset of the language that doesn't have most of these complications (f-strings are a major success, though). Here is another one, list and expression comprehensions shared with ML languages (not that AI one), apparently many aren't aware of them. The itertools package. I would argue that most of these features (basically everything except metaclasses) are not advanced features. These are simple, but for some reason less well known or less used features. Metaclasses are however quite complex (or at least lead to complex behavior) and I mostly avoid them for this reason. And 'Proxy Properties' are not really a feature at all. Just a specific usage of dunder methods. This is all fun and games unless you have to debug someone elses code and they use a new feature that you didnt know about.\nSpeaking for myself, I would be glad if there were a python_light version of the interpreter that has a simple syntax only like the early 3.x versions. just my 2 ct If context managers are considered advanced I despair at the code you're writing. Nice! I would add assert_never to the pattern matching section for exhaustiveness checks:  https://typing.python.org/en/latest/guides/unreachable.html#...  This is a nice list of \"things you might not know\" that is worth skimming to add to your too", "positive": "Sumo \u2013 Simulation of Urban Mobility. I've been wanting to build a city builder using urban planning libraries like this Imaging the simulation being running headless, decoupled  from the GUI client This looks really polished. I've always found crowd and traffic simulation fascinating. The Projects page is worth looking at too. Since it's almost on-topic, anyone know if/how these tools emulate sustained irrational behavior? Example: For over a decade, the freeway on-ramp nearest my work had two main ways of getting to it from downtown.  One of them involved a stop-sign crossing a road that had the right-of-way (i.e. a two-way stop).  The other had timed traffic signals.  Every evening around 5pm,  the traffic would backup from the stop-sign for multiple blocks.  Meanwhile the route with lights was completely smooth. Eventually the stop-sign was replaced with a signal, but I marveled at how many people persisted in making their daily commute much worse than it needed to be. This is fascinating. Even supports simulating multiple modes of transportation (ped, bicycle, car\u2026). I\u2019ll have to give this a test run later. How much do the various \"Maps\" apps change things? I have a longer commute, and when the freeway is clogged, Maps will direct me to an exit where I weave around town and country. There's usually a convoy of cars with me, but the freeway also seems to stay clogged. Any plans to deploy to the web? I ride rental scooters almost 10k minutes per year and would really like to get my hands on my own ride data to plug it into something like this (or simpler) to find the optimal routes for my regular trips. Google Maps (or others) works good to find a resonable route, but I can do better on my own. One-way streets where bikes are allowed to go do opposite way is sometimes missing, short desire paths connecting bike ways, crossings where it's safe to do an (illegal) right-on-red etc. Tried a GDPR data claim from Voi but got nothing back :( But I hope the data is someho", "negative": "Pebble Round 2. I just placed my pre-order.  I never bought the original Pebble Round because it didn't look that good in my opinion, but this one looks great!  I like that there is no huge bezel anymore, and that the battery life is now an estimated 2 weeks instead of 3 days.  It looks more classy and less like a smartwatch. Proud of this one! Feel free to ask any questions you might have. (Pebble founder) I had pre-ordered a Time 2, but I switched to the Round 2 because it's cheaper and I don't really care about the features it is missing (heart rate monitor and speaker) or the shape of the face. It's awesome that they let you switch without losing your place in line, very customer-focused of them. Damn that's a nice looking watch! Really feels like they got to build what they wanted to 10 years ago but the tech wasn't there. Can't wait to build some sleek round watch faces once I get mine (unless there's an emulator already?) It sure looks nice but I'm keeping my Time 2 order as it's got a much better battery life. Still, I'm sure this will appeal to many people. I'm also going for Time 2 because heartrate monitor. Round 2 looks so nice, gratz on design! That Mario watchface is so fun on it. I still consider the original Pebble Time Round to be the best smartwatch ever made, even 10 years on. Until now. This is everything I ever wanted in a watch. I can't wait to get mine! I may have to spend some time doing remakes of my favorite watch faces for the new screen resolution.  > No more bezel  Maybe I'm looking at the wrong image, but I see a silver bezel going all around the watch screen. I thought \"no bezel\" on a screen means the screen goes all the way to the edges of the device. Still want one tho. May the build quality and customer support be better this time around vs. last time. For a while I\u2019ve wanted a smartwatch that\u2019s not too smart, and is more focused on looks\u2026 I think this might be the watch I finally keep Anybody know how much the price goes up, typica"}
{"anchor": "\u03c00.5: A VLA with open-world generalization. This is amazing! As someone working with industrial robots, normally under strict environmental constraints and control, witnessing such real-world robotics progress truly excites me about the future! By the way, they\u2019ve open-sourced their \u03c00 model (code and model weights). \nMore information can be found here:  https://github.com/Physical-Intelligence/openpi  Is the robot platform they're using something they've developed themselves? The paper doesn't seem to mention any details outside of sensors and actuators. These variable-length arrays are getting quite advanced I'm genuinely asking (not trying to be snarky)... Why are these robots so slow? Is it a throughput constraint given too much data from the environment sensors? Is it processing the data? I'm curious about where the bottleneck is. I'm just a layman, but I can't see this design scaling. It's way too slow and \"hard\" for fine motor tasks like cleaning up a kitchen or being anywhere around humans, really. I think the future is in \"softer\" type of robots that can sense whether their robot fingers are pushing a cabinet door (or if it's facing resistance) and adjust accordingly. A quick google search shows this example (animated render) which is closer to what I imagine the ultimate solution will be:  https://compliance-robotics.com/compliance-industry/  Human flesh is way too squishy for us to allow hard tools to interface with it, unless the human is in control. The difference between a blunt weapon and the robot from TFA is that the latter is very slow and on wheels. Amazing! On a fun note, I believe if a human kid were cleaning up the spill and threw the sponge into the sink like that, the kid would be in trouble. XD Does the general laws of demos apply here? Than any automation shown is the extent of capabilities not the start? Finally, machines doing the work we  dont  want to do Most of it is open source. Their VLAs are based upon Gemma models + vision encoders", "positive": "Waymo granted permit to begin testing in New York City. I saw one of these on Chambers Street just yesterday afternoon, but it must have been in manual mode, of course. It's fascinating seeing all the comments elsewhere anytime Waymo starts testing in another city along the lines of, \"ah, but how will they handle X, Y, and Z here?? Checkmate, robots!\" despite having already launched service in several other cities. Granted, NYC is the biggest city in the US, so maybe that sort of reaction is more reasonable there than when people in Dallas or Boston do it. Very cool. I wonder what scale it has to hit for this to become a profitable line item for Google and what their revenue targets are for it. Man I love Waymo everytime I'm in SF. Truly feel like I'm living in the future when I sit in one I'm cautiously optimistic about this self-driving thing. Waymo at least seems to have figured out a lot of it. Would it be way better to make walkable neighborhoods, mixed-use developments, and reliable and frequent public transit? Yes. Yes it would. But, in lieu of that, self-driving has a lot of advantages in the long run, even if the technology isn't 100% perfect right now. It's insane that they need permits for 8 cars that have humans driving them in 2025, when they're already fully automated in SF. > We\u2019re a tech-friendly administration Clearly not. Is this the first time Waymo is doing winter / snow testing at scale? I think some of the Pittsburgh-based self-driving firms may have tried this, but unaware how far they got. I\u2019m curious if autonomous cars will become targets for aggressive drivers. Like a driver isn\u2019t going to be as scared cutting off a Waymo or tailgating one because the AI isn\u2019t gonna get road rage or honk like hell. In some places I could see the Waymo\u2019s getting severely bullied if that\u2019s the case. The game-theoretic aspect of this is interesting to me. A lawful robot will never make progress in Manhattan because the people will just walk across its path con", "negative": "A macOS app that blurs your screen when you slouch. I think the idea is wonderful, but a not-audited application that uses things like the camera is a \u201cno go\u201d for me. Get it notorized and ask for some money! I will gladly pay it (and I hope others will do it as well). Awesome concept: ergonomics and/or posture monitoring is a market opportunity for heavy users.  Once launched, Posturr runs in the background and displays a brief \"Claude Mode Active\" notification.  I haven\u2019t checked the code yet, but what does the \u201cClaude Mode\u201d mean? Is it a poor naming choice? It implies that the local app is somehow connected to Claude (?) Why use a proprietary stack for building this when there is a far more capable open ecosystem available at your fingertips?  https://huggingface.co/models?other=human-pose-estimation   https://huggingface.co/models?other=3d-human-mesh-recovery  Great, now I'll get sick eyes too * laughs histerically How can you tell if a short person is slouching? Or a tall person? Does anyone ever reach a high level of productivity with correct posture? I can't. I would love this but for detecting when I'm not wearing my glasses! I'm not sure how you can use a laptop with good posture. An external monitor at the right height seems like a necessity. I'm also optimistic about monitors in the form of glasses- even less effort needed to set yourself up for perfect posture. But the sweet spot problem is still very much a thing from what I've seen- can't wait until it's normal for them to have eye tracking, foveated rendering and streaming, and be wireless. Staying in upright posture for too long is also not good for you. Anyone want to vibe code this to work on linux or M$ Install a pull up bar in your room. It will fix your back better than anything else. You can measure my productivity by how slouched I am. Sitting up straight at my desk, chair locked, perfect posture? I\u2019m doing nothing, maybe looking through System Preferences to change the system highlight color. "}
{"anchor": "'The old order is not coming back,' Carney says in speech at Davos. Yup, the middle powers have to organize and work together to avoid being chum.  The economic power is there, and they can shift from purchasing US weaponry (thus paying US workers) into purchasing middle-power weaponry (thus paying middle-power workers).  Car/truck plants can be repurposed, and if Ukraine's lesson is valid then smaller, portable weaponry is now the preferred solution.  Cheaper, and the middle powers don't have huge investments in tanks and ships. The Theucydides quote Carney leads with, of course, recently rolled off the tongue of the white house deputy chief of staff, Stephen Miller.  The days of might making right are, apparently, back. Just in case anyone thought the genie could be stuffed back into the bottle once Trump is gone, Carney goes on to state that the rules-based world order we've been living under since WWII is somewhat of a sham.  The rules have not been applied equally.  Some nations, the powerful ones, have been given much more latitude to do what they want. Middle nations have gone along with this to avoid trouble. The reward for avoiding trouble for so long is...  big  trouble (e.g. invasion threats for an ally of a big power and economic terrorism applied to its allies).  So, why pretend the old system works to avoid trouble if the trouble lands on your doorstep anyways? The answer seems obvious.  Middle powers of the old rules-based order need to band together and put bigger powers in their place.  It's not impossible.  Just very, very difficult.  France and Germany may be sticking up for Greenland, but where's Hungary (another EU member)?  For this to work, you need  everyone . Also, looking ahead, how would you prevent such an alliance of smaller powers, were it successful, from behaving like a bigger power? Trump is currently showing off AI photos where he's meeting with world leaders in front of a map where both Greenland and Canada are a part of the U.S.[1", "positive": "Ask HN: How can we solve the loneliness epidemic?. I'm also in this group, so I have a few theories as to what causes it and how to fix it. For one thing, I was severely traumatized as a kid, which delayed a lot of my social skills. I'm catching up but not all the way there yet. When my social battery is full, I can do pretty well, but if I'm even a little down, it's basically impossible to act normally. I also had it hammered into me as a kid that nobody wants me around, nobody could ever love me, I'm a failure, a burden, a creep, a weirdo, and nothing but a bothersome nuisance that nobody would ever want to spend 30 seconds alone with. I'm trying to reject these thoughts, but it's difficult when you have nobody to talk to. It's like pulling yourself up by your bootstraps. I wonder how many people have the same issue. I've made a few friends in person, but I rarely get to see them. Well I've started doing public surveys in my nearby big city, and documenting the results. I just hold out a posterboard that says \"how alone do you feel\"[1] or \"have you ever been in love\" etc, and hold out a marker, and people come up and take the survey. At first I did this out of sheer loneliness and boredom. But I have done it for enough months that some people have come up to me and told me that I've helped them, or that they look forward to my signs. I'm trying to reach those people who feel the way I feel have no way of connecting with anyone, or at least feel that they don't. Do you have any new ideas of how to achieve this? [1]  https://chicagosignguy.com/blog/how-alone-do-you-feel.html  Why do they feel they can't join any local groups?  Fix that. Intentionally choose community and the effort it takes to build and cultivate it [1] [2] [3] [4] [5]. People are work, but you cannot live without community [6]. [1]  https://web.archive.org/web/20250212233145/https://www.hhs.g...  [1]  https://thepeoplescommunity.substack.com/  [3]  https://www.tiktok.com/@amandalitman/video/7592750", "negative": "Bugs Apple loves. This is obvious AI-generated web design style. This is another level of petty, I love it  Maybe it will inspire them to hire more engineers and we can kill two birds with one stone. Site looks to be by  https://github.com/polymath-ventures/  This is spot on! I have experienced all these issues at one point or other and my spotlight search is frozen as I type this on a Mac mini. Had the pleasure of making an Apple account to join our company's developer team. I filled out the form on the website 7 times: Edge on Windows, Edge on macOS, Safari on macOS, using 2 different phone numbers. No matter what, Apple just refused to send the verification code to me.\nIt only worked after I remember Apple is a dick to the web platform, then I managed to create one from the popup in the App Store. I actually keep the Gmail app installed on my iPhone specifically for searching my mail. It's infuriating. Yeah, these are funny. There's a strange logic (that I understand is not  just  at Apple) where if you ship a known bug, it becomes harder next release to fix it\u2026 because we already shipped the bug once (twice, etc.). Apple engineers care though. If they were allowed to (given time, priority), they would love to knock out some of their oldest and most annoying bugs. And I understand that from time to time a bug-fix-only OS release is planned\u2026 but things always come up. New hardware, \"AI\"\u2026 who knows. Maybe someday we'll get another Snow Leopard (bug-fix-only OS release). I'm still waiting for apple to fix ringtones on siri generated alarms Solid list. I\u2019d like to add the following: - All: Contact syncing with Office 365 results in stored birthdays getting moved forward by one day. \n- macOS: Bluetooth audio stuttering when going in and out of full screen view in a given app such as PowerPoint. \n- macOS: Unlock using Apple Watch will randomly stop working\n- macOS: Safari suddenly going out to lunch and taking 30+ seconds to load a page (fixed by force quitting the ent"}
{"anchor": "Early-Retirement Update. Life is a like a box of chocolates. You never know what you're gonna get. I \"retired\" for a month, first two weeks I was so bored just exercising and consuming content, then got kind of depressed, and wound up making plans to start a new business. Then I took a new role at a startup and went back to the grind. I came to the conclusion I just can't stop working. If it isn't for a company then I'd probably start a non-profit and build a new thing that is more idealistic. My dad was the same way, after 6 months of being retired, smoking weed, and playing videogames he got a job at a golf course - free golf and shoots the shit with a lot of people. Work gives purpose in life, IMO. TLDR: life can change in ways that mess with your expectations, therefore better be prepared. Also: FI on bare basics may seem like a great idea until (1) your spouse leaves you or (2) you get ill or (3) both. So sorry for seeing reality catch up with you, and nice to see you admit it. I need to work again for about 10 years and then be FI. A very useful read because the author is brutally honest. For me, while financially independent, I must have something that gets me out of bed every day - give me too much open-ended time and I wither. I suspect that a lot of introspection is valuable in order to successfully navigate the  withdrawal from typical society. Short Version: - LeanFIRE in 2015 (~30Kish USD annual spend) - first couple years were great, in the third year cracks started to show - they and their partner's goals were no longer aligned and they ended up splitting - OP was diagnosed with a genetic condition that changed their expenses and lifestyle - Ended up getting a job again at the end, but while \"retired\" their net worth actually increased by 20% I always get a kick out of people who think they\u2019re financially independent with such a small stash. Outside some regions with relatively extreme living conditions (e.g. undeveloped and underdeveloped countries),", "positive": "Kimi Released Kimi K2.5, Open-Source Visual SOTA-Agentic Model. > For complex tasks, Kimi K2.5 can self-direct an agent swarm with up to 100 sub-agents, executing parallel workflows across up to 1,500 tool calls. > K2.5 Agent Swarm improves performance on complex tasks through parallel, specialized execution [..] leads to an 80% reduction in end-to-end runtime Not just RL on tool calling, but RL on agent orchestration, neat! Those are some impressive benchmark results. I wonder how well it does in real life. Maybe we can get away with something cheaper than Claude for coding. Kimi was already one of the best writing models. Excited to try this one out Huggingface Link:  https://huggingface.co/moonshotai/Kimi-K2.5  1T parameters, 32b active parameters. License: MIT with the following modification:  Our only modification part is that, if the Software (or any derivative works\nthereof) is used for any of your commercial products or services that have\nmore than 100 million monthly active users, or more than 20 million US dollars\n(or equivalent in other currencies) in monthly revenue, you shall prominently\ndisplay \"Kimi K2.5\" on the user interface of such product or service.  Actually open source, or yet another public model, which is the equivalent of a binary? URL is down so cannot tell. I've read several people say that Kimi K2 has a better \"emotional intelligence\" than other models. I'll be interested to see whether K2.5 continues or even improves on that. There are so many models, is there any website with list of all of them and comparison of performance on different tasks? Curious what would be the most minimal reasonable hardware one would need to deploy this locally? As your local vision nut, their claims about \"SOTA\" vision are absolutely BS in my tests. Sure it's SOTA at standard vision benchmarks. But on tasks that require proper image understanding, see for example BabyVision[0] it appears very much lacking compared to Gemini 3 Pro. [0]  https://arxiv.org/htm", "negative": "Show HN: Rails UI. Is this another Tailwind wrapper? Yes, it is. ugh this looks dated even by 2016 standards when will developers learn UI actually matters bootstrap was a mistake, and lowered the bar for everyone i don't get these types of products anymore. i think they're useful in their own way, but i can literally create styles with claude/gemini in a heartbeat and not have to pay some insane fee. I think you missed a trick not naming it Railwind UI. I used this about a year ago when I went through a short Rails phase. I was a bit surprised not to see more Rails-specific UI libraries considering how batteries-included the rest of the framework is, and at the time I didn't really 'get' tailwind. I'm not in a Rails phase anymore, but nice work on the library! maybe I'm just dumb but a lot of these elements don't seem to work? the \"...\" buttons don't open any flyout, the dropdown doesn't open up... otherwise looks cool though I wish I could use this \u2013 unfortunately UI frameworks are a political problem at every company I've worked at. The designers feel undermined or threatened by it, and product owners want to dictate design. Despite the massive productivity benefits of a UI framework, I've never been able to convince stakeholders to actually adopt one. If you\u2019re showing off a UI framework, I shouldn\u2019t be accidentally scrolling left and right on the page on mobile / my iPhone. Couldn\u2019t be bothered to scroll down the page to look at components while accidentally activating horizontal scrolling. Broken in Safari on iphone. For example: - table background moves left when table is scrolled horizontally - actions in table and dropdown do nothing on tap - text on buttons is selectable (really?) im always surprised that Rails is still relevant i havent used it since 2006 opting for php and django i might give it another shot, any reason you like this more than django or other frameworks I have hardware acceleration disabled in Firefox and my 5800X spins up trying to rend"}
{"anchor": "Warren Buffett steps down as Berkshire Hathaway CEO after six decades. I wonder how this will affect BRK-B, given that so many investors (or at least the \"retail \" ones) buy its shares with the assumption that they provide exposure to Buffett's strategy. In any case, I hope Warren can experience not working at all in the few years he likely has left after being alive for over 1/3 of his country's existence! I will never undertand this people that live all their life working, when they clearly have the chance to retire much sooner. I will retire right away if I had 10 millions. Maybe 50 millions if I was younger than 40. I can't help but wonder if Buffett's dividend focused strategy will continue to be a successful approach in the future.  Buffett is no slouch, but seems to have fallen behind relatively unsophisticated investors like Musk and Zuckerburg as time went on and they focused on valuation more than returns/profit. Here is a fantastic farewell message that Seth Klarman wrote on  Buffett's retirement for The Atlantic, How Buffett did it?  https://web.archive.org/web/20250000000000*/https://www.thea...  Driving 7 minutes to work and stopping at a drive-thru to pick up McDonalds breakfast every day. The man is a true American hero. I read somewhere that Bershire Hathaway had sort of finished it's mission.  40 years ago there were lots of large companies who were very 'inefficient' and BH would come along, invest a lot,  and start demanding changes. Company performance would improve and BH would make big $$$$. Now there are few of these and it is hard to do. I don't know enough to know whether it is right or wrong. but I think that is what I read. I just asked ChatGPT what Warren Buffett's strategy is, and it said buying undervalued companies and holding for a long time. Is that true? I thought it's not a good idea to buy loser companies. A very good (IMO) explanation of Warren Buffets success here:  https://m.youtube.com/watch?v=9owVrLm7mls  Greeks had their My", "positive": "Lazy-brush \u2013 smooth drawing with mouse or finger. This is so satisfying. These types of experiments are something I really love about the open-web, and part of what bums me out about how most social networks tend to throttle links. The dragging behavior is so intuitive \u2013 it's funny because usually if you create this kind of resistance in a UI it can be confusing, but in this context it works so well. I think this is the same as the brush stabilizer in Krita. Check out drawmote from the same author, where this library is being used.  https://drawmote.app/  Wow, this is amazing! I see you've been building this on GitHub for 7 years - that's truly impressive dedication. What keeps you motivated to stick with this product for so long? An alternative that works very well for signatures too is Perfect Freehand (by the guy behind TLDRaw)  https://perfect-freehand-example.vercel.app/  OT, but I love the author's retro homepage. Just seeing that made me smile this morning This is really cool and reminded me of drawing as a kid. Thank you! I believe a logic similar to this was used to enact the \"Gestures\" system in Black and White 1. Breaking down the mouse-movements into vectors following a guide-point. ( https://blackandwhite.fandom.com/wiki/Gesture ). This is very nice, not just for finger/mouse painting! I tried it on my Cintiq and it was actually a lot better for me than brush stabilization usually is - I think the logic is the same as seen in e.g. Krita, but the visualization of the cursor and where the paint will appear is very helpful. Usually painting software doesn't have such an indicator of where the actual stroke will be placed and when it will move. Great project, I had some fun playing around :) Neat! This is known as a stabilizer in the digital art community. Really cool! I wonder what Duo Lingo are using behind the scenes. I've been busy with the Chinese and Japanese courses, and one thing I quickly noticed is how there are two different 'grades' of practisin", "negative": "AI code and software craft. Enterprise software tends to particularly bad because it's being sold to managers who won't use it themselves. Consumer software tends to be more user-friendly (or it won't sell), but popular software isn't always what you want. When writing software for yourself, there is a bias towards implementing just the features you want and never mind the rest. Sometimes the result can be pretty sloppy, but it works. However, code health is a choice. You just need to know what to ask for. A coding agent can be used as a power washer to tidy up a project. This won't result in great art, but like raking leaves or cleaning your steps or plowing a driveway, it can be satisfying. Just as you wouldn't use a power washer to clean a painting, maybe there's some code that's too delicate to use a coding agent on? But for a project that has good tests and isn't that delicate, which I believe includes most web apps, nobody's going to want to pay for you to do it by hand anymore. It would be like paying someone to clear the snow in a parking lot with a shovel rather than hiring someone with a plow. This argument is basically just the 1800s Luddite vs Industrialist argument recast for a new age. Group A thinks quality is about human agency, and that machines are being used to bypass the apprenticeship system and produce inferior goods. Group B thinks efficiency is the highest priority, and craft is just vanity. Of course as we know we went a third way, and human roles just shifted. I think one promising shift direction is humans do NOT like to talk to bots, especially not for anything important. It's biological. We evolved to learn from and interact with other humans, preferably the same group over a long time, so we really get to understand/mirror/like/support each other. > People have said that software engineering at large tech companies resembles \"plumbing\" > AI code [..] may also free up a space for engineers seeking to restore a genuine sense of craft and "}
{"anchor": "Day Fifteen of Iran's Nationwide Protests: Sharp Rise in Human Casualties. nationwide protests in the US  https://www.msn.com/en-us/news/us/protests-against-ice-plann...   https://www.nytimes.com/2026/01/10/us/ice-shooting-protests-...   https://www.cnn.com/2026/01/11/us/ice-protests-shootings-min...  Israel is openly committed [0] to seeing regime change in Iran; they were mowing down civilian and military leadership just last year. The US got involved. There is the history of western involvement [1] in overthrowing Iranian governments. With that background I'm more worried about what the US's role here will be rather than what may or may not be taking place in Iran. My understanding is that the simulations around an invasion of the country were even more disastrous than the excursions in Afghanistan and Iraq and we really could use some signals of competence out of the US right now. We seem to be dangerously far into a WWI or WWII style environment internationally and we're already past the threshold of nuclear risk that sane actors would accept. [0]  https://en.wikipedia.org/wiki/Iran%E2%80%93Israel_war  [1]  https://en.wikipedia.org/wiki/Iran#Mosaddegh_and_the_Shah's_...  The US and AU both have told citizens to get out of Iran in the last 24-48 hours. If they are unable to they should shelter in place. I think it's about to kick off. US:  https://ir.usembassy.gov/iran-security-alert-land-border-cro...  AU:  https://www.smartraveller.gov.au/destinations/middle-east/ir...  Notice how hard people work to burry reports of atrocities that are committed by the Islamic Republic. Things are not what they appear. In both cases the protests won't achieve much because half the population supports the government, and in both cases the half that supports the government is better armed. It's so strange. There is a real place on Earth which is much more brutal and oppressive than the wildest fantasy that Margaret Atwood could come up with. A place that rapes virgins before ex", "positive": "Mathematical Foundations of Reinforcement Learning. The best lectures on Reinforcement Learning and related topics are by Dimitris Bertsekas:  https://web.mit.edu/dimitrib/www/home.html  Another great resource on RL is Mykel Kochenderfer's suite of textbooks: \n https://algorithmsbook.com/  Also worth mentioning Murphy's WIP textbook[0] focused entirely on RL, which is an outgrowth of his excellent ML textbooks. [0]:  https://arxiv.org/abs/2412.05265  Awesome resource, in case someone is interested I implemented most of suttons book here  https://github.com/ivanbelenky/RL  I don't know how to go from understanding this material to having a job in the field. Just stuck as a SWE for now. Highly recommended .. even the main contents diagram is a great visual overview of RL in general, as is the 30 minute intro YT video. Im expecting to see a lot of hyper growth startups using RL to solve a realworld problem in engineering / logistics / medicine LLMs currently attract all the hype for good reasons, but Im surprised VCs dont seem to be looking at RL companies specifically. 6-lecture series on the Foundations of Deep RL by Pieter Abbeel is also very recommended. gives very good overview and intuition\n https://youtu.be/2GwBez0D20A  And if you want to understand the theory of Skinner's Verbal Behavior check out  https://bfskinner.org/wp-content/uploads/2020/11/978_0_99645...  During the openai gym era of RL, one of the great selling pts was that RL was very approachable for a new comer as the gym environments were small and tractable that a hobbyist could learn a little bit of RL, try it out on cartpole and see how it'd perform. Are there similarly tractable RL tasks/learning environments with LLMs? From the outside, my impression is that you need some insane GPU access to even start to mess around with these models. Is there something one can do on a normal MacBook air for instance in this LLM x RL domain? > This book, however, requires the reader to have some knowledge of ", "negative": "Show HN: Bonsplit \u2013 Tabs and splits for native macOS apps. I don't know why, but I thought this was going to sandbox style tab/split support for the all the baselines macos apps. This is very cool, but somehow got myself disappointed that something I didn't know I wanted doesn't exist. This is very interesting, I haven\u2019t touched macOS development for quite a while but it\u2019s good to know that libraries are still being written for both AppKit and SwiftUI on macOS. I do feel that this library would benefit from an explanation on why this was needed. AFAIR AppKit already provides a native tabbing API where you can \u201cjust\u201d (that \u201cjust\u201d is doing a lot of heavy lifting) implement a few delegate methods and you get tabbing behavior for free, especially on document-based apps. (Sorry, I do not remember the specifics, it might have been a tad more difficult) I\u2019m not updated on the SwiftUI equivalent, but I would imagine that a similar API would exist much alike API for multiple windows or multiple documents. I think everyone would benefit from a \u201cwhy\u201d explanation (which I definitely think would exist, since I\u2019ve used too many AppKit APIs in pain), and also some screenshots for a demo app (so that we can expect how it would look and how much the look and feel would deviate from the native counterparts). The title really should include \"library\"... This is excessively beautiful, both the website and the library's UI. But I have to ask: what's the rationale on dedicating such an elaborate and gorgeous website for just a library? Are you hoping to get hired for web design? Are you seeking fame and repute? Do you merely do it for the love of the game? Why, for the love of all that's good, pray tell  why  put all this effort into  mere documentation ? - library - functionality/effect looks like Sublime Text origami mode This is quite beautiful.  I had a somewhat similar use case last year and built something that wasn't this polished. The only feature that seems to be missing for wha"}
{"anchor": "The first commercial space station, Haven-1, now undergoing assembly for launch. The career path of going from developing eDonkey to launching a space station will never cease to amaze me. Anyone want to take bets on what continent it crashes on? In this context, how does the business side of things look like with such large projects? What happens if their revenue optimization software calculates that US can actually pay much more for much less?  With the liberalization of infrastructure things like that happen, in Europe trains are infamous for getting shittier with privatizations and nationalization becomes political topic. IIRC Texas grid had become crazy expensive in a cold winters some years ago, people dying or paying crazy prices. Then there's the case of the investors going political, at some point Elon Musk threatened halting projects essential for the US government when he had a public fight with Trump. What happens if China leaps ahead by not seeking profits of all this? Is there a mechanism to force US private space companies not to seek profits or cap profits? Sure SLS costs vs SpaceX are infamous but private ownership doesn't necessarily guarantee success considering that Boeing failed miserably both with NASA contracts and fully commercial operations. Brave new world I guess, if it doesn't pan out there are the Chinese and the Russians. I thought Mir was briefly a commercial space station? Is this going to be like that submarine that guy built to bring people to the Titanic? Does not appear to be any bets on Polymarket of Kalshi.  HN does not have a feature for this.  Closest is poll. [1]  Out of curiosity why do you think it will de-orbit?  Or is the bet that SpaceX will not be able to get it up? [1] -  https://news.ycombinator.com/newpoll  According to Wikipedia, it has a planned life span of just three years, so we won't have to wait much to find out. It won't be a proper crash, though. You have a point. I would further add that private ownership o", "positive": "Advanced Python Features. TFA's use-case for for/else does not convince me:       for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    else:\n        primary_server = backup_server\n    deploy_application(primary_server)\n  \nAs it is shorter to do this:       primary_server = backup_server\n    for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    deploy_application(primary_server)   The way the language is evolving, it seems likely to me that people in the applications camp (ML, simple web-dev, etc.) will soon need a \"simple Python\" fork or at least an agreed-upon subset of the language that doesn't have most of these complications (f-strings are a major success, though). Here is another one, list and expression comprehensions shared with ML languages (not that AI one), apparently many aren't aware of them. The itertools package. I would argue that most of these features (basically everything except metaclasses) are not advanced features. These are simple, but for some reason less well known or less used features. Metaclasses are however quite complex (or at least lead to complex behavior) and I mostly avoid them for this reason. And 'Proxy Properties' are not really a feature at all. Just a specific usage of dunder methods. This is all fun and games unless you have to debug someone elses code and they use a new feature that you didnt know about.\nSpeaking for myself, I would be glad if there were a python_light version of the interpreter that has a simple syntax only like the early 3.x versions. just my 2 ct If context managers are considered advanced I despair at the code you're writing. Nice! I would add assert_never to the pattern matching section for exhaustiveness checks:  https://typing.python.org/en/latest/guides/unreachable.html#...  This is a nice list of \"things you might not know\" that is worth skimming to add to your too", "negative": "Improving the usability of C libraries in Swift. This was a great read. I've used the naive approach shown in the first example before and its always felt a bit clunky, but I wasnt aware of most of these language features. I'm definitely going to try this out next time I have to write C bindings This is pretty great stuff, I knew about the raw interop features but had no idea what API Notes offered. Quite cool. I can't help but feel that Swift will ultimately be the \"slow and steady wins the race\" safe language of the future. Swift steadily working \"first\" on both tooling and cohabitability with existing ecosystems is a huge boon for adoption. It understands what an ABI is! If I were doing a greenfield cross platform application I think Swift would be the first thing I reach for now. The qualms I have with Swift are mostly some of the more recent complex language features that can make Swift code much harder to understand and read, as well as the brainpower required to use Swift concurrency. That and some performance concerns, though many of those seem like they may be solvable with optimizations in LLVM. I believe Apple is investing in C/C++ interop so much because they realize they'll likely keep their existing low-level system+embedded code rather than port it to Swift.  That's good for people who want to do the same.  A swift API layer can reduce the need for C/C++ developers. But in my experience, there are sharp cliffs whenever you get off the happy path shown in the demos.  That's not a problem with code where you can design workarounds, but when you wrap highly complex (if not arcane) C API, you often can't change or omit portions of the API causing problems.  So while usability may be better, apinotes might not be enough to complete the work. If you're wrapping something, I would recommend cataloging and then verifying all the language features you need to make it work before getting too far in. It's good to have options. I guess this is similar effort as S"}
{"anchor": "Scientists identify brain waves that define the limits of 'you'. Original Paper: Parietal alpha frequency shapes own-body perception by modulating the temporal integration of bodily signals,   https://www.nature.com/articles/s41467-025-67657-w   https://news.ki.se/how-brain-waves-shape-our-sense-of-self  FTA: > With a third group of participants, they used a non-invasive technique called transcranial alternating current stimulation to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt. I know this is largely orthogonal to the article, and I know what \u201cnon-invasive\u201d means and why it\u2019s used in this sentence, but it made me chuckle - \u201cthis technique that changed the subject\u2019s brain waves sufficient to literally impact their sense of self - but don\u2019t worry! It\u2019s non-invasive!\u201d The manipulation part is what fascinates me. They didn't just correlate alpha wave frequency with ownership perception. They used transcranial stimulation to artificially speed up or slow down the waves, and the subjective experience changed accordingly. That's a pretty direct causal link between a measurable brain state and something as fundamental as \"where does my body end?\" Wow, that\u2019s really interesting! It seems like alpha waves are the \u2018tick rate\u2019 of this system, and some set number of ticks are required to update the body model? This has me thinking of Pluribus The idea of \"ownership of a body\" made me think about a quote I heard a long time ago, while talking amongst musicians while waiting to get up and perform. It felt like some secret knowledge that I gained privilege to, while somewhat inebriated and it hasn't left me since. > I _have_ a body, I _am_ a soul. Maybe what they're identifying is the first half of that statement, how we interpret the former, through the presence of the latter. So, how far does the human electric field extend outside the body? May be only picovolts or in that range... But c", "positive": "Anti-aging injection regrows knee cartilage and prevents arthritis. As I've gotten older, my knees have been the main signal letting me know. I tore my meniscus years ago. This is exciting news for people like me. Cartilage is really the final frontier of health. If it wasn\u2019t for joints going bad, people could stay very active and fit pretty much all their life, with consistent exercise and healthy weight.  > Osteoarthritis occurs when a joint is stressed by aging, injury or obesity. The chondrocytes begin to release pro-inflammatory molecules and to break down collagen, which is the primary structural protein of cartilage. When collagen is lost, the cartilage thins and softens; the accompanying inflammation causes the joint swelling and pain that are hallmarks of the disease.  Collagen synthesis in the human body can be aided by  hydrolyzed collagen, Vitamin C, zinc and copper. oh, what a time to be a mouse! They don't say what is injected, calling it only a \"gerozyme inhibitor\". Original article appears to be:  https://www.science.org/doi/10.1126/science.adx6649  Inhibition of 15-hydroxy prostaglandin dehydrogenase promotes cartilage regeneration Mamta Singla  https://orcid.org/0000-0002-6408-1167 , Yu Xin Wang  https://orcid.org/0000-0001-8440-9388 , Elena Monti  https://orcid.org/0000-0002-3767-0855 , Yudhishtar Bedi  https://orcid.org/0000-0002-1213-4116 , [...] , and Nidhi Bhutani  https://orcid.org/0000-0002-7494-5870  FTFA:  \"Both systemic and local inhibition of 15-PGDH with a small molecule inhibitor (PGDHi) led to regeneration of articular cartilage and reduction in OA-associated pain.\"  \"PGDHi\" is a name for both the process \"15-hydroxyprostaglandin dehydrogenase inhibition\" and any inhibitor. This link(a PDF file) shows PGDHi's are powerful stuff:  https://www.biorxiv.org/content/biorxiv/early/2025/04/17/202...  \"PGDHi\"  could  be prostaglandin-E2 (dinoprostone):  https://en.wikipedia.org/wiki/Prostaglandin_E2  which was used in:  https://med.stanford.e", "negative": "House of Lords Votes to Ban UK Children from Using Internet VPNs. Earlier:  https://news.ycombinator.com/item?id=46763548  Does that mean that VPN providers now need identification before you can open an account? Very shallow, naive approach to child safety.  This is like banning children from riding scooters on a highway.  They're just going to use a bike instead.  Danger still exists. VPNs are not the only way around this, so if you want to ban the \"method of access\" you need to be much more broad, and get the parents involved. > may make provision for the provider of a relevant VPN service to apply to any person seeking to access its service in or from the UK age assurance which is highly effective at correctly determining whether or not that person is a child \"The law we made is like super duper good!!\" > Children may also turn to VPNs, which would then undermine the child safety gains of the Online Safety Act \"The law we made is easily circumvented :(\" I foresee a lot of VPN companies starting to offer \"secure proxy\" services or something like that. \"It's not a VPN, it's a secure proxy!\" After enforcing age verification to prevent children from viewing those pesky Gaza genocide videos that Israel did not want them to see, they gotta ensure that those brats wont be able to get around it and still see the videos. Its amazing how this censorship was brought on rapidly and precisely after Netanyahu demanded it at the start of last year. No surprise as half of Starmer government was funded by zionists. [dupe] Discussion:  https://news.ycombinator.com/item?id=46763548  UK nanny state makes it an nonviable place to live. It's pervasive from the moment you step off the plane at Heathrow and see the inane safety stickers covering every surface \"WARNING: DOOR\" \"WARNING: WATER FROM HOT TAP IS HOT\" as well as the CCTV cameras. ah the country of brexit has more \"clever ideas\" something I find myself saying often lately watching BBC News every morning How about Cloudflare Wa"}
{"anchor": "European word translator: an interactive map. Love that the numbers in Catalan are represented as numerals, not as words. EDIT: playing with it, it's a bit sad that large numbers do not work at all (in any language); and that not all common forms of a word are shown.  For example, I tried to see how \"ninety six\" is said in french in France, Belgium and Switzerland, but it does not work. Ukrainian and russian words often use the same letters but are pronounced very differently due to distinct phonetics. On the other hand, some Polish and Czech words sound the same or very similar to Ukrainian but look quite different because of their different alphabets. Therefore, phonetic transcription would be a valuable improvement. You immediately see the difference (or similarly) of languages when using words that are very old, such as \"iron\", or \"stone\", which are words that have existed from the origins of that language. I can mostly speak for German. It seems to mix them all into one general language. But there are a lot of local differences between north and south of Germany, Switzerland and Austria. And it\u2019s not just dialect, but really different words that might not be understood everywhere. \nIf you look at the english part it has at least three different words. Similar in Spanish. There are examples from five language families shown here: Indo-European, Basque, Uralic, Turkic, and Afro-Asiatic. The words for bridge split neatly into language subfamilies.   The only exception appears to be Welsh. You are coloring it by 4 colors like map but you should color countries phonetically (speex, levenshtein or something similar) Wiktionary has dialect maps for common Chinese vocabulary that showcases the differences in terminology across various regions of Chinese, rather than their similarities. Example: sleep ->  https://en.wiktionary.org/wiki/Template:zh-dial-map/%E7%9D%A...  , hide-and-seek ->  https://en.wiktionary.org/wiki/Template:zh-dial-map/%E6%8D%8...  p.s. I'm saying t", "positive": "Is liberal democracy in terminal decline?. The pendulum is swinging back slightly, but I wouldn\u2019t pronounce it dead just yet. We are seeing a decline of American hegemony, accelerated by this current regime. And the ascendancy of a non-democratic superpower. However, the largest chunk of GDP and growth still sits firmly in democratic countries and very consequential American elections are happening this year, and in 2028. The real question is, will Europe find its spine? Terminal velocity achieved ... The only question is whether it'll hit the ground before the next US election. Any emergency 'chute's available? I can\u2019t access the article\u2026 but honestly, I\u2019ve been asking myself the same question for the past ten years.\nThe best answer I\u2019ve found is: not yet \u2014 but the current backlash and drift toward authoritarianism in many democracies is actually the sign that something real is shifting.\nIn a way, the situation looks weirdly similar to Europe before WWII. Democracies were starting to integrate some of the socialist ideas that had emerged in the 19th century, and the dominant forces of capitalism pushed back hard. They let fascists rise, sometimes even supported them. That led to a war, millions of deaths, and then a massive change of mindset: after WWII, every European country implemented strong social protection and regulation.\nToday, the shift is less about social security and more about cultural transformation \u2014 the end of patriarchy, and with it the decline of imperialism and Western dominance. Those foundations started being seriously questioned in the 60s. The dominant forces are resisting because, deep down, they\u2019ve already lost \u2014 there\u2019s no going back. But as always, they can still cause immense damage on the way out. And yes, if they refuse to let go peacefully, it could lead to conflict, and a lot of casualties.\nBut after, democracy will make a come back. I may be too optimist. Unfortunately I suspect yes - for practical reasons not directly linked to dem", "negative": "We Do Not Support Opt-Out Forms (2025). That site doesn't seem to support pages loading either. edit: I feel their pain - I've spent the past week fighting AI scrapers on multiple sites hitting routes that somehow bypass Cloudflare's cache. Thousands of requests per minute, often to URLs that have  never  even existed. Baidu and OpenAI, I'm looking at you. Archive link:  https://web.archive.org/web/20251009081648/https://conscious...  | Since emails are sent from the individual\u2019s email account, they are already verified. This is not how email works, though.  https://archive.ph/QCMjJ  if it helps The irony of a site about AI opt-outs getting hammered by AI scrapers is almost too on the nose. trollbridge's point about scrapers using residential IPs and targeting authentication endpoints matches what we've seen. The scrapers have gotten sophisticated. They're not just crawling, they're probing. The economics are broken. Running a small site used to cost almost nothing. Now you need to either pay for CDN/protection or spend time playing whack-a-mole with bad actors. ronsor hosting a front-page HN project on 32MB RAM is impressive and also highlights how much bloat we've normalized. The scraper problem is real, but so is the software efficiency problem. It\u2019s wild when I read a professional looking website like this and Conscious Digital misspells their own org name as \u201cConsious Digital\u201d in the first paragraph. I\u2019m glad they\u2019re fighting against email spam but it just raises all sorts of red flags in my mind, or at least it used to. Funny enough, these days it indicates the article was written by a human. I had a dev join my team and made a few typos and it gave me a chuckle, as it\u2019s a whole class of mistake I hadn\u2019t seen in awhile. The \"required login\" pattern is particularly a problem. I seem to have namesakes around the US and UK that use my email address as their own when signing up for various services (mobile phone services, Shopify, Uber, various banks and investmen"}
{"anchor": "28M Hacker News comments as vector embedding search dataset. Oh to have had a delete account/comments option. I've been embedding all HN comments since 2023 from BigQuery and hosting at  https://hn.fiodorov.es  Source is at  https://github.com/afiodorov/hn-search  Am I misunderstanding what a parquet file is, or are all of the HN posts along with the embedding metadata a total of 55GB? I know it's unrelated but does anyone knows a good paper comparing vector searches vs \"normal\" full text search? Sometimes I ask myself of the squeeze worth the juice Scratches off one of my todos, I think it would be useful to add a right-click menu option to HN content, like \"similar sentences\", which displays a list of links to them. I wonder if it would tell me that this suggestion has been made before. Finetune LLM to post_score -> high quality slop generator I don't remember licensing my HN comments for 3rd party processing. Maybe I\u2019m reading this wrong, but commercial use of comments is prohibited by the HN Privacy and data Policy. So is creating derivative works (so technically a vector representation) I don't know how to feel about this. Is the only purpose of the comments here is to train some commercial model? I have a feeling that, this might affect my involvement here going forward. Don't use all-MiniLM-L6-v2 for new vector embeddings datasets. Yes, it's the open-weights embedding model used in all the tutorials and it  was  the most pragmatic model to use in sentence-transformers when vector stores were in their infancy, but it's old and does not implement the newest advances in architectures and data training pipelines, and it has a low context length of 512 when embedding models can do 2k+ with even more efficient tokenizers. For open-weights, I would recommend EmbeddingGemma ( https://huggingface.co/google/embeddinggemma-300m ) instead which has incredible benchmarks and a 2k context window: although it's larger/slower to encode, the payoff is worth it. For a compromi", "positive": "Russia Once Offered U.S. Control of Venezuela for Free Rein in Ukraine. I have suspected Putin is being played by Trump's \"peace deal\" on Ukraine - using it the US has already got Putin to back off from aiding and supporting Iran, which has hurt it. And now Russia (and China) has lost some influence in Venezuela too. Meanwhile Russia still has a war raging on (which it will of course win but not anytime soon) as American western allies in Europe continue to obstruct the peace process. Just hope there isn't any political missteps from either side that accidentally triggers World War 3. I wonder when Russia will stop pretending that EU does not exist and will start talking to it like to equal and start negotiating with EU, not with remote USA which are trying to retreat from conflict. Maybe Russia should recognize that EU has its own sphere of influence and Russia should respect it - so when is Russia going to demilitarize Kaliningrad, because having a military base so deep in EU is unacceptable? Archive / paywall:  < https://archive.is/72W5J > > I have suspected Putin is being played by Trump That's a nice counter-narrative to pretty much  everything  I've seen -  one of my favourite examples [0]: > She tells the story of Putin \u201ctrolling\u201d Mr Trump by saying that he was such a great supporter of Israel that \u201cmaybe they should just name the country after you\u201d \u2013 to which the US president, oblivious to the sarcasm, said, \u201cOh no, that would be a bit too much.\u201d [0]  https://www.independent.co.uk/voices/editorials/donald-trump...  > Meanwhile Russia still has a war raging on (which it will of course win but not anytime soon) Russian goal is to control whole Ukraine like they control Belarus. This is not achievable. Not with the current state of Russian logistics or state of Russian economy. One of the reasons why is Russia struggling is absurdly arrogant denial of reality. Why they are negotiating with USA, which has more and more marginal role in the whole conflict and not", "negative": "Windows 11 January Update Breaks Notepad. SpywareOS couldn\u2019t even be bothered to allow text editor functionality, wasn\u2019t in the KPIs of user activity monitoring and monetizing Partway through this article, Winbuzzer asks me to \"Install Winbuzzer Prompt Station.\" I don't think this is a legitimate source. It looks like most of the article is a rehash of this Windows Central article from a day earlier:  https://www.windowscentral.com/microsoft/windows-11/windows-...  I love what Microsoft is doing. Keep it up! I just had to boot Windows yesterday for some quick work (adding Windows support to my browser I've built from scratch) and since I barely have any tools on the Windows installation, I used notepad.exe to edit stuff. And of course, it has a very obvious bug, any file shows \"$filname.$ext.txt\" in the title bar, regardless if it's a .txt or not. So opening config.toml shows as config.toml.txt. Seemingly Microsoft got rid of the entire QA department, judging by the amount of bugs. Seriously, does the developers who implement these changes not open up the application they're editing even once  before they push this out to customers? What the fuck is going on? This is heartbreaking in a way to see what's become of it. Windows was my childhood playground. I can't not feel some kind of attachment and a desire to save it. Notepad has been broken since they added telemetry to it a decade ago. I'm not joking. If you break telemetry globally, notepad will crash, along with calc and paint. Recently I've installed Windows XP on an 20 years old machine to run an old software synth on it. Man, was XP a slick and neat system from today's perspective! Back in the days it felt sluggish, but now in comparison, I think it was one of the best Windowses ever. > Microsoft forum user Kave discovered the problem on Tuesday when trying to access work-related information stored in Notepad. \u201cGetting the error code 0x803f8001 for most my microsoft apps including my Notepad app which has imp"}
{"anchor": "Giving Up a $250k Salary to Retire Early Is Hard. This is the OP:  https://www.vetmed.auburn.edu/faculty/erik-hofmeister/  This (+ many other signals) are giving me the \"market top\" vibe. Sad to see people still parroting the 4% rule when you can get \"risk free\" US Treasuries, today, paying more than that. Not to speak of the numerous, still conservative, investments paying far higher. This isn't the 2010s era with ultra low fixed income yields. If you intend to retire early, please educate yourself on the state of the market Someone in the article's comments asked about working part time and the author responded \"veterinary academia doesn\u2019t really understand <1.0 FTE.\" Is the same true of FAANG-ish companies? Can you (officially) work part time in a big tech job? College professor in Alabama makes $250k? Not bad. I guess being a doctor helps. I think the vibe may instead be: growing income disparity. The WSJ reported over the weekend that over 50% of all consumer spending now comes from the top 10% of household incomes. So while some folks are flush to retire early, many are not. I think 4% is still a fine thing to plan around. I don't think it's wise to plan as if today's treasury rates will last your entire retirement. The 4% rule requires increasing that amount at the rate of inflation throughout retirement. 30 years in the case of the original studies. Even with an inflation rate of 2.5%, the required withdrawal will more than double after 30 years. The 4.625% you can lock into a 30-year Treasury would not be enough. What does the 4% rule have to do with yields of treasuries? This is a 30-year time horizon that changes spending purely based on inflation figures. Yields in the market do not matter. You can and many do, although this tends to be reserved for more senior engineers.  Obviously a pay cut is involved. Strictly the answer is yes with the more truthful answer being it depends on your manager. The easiest way is probably being in a country that requires", "positive": "Size of Life. Cool, but a little more thought on the content rather than the presentation would improve it.  For example starting with an arbitrary segment of DNA double helix and saying how \"tall\" this arbitrary segment is, is just silly. Instead, it should show how _wide_ it is.  And for extra coolness, keep it in frame, coiling longer and longer as you go, and eventually have the same strand, which has been with us all the time, as a specific example (e.g. human chromosome 7 or some such) by _length_ double clicking makes the animation jitter. ive had to deal with matching derivatives of smooth slopes in rendering as well. the animation seems to be finite time (and so variable velocity) and mashing click is just updating the final point without matching the current derivative. I don't understand how the location of a 377 foot tall tree could be kept secret. Wouldn't that type of thing be visible in satellite imagery at the very least? It seems to be like some of the scales slightly off? If you are looking at the ladybird (ladybug) with the amoeba to the left, the amoeba isn't an order of the magnitude smaller - it would actually be visible by the human eye (bigger than a grain of sand)?  Indeed, the amoeba seems the same size as the ladybird's foot? Similarly, this makes the bumblebee appear smaller than a human finger (the in the adjacent picture),  which isn't the case? > A highly social, relatively hairless bipedal ape that was once a nomadic hunter-gatherer, but has adapted to create websites I like it, but the switch from metric to inches is confusing, and I think introduces a bug - there's no way a sea snail is 5-6 neurons high. Wonderful. The music, illustrations, and sliding sound effect reminded me of the game Braid. This was awesome! Also, I couldn't stop my child brain from anticipating \"your mom\" at the end. I always click when I see neal.fun. I like the stuff un the sute but the number if partners and affiliates in the consent window is very off putt", "negative": "Postmortem: Our first VLEO satellite mission (with imagery and flight data). Founder/CEO of Albedo here. We published a detailed write-up of our first VLEO satellite mission (Clarity-1) \u2014 including imagery, what worked, what broke, and learnings we're taking forward. Happy to answer questions.  https://albedo.com/post/clarity-1-what-worked-and-where-we-g...  So the root cause was the lubricant in the gyros couldn\u2019t stand up to operating temperatures. I\u2019d be interested to read a postmortem of the systems engineering approach there. Terrific writeup.  Massive congrats to the whole team for all that creative thinking in flight and all that was achieved.  (Add a note about updating FPGA's in space!)  Looking forward to team Bedo unlocking VLEO for everyone. With image resolution this high, ground accuracy becomes an important factor as many people that prefer higher resolutions also want geospatially accurate images. Did you have any findings or results on this? What an impressive project. > Next up was maneuvering from our LEO drop-off altitude down to VLEO, where it would be safe to eject the telescope contamination cover Why would it be unsafe to do this earlier? > We had been tracking intermittent memory issues in our TT&C radio throughout the mission, working around them as they appeared. Our best theory is that one of these issues escalated in a way that corrupted onboard memory and is preventing reboots. We've tried several recovery approaches. So far, none have worked, and the likelihood of recovery looks low at this point. Seems to be a pretty big problem as well, I wonder what their ideas are to diagnose the root cause here. It all sounds a bit overoptimistic, but that may just be my interpretation. Congrats on having a successful mission, it seems quite successful for a first try, and you clearly have some talented people on your team. But I\u2019m going to give you my unsolicited opinion on the writing style. The writing style sounds more like a tech bro describi"}
{"anchor": "Shipmap.org. This is pretty amazing to watch! I did just watch a dot go through the Great Lakes, to Chicago, then take to the air and make a bee line straight to the Gulf of Mexico. Probably some weird artifact but made me chuckle. Like interactive documentary, loved it! It appears to cover only the year 2012. I'm getting \"Please use a modern browser to view this content\", but I'm running the latest version of Chrome. Says WebGL is not supported..? Even at 1 hour ticks am I assuming that these are moving far too quickly? Used this when I moved internationally. Cool to watch your stuff moving around the world! This is weirdly beautiful, like the maps of undersea internet cables that frequently come up here as well. You can clearly see: 1) oil flowing out of the Persian Gulf from the Middle East to China 2) ships waiting to get through the Panama and Suez Canals 3) why people talk about \u201cshipping lanes\u201d. There are some obvious tracks everyone follows, because it\u2019s the cheapest way from A to B (e.g. cape of good hope to straight of malacca). 4) why Singapore got to be such an important global hub. 5) why the houthis and the Somali pirates could cause such havoc 6) nobody goes in the southern ocean! (Why would they? Unless you\u2019re bringing supplies to Antarctica\u2026) a few ships drop down to go around Cape Horn but that\u2019s it. and so much more. I wish it included more up-to-date data\u2026 The scale of it is mind boggling. Quite a few routes on the heat map that appear to not be following great circle lines (i.e. \"straight\" lines from china to the west coast) - is that from seasonal currents allowing for more efficient transit with the tradeoff of taking a longer route? A lot of people have called out some interesting things - one thing that I notice is how the cold water ports shut down in the winter (in the northern hemisphere). It's one of those things I've always heard and known about, but to see it visually conceptualized (and the implications on economy and national interes", "positive": "In New York City, congestion pricing leads to marked drop in pollution. > Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death. Minor nitpick, but tailpipes aren't the primary source of emissions. The study is about PM2.5[0]. which will chiefly be tires and brake pads. Modern gasoline engines are relatively clean, outside of CO2, though diesel engines spit out a bunch of bad stuff. [0]  https://www.nature.com/articles/s44407-025-00037-2  See also  https://news.ycombinator.com/item?id=46213504  There was a study published about how much air pollution dropped in NYC during the COVID lockdown. PM2.5 was found to have dropped 36%. However with more robust analysis, this drop was discovered to not be statistically significant. I would caution anyone reading this who is tempted by confirmation bias. Source:  https://pmc.ncbi.nlm.nih.gov/articles/PMC7314691/  To head off the almost inevitable recapitulation of yesterday's parade of misinformed complaints by teenage libertarians, please actually read the paper before commenting. The paper shows there was no significant reduction in entries to the congestion charge zone by cars, vans, and light trucks. And you can confirm this conclusion is consistent with their source data using their github repo. The reduction in pollution is coming from the significant decline in heavy truck traffic. Truckers were using lower manhattan as a cut-through route to other places and they are now doing that less, exactly as congestion pricing planners long argued. Not surprising. The real question is how do we measure the opportunity cost of these measures? Is it a net gain? You could, at the extreme, ban all motor vehicles but the opportunity cost would outweigh the benefits. This article confirms my existing bias/belief that user pays and auction[0] based systems improve governmental programs and finite supp", "negative": "Claude Code's new hidden feature: Swarms.  https://xcancel.com/NicerInPerson/status/2014989679796347375  In his second post he included a link to GitHub:  https://github.com/mikekelly/claude-sneakpeek  Isn't this pretty much what Ruv has been building for like two years?  https://github.com/ruvnet/claude-flow  Listen team lead and the whole team, make this button red. It feels like Auto-GPT, BabyAGI, and the like were simply ahead of their time Answering the question how to sell more tokens per customer while maintaining ~~mediocre~~ breakthrough results. Claude Code in the desktop app seems to do this? It's crazy to watch. It sets of these huge swarms of worker readers under master task headings, that go off and explore the code base and compile huge reports and todo lists, then another system behind the scenes seems to be compiling everything to large master schemas/plans. I create helper files and then have a devops chat, a front end chat, an architecture chat and a security chat, and once each it done it's work it automatically writes to a log and the others pick up the log (it seems to have a system reminder process build in that can push updates from other chats into other chats. It's really wild to watch it work, and it's very intuitive and fun to use. I've not tried CLI claude code only claude code in the desktop app, but desktop app sftp to a droplet with ssh for it to use the terminal is a very very interesting experience, it can seem to just go for hours building, fixing, checking it's own work, loading it's work in the browser, doing more work etc all on it's own - it's how I built this:  https://news.ycombinator.com/item?id=46724896  in 3 days. I'm already burning through enough tokens and producing more code than can be maintained - with just one claude worker. Feel like I need to move into the other direction, more personal hands-on \"management\". A guy who worked at docker on docker swarm now works at Anthropic so makes sense How is this different fro"}
{"anchor": "Google engineer says Claude Code built in one hour what her team spent a year on. in that one year, more was accomplished than writing a body of code. people learned, explored concepts, and discovered lateral associations, developed collective actions, consolidated future solidarity. claude just output some code. Says more about Google's engineers than Claude Code IMO. \"I'm not joking and this isn't funny. We have been trying to build distributed agent orchestrators at Google since last year. There are various options, not everyone is aligned... I gave Claude Code a description of the problem, it generated what we built last year in an hour.\"  https://x.com/rakyll/status/2007239758158975130  This just shows Google engineering is a corporate shithole. It's time to sell Google stocks. I\u2019m deeply skeptical of these claims. Every time someone says \u201cAI built in an hour what took us a year,\u201d what they really mean is that humans spent a year doing the hard thinking and the AI merely regurgitated it at silicon speed. Which is, of course, completely different from productivity. Also, if it truly took your team a year, that probably says more about your process than about AI. But not in a way that threatens my worldview. In a different way. A safer way. Let\u2019s be clear: writing the code is the easy part. The real work is the meetings, the alignment, the architectural debates, the Jira grooming, the moral struggle of choosing snake_case vs camelCase. Claude didn\u2019t do any of that. Therefore it didn\u2019t actually do anything. I, personally, have spent years cultivating intuition, judgment, and taste. These are things that cannot be automated, except apparently by a probabilistic text model that keeps outperforming me in domains I insist are \u201csubtle.\u201d Sure, the output works. Sure, it passes tests. Sure, it replaces months of effort. But it doesn\u2019t understand what it\u2019s doing. Unlike me, who definitely understands everything I copy from Stack Overflow. Also, I tried AI last year and it", "positive": "Canada. So you say the highs aren\u2019t as high and the lows certainly aren\u2019t as low as in the US.  Given that few really experience the highs, I think the Canadian choice is correct.  It\u2019s a stereotype, but the people do tend to be friendlier and the pace is slower.  But I\u2019ve found that the quality of work is a function of one\u2019s inner makeup not the external environment.  We\u2019ll see what the next 5-10 years looks like in N America. I was not born in Canada, but I chose to immigrate here and it's one of the top 5 best choices I've ever made. I have access to so much that in other places would be wildly expensive. My life is richer due to the diversity of the people I am surrounded by, if I bought every book I borrowed from the library last year it would have cost $3000 or more, and even after moving away from a large city I have access to public transit good enough to cover most of my needs. It's actually really wild to think I spent a couple of years working in Boston more than a decade ago, and I used my zipcar subscription way more often than I've ever had to use a communauto in fake london (a city no one would mistake for having good urban planning). The Canada the author refers to is gone. Canada is far from perfect but there is no other country in the world I would ever consider leaving it behind for. I grew up in Canada and live in the US now with kids. The US is not one country. It's two that are radically different. There's wealthy America. The top 5% to 10% that have healthcare, have their own safety nets, don't need to worry about money, their kids go to select schools that they can buy into (mostly by buying into the right neighborhoods), an amazing pension plan, etc. My kids go to a fancy library with reading time, puppets and classical music. All the things I love about Canada and more. That country is amazing and the quality of life is unparalleled unless you're obscenely wealthy. The bottom 80 to 90% percent of Americans live a life that is far inferior t", "negative": "Porsche sold more electrified cars in Europe in 2025 than pure gas-powered cars. While the headline is interesting. I think the table at the end of the article is more so. - Worldwide sales -10% YoY - China sales -26% YoY And when you cross compare Porsche saying they sold more EV powertrains than their gas equivalents against China's new found foothold as the market leader in consumer electric cars (BYD, NIO, Xiaomi, etc...) Then I think you see an early indication not just of electric car dominance, but of the (very potential) rise of China as the premier automotive super power.  https://youtu.be/ghY78-yWr7o  The key part is electrified and not pure electric. I think Porsche is really in trouble here. I\u2019m not anti-EV but the electric Macan and Cayenne look awful. They are under equipped technologically relative to their Chinese peers (heck basically anything). Porsche sort of sold its soul for this tech-forward design but it doesn\u2019t deliver any meaningful benefits, these cars don\u2019t even have level 2+ highway cruise control. In the meantime I get a bunch of crap screens and lose all the glorious physical buttons and I don\u2019t even have a fun engine rumble to make up for it? So, the cars are ugly and uncool (I grant a matter of taste), aren\u2019t selling in their target market (China) won\u2019t sell meaningfully in their backup market (US) and they\u2019re behind GM, Tesla and BYD in all regards on quality of life stuff. Not a recipe for endurance. a lot of these luxury brands have been eating off china the past few years but now they've lost their luster since china makes cars better than most luxury brands and china has a moat in EVs so what's left is either the US or emerging markets Is this shocking? Obviously including PHEVs helps a bit, but even outside of this it is exactly what should be happening. Their biggest sellers are SUVs, and at these price points, the EVs can be substantially than their ICE counterparts. For 2026, they probably won't even need the PHEVs to get the"}
{"anchor": "My Life in Weeks. Powerful in how it puts it all into perspective is all I could say. I\u2019ve been using MarkWhen for a similar life timeline  https://markwhen.com  This was epic, thanks for sharing! This is a terrifying reminder of the shortness of our lives. I remember reading a blog by Tim Urban, where he showed that you could put all the weeks in your life on a single piece of A4 paper, and it didn\u2019t feel nice. Thanks for sharing, this format really puts things into perspective. This is fascinating. Idk if it was a good or bad thing. In college I once looked up some insurance chart of life expectancy probabilities. It puts things in perspective that\u2019s for sure. That was nice to watch. I spent about 25 minutes going through that. But it was horrifying for me. I realized that I wanted to see if the source code is available but then realized that I really don't remember those details. I remember random things for my childhood but I don't remember the date when I started elementary school. I know that I got my first computer when I was in third grade but don't remember the date. I don't even remember the date I started college and I probably wrote the wrong date couple of times during grad school application. While I started recording something less than a diary to record some of these but this was around covid. Thanks OP and HN for this reality check. From this view it's clear how wasteful ontogeny is. All of that physical and psychological development takes too much valuable time and investment. And we haven't even gotten to Gina's retirement years yet. Clearly the future is in using 3D bioprinting to build fully formed adults as if sprung from the brow of Zeus. Skill and memory transfer are a technical problem only as long as we cling to our bias against our artificially intelligent upgrades. Aging is defeated by implanting our old model weights into a new print. So much efficiency is waiting if we dare to free ourselves from convention. Woah, look at how sparse our", "positive": "Live Map of the London Underground. Very cool. Especially as it a real map not a 'network diagram' who is so confusing. > Data -> TfL live tube data > *You will regret using this data. You will regret using this API.* > It serves data from individual arrivals boards, which all spell stations differently > It has a load-balancer that regularly returns data that is older than the data returned in the previous request. Won't someone think of the Ai overlords who will take care of all this for us in the future. A bit of consistency goes a long way. Looks great but I'm watching this while sitting on a tube right now. What I assumed was my train was lagging by quite a bit and then disappeared! It's cool to see how fast the trains go on different lines. But... where's the Elizabeth line? You get the tooltip when you hover over it, but the polyline is missing. One of the best game I ever played is the text based souvenir game shopping game on Windows 3. I can't recall the name of the game now since it's more than 30 years ago, but it's about shopping souvenirs using London Underground Tube. You have a semi realistic time constraints like train schedules, your flight schedules and of course list of souvenirs items to shop. This is totally offline since there is no Internet available at the time but it's very engaging nonetheless. My proposal for the modern version of the game is to use real-time train schedules (with delays, ticket discounts, etc) that are available publicly on the Internet for many metropolitan cities in the world for examples Tokyo, London and Berlin. Imagine you can have a real-world realistic in-app in-game items purchases feature that you personally can buy in the game and delivered to you or anyone you fancy of giving souvenirs except that you only virtually went there. Maybe a slight bug: the overlay doesnt appear to be locked to the map - when I scroll around, the overlay moves. Currently the northern lines' southern terminal is hovering over Kingsto", "negative": "We Do Not Support Opt-Out Forms (2025). That site doesn't seem to support pages loading either. edit: I feel their pain - I've spent the past week fighting AI scrapers on multiple sites hitting routes that somehow bypass Cloudflare's cache. Thousands of requests per minute, often to URLs that have  never  even existed. Baidu and OpenAI, I'm looking at you. Archive link:  https://web.archive.org/web/20251009081648/https://conscious...  | Since emails are sent from the individual\u2019s email account, they are already verified. This is not how email works, though.  https://archive.ph/QCMjJ  if it helps The irony of a site about AI opt-outs getting hammered by AI scrapers is almost too on the nose. trollbridge's point about scrapers using residential IPs and targeting authentication endpoints matches what we've seen. The scrapers have gotten sophisticated. They're not just crawling, they're probing. The economics are broken. Running a small site used to cost almost nothing. Now you need to either pay for CDN/protection or spend time playing whack-a-mole with bad actors. ronsor hosting a front-page HN project on 32MB RAM is impressive and also highlights how much bloat we've normalized. The scraper problem is real, but so is the software efficiency problem. It\u2019s wild when I read a professional looking website like this and Conscious Digital misspells their own org name as \u201cConsious Digital\u201d in the first paragraph. I\u2019m glad they\u2019re fighting against email spam but it just raises all sorts of red flags in my mind, or at least it used to. Funny enough, these days it indicates the article was written by a human. I had a dev join my team and made a few typos and it gave me a chuckle, as it\u2019s a whole class of mistake I hadn\u2019t seen in awhile. The \"required login\" pattern is particularly a problem. I seem to have namesakes around the US and UK that use my email address as their own when signing up for various services (mobile phone services, Shopify, Uber, various banks and investmen"}
{"anchor": "Scientists unlock brain's natural clean-up system for new treatments for stroke. Very interesting, especially in light of the Chinese study\u2019s claiming to have success with a large subset of Alzheimer\u2019s by adding a shunt to the cervical lymphatic nodes, which seems to be exactly what they\u2019re doing here too. For those who don\u2019t want to wait and have someone they love who can benefit from this, simply massaging the lymph nodes in the neck 10 minutes a day also significantly increases flow through these lymph nodes and thereby increases drainage of lymph from the brain. Full article:  https://www.monash.edu/news/articles/scientists-unlock-brain...  Yeah, the body-wide mucous thinning properties of NAC are one of the reasons it has racked up papers showing its efficacy in a truly staggering number of illnesses and conditions. (Including neurodegenerative diseases.) Highly recommend reading the actual literature on its effects in regard to cystic fibrosis, pancreatitis, COPD, neurodegenerative disorders, high blood pressure, ulcers, IBD, liver and kidney problems, OCD... The list goes on at a pretty extreme length, and it sounds too good to be true, but the papers are out there. I love getting my lymph nodes drained. Feels so good afterward. Mainstream science has poo-poohed for years any notion that Oriental medicine practices for facilitating lymph flow have any utility. Nice to hear they're back on the allopathic table. Is this this something that can help with autism symptoms? Hmm, I had a bunch removed due to thyroid cancer. I wonder if that reduced my brains ability to clean itself out. It would be really interesting if we find out that a simple 10 minute daily massage of the lymph nodes in the neck significantly prevents Alzheimer's. Is this something I can do to myself? Is there some kind of video tutorial to see what I really need to do? Makes me wonder if body posture promoting blood flow to the head (yoga or else) can be helpful here too. Can you suggest a revi", "positive": "Moravec's Paradox and the Robot Olympics. Those videos are very impressive. This is real progress on tasks at which robotics have been failing for fifty years. Here are some of the same tasks being attempted as part of the DARPA ARM program in 2012.[1] Compare key-in-lock and door opening with the 2025 videos linked above.\nHuge improvement. We just might be over the hump on manipulation. [1]  https://www.youtube.com/watch?v=jeABMoYJGEU  I genuinely did not expect to see a robot handling clothing like this within the next ten years at least. Insanely impressive I do find it interesting that they state that each task is done with a fine tuned model. I wonder if that\u2019s a limitation of the current data set their foundation model is trained on (which is what I think they\u2019re suggesting in the post) or if it reflects something more fundamental about robotics tasks. It does remind me of a few years ago in LLMs when fine tuning was more prevalent. I don\u2019t follow LLM training methodology closely but my impression was that the bulk of recent improvements have come from better RL post training and inference time reasoning. Obviously they\u2019re pursuing RL and I\u2019m not sure spending more tokens at inference would even help for fine manipulation like this, notwithstanding the latency problems with that. So, maybe the need for fine tuning goes away with a better foundation model like they\u2019re suggesting? I hope this doesn\u2019t point towards more fundamental limitations on robotics learning with the current VLA foundation model architectures Sergey Levine, one of the co-founders, sat for an excellent Dwarkesh podcast episode this year, which I thoroughly recommend.      > The gold-medal task is to hang an inside-out dress shirt, after turning it right-side-in, which we do not believe our current robot can do physically, because the gripper is too wide to fit inside the sleeve\n  \nYou don't need to fit inside the sleeve to turn it inside out... Think about a sock (same principle will apply, ", "negative": "Ultraprocessed foods make up to 70% of the US food supply (2025). Just don't buy those foods. Buy fresh vegetables, tofu, and meat from the edges of the grocery store.   Simple.  Done. This article equates ultraprocessed foods and hyperpalatable foods (foods designed to make people want to eat them more).  While many hyperpalatable foods are classified as ultraprocessed, simply being hyperpalatable does not mean it's ultraprocessed. Worth noting that the Nova food classificationvsysten (which this article references) completely disregards the actual nutritional content of foods. For a good primer on a lot of the misconceptions around UPFs, check out [0]. [0]  https://www.harvardmagazine.com/research/harvard-ultraproces...  Headline is massively misleading. The actual study cited by the article, measures this as 71% of food products offered for sale in the US, by count of unique items, are ultraprocessed. Not that 71% of food products sold by weight or volume or dollar amount are ultraprocessed. This is just observing that if you list all food products for sale in the US, \"pear\" appears on that list once but \"Store Brand salty corn chips\" appears 25 times. (2025) OP More recently:  Ultra-processed foods make up more than 60% of us kids' diets   https://news.ycombinator.com/item?id=44823288   How America got hooked on ultraprocessed foods   https://news.ycombinator.com/item?id=45605921   California passes law to ban ultra-processed foods from school lunches   https://news.ycombinator.com/item?id=45525041  why does the USA not have the concept of buying home made meals from other people? I have never heard of a lunch box service or people buying one It's hard to get much more processed than sugar itself. Out of everything else, that should be one that's easy to remember. Pure white crystals often indicate the presence of a chemical in its most concentrated form. Among other dangers, are the hazard of overdosing more easily, intentionally or not. In this case, it seems "}
{"anchor": "Voronoi map generation in Civilization VII. Related:  https://www.redblobgames.com/x/2022-voronoi-maps-tutorial/  I've been trying to generate my own maps using Voronoi diagrams as well.  I was using Lloyd's algorithm [0] to make strangely shaped regions \"fit\" better, but I like the insight of generating larger regions to define islands, and then smaller regions on top to define terrain. One of the things I like about algorithms like this is the peculiarities created by the algorithm, and trying to remove that seems to take some of the interesting novelty away. - [0]  https://en.m.wikipedia.org/wiki/Lloyd%27s_algorithm  This kind of exploratory/creative programming is bar none the most fun you can have as a software engineer. I love reading write-ups about projects like this because you can practically feel the nerdy joy radiating off the screen. Haven't played any of the new Civ games but find this very interesting. On a related note, I've started a blog on procedural content generation and GenAI content synthesis:  https://gamedev.blog/ . Would love any feedback / suggestions! I intend to cover Voronoi diagrams in the near future + a Python implementation and turning it into a 3D map with Unity This is super interesting! I've dabbled with Perlin noise procedural generation using AlphaEvolve[0] and wonder if it would be interesting to do one with Voronoi map too! [0]:  https://blog.toolkami.com/alphaevolve-toolkami-style/  Raymond Hill (unblock) also made JavaScript voronoi library  https://github.com/gorhill/Javascript-Voronoi  I really wish they just made Civ 5 again, but with these sorts of cool updates. Kinda surprised that it's taken this long. Voronoi for map generation is not a new concept, and it produces excellent results. One of the best webs for gamedev. The a-star/Dijkstra section is legendary. It is quite infectious! I would have never thought to use Voronoi like this, my only use is with data visualizations. Civ4-Beyond the Sword is IMHO the last good", "positive": "AI will make formal verification go mainstream. I'm convinced now that the key to getting useful results out of coding agents (Claude Code, Codex CLI etc) is having good mechanisms in place to help those agents exercise and validate the code they are writing. At the most basic level this means making sure they can run commands to execute the code - easiest with languages like Python, with HTML+JavaScript you need to remind them that Playwright exists and they should use it. The next step up from that is a good automated test suite. Then we get into quality of code/life improvement tools - automatic code formatters, linters, fuzzing tools etc. Debuggers are good too. These tend to be less coding-agent friendly due to them often having directly interactive interfaces, but agents can increasingly use them - and there are other options that are a better fit as well. I'd put formal verification tools like the ones mentioned by Martin on this spectrum too. They're potentially a fantastic unlock for agents - they're effectively just niche programming languages, and models are really good at even niche languages these days. If you're not finding any value in coding agents but you've also not invested in execution and automated testing environment features, that's probably why. Unless you feed a spec to the LLM, and it nitpicks compiled TLA+ output generated by your PlusCal input, gaslights you into saying the code you just ran and pasted the output of is invalid, then generates invalid TLA+ output in response. Which is exactly what happened when I tried coding with Gemini via formal verification. I love HN because HN comments have talked about this a fair bit already. I think on the recent Erdos problem submission. I like the idea that languages even like Rust and Haskell may be more accessible. Learn them of course but LLM can steer you out of getting stuck. If AI is good enough to write formal verification, why wouldn't it be good enough to do QA? Why not just have AI do ", "negative": "Environmentalists worry Google behind bid to control Oregon town's water. At this point, Google could be a drop-in replacement for the corporate villain in any 1980s/1990s action movie. Why on earth do they want water from the national forest when the massive Columbia River is right there!? Is it too expensive to treat the river water? /s At this moment I just assume by default that those \u201cwatchdogs\u201d, \u201cenvironmentalists\u201d, \u201cnonprofits\u201d are mix of nimby-ists and/or thinly  veiled attempts of extracting money (it\u2019s a nice things you got here. It would be a shame if some rare species of a frog would be found here. A small donation for the great cause/good, of course, would help us to work on ensuring that nobody gets in harms way). Stupid question: datacenters need water for cooling right? But they don't boil that water, ie it comes out of the datacenter just a little warmer? If that is the case does it matter to the city? The warmer water can still be used for agriculture or any other common usage. I know google fiber kinda flumped, but if they are already doing their own power generation for data centers they might decide to sell that power to the public too. What is really scary is that I foresee a day where these big tech companies will see it is more profitable to serve utilities to people than web services. Then, after they have a monopoly in most areas, they will enshitify it too. The amount of people here in the comments happily suggesting to let Google use the clean water for their AI datacenters and return dirty water to use in crops is a bit worrying How far we have fallen from the \"Do no evil\" marketing. More people should scrutinize the methodology behind these AI data center water usage reports. One widely cited Berkeley Lab figure includes the water evaporated from reservoirs behind hydroelectric dams. Excluding that factor cuts their water usage estimate by more than half. On AI & water, looks like all US data center usage (not just AI) ranges from 628M "}
{"anchor": "Mitochondria as you've never seen them. Wow! Really shows how mitochondria are actually just bacterial cells living inside us! Mitochondria are so absurdly more complex and interesting than what is mostly taught in schools.\nAwesome video! So each of our cells is a habitat for a network of wiggly energy-producing worms... Madeline L'Engle was right all along I studied an BSc in genetics and none of our lectures or textbooks presented mitochondria any differently from the classic bean shape they introduce in school. This is surely old news to folks who specialise in mitochondria, but it's easy to miss out on these fundamentals even if you've studied in a relevant area at degree level, because there's just so much to know in biology. In fact, it's one of those fields where the more you learn, the more you realise we'll never reach a satisfactory understanding in our lifetime. You could chuck an endless supply of PhD students at every constituent domain for generations and still feel like you've scarcely scratched the surface of the many things there are to question. To think I've spent hours upon hours each week for years and year with the express goal of producing more of these in the muscle cells of my legs, and I call this novel goal \"exercise\". Without this symbiotic relationship in cellular life on other planets, would it prevent complex cellular life? So beautiful and so sad to think about how much more interesting biology is than what we can teach from textbooks. This makes me want to further explore the similarities in form and function of mitochondrial networks and mycelial networks. Really sucks that antibiotics, especially bacteriocidal ones, appear to target mitochondria as if they were bacteria. This mistargetting causes sometimes severe and long-lasting side effects. The Seven Daughters of Eve are alive and well, I see Is the link supposed to go to a slideshow? Does anyone here have a sense of what time frame the video covers? Like, is that real-time and ", "positive": "My trick for getting consistent classification from LLMs. If you already have your categories defined, you might even be able to skip a step and just compare embeddings. I wrote a categorization script that sorts customer-service calls into one of 10 categories.  Wrote descriptions of each category, then translated into embedding. Then created embeddings for the call notes and matched to closest category using cosine_similarity. Arthur\u2019s classifier will only be as accurate as their retrieval. The approach depends on the candidates to be the correct ones for classification to work. Under-discussed superpower of LLMs is open-set labeling, which I sort of consider to be inverse classification. Instead of using a static set of pre-determined labels, you're using the LLM to find the semantic clusters within a corpus of unstructured data. It feels like \"data mining\" in the truest sense. Dunno if this passes the bootstrapping test. This is sensitive to the initial candidate set of labels that the LLM generates. Meaning if you ran this a few times over the same corpus, you\u2019ll probably get different performance depending upon the order of the way you input the data and the classification tag the LLM ultimately decided upon. Here\u2019s an idea that is order invariant: embed first, take samples from clusters, and ask the LLM to label the 5 or so samples you\u2019ve taken. The clusters are serving as soft candidate labels and the LLM turns them into actual interpretable explicit labels. I think a less order biased, more straightforward way would be just to vectorize everything, perform clustering and then label the clusters with the LLM. Nice! So the cache check tries to find if a previously existing text embedding has >0.8 match with the current text. If you get a cache hit here, iiuc, you return that matched' text label right away. But do you also insert a text embedding of the current text in the text embeddings table? Or do you only insert it in case of cache miss? From reading the ", "negative": "High-speed train collision in Spain kills at least 39. Always try to sit in seats where your back is toward the direction of motion. The train in question is a Frecciarossa 1000  https://en.wikipedia.org/wiki/Frecciarossa_1000  The Italians designed it but won't run it at more than 300km/h in Italy citing local infrastructure concerns. I guess that leaves other countries to find the edge cases. I'll be interested to find out how fast it was going during the crash. If you\u2019re interested in this kind of thing, look up plainly difficult on youtube. He has more videos on train crashes than I\u2019ve seen, and I\u2019m embarrassed how many I\u2019ve seen. Here\u2019s one to get you started:  https://youtu.be/VV2rIHEp5AM?si=sSBT9s49PqbLTGbt  There are a lot of safety lessons embedded in these videos, which is why I like them. I also did a double take when I heard \"semaphore\"; its history goes back far longer than the ~century of software engineering.  https://en.wikipedia.org/wiki/Semaphore  For many years the Spanish state-owned company RENFE had a monopoly on Spain's huge high speed rail network. However their high prices, inconvenient schedules and poor customer service were often criticized, and so when, to the annoyance of RENFE and many spanish politicians, additional foreign operators entered the market on the key Madrid - Barcelona route, ridership doubled whilst ticket prices halved. So I would standby for this tragedy to be used for political purposes to try and get foreign operators banned from Spanish tracks, regardless of the facts of the matter. Updated to 39 people now, but probably the number can still go up Terrible and condolences to anybody affected. For a bit of context according to the OECD 2023 Spain had ~1800 on the road during the previous year, so that's about 5/day. There are more deaths on the road in Spain in a couple of weeks than this tragic accident. Either way it's too many deaths obviously but I want to highlight what a freak event this is compared to a more p"}
{"anchor": "Space Elevator. I always enjoy Neal's pages. I found planes at high altitude very interesting, didn't know we could fly that high! It was enjoyable and informative. Learned that sprites can be 50km long!! This was incredible! Couldn't stop scrolling and reading. For a kid of a certain age and curiosity it'll blow their mind! I'm so grateful the creator made this, shame that his \"buy me a coffee\" isn't a simple PayPal or Apple Pay but you have to put in credit card or bank details!! Excellent! My wrist started to hurt 0.01% of the way to the moon. The atmosphere of this reminded me of the game Outer Wilds TIL it's estimated that over 48 tons of meteors hit the atmosphere every day. Regarding actual space elevators though, while they're not sci-fi to the extent of something like FTL travel - ie. they're technically not physically impossible - they're still pretty firmly in the realm of sci-fi. We don't have anything close to a cable that could sustain its own weight, let alone that of whatever is being elevated. Plus, how do you stabilize the cable and lifter in the atmosphere? A space elevator on the moon is much more feasible: less gravity, slow rotation, no atmosphere, less dangerous debris. But it's also much less useful. Was hoping would go to geostationary orbit as an actual space elevator would :) I love this guy. Re playing this gem  https://neal.fun/stimulation-clicker/  I just clicked the temperature thingy in annoyance because I don't use Fahrenheit and to my delight, it just switched to Celcius the website feels heavy, can we optimize this further?? (not a web dev) A beautifully executed project here, I bought Neal a coffee. What evolutionary advantage, I wonder, is there to Ruppell's griffon vulture flying at 11400 meters? edit: units The rockets at higher altitudes were all in wrong orientation. In reality, they don't fly straight up. Giant Space Bola is much more attractive. It is a 10000 km string with capsules at both ends. It rotates in sync with ear", "positive": "Tmux \u2013 The Essentials (2019). it's missing changing Ctrl+B to Ctrl+A:       # ~/.tmux.conf\n    set-option -g prefix C-a   I like tmux a lot, but like its predecessor \"screen\" I mostly use it for explicitly running long-lived jobs (i.e. for its detach feature), and for very special situations where I have elaborate tmux window configurations with dedicated stuff running in each window/pane. Note that I have been using text-only terminals since the 1980s, but I've adapted my tty usage over time. The problem that tmux (or screen) brings are first and foremost: * Smooth/fast scrolling goes away. I can no longer give my trackpad a slight push to find myself tens or hundreds of lines in the scrollback history, and visually scan by slightly pushing my fingers back and forth. Instead I have to use the horrendous in-tmux scrollback using \"Ctrl-b [\". * My terminal app's tabs and windows are not tmux's tabs and windows. I cannot freely arrange them in space, snap them off with the mouse, easily push them to another desktop, and so on. I have to start a multiple tmux clients and do awkward keyboard interactions with them for any of the same. * tmux's terminal emulation and my terminal emulator's terminal emulation (heh) are not congruent. As a result, programs cannot make full use of my actual terminal's capabilities. For example selecting, copying, and pasting text sometimes behave weirdly, and there are other annoyances. What I'd  really  like to have instead is terminal session management at a higher level, i.e. involving my actual graphical terminal app itself. Attaching to a running session would mean restoring the terminal app's windows and tabs, and the entire scrollback history within (potentially with some lazy loading). tmux could likely be a major part of that, by providing the option of replacing its tty-facing frontend with a binary protocol that the graphical terminal app talks to, while keeping the backend (i.e. the part that provides the tty to anything running ", "negative": "JRR Tolkien reads from The Hobbit for 30 Minutes (1952). This is so good.  You can tell that Andy Serkis based his gollum voice off of this. I wonder what Tolkien would say of so much of the symbolism from his novels being used to bootstrap a horrible dystopian control grid? Would he approve or disapprove? The way that orcs are dehumanized you have to wonder. Is there a version minus the music? This is the most magnificent audio version ever recorded of The Hobbit - by Nicol Williamson in the early 1970's. Zip file with mp3 in it:  https://drive.google.com/file/d/1b2aPKgVVguOKMOOqWskaliOviYr...  Best enjoyed on a rainy afternoon in an armchair with a cup of tea. Of course he didn't live to see the Peter Jackson movies but I think I've heard his son didn't like them My favorite recent LotR media: There is a Lord of the Rings MMO (like World of Warcraft) and a guy made a video recording a walk from the Shire to Mordor. Like you can just walk from the Shire to Mordor in the game. And it's almost 10 hours long in real world time to do that! But on top of that the whole journey is narrated by the Lord of the Rings audio book, with the relevant parts of the journey.  https://youtu.be/LYipECdYpXc  Incredibly relaxing People who don't like \"On The Road\" should listen to Jack read it in his own voice. It is amazing how Lord of the Rings persists in the world. Christopher Lee reading the Children of Hurin is also fantastic. tangential comment, but if anyone is interested in one of the best (imo \"legendary\") audio books on LOTR look no further than Phil Dragash :  https://archive.org/details/tlotrunabridged . Okay who\u2019s going to clone this using AI and have it read the entire book? Anyone?! I drink in his old local. A bit weird in there I would imagine if you're an American. Although I am a bit American and it is a bit weird in there. Ranged Touch's Shelved By Genre podcast is doing an entire year on The Hobbit + Lord of the Rings.\n https://rangedtouch.com/2026/01/02/the-hobbi"}
{"anchor": "Presence in Death. The research mentioned in the article (which indicates no EEG activity):  https://pmc.ncbi.nlm.nih.gov/articles/PMC7876463/  If TRUE and consciousness is eternal (using whatever framework you like), the idea of death becomes double sided. On one hand, physical death is sad as it's the end of this physical 'epic story' before our consciousness moves onto a new body/story. On the flip side, approaching body death is a sort of a temporary great relief as we are immortal and cannot actually die. I.e. After ten thousand years of being alive, a vampire looks forward to sleeping in their coffin at night. There are stories about bodies of Christian monks that did not decompose for a log time after the dearth. Modern take on it attributes it to the climate in caves where the body was put after the dearth. But another important part was diet. Often the well-preserved bodies were of those who had eaten only rough bread and water for months and years before the dearth. So I suspect both of the factors are at the play here as well. Here's the documentary referred to:  https://www.imdb.com/title/tt21945758/  It's rentable at the usual places. I might check it out. I have been studying and practicing tibetan buddhism for a little over a year now, particularly dream yoga, but branched into some of the other practices. I'm always a skeptic but it is fascinating some of the stuff they can do. There is scientific evidence they can raise and lower their body temperatures through meditation, withstanding great heat/cold and deprivation conditions. I've played around with deprivation and what it has done for my mental health and body has surprised me. I'm but a novice, but I absolutely believe they are tapping into something scientific about the body/mind that is still unknown. There are reasons to be extremely skeptical about some of their claims, but, some of it is very interesting and credible. Some of these esoteric states are really weird, and it seems crazy to me", "positive": "Copenhagenize Index 2025: The Global Ranking of Bicycle-Friendly Cities. great website, very helpful for traveling cyclists Of course it helps if the city, and country in general, is completely flat. Cities in Norway or Nepal have mother nature against all form of manual locomotion. I'm not surprised to see Utrecht in the first place, but quite a bit surprised to see the other Dutch cities so low. No offense, but Rotterdam or The Heague is 100x better than Paris from safety and convenience point of view. I'm curious why is the ranking like this. \"Welcome to the famous five-minute WordPress installation process! Just fill in the information below and you\u2019ll be on your way to using the most extendable and powerful personal publishing platform in the world.\" Ooops. Bicycling is part of the mobility culture of Montreal, but whether Montreal is actually  friendly  to bicyclists is open to heated debate. Cars dominate the topology. Why the Copenhagenize Index when Copenhagen is not particularly bike friendly by Dutch standards? I went to Copenhagen this summer. I was quite disappointed in the bicycle infrastructure, I felt like it was on par with what we have in Stockholm. Rented bikes and biked around for two days. It was nice! Not sure how this index is being calculated (site breaks a lot), but my general feeling was that Denmark is just better at marketing than actual infrastructure when comparing to Stockholm at least Ranking Bordeaux and Nantes next to Amsterdam is nonsense. Amsterdam is miles ahead in terms of infrastructure. This ranking dilutes the most important thing to get these results : good bike lanc\u00e9s everywhere with no discontinuity. Disclaimer : I've built villes.plus, an open source automated evaluation of bike lanes. 100 points, compute itineraries in \"secure\" mode with Brouter between these points, count the % of secured km -> score. Amsterdam tops at 8/10. Bordeaux is at 3/10, Nantes 2/10.  https://villes.plus/cyclables/Amsterdam?id=271110   https://v", "negative": "We invited a man into our home at Christmas and he stayed with us for 45 years. beautiful... kindness can go a long way :) we could all do better (and I point mostly at myself now) Ronnie led a rich life. I feel ashamed that my selfish life feels pale in comparison. It's amazing these people did not worry about the extra expense and inconvenience of taking care of another person, with children of their own to take care of. My parents once took a struggling man in. I think he stayed with them for about three years, up until the moment I was conceived and my mom started planning for a future for our family and helped him get into a housing project. For all of my life before adulthood this man would show up once in a while on his racing bike  for coffee, talk and proceed to stay for dinner. He was kind, funny and a tidbit strange. His life's story had more drama than a soap opera, but you wouldn't know it. After my father died I proceeded to look for him, but never found him. I still search online for him once in a while, fully knowing he probably isn't alive anymore and probably wouldn't use online anyways. There is some story in my head that he probably showed up to my dads doorstep once on his racing bike to find other people living there, but was too shy to ask for details. A trace lost. I'm not crying! You're crying! Beautiful story but with a sad undertone. A large percentage of the homeless have autism [1].  And that really sucks.  If these people don't have support, their lives can turn miserable fast.  And unfortunately it's just way too easy for these people to end up in abusive situations. It's a lot of work to care for people with autism (moderate to severe).  There is no standard for what they need, their capabilities can be all over the board.  Some of them are capable like ronny in this story and they can hold down jobs.  But others need 24/7 caregiving in order to survive.  Unfortunately I don't think those with severe autism survive for long when they "}
{"anchor": "FAA institutes nationwide drone no-fly zones around ICE operations. Not shady at all. Can\u2019t have the public see what\u2019s going on. Bubble of protection is 3000 feet laterally and 1000 feet vertically. From the article: \u201cUnlike traditional Temporary Flight Restrictions, the NOTAM does not provide geographic coordinates, activation times, or public notification when the restriction is in effect near a specific location. Instead, the restricted airspace moves with DHS assets, meaning the no-fly zone can appear wherever ICE or other DHS units operate.\u201d \u201cIn practical terms, a drone operator flying legally in a public area could unknowingly enter restricted airspace if an ICE convoy passes within the protected radius.\u201d This is a useful measure to point the law as a weapon against drone operators who may be recording what\u2019s going on by accident or on purpose. Any drone made in the last few years is going to be emitting its ID, which likely has been registered with the pilot\u2019s name and contact information. They can then after the fact come down on that person without having to get facial recognition, grab cellphone beacons, or other similar steps. My understanding is that DJI drones no longer enforce no-fly zones.  Supposedly they still warn you when entering a restricted zone, but hard geofencing functionality is no longer in effect.  Anyone know if that's true? I don\u2019t fully understand why drone operators follow these laws. Or any \u201cno-fly\u201d rules in general. Around an airport, it seems like common sense to not fly. Can\u2019t someone just\u2026buy/build a drone and fly is surreptitiously? Doesn\u2019t anything under 250g basically slip under the radar (not literally radar). Seems like most drones they care about might end up not being trackable anyway. > ALL UNMANNED ACFT ARE PROHIBITED FROM FLYING WITHIN A STAND-OFF DISTANCE OF 3000FT ... LATERALLY AND 1000FT ABOVE ... > TO: DEPARTMENT OF DEFENSE (DOD), DEPARTMENT OF ENERGY (DOE), AND DEPARTMENT OF HOMELAND SECURITY (DHS) FACILITIES AND M", "positive": "Mathematical Foundations of Reinforcement Learning. The best lectures on Reinforcement Learning and related topics are by Dimitris Bertsekas:  https://web.mit.edu/dimitrib/www/home.html  Another great resource on RL is Mykel Kochenderfer's suite of textbooks: \n https://algorithmsbook.com/  Also worth mentioning Murphy's WIP textbook[0] focused entirely on RL, which is an outgrowth of his excellent ML textbooks. [0]:  https://arxiv.org/abs/2412.05265  Awesome resource, in case someone is interested I implemented most of suttons book here  https://github.com/ivanbelenky/RL  I don't know how to go from understanding this material to having a job in the field. Just stuck as a SWE for now. Highly recommended .. even the main contents diagram is a great visual overview of RL in general, as is the 30 minute intro YT video. Im expecting to see a lot of hyper growth startups using RL to solve a realworld problem in engineering / logistics / medicine LLMs currently attract all the hype for good reasons, but Im surprised VCs dont seem to be looking at RL companies specifically. 6-lecture series on the Foundations of Deep RL by Pieter Abbeel is also very recommended. gives very good overview and intuition\n https://youtu.be/2GwBez0D20A  And if you want to understand the theory of Skinner's Verbal Behavior check out  https://bfskinner.org/wp-content/uploads/2020/11/978_0_99645...  During the openai gym era of RL, one of the great selling pts was that RL was very approachable for a new comer as the gym environments were small and tractable that a hobbyist could learn a little bit of RL, try it out on cartpole and see how it'd perform. Are there similarly tractable RL tasks/learning environments with LLMs? From the outside, my impression is that you need some insane GPU access to even start to mess around with these models. Is there something one can do on a normal MacBook air for instance in this LLM x RL domain? > This book, however, requires the reader to have some knowledge of ", "negative": "Claude's new constitution. I don't care about your \"constitution\" because it's just a PR way of implying your models are going to take over the world. They are not. They're tools and you as the company that makes them should stop the AGI rage bait and fearmongering. This \"safety\" narrative is bs, pardon my french. I don't understand what this is really about. Is this: - A) legal CYA: \"see! we told the models to be good, and we even asked nicely!\"? - B) marketing department rebrand of a system prompt - C) a PR stunt to suggest that the models are way more human-like than they actually are Really not sure what I'm even looking at. They say: \"The constitution is a crucial part of our model training process, and its content directly shapes Claude\u2019s behavior\" And do not elaborate on that at all. How does it directly shape things more than me pasting it into CLAUDE.md?  https://www.anthropic.com/constitution  I just skimmed this but wtf. they actually act like its a person. I wanted to work for anthropic before but if the whole company is drinking this kind of koolaid I'm out. >  We are not sure whether Claude is a moral patient, and if it is, what kind of weight its interests warrant. But we think the issue is live enough to warrant caution, which is reflected in our ongoing efforts on model welfare. > It is not the robotic AI of science fiction, nor a digital human, nor a simple AI chat assistant. Claude exists as a genuinely novel kind of entity in the world > To the extent Claude has something like emotions, we want Claude to be able to express them in appropriate contexts. > To the extent we can help Claude have a higher baseline happiness and wellbeing, insofar as these concepts apply to Claude, we want to help Claude achieve that. Wait until the moment they get a federal contract which mandates the AI must put the personal ideals of the president first.  https://www.whitehouse.gov/wp-content/uploads/2025/12/M-26-0...  I just had a fun conversation with Claude about"}
{"anchor": "DeepSeek-v3.1. For reference, here is the terminal-bench leaderboard:  https://www.tbench.ai/leaderboard  Looks like it doesn't get close to GPT-5, Claude 4, or GLM-4.5, but still does reasonably well compared to other open weight models. Benchmarks are rarely the full story though, so time will tell how good it is in practice. It's a hybrid reasoning model. It's good with tool calls and doesn't think too much about everything, but it regularly uses outdated tool formats randomly instead of the standard JSON format. I guess the V3 training set has a lot of those. It seems behind Qwen3 235B 2507 Reasoning (which I like) and gpt-oss-120B:\n https://artificialanalysis.ai/models/deepseek-v3-1-reasoning  Pricing:  https://openrouter.ai/deepseek/deepseek-chat-v3.1  Unrelated, but it would really be nice to have a chart breaking down Price Per Token Per Second for various model, prompt, and hardware combinations. For local runs, I made some GGUFs! You need around RAM + VRAM >= 250GB for good perf for dynamic 2bit (2bit MoE, 6-8bit rest) - can also do SSD offloading but it'll be slow. ./llama.cpp/llama-cli -hf unsloth/DeepSeek-V3.1-GGUF:UD-Q2_K_XL -ngl 99 --jinja -ot \".ffn_.*_exps.=CPU\" More details on running + optimal params here:  https://docs.unsloth.ai/basics/deepseek-v3.1  Seems to hallucinate more than any model I've ever worked with in the past 6 months. About halfway between V3 and Qwen3 Coder.  https://brokk.ai/power-ranking?version=openround-2025-08-20&...  Cheep! $0.56 per million tokens in \u2014 and $1.68 per million tokens out. They say the SWE bench verified score is 66%. Claude Sonnet 4 is 67%. Not sure if the 1% difference here is statistically significant or not. I'll have to see how things go with this model after a week, once the hype has died down. Looks quite competitive among open-weight models, but I guess still behind GPT-5 or Claude a lot. I have yet to see evidence that it is better for agentic coding tasks than GLM-4.5 Sad to see the off peak discount", "positive": "AI is a horse (2024). It's also a big bloatey gas bag that needs constant de-farting to function \"I've been through the desert On AI with no name It felt good to be out of the rAIn In the desert, you can remember your name 'Cause there ain't no one for to give you no pain\" Or your typical American teenager. All true apart you can only lead it to water - it drinks ALL the water regardless of anything else. And the salesman always says it\u2019s great while it\u2019s in fact lame. \"Computers aren't the thing. They're the thing that gets you to the thing.\" My favorite quote from the excellent show halt and catch fire. Maybe applicable to AI too? I was expecting a spin about the faster horses Ai is a horse, i get it!\n I have a horse, and I put money in the front of the horse, and get \"ponyium\" out the back. If an AI aims at the thing we call it hallucinations, when humans do it we call the delusion goal setting. Either way it is an imagined end point that has no bearing in known reality. \"No, I am not a horse.\" Horse rumours denied. This micro blog meta is fascinating. I've seen small micro blog content like this popping up on the HN home page almost daily now. I have to start doing this for \"top level\"ish commentary. I've frequently wanted to nucleate discussions without being too orthogonal to thread topics. you rather don't want it in your bed Some day, I imagine one will be a senator AI is not a horse (2023)  https://essays.georgestrakhov.com/ai-is-not-a-horse/  I've always said that driving a car with modern driver assist features (lane centering / adaptive cruise / 'autopilot' style self-ish driving-ish) is like riding a horse. The early ones were like riding a short sighted, narcoleptic horse. Newer ones are improving but it's still like riding a horse, in that you give it high level instructions about where to go, rather than directly energising its muscles. A horse that can do your homework. Maybe from the client's point of view, although it's more likely a Tamagotchi. B", "negative": "There's only one Woz, but we can all learn from him. Woz is by far the person in computing history for whom I have the most respect. Dude is an absolute  legend , and from everything I have heard is humble and kind on top of his crazy skills. If I could get to the point where I had even 10% of his skill and generosity of spirit, I would consider myself to have done pretty well. It\u2019s a stark contrast to today's mindset where we often just throw more resources at the problem.  His obsession with elegance over features is something I try to keep in mind, even if it's harder in modern web dev. \" Let's make it shorter and punchier.  \"Woz's floppy disk controller design is still the gold standard for doing in software what competitors needed a whole board of chips to do.  That kind of obsession with elegance over brute force is exactly what's missing in modern engineering. Only one Woz? What about Scott? Coincidentally one of the earliest Apple I prototypes ends its auction tomorrow if you have over $500K to spare:  https://news.ycombinator.com/item?id=46605420  For me, anyone who is involved in FOSDEM in any way deserves more respect (regarding revolutionary things we can learn) I learned some very bad jokes from him. It's kinda funny... In '89 a friend and I were talking about starting a startup like the two Steve's (we didn't know about Ron Wayne back then.)  We both knew exactly what Woz did, but were a bit sketchy on Jobs role in the early days.  Don't get me wrong, I'm not saying Jobs was a layabout, only that the strengths he brought to the table were more abstract. So I would also say... the kinds of things we learn from Woz are concrete and we get immediate feedback if we learned them wrong. Everyone chooses the wrong Steve to worship. I can't think of a single person who embodies the spirit of this site more than Woz. dang could replace the guidelines with a picture of Woz and we'd all know what it meant. modern engineering is launching an electron to-do list ap"}
{"anchor": "\u201cThe closer to the train station, the worse the kebab\u201d \u2013 a \u201cstudy\u201d. Anecdotally, it's the same for coffee. Office lobby coffee shops are invariably terrible. The decent ones are always at least a 5-10 minute walk away. This makes intuitive sense. High mass-transit corridor real-estate (rail, air, road) leases come at a premium so those higher fixed-costs and must be balanced against a higher-volume of less-breadth of service with the same fixed (or even slightly higher) labor costs. In food service, high-volume is (mostly) inversely correlated with quality. Looking at their actual results ( https://preview.redd.it/znmnejgab5je1.png?width=1000&format=... ), I don't see any positive or negative correlation. Although I can subjectively confirm the hypothesis. I've observed the following: 1) An alarming number of regions in the world have a pizza joint called \"New York Pizza\", \"Manhattan Pizza\", or similar. 2) The similarity of the pizza therein to the actual thin, greasy slices served up in pizza joints from actual New York is inversely proportional to the location's distance from New York. So, the New York Pizza in Boston -- pretty close. The New York Pizza in Brisbane, QLD is alien by comparison and I think they consider \"pepperoni\" and \"salami\" interchangeable down there. He didn't find a correlation, or rather found that there is no correlation, between proximity to a railway station and how the kebab is reviewed. It's a nice study for a statistics class! The only place this isn't true is Japan. Always like reading the Best Kebab reviews on trip advisor. It\u2019s right next to Queen Street railway station so fits with the study.  https://www.tripadvisor.co.uk/Restaurant_Review-g186534-d125...  > Not only was my food uncooked but I also discovered a pubic hair in my chips and cheese, then when I proceeded to report the problem, I was chased with a knife. Down Dundas Street.Absolutely scandalous LOL we may need to update the title of this post, half the top level comment", "positive": "Gemini Embedding: Powering RAG and context engineering. The Matryoshka embeddings seem interesting: > The Gemini embedding model, gemini-embedding-001, is trained using the Matryoshka Representation Learning (MRL) technique which teaches a model to learn high-dimensional embeddings that have initial segments (or prefixes) which are also useful, simpler versions of the same data. Use the output_dimensionality parameter to control the size of the output embedding vector. Selecting a smaller output dimensionality can save storage space and increase computational efficiency for downstream applications, while sacrificing little in terms of quality. By default, it outputs a 3072-dimensional embedding, but you can truncate it to a smaller size without losing quality to save storage space. We recommend using 768, 1536, or 3072 output dimensions. [0] looks like even the 256-dim embeddings perform really well. [0]:  https://ai.google.dev/gemini-api/docs/embeddings#quality-for...  To anyone working in these types of applications, are embeddings still worth it compared to agentic search for text? If I have a directory of text files, for example, is it better to save all of their embeddings in a VDB and use that, or are LLMs now good enough that I can just let them use ripgrep or something to search for themselves? Question to other GCP users, how are you finding Google's aggressive deprecation of older embedding models? Feels like you have to pay to rerun your data through every 12 months. I feel like tool calling killed RAG, however you have less control over how the retrieved data is injected in the context. > Embeddings are crucial here, as they efficiently identify and integrate vital information\u2014like documents, conversation history, and tool definitions\u2014directly into a model's working memory. I feel like I'm falling behind here, but can someone explain this to me? My high-level view of embedding is that I send some text to the provider, they tokenize the text and then run ", "negative": "Claude Code's new hidden feature: Swarms.  https://xcancel.com/NicerInPerson/status/2014989679796347375  In his second post he included a link to GitHub:  https://github.com/mikekelly/claude-sneakpeek  Isn't this pretty much what Ruv has been building for like two years?  https://github.com/ruvnet/claude-flow  Listen team lead and the whole team, make this button red. It feels like Auto-GPT, BabyAGI, and the like were simply ahead of their time Answering the question how to sell more tokens per customer while maintaining ~~mediocre~~ breakthrough results. Claude Code in the desktop app seems to do this? It's crazy to watch. It sets of these huge swarms of worker readers under master task headings, that go off and explore the code base and compile huge reports and todo lists, then another system behind the scenes seems to be compiling everything to large master schemas/plans. I create helper files and then have a devops chat, a front end chat, an architecture chat and a security chat, and once each it done it's work it automatically writes to a log and the others pick up the log (it seems to have a system reminder process build in that can push updates from other chats into other chats. It's really wild to watch it work, and it's very intuitive and fun to use. I've not tried CLI claude code only claude code in the desktop app, but desktop app sftp to a droplet with ssh for it to use the terminal is a very very interesting experience, it can seem to just go for hours building, fixing, checking it's own work, loading it's work in the browser, doing more work etc all on it's own - it's how I built this:  https://news.ycombinator.com/item?id=46724896  in 3 days. I'm already burning through enough tokens and producing more code than can be maintained - with just one claude worker. Feel like I need to move into the other direction, more personal hands-on \"management\". A guy who worked at docker on docker swarm now works at Anthropic so makes sense How is this different fro"}
{"anchor": "Attention Wasn't All We Needed. I know this probably seems like such a small detail to a lot of people, but I really love that the author adds comments. I can't stand reading PyTorch or other neural network code and asking myself, \"What architecture am I looking at here?\" or \"What the hell are these operations for?\" It's always like an mash up of reading some published paper code with deep effort behind it along with all the worst programming practices of complete unreadability. This is an excellent summary of these techniques :) I like that every single one comes with an example implementation, with shape comments on the tensors. Thanks Stephen! > Let's look at some of the most important ones that have been developed over the years and try to implement the basic ideas as succinctly as possible. One big architectural tweak that comes to mind and isn't in the article is QK norm:  https://arxiv.org/pdf/2010.04245  > Cosine Schedule A lot (most?) of new training runs actually don't use cosine schedule anymore; instead they keep the learning rate constant and only decay it at the very end, which gives equivalent or better results. See:  https://arxiv.org/pdf/2405.18392 \n https://arxiv.org/pdf/2404.06395  > There is a highly optimized implementation of AdamW in PyTorch. A fun tidbit - it's actually not highly optimized from my experience. Imagine my surprise when I reimplemented it in Triton (because I needed to tweak a few things) and I got better performance than the built-in PyTorch implementation. The explanation for Multi-head Latent Attention  https://www.stephendiehl.com/posts/post_transformers/#multi-...  does  not  match the definition in the DeepSeek-V2 paper  https://arxiv.org/pdf/2405.04434#subsection.2.1  MLA as developed by DeepSeek is a technique to reduce the memory footprint of the KV cache by storing only two vectors of size  latent_dim  and  rope_dim  per token and layer, instead of 2 *  num_heads  vectors of size  head_dim . (DeepSeek-V3 has  num_head", "positive": "\u201cErdos problem #728 was solved more or less autonomously by AI\u201d. Reconfiguring existing proofs in ways that have been tedious or obscured from humans, or using well framed methods in novel ways, will be done at superhuman speeds, and it'll unlock all sorts of capabilities well before we have to be concerned about AGI. It's going to be awesome to see what mathematicians start to do with AI tools as the tools become capable of truly keeping up with what the mathematicians want from the tools. It won't necessarily be a huge direct benefit for non-mathematicians at first, because the abstract and complex results won't have direct applications, but we might start to see millenium problems get taken down as legitimate frontier model benchmarks. Or someone like Terence Tao might figure out how to wield AI better than anyone else, even the labs, and use the tools to take a bunch down at once. I'm excited to see what's coming this year. This is great, there is still so much potential in AI once we move beyond LLMs to specialized approaches like this. EDIT: Look at all the people below just reacting to the headline and clearly not reading the posts. Aristotle ( https://arxiv.org/abs/2510.01346 ) is key here folks. EDIT2: It is clear much of the people below don't even understand basic terminology. Something being a transformer doesn't make it an LLM (vision transformers, anyone) and if you aren't training on language (e.g. AlphaFold, or Aristotle on LEAN stuff), it isn't a \"language\" model. You can try out Aristotle yourself today  https://aristotle.harmonic.fun/ . No more waitlist! Can anyone with specific knowledge in a sophisticated/complex field such as physics or math tell me: do you regularly talk to AI models? Do feel like there's anything to learn? As a programmer, I can come to the AI with a problem and it can come up with a few different solutions, some I may have thought about, some not. Are you getting the same value in your work, in your field? For context, Teren", "negative": "Recent discoveries on the acquisition of the highest levels of human performance. This sort of tracks for me. The smartest people I know as adults mostly fucked around a lot and had wide interests that all culminated in them doing a great thing greatly. The smartest people I know as kids spent hours grinding on something and crashed out in college and are mostly average well-to-dos now. Hardly a recent discovery. This is basically the entire foreword of David Epstein's book called Range: Why Generalists Triumph in a Specialized World A summary, since the paper isn't open access:  https://scientificinquirer.com/2025/12/21/the-counterintuiti...  > For example, world top-10 youth chess players and later world top-10 adult chess players are nearly 90% different individuals across time. Top secondary students and later top university students are also nearly 90% different people. Likewise, international-level youth athletes and later international-level adult athletes are nearly 90% different individuals. Motivation if you feel like you're young and failing That could simply be explained by early high achievers being worked hard by their parents or something else while people with innate abilities making progress slower (because most people are not overworked). For the first group they sizzle either because the pressure is removed as they grow up or because they hit their ceiling. Couldn't this be explained by Berkson's Paradox [0]? [0]  https://xcancel.com/AlexGDimakis/status/2002848594953732521  Seems very Taleb's Ugly Surgeon / Berkson's Paradox to me. It's like how software engineers who are at Google are worse if they're better competitive programmers. e.g.  https://viz.roshangeorge.dev/taleb-surgeon/  Exponential growth is the path of longsuffering, and one doesn't always make it. It sucks and looks and feels bad for all involved. This is why advice such as, \"Ignore the naysayers.\" is clutch. And other advice once one starts to rocket shoot like \"Stay in your lane."}
{"anchor": "Ask HN: Where do seasoned devs look for short-term work?. Now is not a great time to be looking for this kind of work unfortunately. I think your network is the best place to look for this sort of work. Sometimes people will reach out to me with short term projects which is the best way to get gigs like this. Maybe start looking at your colleagues on linkedin, see what they are up to, and think of ways to contribute to what they are working on. The best people to contact in this scenario are leadership and decision makers. A SWE II isn't gonna help you much but a CTO at an early stage startup might be a good person to send a DM if they are friends with you (or even if they aren't!) :) Short term work is more plentiful when money is easy and there\u2019s a lot of entrepreneurial activity going on due to some recent catalyst such as mobile app platforms or the dotcom boom etc. Right now we\u2019re in the AI boom and some people may be making money peddling agentic solutions but money is tight and businesses are hurting. It\u2019s also hard to trust a short term dev who doesn\u2019t really need the money. You have no leverage over them. They sort of just do as they please. Most ad-hoc work I've picked up has been people I've previously worked with/for. Maybe worth reaching out to people you have a prestablished relationship with I did this a few years ago and the winning recipe was a shameless (i.e. deeply shameful) linkedin post where I pretty much just summarized my skillset and explained that I was looking for a senior engineer equivalent of a summer internship, with no chance of extension. Got me 3-4 offers. None of the offering companies had ads out for roles like this, so this was pretty much the only way. I'd believe you're better off working on yourself. Maybe do toy projects for your potential portfolio, learn an additional skill (AI?), and build many weekend projects until something sticks. Publishing articles, etc to demo your skill helps you stay top of mind. Even if only the ", "positive": "alphaXiv: Open research discussion on top of arXiv. I remember seeing this idea some years ago. I think it was called qrxiv.org or something like that, but can't find it anymore. I hope this one has better luck, getting the users in the fragmented space of preprints can be a challenge. Hey alphaxiv, you won\u2019t let me claim some of my preprints, because there\u2019s no match with the email address. Which there can\u2019t be, as we\u2019re only listing a generic first.last@org addresses in the papers. Tried the claiming process twice, nothing happened. Not all papers are on Orcid, so that doesn\u2019t help. I think it\u2019ll be hard growing a discussion platform, if there\u2019s barriers of entry like that to even populate your profile. hnews tries to say one positive thing challenge impossible i always love any idea for curating high iq internet community This seems like a horrible idea. I know we need an alternative to peer review but an online comment section feels like something worse than that. This is great. Already loving the discussions/comments I see there. I believe this site is missing a very important thing, direct links to the different categories with a list of papers.\nThis is at least how I (and I believe many others) browse arXiv. I open it up in the morning, scroll through a few categories and open a few papers that look interesting to me. I could see myself using alphaxiv for that, and then, if there's a comment section, I might even read it, and, who knows, leave a comment. But there's no way I'm going to be changing the address or going to some other site to search for papers just to see whether there are some comments. ps: I see the extension adds a \"discussion\" link to arxiv, it is a pity that it is only available for Chrome. What's the main thing that this new website adds over scirate? Great idea. - The frontpage should directly show the list of papers, like with HN. You shouldn't have to click on \"trending\" first. (When you are logged in, you see a list of featured papers ", "negative": "I'm addicted to being useful. I can relate to this. I find that I have the same issue. If this resonates with you, I highly recommend picking up a copy of Tracy Kidder's 1981 novel  The Soul of a New Machine . You'll be hooked by the end of the introduction. Can definitely relate to this. But I have found that, when running a team, it can be very counter productive. If you constantly solve all the problems that come it can be stifling for the people you manage. Help is the sunny side of control. >  I don\u2019t mind the ways in which my job is dysfunctional, because it matches the ways in which I myself am dysfunctional As a fellow traveller, I offer one caution: learn to turn this down in personal relationships as it can be counterproductive. It took decades for my wife to finally get through and explain not every problem she voices is something that needs a solution. Some times people just want to be heard. It bugs the hell out of me because I tend to need to solve All The Problems before I can do any self-care, but rather than seem heroic, I think this attitude can seem transactional or uncaring as though everyone is just a screw that needed a bit of tightening, etc. I wonder if this sort of thing can lead to faster burnout or such. I've sorta over time leaned toward guarding my own space/time since somehow I get more tired out, and over time more burned out, if I don't. I can very much relate to the OP in this. I enjoy writing code, figuring out problems, finding solutions and in general helping other people with things that require some kind of software to be created or updated. And until year or two ago I thought I'd be able to continue to do what I love while getting paid decent money for it. With the advent of vibe coding and AI I'm starting to feel less sure in the future. I feel the same way. I retired last summer, but that only means that I found a place that needs me, where I can work part time without worrying too much about money. I remember, decades ago, r"}
{"anchor": "Android's full desktop interface leaks: New status bar, Chrome Extensions. This looks like it will help a lot of students and families who are on a budget. If you can just plug your phone into a screen you do not need to buy a separate laptop anymore. The browser extensions are the most important part because that is what makes a computer useful. I am glad to see they are thinking about this. Is this going to mean ChromeOS is going to eventually die or be merged with Android? Curious. Well, that would be nice, honestly - to have Android as another option for desktop OS. I remember there were some experiments to create a hardware laptop shell to insert smartphone into. If it comes with fully functional command line, unix utils and ability to install linux apps from different stores, that would be great OS. The Chrome Extensions support is the interesting part here. That's often the dealbreaker for using mobile devices as computer replacements. Google's had this weird situation where Android and ChromeOS overlap more every year. At some point maintaining two operating systems with converging feature sets seems wasteful. My guess: ChromeOS probably survives for the education market where manageability matters more than capabilities. But for consumers? Android on a big screen with keyboard and mouse might just be good enough. I wonder what gogole's strategy with fuchsia is going to be. So I'm guessing ... no full adblockers allowed? It really does look to be a rewrite of ChromeOS to make it a native Android experience with very few tweaks to the User experience that I can see. I think it's a good idea on Google's part. The trend of consumers using mobiles as their one and only computing experience is still strong.\nThis will blend the experience consumers have between desktops and their primary computing platform. It is interesting to consider the different developments happening with the big mobile orgs regarding the convergence computing paradigm: - Samsung\u2019s Dex has b", "positive": "Roam 50GB is now Roam 100GB. Nice that instead of completely cutting you off at the cap they put it in super slow 500 kbits. That is actually usable and used to be the fastest speed you could get at home. That's not bad for the cheap plan. Even the slow mode is fast enough for video conferencing and doing basic remote work. They still have a separate unlimited plan for anyone who needs more. I\u2019ve kept it on the backup service for 10 GB at $10 or whatever and it\u2019s pretty cool. Used it off my balcony in SF when Google Fiber had a 1 hr outage, take it on road trips, and stuff like that. Totally worth it. I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff. Aside from the fact it allows you to work with Starlink to buy more fast speed, it also allows core stuff to continue to function (e.g. basic notifications, non-streaming web traffic, etc). They could make it 1000GB for US$10/month and I still wouldn't give any money to a company associated with that man. Finally I can use Codex/OpenCode even out in the woods. No work-life balance; just vibing everywhere I go. I had a \u201chit\u201d post on bsky [0] (90 likes, big numbers for me) asking whether people would want an unlimited mobile plan throttled at 256kbps for $2/month. Seems like yes? There\u2019s lots to say about how useable it is (I often get throttled when traveling and it\u2019s really not that bad + it helps curb any desire to scroll videos!) But mainly I want to ask - I looked into it for a minute and it seems like you couldn\u2019t start an mvno because carriers wouldn\u2019t let you cannibalize them? You can get very cheap IoT plans but if you tried reselling IoT as esims for consumers, the carriers would kill it? So yeah - Starlink to mobile is actually the only viable way that routes around this problem? (((email in profile if you\u2019re cuckoo enough like me and want to start a self service\u2019d throttled mvno))) [0]  https://bsky.app/profile/greg.technology/post/3mbmwsytnyc23  I want the old plan back. If ", "negative": "OpenSSL: Stack buffer overflow in CMS AuthEnvelopedData parsing. Can someone translate \"Applications and services that parse untrusted CMS or PKCS#7 content using AEAD ciphers (e.g., S/MIME AuthEnvelopedData with AES-GCM) are vulnerable\" to human? 2026 and we still have bugs from copying unbounded user input into fixed size stack buffers in security critical code. Oh well, maybe we'll fix it in the next 30 years instead. Is this really exploitable? Is stack smashing really still a thing on any modern platform? Another \"fix\" in the long line of OpenSSL \"fixes\" that includes no changes to tests and therefore can't really be said to fix anything. Professional standards of software development are simply absent in the project, and apparently it cannot be reformed, because we've all been waiting a long time for OpenSSL to get its act together. Looks like Debian and some other distros are still on the vulnerable 3.5.4. Why did Openssl publish before the distros rolled to the fixed version? Very strange, as I type this both Bullseye and Bookworm are marked as fixed but Trixie isn't yet:  https://security-tracker.debian.org/tracker/CVE-2025-11187  I'd encourage folks to read the recently-published statement [1] about the state of OpenSSL from Python's cryptography project. [1]:  https://news.ycombinator.com/item?id=46624352  I just looked at the vuln in detail. If you are using OpenSSL compiled with Fil-C, then you're safe. This attack will be nothing more than a denial of service (the attacker won't get to actually clobber the stack, or heap, or anything). Services that process CMS[1] or PKCS#7 envelopes may be vulnerable to this bug. The most common example of these is S/MIME (for signed/encrypted email), but PKCS#7 and CMS show up in all kinds of random places. (Unless I'm missing something, a key piece of context here is that CMD/PKCS#7 blobs are typically allowed to select their own algorithms, at least within an allowlist controlled by the receiving party. So the fact"}
{"anchor": "Ask HN: What did you read in 2025?. Lots of news and articles, but also \"The Craft\", a history of Freemason's by John Dickie, was one of the more interesting books. Frankenstein. Superb science fiction, very readable even though written 200 years ago. And Wuthering Heights, which strangely like Frankenstein, has a complex narrative structure and an unhinged, obsessive central character - Emperor of Rome by Mary Beard, very entertaining. - Lolita, it's mostly what you've read about it. - a few short stories by Heinrich von Kleist. I mostly read fiction but I made time for a couple of nonfiction books this year. On the fiction side I really enjoyed \"Luminous\" and \"When We Where Real\". -  https://en.wikipedia.org/wiki/Luminous_(novel)  -  https://www.simonandschuster.com/books/When-We-Were-Real/Dar...  On the nonfiction side, I can recommend \"Careless People\" and \"Apple in China\". -  https://en.wikipedia.org/wiki/Careless_People  -  https://en.wikipedia.org/wiki/Apple_in_China  I read Sad Tiger by Neige Sinno. Really unsettling but definitely worth reading. One of my favourite reads from this past year was  Infinite Powers: How Calculus Reveals the Secrets of the Universe  by Steven Strogatz. It's a wonderful review of the history of calculus, including intuitive explanations of the basics. History of the Franks, by Gregory of Tours Getting into reading again this year after a long break. The most memorable read of this year was \"The Count of Monte Cristo\" (1846) by Alexander Dumas . It's one of the greatest stories ever told. It's ~1250 pages but I sped through it in 3 weeks even if I'm a slow reader. Highly recommended! I also read The Stranger by Camus and the two top Orwells which lived up to the hype. Very much enjoyed the Hyperion Cantos series by Dan Simmons.  https://en.wikipedia.org/wiki/Hyperion_Cantos  I got really into Hemingway\u2019s work, reading all the best ones, but my favourite being \u2018A moveable feast\u2019 his diary essentially released at the end of his life", "positive": "40M Americans Live Alone, 29% of households. Any causes? Is it that we are too independent and don\u2019t like collectivism? A conspiracy might say it\u2019s on purpose to have more people pay for things typically bought for a couple. Like everyone having their own house, cable bill, utility bill, water bill, \u2026 If more people lived together with friends, that\u2019d make a dent in both the housing and loneliness crises. Is it a bad thing? People's life choices are their own. 29% seems like a fairly neutral number. Incidentally, that newsletter has a lot of interesting charts.  https://www.apolloacademy.com/the-daily-spark/  It's not a high number when compared to other first-world countries:  https://statranker.org/population/top-10-countries-with-high...  Is this page just a single chart and a massive legal disclaimer? When I was a twentysomething, I had roommates. This saved money on rent and bulk purchases (which let me spend more time having fun  and  save money) and provided a starter-kit social circle in a new city. It also honed conflict-resolution skills and ability to be civil. And when I got a partner, it made moving in together smoother. Something I\u2019ve noticed recently is many college graduates living alone. That\u2019s fine. But it\u2019s a weird default for early in one\u2019s career. If I had one general piece of advice for anyone starting their career, it would be to seek out a living situation with roommates. Side question: are more college students staying in solo dorms? Part of the \"housing crisis\" is older Americans aging-in-place and using way more home than they need too. A widow/er might occupy the same suburban single family home in retirement that could house 5 people. Even as new homes are much bigger than decades past\u2026 The best thing I ever did for my mental health was to start having children. Humans, like every other living creature, are hardwired by billions of years of evolution to reproduce. So what? After living with parents, roommates, spouses and others for most", "negative": "40% of Kids Can't Read and Teachers Are Quitting [video]. From the summary of video: \"40% of fourth graders can't read. Kids are asking their teachers why they need to learn to read when AI can do it for them. Social media has destroyed their attention spans and now teachers aren't teaching, instead they're managing withdrawal symptoms.\" Why are fourth graders on social media and using AI already? My fourth grade kid has no social media presence and definitely isn't familiar with AI tools. This sounds like a parent problem. (a joke) 100% of kids can't read then 60% learn Australia's social media ban for young teenagers is probably a good thing but time will tell. Per stats in the video results are roughly the same as in 1992, with peak roughly at 2019. I do not know why is 1992 baseline, but for some reason it is. OK, I found it, peak was 2020. Just in case someone will (again) argue this means we have to go back to pedagogy of 1970. Don\u2019t they still need to read what AI writes? Or did they skip to the TTS stage? Why are you letting kids that can't read pass the grade? The 40% stat is not great, there's a better unpacking of it here:  https://www.youtube.com/watch?v=ZvCT31BOLDM  While I appreciate the sentiment of the video, I can\u2018t get past the sensationalist rhetoric / framing of the problem. \u201eSkibidi Toilet is rotting brains!! Kids don\u2018t want cartoons!!\u201c. I suppose videos like this might get people to think about the problem who hadn\u2018t considered it before. This is 100% the fault of parents. Annual escalation of the grade, e.g. eight grade, should be altogether eliminated in favor of one month modules. This avoids wasting a whole year if one fails the grade. Faster feedback is better, up to a point, and it is better here. How would this work in practice though if a teacher has to teach an entire class? Of course it would have to use computer instruction, with the teacher helping small batches of students who're in the month-long module, but only for a fraction of"}
{"anchor": "SpaceX lowering orbits of 4,400 Starlink satellites for safety's sake. From a comment : >The first move in the coming WWIII, where the emperors try to expand their empires militaril,y will be to wipe out any orbit with Starlink satellites. I find this highly unlikely, given Starlink is soon to reached 10k satellites and will continue to grow. Why expand 10 000 ballistic missiles to bring down one of many communications networks ? There are so many satellites in orbit that there is a pretty good chance that if even one was to be hit by something and explode in many pieces, it would crash another one and then another one until there is nothing left. The nasa is pretty scared of it, so is SpaceX. I think it's important to note that not all collisions are equally dangerous. Consider a sat on a polar orbit colliding with one on a equatorial orbit. Or two satellites on different directions.  That  is going to be spectacular. Otoh, these kind of collisions are unlikely and should be manageable by just assigning certain shells (say 5km) for every possible direction and orientation. If two Starlink satellites collide that go roughly in the same direction, it's not exactly a huge problem. I think the biggest issue is to coordinate this and potentially disallow some excentric orbits. What\u2019s the plan as the solar maximum returns? Can anyone explain how does one technically lower a satellite? 3 week old news OP? Previously:  https://news.ycombinator.com/item?id=46457454  Won't this make running Starlink more expensive? Lower orbits > Increased atmospheric drag > More fuel expended to maintain orbit > Heavier sats due to more fuel > Increased launch cost per unit Or even: Lower orbits > Increased atmospheric drag > Quicker orbit decay > Shorter lifespan of sats > More frequent launches Forgive my Kerbal-based space knowledge here. Because Kessler syndrome means you don't need to hit all 10k yourself. Lowering the orbits just means that we get back to normal faster, not that the i", "positive": "Show HN: SQL Noir \u2013 Learn SQL by solving crimes. This is really lovely. It makes me happy that you invested time into building this for other people. this is awesome! soooo fun. Thank you for building this. Sharing it immediately Really cute. But I really want the ability to put the different tabs -- Brief, Workspace, Schema -- side-by-side. I know SQL and wanted to play with this, but the UX was frustrating enough to drive me away, even though it is really pretty. This is pretty fun, I tried the two free mysteries and was fun solving them. One nit, would be nice if the SQL editor supported comments so we can comment out old queries before running new one so as keeping a history esp if we need to run the same queries again. Good stuff :) This gives me a childhood flashback to a show called MathNet, an educational police procedural (a la Dragnet) where both investigators have holstered calculators.  https://en.m.wikipedia.org/wiki/Mathnet  reminds me of  https://mystery.knightlab.com/  That was fun!\nOne question, is there a way to execute the current hovered/selected query and not the first on in the workspace? Something is weird in at least firefox.\nType or paste:     select \\* \n  from crime_scene;\n  \nthen TYPE so you add a comment     select \\* \n  from crime_scene;\n  --\n  \nI see     select ----from---------------- \n  \nbut when I select the text I see what I wrote - I like the comment my text (and I was pulling in the instructions) but it renders some interesting garbage pretty fast. Feature request: Badges for completing challenges. Issue Closed, Won\u2019t Fix. Badges?? We don\u2019t need no  stinking  badges! When I was in university, my instructor linked something like this for SQL practice (a crime solving minigame, just like this one). I remember getting really into it, even going to the extreme of trying to find the most efficient one-liner solution. Thanks for making this. I\u2019ll be passing the torch by linking it to anyone interested in learning SQL. This is super fun!", "negative": "San Francisco coyote swims to Alcatraz. I would be surprised if the Coyote would be quick to get back into the water after such a difficult swim. It would, I suspect, want to recover and find food. So I support the theory the Coyote is just hiding somewhere. The island is small but not that small that it couldn\u2019t hide somewhere. I wonder if a turtle drowned halfway across. If a Coyote could do it, all those famous escapees must have had too. That roadrunner thought he'd be safe hiding out on the notorious prison island... It's a 1.5mi swim. I remember visiting Angel Island (a 0.5mi swim) and seeing the abundance of raccoons they have, and asked a ranger how they got there. They also swam. Growing up on a lake I would regularly watch deer swim the quarter mile back and forth between the shore and a nearby island, with no problem. Video:  https://www.youtube.com/watch?v=br4-VsvRcII  Poor thing, talk about going in the wrong direction :) Impressive though. If you time things right, and don't get swept out to sea, it's the 54 degree water that is the real danger. I'm no medical person, but it sure seems like that the animal is suffering from hypothermia and fatigue. I'm sure it'll have happy hunting once it recovers. This sort of thing is a huge problem here in New Zealand. The only native mammal here is a bat, we have mostly birds which evolved for a really long time with only avian predators. So they\u2019re hilariously poorly adapted for surviving standard predators (cats, rats, dogs etc) which first the Maori and subsequently Europeans brought. For example, many of them are flightless and tend to freeze when threatened - works well against eagles but is a terrible idea when threatened by a cat. As a result, we have many animals, mostly birds, which are totally unique and also critically endangered. Many of them can only survive on offshore islands which have been comprehensively cleared of predators at vast effort and expense. The islands need to be relatively accessible"}
{"anchor": "Kidnapped by Deutsche Bahn. DB is a lot better run than British trains... My God. Twenty minutes late is normal in the UK. At some point your Regio Express turned into an Intercity. Free upgrade! DB is continually the worst train experience I have in Europe. I have never been on a train in Germany that's on time or that stops at the right station. Several times I've had to find someone young (and who speaks English) and say, \"I'm just going to follow you to the next train.\" I've been told that the UK is worse, but I don't have much experience with it outside of Eurostar. There're certain kinds of rewards to encourage traveling by rail in Europe. For example, a training course I attended refunded part of your travel expenses if you took a long-distance train. And there're people who believe in not flying for the sake of the planet. But at this point, I'm convinced you should avoid any train in and around Germany. This includes Denmark as well. Just take a plane, but don't have a layover in Germany. The same could probably be said about France. My first train from Paris to Nancy stopped for about 2hrs in the middle of nowhere. As the machinist said: \"The train is tired.\" Other countries like Italy or Spain seem to actually have well-functioning rail though. And here I was annoyed that the train going half the route (as in schedule, not coz of any accident) is named the same so I got on too early one by accident and had to walk a stop away. Deutsche Bahn seems very similar to most of the railway in England. Customer service is non-existent; delays are highly normalised. The UK government hates how expensive it is to operate, so they are reducing subsidies and massively prioritising the most profitable routes and raising prices. Staff got nice condition/pay bumps during COVID and all have the attitude that they are doing us a favour. I don't mean that lightly or that I've had one bad experience with a member of staff on a bad day. They are work-shy, offensive, rude, lac", "positive": "Auto-grading decade-old Hacker News discussions with hindsight.  LLMs are watching (or humans using them might be). Best to be good.  Shades of Roko's Basilisk! Commenters of HN: Your past thoughts have been dredged up and judged. For each $TOPIC, you have been awarded a grade by GPT-5.1 Thinking. Your grade is based on OpenAI's  aligned  worldview and what OpenAI's blob of weights considers Truth in 2025. Did you think  well , netizen? Are you an Alpha or a Delta-Minus? Where will the dragnet grading of your online history happen next? Random Bets for 2035: * Nvidia GPUs will see heavy competition and most chat-like use-cases switching to cheaper models and inference-specific-silicon but will be still used on the high end for critical applications and frontier science * Most Software and UIs will be primarily AI-generated.  There will be no 'App Stores' as we know them. * ICE Cars will become niche and will be largely been replaced with EVs, Solar will be widely deployed and will be the dominate source of power * Climate Change will be widely recognized due to escalating consequences and there will be lots of efforts in mitigations (e.g, Climate Engineering, Climate-resistant crops, etc). It's fun to read some of these historic comments! A while back I wrote a replay system to better capture how discussions evolved at the time of these historic threads. Here's Karpathy's list from his graded articles, in the replay visualizer: Swift is Open Source\n https://hn.unlurker.com/replay?item=10669891  Launch of Figma, a collaborative interface design tool\n https://hn.unlurker.com/replay?item=10685407  Introducing OpenAI\n https://hn.unlurker.com/replay?item=10720176  The first person to hack the iPhone is building a self-driving car\n https://hn.unlurker.com/replay?item=10744206  SpaceX launch webcast: Orbcomm-2 Mission [video]\n https://hn.unlurker.com/replay?item=10774865  At Theranos, Many Strategies and Snags\n https://hn.unlurker.com/replay?item=10799261  Notable how this", "negative": "California is free of drought for the first time in 25 years. As John Steinback said in  East of Eden : \u201cI have spoken of the rich years when the rainfall was plentiful. But there were dry years too, and they put a terror on the valley. The water came in a thirty-year cycle. There would be five or six wet and wonderful years when there might be nineteen to twenty-five inches of rain, and the land would shout with grass. Then would come six or seven pretty good years of twelve to sixteen inches of rain. And then the dry years would come, and sometimes there would be only seven or eight inches of rain. The land dried up and the grasses headed out miserably a few inches high and great bare scabby places appeared in the valley. The live oaks got a crusty look and the sage-brush was gray. The land cracked and the springs dried up and the cattle listlessly nibbled dry twigs. Then the farmers and the ranchers would be filled with disgust for the Salinas Valley. The cows would grow thin and sometimes starve to death. People would have to haul water in barrels to their farms just for drinking. Some families would sell out for nearly nothing and move away. And it never failed that during the dry years the people forgot about the rich years, and during the wet years they lost all memory of the dry years. It was always that way.\u201d The dams in california were built years ago for a smaller population and since then they've only removed them. If we simply built like the people who first came to california did we would never have water shortages again. Any water shortage is a 1:1 failure of the state to do the clear and obvious task needed. strange because this is one of the warmest winters in decades. snow levels are far below normal, i saw 8% of normal in truckee. full reservoirs now are great but keeping them filled depends on a long snow melt going into june. i don\u2019t think this is going to be a good year for that And yet our water rates are still as if we are in a drought. Previ"}
{"anchor": "Watching o3 model sweat over a Paul Morphy mate-in-2. O3 is massively underwhelming and is obviously tuned to be sycophantic. Claude reigns supreme. I've commited the 03 (zero-three) and not o3 (o-three) typo too, but can we rename it on the title please So, are we talking about OpenAI o3 model, right? On a similar note, I just updated LLM Chess Puzzles repo [1] yesterday. The fact that gpt-4.5 gets 85% correctly solved is unexpected and somewhat scary (if model was not trained on this). [1]  https://github.com/kagisearch/llm-chess-puzzles  Where does this obsession over giving binary logic tasks to LLMs come from ? New LLM breakthroughs are about handling blurry logic, non precise requirements and spitting vague human realistic outputs. Who care how well it can add integers or solve chess puzzles ? We have decades of computer science on those topics already I remember reading that got3.5-turbo instruct was oddly good at chess - would be curious what it outputs as a next two moves here. So... it failed to solve the puzzle? That seems distinctly unimpressive, especially for a puzzle with a fixed start state and a limited set of possible moves. Nice puzzle with a twist of Zugzwang. Took me about 8 minutes, but it's been decades since I was doing chess. LLMs are not chess engines, similar to how they don\u2019t really calculate arithmetic.  What\u2019s new? carry on. I just tried the same puzzle in o3 using the same image input, but tweaked the prompt to say \u201cdon\u2019t use the search tool\u201d. Very similar results! It spent the first few minutes analyzing the image and cross-checking various slices of the image to make sure it understood the problem. Then it spent the next 6-7 minutes trying to work through various angles to the problem analytically. It decided this was likely a mate-in-two (part of the training data?), but went down the path that the key to solving the problem would be to convert the position to something more easily solvable first. At that point it started trying to ", "positive": "Show HN: FaceTime-style calls with an AI Companion (Live2D and long-term memory). It creates a conflict to build a system that is both a private friend and a public performer. You cannot maximize intimacy and fame at the same time. What are you using for tts/stt/models? Building on zemo's point about parasocial relationships: traditional parasocial interaction involves a performer who doesn't know you exist. Here the AI does respond to you specifically, which changes the dynamic. Is it still parasocial if the other party is responsive but not conscious? Or is this something new that we don't have good language for yet? For better lip sync you could try using rhubarb to extract from the mp3.\nWhat is your backend speech processor so you can get the real-time streaming response?\nRhubarb would add a bit of latency for sure. wow we got personal vtubers now! You're describing Parasocial interaction:  https://en.wikipedia.org/wiki/Parasocial_interaction  far from being impossible, it's the entire influencer economy. This form of social media has been extremely widespread for a decade or so running; it's probably the dominant form of social media. 100% agree. Maximizing intimacy and scaling distribution pull in opposite directions. We\u2019re experimenting with keeping the \u201ccharacter\u201d consistent while letting personalization live in private memory and user-controlled settings. Still early, and this tension is real. Appreciate it. If you try it and anything feels off (latency, turn-taking, uncanny moments), I\u2019d love concrete feedback. That\u2019s what we\u2019re grinding on right now. It will quickly distill down to clients using the service just for sex and sex-adjacent activities. No kink-shaming, but this sort of thing enables self-destructive hard-to-return-from anti-social behaviour. Totally fair reaction. We\u2019re building this with clear boundaries: we don\u2019t position it as therapy replacement, we add safety rails, and gives user a choice what mode they want and guardrails differ based ", "negative": "Qualcomm CEO pockets 15% pay rise as profits fall 45%. >The bump came in a year when Qualcomm reported full-year revenue of $44.3 billion, up 14 percent, but net income plunged 45 percent to $5.5 billion after the company booked a hefty non-cash tax charge tied to changes in US tax law. In other words, sales were up, profits went backwards, and executive pay kept climbing anyway. I do find this frustrating as an IC. I'm lucky to get a COL raise every year, much less 10-15% in a down year. Not to mention the absolute ridiculous explosion of C-Suite pay in comparison to workers. Something has to change if these companies want to continue to be successful long term. > By contrast, Qualcomm calculated the annual total compensation of its median employee at $101,639, putting Amon's pay at roughly 292 times that figure. For those who missed that in today's brand of capitalism in some countries, employees are very much peasants and serfs. America is just it's usual stupid self again. C Level pay and any other position pay has nothing in common anymore. I guess some are humans and some are demi-gods The article mentions a one time tax charge which resulted in the reduction in profits but doesn't explain the context of the tax charge. Likely because it doesn't fit the narrative the author tried to create. Qualcomm chose to take a one time non-cash tax charge of $5.7 billion to take advantage of changes in the tax code which were part of the Big Beautiful Bill enacted last year. By taxing the charge their effective tax rate and cash tax payments moving forward will be reduced. In other words they traded short term profits for increased long term profits. Meta similarly took a $15.9 billion charge for the same reason. Many other companies have already done the same or are expected to. Especially those which have large R&D investments. Shit like this just makes me feel more and more that all executives need to be removed. Wouldn't a CEO be the easiest person to replace with AI?"}
{"anchor": "10 years of personal finances in plain text files. This seems to be, in effect, advertising for a book about how to use the underlying FOSS software to do this. I would be okay with that as a monetization model, except that the book author despite being a self-described FOSS dev doesn't seem to have anything to do with the project ( https://github.com/beancount/beancount/graphs/contributors ). Ah, not quite true. The author fixed a typo in a docstring once ( https://github.com/beancount/beancount/commit/8584763b618f76... ). Plain text files are appreciated. I started storing all my notes (500+ by today) in markdown files locally. It's easy to search and navigate with grep and ag/rg. It's easy to edit in Vim or your favorite editor. It's easy to append all sorts of informations. I add some flags and properties in metadata, like last_reviewed, some tags, etc. The versioning and sync is solved by git + a private github repo. I have 14 years of personal (and 2 years of sole proprietorship) finance data in beancount. I tried all the available personal finance apps there are, from cloud/online offerings to offline apps. Eventually, I settled on beancount because it is the most versatile file format. In addition to tracking finances, I can track stocks, unvested RSU grants, vacation hours, and even personal training I have paid for but yet to use. It's cumbersome at times, and I do miss the (G)UI of entering transactions, but with (neo)vim I got used to it and I breeze trough my finances in 15-20 minutes once a week. > 30-45 minutes every single month That's 6\u20139 hours every year! 5 years: 30\u201345 hours 10 years: 60\u201390 hours I've been beancount'ing for years now As we've crossed into the new year I've switched to a similar directory setup as the OP with 1 file per year. Previously I just had one file that was from 2022 which ended up being like 2 million lines of text, which was starting to bog down the emacs plugin. What I appreciate the most about this approach to personal ", "positive": "BYD's cheapest electric cars to have Lidar self-driving tech. Lidars come down in price ~40x.  https://cleantechnica.com/2025/03/20/lidars-wicked-cost-drop...  Meanwhile visible light based tech is going up in price due to competing with ai on the extra gpu need while lidar gets the range/depth side of things for free. Ideally cars use both but if you had to choose one or the other for cost you\u2019d be insane to choose vision over lidar. Musk made an ill timed decision to go vision only. So it\u2019s not a surprise to see the low end models with lidar. Keep in mind, that $25k AUD is just $16600. And for that price, you're getting a real car with driver-assist features and a reasonable crash safety rating. The US car manufacturers are cooked. Still not convinced of the safety of lidar. I guess all these cars with cheap lidar sensors on board will generate real world safety data over the next few years. The roof mount seems very practical, but it's a look that may turn off some buyers... buyers who care about looks. For SUVs, maybe it could be blended in with a roof air scoop, like on some off-road trucks. Or a light bar. Where is the LiDAR on the Atto 1? In the grille? How much worse is the field of view? How do you train a model to drive with LiDAR when the human drivers who generate the training data don\u2019t use LiDAR? Related: Volvo drops LIDAR...  https://www.carscoops.com/2025/11/volvo-says-sayonara-to-lid...  Are you serious, a car with Lidar sensor that's not even available in Bugatti Tourbillon that cost 500x more? Joking aside, this BYD Seagull, or Atto 1 in Australia (AUD$24K) and Dolphin Surf in Europe (\uffe118K in the UK), is one the cheapest EV cars in the world and selling at around \uffe16K in China. It's priced double in Australia and triple in the UK compared to its original price in China. It's also one of China best selling EV cars with 60K unit sold per month on average. Most of the countries scrambling to block its sales to protect their own car industry or increas", "negative": "Show HN: An interactive map of US lighthouses and navigational aids. Very cool. One bug I noticed though is if you continue to zoom out you lose some and then all lights. Or it's almost like it only shows the first X lighthouses? On Mac Safari, holding shift and using the magic mouse to scroll up or down reverses the zoom direction. This is both right (Shift-X is the reverse of X due to convention) \nBut is also wrong (Shift-Scroll is the macOS gesture for scrolling on maps where Scroll alone doesn't zoom in or out). TLDR: I really wish Apple would adopt the \"scroll up to zoom in\" convention used by the rest of the free world. Cool app. Might want to warn about seizures and migraines, though.  Some people are sensitive to flashing lights. I was surprised to find on an old USGS map (while researching a typo in the GNIS; it turns out the National Map Team is very responsive, they fixed the typo within 48 hours of reporting it) that there used to be Coast Guard navigation lights on the Ohio River. Makes perfect sense in hindsight, just never dawned on me that they would have responsibilities on large navigable rivers as well. Nothing in Michigan? The state with the most light houses out of any in the US? Neat! These might be useful to integrate with: OpenStreetMap (OSM) Wiki > OpenSeaMap:   https://wiki.openstreetmap.org/wiki/OpenSeaMap   https://map.openseamap.org/  \"Depth Data for Nautical Charts\"  https://github.com/osmandapp/OsmAnd/discussions/18116  Very cool. I wish we could add to these if it was generated with LLM. I understand a disclosure would help, but it would make those who have spent much care and attention stand out immediately as opposed to during bug season 59,000 navigational aids is a lot more than I expected. Nice work turning the USCG Light List into something browsable. Nice app but it really needs to allow the user to select the lights of interest before it displays. As noted in a different thread it has a display limit of 500 points and you need"}
{"anchor": "TikTok users can't upload anti-ICE videos. The company blames tech issues. well\u2026 i submitted it as  https://lite.cnn.com/2026/01/26/tech/tiktok-ice-censorship-g...  but i guess HN drops the lite off of it? le sigh, here\u2019s hoping  someone  can frontpage one of these tiktok censorship stories today\u2026? The forced US hosted tik-tok sale is all about hiding information from the US public that most people in the rest of the world have easy access to. On Twitter, there's a bunch of reports that TikTok suddenly prevents people from sending the word \"Epstein\" in DMs [1]. I had expected an Orbanisation (aka, what happened to the media sphere in Hungary after Orban took over and his cronies bought up almost all media) of Tiktok, but not that fast, it's like less than a week after the deal [2]. Scary shit if you ask me, and it's made scarier by the fact that Tiktok has already been changing the way our youth speaks due to evading censorship (e.g. \"graped\" instead of \"raped\", \"unalived\" instead of kill/murder/execute/suicide). [1]  https://x.com/krassenstein/status/2015911471507530219  [2]  https://techcrunch.com/2026/01/23/heres-whats-you-should-kno...  I hope for the good of mankind,  all  sides of politics unite against deplatforming and oppressing opposing viewpoints. It's sad that certain topics (anti-ICE, Epstein) neutered on a social media platform, but this went on for years when the politics were reversed. Let everyone have their say, I say. Is it a technical glitch that prevents the uploads? Or is it a technical glitch that let's people know that that content is being censored Anecdotal to myself. I shamefully sometimes use TikTok, I particularly like recipe clips and even I noticed something in the last week, most noticeably around this weekend where the algorithm for recommendations changed. It\u2019s like they completely wiped my preferences. I try not to watch anything political so I cannot say much about censorship of content but something was noticeable in the last wee", "positive": "alphaXiv: Open research discussion on top of arXiv. I remember seeing this idea some years ago. I think it was called qrxiv.org or something like that, but can't find it anymore. I hope this one has better luck, getting the users in the fragmented space of preprints can be a challenge. Hey alphaxiv, you won\u2019t let me claim some of my preprints, because there\u2019s no match with the email address. Which there can\u2019t be, as we\u2019re only listing a generic first.last@org addresses in the papers. Tried the claiming process twice, nothing happened. Not all papers are on Orcid, so that doesn\u2019t help. I think it\u2019ll be hard growing a discussion platform, if there\u2019s barriers of entry like that to even populate your profile. hnews tries to say one positive thing challenge impossible i always love any idea for curating high iq internet community This seems like a horrible idea. I know we need an alternative to peer review but an online comment section feels like something worse than that. This is great. Already loving the discussions/comments I see there. I believe this site is missing a very important thing, direct links to the different categories with a list of papers.\nThis is at least how I (and I believe many others) browse arXiv. I open it up in the morning, scroll through a few categories and open a few papers that look interesting to me. I could see myself using alphaxiv for that, and then, if there's a comment section, I might even read it, and, who knows, leave a comment. But there's no way I'm going to be changing the address or going to some other site to search for papers just to see whether there are some comments. ps: I see the extension adds a \"discussion\" link to arxiv, it is a pity that it is only available for Chrome. What's the main thing that this new website adds over scirate? Great idea. - The frontpage should directly show the list of papers, like with HN. You shouldn't have to click on \"trending\" first. (When you are logged in, you see a list of featured papers ", "negative": "Capital One to acquire Brex for $5.15B. Tough outcome for many involved given peak valuation @ 12B This looks like a bad deal for Brex as they were valued at 12 billion. Capital One got a nice discount.  https://www.ycombinator.com/companies/brex   https://www.clay.com/dossier/brex-funding   https://www.brex.com/  Fintech trading poorly. Also Brex didn't successfully make the AI pivot like their competitors at Ramp Why are people saying this seems like a bad deal? If they really only raised $1.7b, per Crunchbase, then this seems to me like a very good outcome for everyone involved except its late stage investors.  And, even for the late stage investors, they're breaking even. Pretty steep haircut from their $12b peak in 2022. And that's before you factor in their revenue that's grown 2.5* from ~$312M in 2022. If their figures are to be believed, Capital one is getting an asset growing 50% YoY, for just 7* revenues. Maybe just pull a Bending Spoons after the acquisition, layoff most of the staff, and bring a lot of ops in-house and they'll be in profit ASAP. Brex post:  https://www.brex.com/journal/brex-and-capital-one-join-force...  Feels like a great outcome for Brex. Mercury and Ramp seem to have been chipping away at their leadership position in recent years, so I wonder how their growth trajectory changed over that period. Sold for $5.15B. Brex last raised $300M in Oct 2021 at a $12.3B valuation. They refused my business because I didn't have SV VC money Chase got it instead, but they are losing it next month because of their shenanigans and greed Wish crypto hadn't been co-opted by the same people and worse Feels like they were first in the space but then somehow Ramp ran away from dev with a higher dev pace. Fascinating to see. The investors all have liquidity preferences so the ones that invested at higher valuations didn't lose any money. But all employees after 2021 are underwater. I wonder if they got any relief from management or if they got screwed. Ramp"}
{"anchor": "A (Long) Peek into Reinforcement Learning. Very nice! I also recommend the CS885 course from university of Waterloo which is all on YouTube. It covers Bayesian reinforcement learning which is missing from most courses (including this one). (2018) Has RL changed since then? Is anyone aware of a course that is beyond the basics and is focused on modern algorithms? If you want a (long) peek at RL read Sutton and barto. Amazing book. Curious what people here have built using RL? Lillian's writing is really crisp without compromising the technical details. I learnt reinforcement learning from Udacity course. It was one of the finest on the internet. Whenever I couldn't find some thing in the course I went to this website. I created my own small introductory course for RL, a pure hands-on experience for learners. Here a link to the lecture playlist:  https://www.youtube.com/playlist?list=PLdAoL1zKcqTXFJniO3Tqq...  This page covers the basics which are pretty timeless. You'd want to understand this before learning about any more recent advances. It doesn't get into state of the art algorithms, for example proximal policy optimisation isn't mentioned although the paper on this was published in 2017 and is probably considered the best algorithm for at least some applications. It sort of depends on which direction you want to go in. If you're interested in deep RL as applied specifically to LLMs, I'd second another commenter's recommendation of Spinning Up from OpenAI. It hasn't been updated for a while and is a little outdated, but it provides a really nice introduction to some key ideas like PPO:  https://spinningup.openai.com/en/latest/user/introduction.ht...  If you want to get more of a bird's eye view of modern deep RL in general, then HuggingFace's course is a good place to start. The course itself is kind of \"all over the place\"\u2014not necessarily a bad thing, just maybe not what you want if you're looking to go super deep on a single topic. But if you want to get a look", "positive": "Over 40% of deceased drivers in vehicle crashes test positive for THC: Study. I\u2019m not surprised so many deceased drivers were under the influence of THC. I see people smoking and vaping at stoplights all the time. I am however, surprised this study claims legalization didn\u2019t change the rate. Anecdotally, on the west coast, I\u2019ve seen far more of this, and also people casually smoking in public spaces (parks or train stations or whatever) since legalization. And what share of the remaining 60% were killed by the initial 40%? I am curious what percentge of the general populous test positive for THC. It would give better context to a dead drivers testing positive for THC. Feels like a low sample size, but I'm not statistician or doctor. That said, almost everyone I know that consumes THC has no qualms driving while doing it, and many of them also at work. It's a huge peeve of mine. Based on the headline, I was guessing it was any amount of positivity, and may be close to the population level, but it's actually impairment levels of THC: > In a review of 246 deceased drivers, 41.9% tested positive for active THC in their blood, with an average level of 30.7 ng/mL \u2014 far exceeding most state impairment limits. Since COVID in CA, it feels like driving has become far more dangerous with much more lawlessness regarding excessive speeding and running red lights,  going into the left lane to turn right in front of stopped cars, all sorts of weird things. But I can't tell if my anecdotes are significant. It seems that Ohio's impaired drivers have been consistent through the past six years though. Is there a full study somewhere? I'd expect them to screen for other psychoactive substances as well, of which I see no mention here. Whenever you think to yourself \"People couldnt be that stupid, right?\" read this study and plan accordingly. Wish the paper were available - would love to know the percentage with alcohol. The other question I have - my prior is that a bad driver (tired, d", "negative": "Claude Code's new hidden feature: Swarms.  https://xcancel.com/NicerInPerson/status/2014989679796347375  In his second post he included a link to GitHub:  https://github.com/mikekelly/claude-sneakpeek  Isn't this pretty much what Ruv has been building for like two years?  https://github.com/ruvnet/claude-flow  Listen team lead and the whole team, make this button red. It feels like Auto-GPT, BabyAGI, and the like were simply ahead of their time Answering the question how to sell more tokens per customer while maintaining ~~mediocre~~ breakthrough results. Claude Code in the desktop app seems to do this? It's crazy to watch. It sets of these huge swarms of worker readers under master task headings, that go off and explore the code base and compile huge reports and todo lists, then another system behind the scenes seems to be compiling everything to large master schemas/plans. I create helper files and then have a devops chat, a front end chat, an architecture chat and a security chat, and once each it done it's work it automatically writes to a log and the others pick up the log (it seems to have a system reminder process build in that can push updates from other chats into other chats. It's really wild to watch it work, and it's very intuitive and fun to use. I've not tried CLI claude code only claude code in the desktop app, but desktop app sftp to a droplet with ssh for it to use the terminal is a very very interesting experience, it can seem to just go for hours building, fixing, checking it's own work, loading it's work in the browser, doing more work etc all on it's own - it's how I built this:  https://news.ycombinator.com/item?id=46724896  in 3 days. I'm already burning through enough tokens and producing more code than can be maintained - with just one claude worker. Feel like I need to move into the other direction, more personal hands-on \"management\". A guy who worked at docker on docker swarm now works at Anthropic so makes sense How is this different fro"}
{"anchor": "Purely Functional Sliding Window Aggregation Algorithm. This is a very interesting algorithm which is more or less known in the folklore, but is still relatively obscure. I have used it as a part of temporal logic monitoring procedure:  https://github.com/Agnishom/lattice-mtl/blob/master/src/Moni...  This is similar to an approach I use but instead of a queue, I accomplish this using a ring buffer that wraps around and overwrites entries older than window size. We maintain a global window aggregate, subtract ring buffer slot aggregate for entries dropping out and accumulate new entries into new slot aggregate while adding it to the global aggregate. Everything is o(1) including reads, which just returns the global window aggregate. That was a well written and easily approachable blog post on what I found to be an interesting topic. Aside from the topic itself, I think I also learned a bit about structuring technical articles. Competitive Programming in Haskell...I can only define this as Masochistic Aesthetics... I have made a quick c++ implementation for those unfamiliar with Haskell :  https://gist.github.com/unrealwill/5ca4db9beefafaa212465277b...  The queue method is popular, but there's a much faster (branch-free) and in my opinion simpler way, known as the van Herk/Gil-Werman algorithm in image processing. It splits the input into windows and pairs up a backward scan on one window with a forward scan on the next. This works for any associative function. I was very surprised when I learned about it that it's not taught more often (the name's not doing it any favors)! And I wrote a tutorial page on it for my SIMD-oriented language, mostly about vectorizing it which I didn't quite finish writing up, but with what I think is a reasonable presentation in the first part:  https://github.com/mlochbaum/Singeli/blob/master/doc/minfilt...  I also found an interesting streaming version here recently:  https://signalsmith-audio.co.uk/writing/2022/constant-time-p...  EDIT:", "positive": "NanoChat \u2013 The best ChatGPT that $100 can buy. Wow, how do we sign up for the Eurekalabs course and how much does it cost? I've always thought about the best way to contribute to humanity: number of people you help x how much you help them. I think what Karpathy is doing is one of the highest leverage ways to achieve that. Our current world is build on top of open source projects. This is possible because there are a lot of free resources to learn to code so anyone from anywhere in the world can learn and make a great piece of software. I just hope the same will happen with the AI/LLM wave. Eureka Labs:  https://github.com/EurekaLabsAI  What a prolific person Andrej is. It's been more than amazing to follow along! Here's the announcement post [0] from Karpathy, which provides a bit of additional context. [0]  https://x.com/karpathy/status/1977755427569111362  > Thank you to chief LLM whisperer   Alec Radford for advice/guidance. oh man an Alec x Andrej podcast would BREAK THE INTERNET... just saying... going from glory days of GPT1 to now building GPT3? in 4 hours Should be \"that you can train for $100\" Curios to try it someday on a set of specialized documents. Though as I understand the cost of running this is whatever GPU you can rent with 80GB of VRAM. Which kind of leaves hobbyists and students out. Unless some cloud is donating gpu compute capacity. >If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for --device_batch_size in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. That sounds like it could run on a 24gb GPU. Batch size of 8 would imply 20gb mem, no? ...presumably just takes forever This weekend I just cracked into nanoGPT ( https://github.com/karpathy/nanoGPT ), an older but fabulous learning exercise where you build and train a crappy shakespeare GPT with ~0.8M parameters on a cpu. Results are about what you'd expect from that, they", "negative": "Exercise can be nearly as effective as therapy for depression. This is a finding that keeps coming up, and I've certainly found it true in my life, but there's a significant chicken-and-egg problem in that depression frequently precludes the motivation to exercise, and if you don't already have a deeply-disciplined routine to overcome the lack of motivation, people won't do it. Exhortation to develop those good habits in the good times, I suppose. I take this to mean therapy for depression (particularly for men) is barely effective at all and exercise is not quite as barely effective at all. If therapy for depression were a pill, I'm not sure it'd demonstrate enough efficacy to get approved. It's almost as if humans were optimized to constantly move around all day by evolution. Huh. Who would have thought. I will speak from my experience. I have diabetes and I try to manage it well, with workout. But sometimes when the sugars are high for a while, I can feel it, the sadness, the hopelessness. It took me a while to understand that is high sugar levels and a mild form of depression. Now I will do some workout when I feel that and after a little workout, I can see how my mind also start to feel better. This is not a solution for everyone who is experiencing depression probably but might help some who are experiencing because of high sugar levels. If it helps anyone I take antidepressants and have had a positive experience with them. Depression can be caused by a chemical imbalance and no amount of exercise or talking about it will fix it. One of the most frustrating things when your really low is people giving advice like do exercise to feel better - please don\u2019t do this. I decided to go unmedicated from SSRIs/mood stabilizers in 2024 and it changed my life for the better. Prior to stopping, I thought I was physically unhealthy until I found out excessive overheating & exhaustion was a common side effect of Zoloft. Since then, I've lost around 40 pounds and have been a"}
{"anchor": "BYD's cheapest electric cars to have Lidar self-driving tech. Lidars come down in price ~40x.  https://cleantechnica.com/2025/03/20/lidars-wicked-cost-drop...  Meanwhile visible light based tech is going up in price due to competing with ai on the extra gpu need while lidar gets the range/depth side of things for free. Ideally cars use both but if you had to choose one or the other for cost you\u2019d be insane to choose vision over lidar. Musk made an ill timed decision to go vision only. So it\u2019s not a surprise to see the low end models with lidar. Keep in mind, that $25k AUD is just $16600. And for that price, you're getting a real car with driver-assist features and a reasonable crash safety rating. The US car manufacturers are cooked. Still not convinced of the safety of lidar. I guess all these cars with cheap lidar sensors on board will generate real world safety data over the next few years. The roof mount seems very practical, but it's a look that may turn off some buyers... buyers who care about looks. For SUVs, maybe it could be blended in with a roof air scoop, like on some off-road trucks. Or a light bar. Where is the LiDAR on the Atto 1? In the grille? How much worse is the field of view? How do you train a model to drive with LiDAR when the human drivers who generate the training data don\u2019t use LiDAR? Related: Volvo drops LIDAR...  https://www.carscoops.com/2025/11/volvo-says-sayonara-to-lid...  Are you serious, a car with Lidar sensor that's not even available in Bugatti Tourbillon that cost 500x more? Joking aside, this BYD Seagull, or Atto 1 in Australia (AUD$24K) and Dolphin Surf in Europe (\uffe118K in the UK), is one the cheapest EV cars in the world and selling at around \uffe16K in China. It's priced double in Australia and triple in the UK compared to its original price in China. It's also one of China best selling EV cars with 60K unit sold per month on average. Most of the countries scrambling to block its sales to protect their own car industry or increas", "positive": "A real-time 3D digital map of Tokyo's public transport system. Very cool. Even the building-by-building graphics seem to be correct: a boxy version of my house in Yokohama is in the correct location and has the correct height relative to its neighbors. The map also shows\u2014correctly\u2014that it is raining at this moment in Tokyo but not in Yokohama. This is great, however on first load I didn't get the trains moving. After a refresh they showed up again. Currently sitting on the Yokohama line to Hachioji, a little before Hashimoto station. Looking at the map the train had already reached Hashimoto. Seems like we're running 30 seconds or maybe 1 minute late. Do any of the 'live' camera feeds work? They're all static for me. This is super cool, though. Wow, I love that it shows live flights and airplanes! This is really awesome, I love the way you integrated the live camera feeds. Looking at this map makes me want to move to Tokyo. Sure, the trains stopping at night makes nightlife and catching a morning flight annoying, but train culture* of just making plans to meet at a train station with a friend is so much better than the car dependent place I live. *It's not unique to Tokyo, but I've spent extended periods of time in cities with trains and this is what we often did. Tokyo just has lots of train lines. I saw 3D in the title and assumed it was a cross-section view of the subway tunnels underground. An implementation like that would be a potential security risk to public infrastructure. Berlin edition:  https://www.vbb.de/fahrinfo , there was also a version in a similar 3D style but I wasn't able to dig it up through the search. Related thread with more of these kind of projects:  https://news.ycombinator.com/item?id=32647227  That was disappointing I thought I would see the 3D train track tubes and how deep they are and their position from each other in 3D I just came from working remotely from Japan for almost two months. One of the highlights was the infrastructure fo", "negative": "I'm 34. Here's 34 things I wish I knew at 21. The days are long, but the years are short Congrats, you're half way there to publish your first self-help book! > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. It really seems quite difficult for straight men to succeed at this. > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. You must succeed. I'm not sure I like the framing of this Sex and violence intersect and interweave. It's not realistic to avoid any hurt. > One day \u2013 probably somewhere between 28 and 38 \u2013 you'll wake up and just feel 'off'. A bit sore. A bit tired. That feeling will never leave you. Be grateful for your youth while you have it. This happened when I was 20. I don't know what else to say other than, it fucking sucks. 35. Women can be as horny and lonely as men and all you need to do is talk to them to meet them. This was a revelation to me in my early-thirties. > Eating meat is quite clearly immoral. Unless it will be detrimental to your health, eat as little as possible. Carnivorous animals, are they immoral? >If you're a man, one of your hardest battles may be not giving in to sexual urges that cause harm to others. What the ... Some great life lessons here, but also some I don't agree with: - The lazy person works twice as hard.\nOften I found you can save a lot of time just trying to the minimal possible and gain a lot of insights of why something is minimal vs not -The opinion of the person who rarely offers it is listened to more closely.\nI found the opposite to be true, those who don't offer their thoughts frequently are often dismissed when they do want to share something Anyway, many of the points are great.. I would also add to k"}
{"anchor": "We put Claude Code in Rollercoaster Tycoon. Can't wait for someone to let Claude control a runescape character from scratch Would a way to take screenshots help? It seems to work for browser testing. > We don't know any C++ at all, and we vibe-coded the entire project over a few weeks. The core pieces of the build are\u2026 what a world! The opening paragraph I thought was the agent prompt haha > The park rating is climbing. Your flagship coaster is printing money. Guests are happy, for now. But you know what's coming: the inevitable cascade of breakdowns, the trash piling up by the exits, the queue times spiraling out of control. Edit: HN's auto-resubmit in action, ignore. > The only other notable setback was an accidental use of the word \"revert\" which Codex took literally, and ran git revert on a file where 1-2 hours of progress had been accumulating. Interesting article but it doesn\u2019t actually discuss how well it performs at playing the game. There is in fact a 1.5 hour YouTube video but it woulda been nice for a bit of an outcome postmortem. It\u2019s like \u201chere\u2019s the methods and set up section of a research paper but for the conclusion you need to watch this movie and make your own judgements!\u201d > kept the context above the ~60% remaining level where coding models perform at their absolute best Maybe this is obvious to Claude users but how do you know your remaining context level? There is UI for this? This is a cool idea. I wanted to do something like this by adding a Lua API to OpenRCT2 that allows you to manipulate and inspect the game world. Then, you could either provide an LLM agent the ability to write and run scripts in the game, or program a more classic AI using the Lua API. This AI would probably perform much better than an LLM - but an interesting experiment nonetheless to see how a language model can fare in a task it was not trained to do. Wonder how it would do with Myst. This is what I want but for PoE/PoE2 builds. I always get a headache just looking at ", "positive": "Carnap \u2013 A formal logic framework for Haskell. Past experience in logical frameworks tend to specify documentclass: script, letter, report, etc. If you were wondering, the name comes from a famous philosopher and logician:  https://en.wikipedia.org/wiki/Rudolf_Carnap  An Open Tower project. Copyright 2015-2024. Doesn't look like it is been updated in a while. And the GitHub repos last commits are even older. Dead project? I don't like the trend of naming software projects after real people. It makes web search harder both for people who try to find the person and for people who try to find the project. For something similar, but in Python, I made this a while ago:  https://logics.readthedocs.io/en/latest/  GUI here:  https://taut-logic.com/  Thanks... you just ruined it. I was so happy that finally that splendid slumber during transportation was finally getting the recognition it so richly deserves. ;) I think that's probably unlikely given the long list of universities using it[0]. It's an educational tool for formal propositional logic which hasn't really changed much on 100 years, so probably not a lot of updates are required unless there are big new updates to Haskell itself. [0]  https://carnap.io/about  Hey, Carnap creator here. Definitely not dead (still actively used by plenty of universities), but pretty stable these days. I don't like the trend of naming computer hardware after fruit. Oh I know what I'm doing on my lunch break today. I, too, made something similar in Python -- but simpler and less polished:  https://jon-jacky.github.io/FLiP/www/   https://github.com/jon-jacky/FLiP/  Ha, I\u2019ve been familiar with Carnap for probably a decade and it took your comment for me to realize his name is Car Nap. +1 It seems to of had the web app portion updated a year ago. And as you say, the application itself looks \u2018done.\u2019 I have frequently used Common Lisp over the last 40 years, and I hear comments about libraries being old and not updated in many years: so what!", "negative": "Tell HN: I cut Claude API costs from $70/month to pennies. Can you discuss a bit more of the architecture? Are you also adding the proper prompt cache control attributes? I think Anthropic API still doesn't do it automatically Consider using z.ai as model provider to further lower your costs. It sounds like you don\u2019t need immediate llm responses and can batch process your data nightly? Have you considered running a local llm? May not need to pay for api calls. Today\u2019s local models are quite good. I started off with cpu and even that was fine for my pipelines. This is the way. I actually mapped out the decision tree for this exact process and more here:  https://github.com/NehmeAILabs/llm-sanity-checks  Have you looked into  https://maartengr.github.io/BERTopic/index.html  ? You also can try to use cheaper models like GLM, Deepseek, Qwen,at least partially. As much as I like the Claude models, they are expensive. I wouldn't use them to process large volumes of data. \nGemini 2.5 Flash-Lite is $0.10 per million tokens. Grok 4.1 Fast is really good and only $0.20. They will work just as well for most simple tasks. consider this for addtl cost savings if local doesnt interest you -  https://docs.cloud.google.com/vertex-ai/generative-ai/docs/m...  Pretty straightforward. Sources dump into a queue throughout the day, regex filters the obvious junk (\"lol\", \"thanks\", bot messages never hit the LLM), then everything gets batched overnight through Anthropic's Batch API for classification. Feedback gets clustered against existing pain points or creates new ones. Most of the cost savings came from not sending stuff to the LLM that didn't need to go there, plus the batch API is half the price of real-time calls. This is what i was going to suggest too. Do they or any other providers offer any improvements on the often-chronicled variability of quality/effort from the major two services e.g. during peak hours? Or minimax - m2.1 release didn't make a big splash in the news, but it'"}
{"anchor": "Show HN: Comet MCP \u2013 Give Claude Code a browser that can click. Claude Code now does this natively without need for a 3rd party browser like Comet:  https://support.claude.com/en/articles/12012173-getting-star...  Did you try that one ?  https://chromewebstore.google.com/detail/blueprint-mcp-for-c...  I was going to ask what makes this better than just using Playwright and this largely answers that question. I will have to try it out and see how it compares. I haven't really had luck with MCP in general for quite a while though. I have just been using Google Antigravity for most of my vibe coding needs. Anyone know of any good articles around having claude code build playwright test suites for a given website and parameters? Claude in Chrome is excellent - as is Claude in Excel. I was shocked at how useful the latter is. \"claude --chrome\" does this out of the box and works pretty well. Another day, another MCP server. Wake me up when we stop needing a new protocol for every AI tool to talk to every other AI tool. There is Browser MCP that works reasonably well:  https://browsermcp.io/  What's the difference? I didn\u2019t realize AI could interact with browsers like this already (guess I\u2019m naive).  Isn\u2019t this setting up for the scenario where the AI is duped into logging into your bank account and transferring your money away?   Not sure I have enough trust to allow an AI to touch a browser. I tried it. My Perplexity premium expired, maybe that is it, but it barely did anything. When I put prompt you suggested, it did open Perplexity in Comet and then I guess didn't get response even though Perplexity did research, so it used regular search mcp to get results... It is cool idea, this is what I would like to have, something to automate boring stuff. Find all LinkedIn connections that are not active and remove them from my network for example. I don't think it is your mcp or code, as tech is just not there yet. It is much easier to accomplish this through other automations", "positive": "Day Fifteen of Iran's Nationwide Protests: Sharp Rise in Human Casualties. nationwide protests in the US  https://www.msn.com/en-us/news/us/protests-against-ice-plann...   https://www.nytimes.com/2026/01/10/us/ice-shooting-protests-...   https://www.cnn.com/2026/01/11/us/ice-protests-shootings-min...  Israel is openly committed [0] to seeing regime change in Iran; they were mowing down civilian and military leadership just last year. The US got involved. There is the history of western involvement [1] in overthrowing Iranian governments. With that background I'm more worried about what the US's role here will be rather than what may or may not be taking place in Iran. My understanding is that the simulations around an invasion of the country were even more disastrous than the excursions in Afghanistan and Iraq and we really could use some signals of competence out of the US right now. We seem to be dangerously far into a WWI or WWII style environment internationally and we're already past the threshold of nuclear risk that sane actors would accept. [0]  https://en.wikipedia.org/wiki/Iran%E2%80%93Israel_war  [1]  https://en.wikipedia.org/wiki/Iran#Mosaddegh_and_the_Shah's_...  The US and AU both have told citizens to get out of Iran in the last 24-48 hours. If they are unable to they should shelter in place. I think it's about to kick off. US:  https://ir.usembassy.gov/iran-security-alert-land-border-cro...  AU:  https://www.smartraveller.gov.au/destinations/middle-east/ir...  Notice how hard people work to burry reports of atrocities that are committed by the Islamic Republic. Things are not what they appear. In both cases the protests won't achieve much because half the population supports the government, and in both cases the half that supports the government is better armed. It's so strange. There is a real place on Earth which is much more brutal and oppressive than the wildest fantasy that Margaret Atwood could come up with. A place that rapes virgins before ex", "negative": "The struggle of resizing windows on macOS Tahoe. From \" Safari 15 on Mac OS, a user interface mess \"  https://morrick.me/archives/9368  from 5 years ago: --- start quote --- The utter user-interface butchery happening to Safari on the Mac is once again the work of people who put iOS first. People who by now think in iOS terms. People who view the venerable Mac OS user interface as an older person whose traits must be experimented upon, plastic surgery after plastic surgery, until this person looks younger. Unfortunately the effect is more like this person ends up looking\u2026 weird. These people look at the Mac\u2019s UI and (that\u2019s the impression, at least) don\u2019t really understand it. Its foundations come from a past that almost seems inscrutable to them. Usability cues and features are all wrinkles to them. iOS and iPadOS don\u2019t have these strange wrinkles, they muse. We must hide them. We\u2019ll make this spectacular facelift and we\u2019ll hide them, one by one. Mac OS will look as young (and foolish, cough) as iOS! --- end quote --- At the time it was only Safari that they wanted to \"modernize\". Now it's the full OS. tribunals the cherry on top is the delay between the drag start and the window begining to resize Of all the Linux features to copy, they chose this. Apple's window management has always sucked, with the absurdly crippled resizing being a longstanding embarrassment. Into the 2000s, the only way you could resize a window on the Mac was to drag its lower-right corner. That is it. NO other corner, and no edge. So if the lower-right corner happened to be off-screen because the window was bigger than the screen, you were kind of screwed. You had to fiddle with the maximize & restore gumdrops to trick the OS into resizing the window to make that ONE corner accessible. Then you had to move the corner, then roll all the way up to the title bar and move the window, then roll back down to the corner... until you had the window sized and positioned as you wanted. When Apple gru"}
{"anchor": "Traintrackr \u2013 Live LED Maps. I have the London board in my living room. It's one my favorite parts of the house. Can't recommend it enough. Wow this is presented exactly the same as the flight data led display. It is odd that the advertising method and the comments are similar to the previous. Train Trackr is great, and the weather one is also good too. If you are less into trains (heresy) but still want to look at unusual maps  https://raildar.co.uk/map/KGX  is your place to go. its a  live  junction schematic of any train junction in the UK. Shameless self promotion. I make these:  https://www.stationdisplay.com/  London underground looks awesome, but I can't imagine it having even the vaguest utility in terms of knowing when to leave the house. The data behind these comes from the Darwin feed (National Rail's real-time data) which is surprisingly good once you get past the initial authentication setup. Network Rail also publishes movement data via their OpenData platform if you want to go deeper - actual track circuits and signalling block occupancy. What I find interesting is how these physical displays handle the inevitable \"ghost trains\" in the feed - cancelled services that still show as running, or trains that briefly appear in the wrong location. The software problem is messier than the hardware. Wish it included the overground! The blog is a much more interesting read than the product site:  https://blog.traintrackr.io  I put the NYC one in the office. It\u2019s a good conversation starter and mildly mesmerizing. ayyyyy great to see someone from my local hacking community on the front page! Hi everyone, Richard here, the creator of these traintrackr boards. It's great to see this on the front page! I've been designing PCBs for years, and designed over 250 at last count. We have a couple of products in the pipeline to come out this year, but I'd love to hear what you think we should build next. I have one of these for Boston. It's awesome. I want to find more ar", "positive": "Roam 50GB is now Roam 100GB. Nice that instead of completely cutting you off at the cap they put it in super slow 500 kbits. That is actually usable and used to be the fastest speed you could get at home. That's not bad for the cheap plan. Even the slow mode is fast enough for video conferencing and doing basic remote work. They still have a separate unlimited plan for anyone who needs more. I\u2019ve kept it on the backup service for 10 GB at $10 or whatever and it\u2019s pretty cool. Used it off my balcony in SF when Google Fiber had a 1 hr outage, take it on road trips, and stuff like that. Totally worth it. I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff. Aside from the fact it allows you to work with Starlink to buy more fast speed, it also allows core stuff to continue to function (e.g. basic notifications, non-streaming web traffic, etc). They could make it 1000GB for US$10/month and I still wouldn't give any money to a company associated with that man. Finally I can use Codex/OpenCode even out in the woods. No work-life balance; just vibing everywhere I go. I had a \u201chit\u201d post on bsky [0] (90 likes, big numbers for me) asking whether people would want an unlimited mobile plan throttled at 256kbps for $2/month. Seems like yes? There\u2019s lots to say about how useable it is (I often get throttled when traveling and it\u2019s really not that bad + it helps curb any desire to scroll videos!) But mainly I want to ask - I looked into it for a minute and it seems like you couldn\u2019t start an mvno because carriers wouldn\u2019t let you cannibalize them? You can get very cheap IoT plans but if you tried reselling IoT as esims for consumers, the carriers would kill it? So yeah - Starlink to mobile is actually the only viable way that routes around this problem? (((email in profile if you\u2019re cuckoo enough like me and want to start a self service\u2019d throttled mvno))) [0]  https://bsky.app/profile/greg.technology/post/3mbmwsytnyc23  I want the old plan back. If ", "negative": "Emissary, a fast open-source Java messaging library. Emissary is a simple-to-use, no dependency, yet BLAZING FAST messaging library for decoupling messages (requests and events) and message handlers. Emissary aims to take advantage of the simplicity of using the annotations for handlers (e.g. @RequestHandler/@EventHandler) without the drawbacks of reflection (slow). What differentiates Emissary from other messaging/dispatch libraries? It takes advantage of java.lang.invoke.LambdaMetafactory to avoid the cost of invoking methods reflectively. This results in performance close to directly invoking the request handler and event handler methods. ~ 1000% more throughput compared to other similar libraries (Spring's ApplicationEventPublisher, Pipelinr, EventBus)\n~ 90% faster compared to other similar libraries (Spring's ApplicationEventPublisher, Pipelinr, EventBus) Benchmarks found on the GitHub repository:  https://github.com/joel-jeremy/emissary?tab=readme-ov-file#p...  Naming collision with an ActivityPub server  https://emissary.dev/  I'm a big fan of Guava's EventBus. Easy to implement and straightforward to understand. This library does seem to require more setup and I don't see the immediate advantages, also why does it require an instanceProvider? I don't understand what that does. Assuming that you are the author of Emissary, this could be a Show HN, I think.  https://news.ycombinator.com/showhn.html  Are you planning to add persistent events as well, so that events are not lost due to crashes And i2p rust router  https://github.com/altonen/emissary  Emissary really shines if performance is a top priority. The setup is more or less similar, you register a bunch of event handlers when initializing the library. The main difference is that, in addition to events, Emissary also supports \"request\" messages. Requests enforce the invariant that only one handler should handle it - if there are multiple handlers registered for a given request, Emissary will throw an erro"}
{"anchor": "Show HN: OpenTimes \u2013 Free travel times between U.S. Census geographies. Looks cool. Please allow high max zoom levels, it\u2019s hard to see individual street details on mobile. Amazing! GitHub actions to compute a giant skim matrix is an incredible hack. I pretty regularly work with social science researchers who have a need for something like this... will keep it in mind. For a bit we thought of setting something like this up within the Census Bureau, in fact. I have some stories about routing engines from my time there... Well done, dfsnow! * some islands seem hamstrung by the approach - see Vashon Island for example. * curious what other dataset you might incorporate for managing next level of magnitude smaller trips - e.g. getting a quarter mile to the store for a frozen pizza at the seventh inning stretch. Any plans on adding public transit? It seems that it ignores bridges over rivers making the travel time wildly inaccurate. This is great! I've been thinking about building something like this for ages since I started using Smappen [0] for mapping travel times on road trips. Super useful way to travel if you're on an open-ended trip with flexibility. [0]  https://www.smappen.com/  OK the way you're publishing the data with Parquet and making it accessible through DuckDB is  spectacular . Your README shows R and Python examples:  https://github.com/dfsnow/opentimes?tab=readme-ov-file#using...  I got it working with the `duckdb` terminal tool like this:     INSTALL httpfs;\n  LOAD httpfs;\n  ATTACH 'https://data.opentimes.org/databases/0.0.1.duckdb' AS opentimes;\n\n  SELECT origin_id, destination_id, duration_sec\n    FROM opentimes.public.times\n    WHERE version = '0.0.1'\n        AND mode = 'car'\n        AND year = '2024'\n        AND geography = 'tract'\n        AND state = '17'\n        AND origin_id LIKE '17031%' limit 10;   Travel time context in general could be useful for retrieval before ranking in searches like Yelp or Google maps like products for nearby events a", "positive": "Ask HN: What non-fiction do you read?. Jaws: The Story of a Hidden Epidemic Modern environments and lifestyles have changed our jaw development dramatically, contributing to the high prevalence of sleep-disordered breathing (snoring through to obstructive sleep apnea), chronic tension, jaw joint problems, and orthodontic need. \"The Molecule of More\" by Daniel Z. Lieberman and Michael E. Long. A bit naive but fascinating narrative about how dopamine controls our feelings, addictions, and, basically, happiness. \"Future Noir: The Making of Blade Runner\" by Paul Sammon A deep history of the making of the movie \"Blade Runner\". Very enjoyable if you liked the movie. Pilgrim at Tinker Creek by Annie Dillard Your Inner Fish: A Journey Into the 3.5-Billion-Year History of the Human Body\n - Really cool account of human evolutionary history Stolen Focus (Johann Hari)\n - About how we've lost (and can regain) the ability to focus due to technological distraction (currently social media, etc. but hasn't always been) Chip War\n - History and geopolitical significance of the semiconductor industry Plato's works surrounding Socrates' death: Phaedo, Crito, Euthyphro, The Apology. Its fascinating to discover how many thoughts and ideas they had which are still relevant in our societies today. Also, they are incredibly readable, its like taking part in on a conversation among friends. I only read non-fiction; mostly philosophy. Here are some books off the top of my head: * The Inner Citadel/Philosophy as a Way of Life by Pierre Hadot * Plato's dialogues (someone already mentioned a few of them, but the Republic was missing from their list). * Epictetus (Discourses and Enchiridion) * The various essays/letters of Seneca * Matter and Consciousness by Churchland (older, but fascinating) * The Mediations of Marcus Aurelius * (mostly) any Buddhist texts * What a Plant Knows * Moonwalking with Einstein There are tons of fascinating books, way too many to list. All Pulitzer price winning non-f", "negative": "Ask HN: Books to learn 6502 ASM and the Apple II. Pretty much the best resource available:  https://6502.org/  Check the books section and find something that compels you. Also, don't forget the HUGE number of resources for 6502 assembly programming that are available in the  https://archive.org/  magazine and book sections:  https://archive.org/search?query=6502  Rodney Zaks' books are great - I like especially \"6502 Games\", which taught me a lot back in the day:  https://archive.org/download/6502g/6502Games.pdf  I'm also especially fond of the easy6502 emulator - its a very handy tool to have while studying 6502 techniques:  https://skilldrick.github.io/easy6502/  Its not absolutely necessary to learn BASIC before Assembly, but it will definitely help you understand the resources of the machine better if you can debug BASIC ROM code.  My personal 6502 platform of choice, the Oric-1/Atmos machines, has a pretty great ROM disassembly available, from which a lot of great knowledge can be obtained - but it does of course first require an undersanding of BASIC. In case you're curious, the Oric-1 ROM Disassembly:  https://library.defence-force.org/books/content/oric_advance...  (You can get an Oric emulator named Oricutron, or you can access a virtual Oric here:  https://oric.games/  ..) Good luck! This is the book I used when I was writing serial drivers for Apple II ProDOS:  https://archive.org/details/6502_Assembly_Language_Programmi...  And I have a vague memory of this book:\n https://archive.org/details/aiimp/mode/2up  Not sure what level you're at, but I can't remember if this is the text Jef Raskin wrote, but it's a decent backgrounder:\n https://archive.org/details/aiirm/mode/2up  I believe one of the \"standard works\" to learn 6502 back in the day was  Programming the 6502  by Rodnay Zaks. It's out of print, but it was printed in a lot of copies so you should be able to find one second-hand. I'm seconding the recommendation to look at Rodnay Zack's books. For exa"}
{"anchor": "My stages of learning to be a socially normal person. I don't have much to add to this right now other than to say this is really fantastic writing. I don't normally enjoy \"my journey\" kind of blog posts, but this one feels full of valuable insights, and I'm grateful to the author for sharing. It's also just nice to read something written by a skilled writer. I wish I had the drive to do as much work as the author has. Instead I will live more or less where I am now, stably in social mediocrity, perpetually somewhat impedance mismatched with the people around me. really identify. especially with the early yearning to connect and not having the skills. Learned sooo much over the years by being brutally rejected and eventually taking stock of what happened and extracting a rule or two. but then, yeah, next phase, rules don't matter (except when they do) and change moment to moment anyway. funny to read this here on hacker news of all places, where I let my carefully managed, almost always inhibited, childhood nerd self fly free in the comments. OP has definitely gone beyond me in many ways, with his talk about embodiment, and being able to be so empathic that he has elicited tears of gratitude. Enviable. >  I was probably the most severely bullied kid at my school. >  I was demonstrating my erudition Those two things might have been linked. I wasn't there, but I'm suspicious. Fortunately the author learns better by the end of the article, but it stuck out to me because LLMs have made people suspicious of five dollar words like delve so to use the word erudition in this day and age is a choice. Appreciate the writing and the author's fortitude in achieving their goals. While I never had friends, neither online nor in person, I cannot identify with this at all - it reads like a strange, obsessive seeking of external validation which I have never felt myself. Maybe I am just disinterested in people in general. I eat at Chinese restaurants where my waiter is a QR code. Pl", "positive": "Functional programming and reliability: ADTs, safety, critical infrastructure. This article seems to conflate strong type systems with functional programming, except in point 8. It makes sense why- OCaml and Haskell are functional and were early proponents of these type systems. But, languages like Racket don\u2019t have these type systems and the article doesn\u2019t do anything to explain why they are _also_ better for reliability. >In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. This reliability isn't done by being perfect 100% of the time. Things like being able to handle states where transactions don't line up allowing for payments to eventually be settled. Or for telecom allowing for single parts of the system to not take down the whole thing or adding redundancy. Essentially these types of businesses require fault tolerance to be supported. The real world is messy, there is always going to be faults, so investing heavily into correctness may not be worth it compared to investing into fault tollerance. I'm wary of absolute statements about programming. I like good type systems, too, but they won't save you from bugs that are better addressed by fuzz testing, fault injection testing and adversarial mindset shifts. Strong types: yes, it\u2019s definitely better Functional programming: no, functional programming as in: the final program consists in piping functions together and calling the pipe. In my opinion, that tends to get in the way of complex error handling. The problem being that raising Exceptions at a deep level and catching them at some higher level is not pure functional programming. So your code has to deal with all the cases. It is more reliable if you can do it, but large systems have way too many failure points to be able to handle them all in a way that is practical. I think there is a strong case that ADTs (algebraic data types) aren't so great after all. Specifically, the \"tagged\" unions of ADT languages like Haskell ", "negative": "San Francisco coyote swims to Alcatraz. I would be surprised if the Coyote would be quick to get back into the water after such a difficult swim. It would, I suspect, want to recover and find food. So I support the theory the Coyote is just hiding somewhere. The island is small but not that small that it couldn\u2019t hide somewhere. I wonder if a turtle drowned halfway across. If a Coyote could do it, all those famous escapees must have had too. That roadrunner thought he'd be safe hiding out on the notorious prison island... It's a 1.5mi swim. I remember visiting Angel Island (a 0.5mi swim) and seeing the abundance of raccoons they have, and asked a ranger how they got there. They also swam. Growing up on a lake I would regularly watch deer swim the quarter mile back and forth between the shore and a nearby island, with no problem. Video:  https://www.youtube.com/watch?v=br4-VsvRcII  Poor thing, talk about going in the wrong direction :) Impressive though. If you time things right, and don't get swept out to sea, it's the 54 degree water that is the real danger. I'm no medical person, but it sure seems like that the animal is suffering from hypothermia and fatigue. I'm sure it'll have happy hunting once it recovers. This sort of thing is a huge problem here in New Zealand. The only native mammal here is a bat, we have mostly birds which evolved for a really long time with only avian predators. So they\u2019re hilariously poorly adapted for surviving standard predators (cats, rats, dogs etc) which first the Maori and subsequently Europeans brought. For example, many of them are flightless and tend to freeze when threatened - works well against eagles but is a terrible idea when threatened by a cat. As a result, we have many animals, mostly birds, which are totally unique and also critically endangered. Many of them can only survive on offshore islands which have been comprehensively cleared of predators at vast effort and expense. The islands need to be relatively accessible"}
{"anchor": "Linux boxes via SSH: suspended when disconected. This looks quite similar to exe.dev which was on here a while ago - anyone know how it compares? $36/mo for 2/4/50 VPS without public IP... Ok, I get the idea that the service is for non-regular use, but I think even $0.005 per hour ($3.6/mo) of suspended state is too expensive. The same config in Hetzner is just $4.09/mo for 24/7 working VPS with public IPv4 address This is fascinating idea.  I created an idea like this on top of firecracker and custom golang ssh client to build something like this for my own personal use case (the abstraction part of pricing and how to connect it seemed the more difficult part for me atleast) What stack does this use underneath? Good luck with launch, this idea is similar to railway in terms of pricing model. I discussed about it a few comments back and I think its an interesting idea and we are seeing alternatives within such pricing model Also are you using some cloud provider itself or building it yourself, I'd be interested in so many details to discover Have a nice day and looking forward to ya response! Good luck with your project! > Note: The -O flag is required for OpenSSH 9.0+ to use legacy SCP protocol. Why isn't SFTP supported? Is it non-American all the way down? I've been trying to come up with a hypothetical use case for this. I can't use this as a server without keeping an active session right? I wonder if you could get around this by sshing into itself from inside the primary session. Is that an edge case you've considered? Not sure about the security sandbox, but given that paddle.com (your payment provider) takes 5% cut you could consider accepting lightning (bitcoin layer2) payments. QR code generation for lightning invoice is instantaneous just as payment, and will cost less than 0.1% fee (payer pays fee anyway). But the security sandbox should be solid, else it will be used for illegal stuff. But why? Genuinely want to know what one might use this for. I can ima", "positive": "Insights into Claude Opus 4.5 from Pok\u00e9mon. The idea of Claude having \"anterograde amnesia\" and the top-rated comment there by Noosphere89 really resonated with me:     \"I would analogize this to a human with anterograde amnesia, who cannot form new memories, and who is constantly writing notes to keep track of their life. The limitations here are obvious, and these are limitations future Claudes will probably share unless LLM memory/continual learning is solved in a better way.\"\n\n  This is an extremely underrated comparison, TBH. Indeed, I'd argue that frozen weights + lack of a long-term memory are easily one of the biggest reasons why LLMs are much more impressive than useful at a lot of tasks (with reliability being another big, independent issue).\n\n  It emphasizes 2 things that are both true at once: LLMs do in fact reason like humans and can have (poor-quality) world-models, and there's no fundamental chasm between LLM capabilities and human capabilities that can't be cured by unlimited resources/time, and yet just as humans with anterograde amnesia are usually much less employable/useful to others than people who do have long-term memory, current AIs are much, much less employable/useful than future paradigm AIs.   I wonder if there's someone at Antrophic working to fine-tune the model's pokemon playing ability specifically. Maybe not but it sure would be funny. This actually matches my experience quite well. I use vision (often) to try and do 2 main things in Claude code: 1) give it text data from something that is annoying to copy and paste (eg labels off a chart or logs from a terrible web UI that doesn't make it easy to copy and paste). 2) give it screenshots of bugs, especially UI glitches. It's extremely good at 1), can't remember when it got it wrong. On 2) it _really_ struggled until opus 4.5, almost comically so, with me posting a screenshot and a description of the UI bug and it telling me \"great it looks perfect! What next?\" With opus 4.5 it's not ", "negative": "Claude Code's new hidden feature: Swarms.  https://xcancel.com/NicerInPerson/status/2014989679796347375  In his second post he included a link to GitHub:  https://github.com/mikekelly/claude-sneakpeek  Isn't this pretty much what Ruv has been building for like two years?  https://github.com/ruvnet/claude-flow  Listen team lead and the whole team, make this button red. It feels like Auto-GPT, BabyAGI, and the like were simply ahead of their time Answering the question how to sell more tokens per customer while maintaining ~~mediocre~~ breakthrough results. Claude Code in the desktop app seems to do this? It's crazy to watch. It sets of these huge swarms of worker readers under master task headings, that go off and explore the code base and compile huge reports and todo lists, then another system behind the scenes seems to be compiling everything to large master schemas/plans. I create helper files and then have a devops chat, a front end chat, an architecture chat and a security chat, and once each it done it's work it automatically writes to a log and the others pick up the log (it seems to have a system reminder process build in that can push updates from other chats into other chats. It's really wild to watch it work, and it's very intuitive and fun to use. I've not tried CLI claude code only claude code in the desktop app, but desktop app sftp to a droplet with ssh for it to use the terminal is a very very interesting experience, it can seem to just go for hours building, fixing, checking it's own work, loading it's work in the browser, doing more work etc all on it's own - it's how I built this:  https://news.ycombinator.com/item?id=46724896  in 3 days. I'm already burning through enough tokens and producing more code than can be maintained - with just one claude worker. Feel like I need to move into the other direction, more personal hands-on \"management\". A guy who worked at docker on docker swarm now works at Anthropic so makes sense How is this different fro"}
{"anchor": "Danish pension fund divesting US Treasuries. What happens when USD stops becoming the the reserve currency for the world?  And who takes its place? A sensible response, indeed. Investing is about finding the right balance of risk vs reward. When a country becomes less reliable, it becomes a less attractive investment, until the interest they pay rises enough to compensate for the additional risk. Edit: Yes, I am being sarcastic. > $100 million Is that a lot? Seems relatively inconsequential in the grand scheme of things, but perhaps a warning of larger moves to come. Let's see how Norway will react The US keeps voting to raise its debt cieling. Theres not end in sight to endless taxation by both parties. Nobody is reducing spending and delivery continues to go down. > \"The decision is rooted in the poor U.S. government finances,  which make us think that we  need to make an effort to find an  alternative  way of conducting our liquidity and risk management,\" Investment Director Anders Schelde said in a written statement. Not a political decision. Still a bad sign for the US, but not really unexpected. This divestment is so little and with so little aim. The whole situation is been caused by a single guy and 400 enablers, whereas the US is a 400 million people country. The correct form of reaction is a punch in the face during a bilateral meeting, Zelensky came close to doing it but unfortunately he resisted his impulse , that's where the epicenter of all newly generated global problems in the last 10 years lies, in that octogenarian brian of his. When I actually look at the data, a lot of US deficit growth came from several specific shocks, with inconsistent years of recovery. - 9/11 - Iraq War - Covid The US did recover a bit deficit-wise in Obama years, but have not reset the fiscal picture from Covid.  https://fred.stlouisfed.org/series/FYFSD  So much of the way the United States works is having a nearly limitless source of borrowing at low rates in the form of s", "positive": "How Google Maps allocates survival across London's restaurants. Interesting work, but ultimately silly: of course google maps ranks results.  No one (yes, yes, I'm sure like 3 people) want a list of all results, unordered or ordered by something useless like name, when they type in restaurant.  And I cannot put into words how uneager I am to have the city or state government manage what comes up when I put indian or burrito into a map. The other commenter thought the work was silly, but I think it's brilliant. Keep at this!! You're making me hungry :) super interesting project. I would love to generate a similar list for my own neighbourhood I love the idea! And I want to have it for my city :) Is there a project on GitHub or somewhere that I could clone??  (smiling face with halo)  Very interesting. But I wonder how much Google (and other) Maps can actually shape the scene. For tourist hotspots with a lot of visitors, it IS clearly the driving force. But for locals, I don\u2019t think it has an overwhelming effect. Locals know their restaurants and they visit them based on their own rating. They could explore total strange and new ones, but then they will form their own rating and memory immediately and will not get fooled/guided by algorithm (the next time) Google maps is doing the same thing to local business success that social media algorithms are doing to political success. The algorithm controls what you perceive as the consensus of others. It is a dangerous world to have such power so highly concentrated. At least in central London, the \"underrated gems\" feature does not seem to be very good at finding underrated gems. That might just be a feature of the area though. I have gotten so sick of Google Maps that I've done the unthinkable, and have started walking around the city trying establishments at random. It has yielded quite good results basically immediately. People (myself included) have gotten too used to living In The Box. Putting aside the time to just go", "negative": "UK House of Lords Votes to Extend Age Verification to VPNs. So will openvpn now get a new command line argument '--passport-number-for-age-verification 8371652299'? And presumably also a '--webcam-to-use-for-identity' Not made clear in this article - this bill will be passed back to the House of Commons to debate/amend before going back to the House of Lords. This was not the final say. Just for clarification.  House of Lords amendments do not have to be accepted by the House of Commons and may not make it into law. If you do not agree with an amendment then write to your MP, write to the ministers concerned.  If you do not tell them your concerns they will not know. You can ask for an appointment with your MP. You can ask for an appointment with ministers.  Better still you can form an advocacy group and lobby. What if I rent a cheap VPS overseas and wireguard my traffic to that? This is very bad news because I have been in contact with low cost providers (lowendtalk) and the community & even they usually end up renting etc. from datacenters and they usually would have name as well So theoretically, suppose I have a vpn company on A) either such lowend niche providers who might support let's say my mission or we are aligned or B) the hyperscalers or large companies. Now I am 99% sure that large companies would actually restrict VPN creation usage (something remarkably rare right now but still it's a gone deal now) And I feel like even with niche lowendbox providers, suppose I am paying 4 euros or something to a provider to get an IP, they are either using hyperscaler themselves (like OVH) or part of a datacenter itself If a server they own in some capacity runs a vps, can it be considered that they are running a vps and they can get sued by the Safety Act too? If not, then what if this happens one layer above at datacenter and now datacenters might have to comply with them I haven't read the article but wtf. Suppose I run a tmate instance (basically allows you to c"}
{"anchor": "Show HN: TetrisBench \u2013 Gemini Flash reaches 66% win rate on Tetris against Opus. It would be more interesting to make it build a chess engine and compare it against Stockfish. The chess engine should be a standalone no-dependencies C/C++ program that fits in NNN lines of code. Gemini 3 Flash is at a very nice point along the price-performance curve. A good workhorse model, while supplementing it with Opus 4.5 / Gemini 3 Pro for more complex tasks. Very cool! I am a good Tetris player (in the top 10% of players) and wanted to give brick yeeting against an LLM a spin. Some feedback:\n- Knowing the scoring system is helpful when going 1v1 high score - Use a different randomization system, I kept getting starved for pieces like I. True random is fine, throwing a copy of every piece into a bag and then drawing them one by one is better (7 bag), nearly random with some lookbehind to prevent getting a string of ZSZS is solid, too (TGM randomizer) - Piece rotation feels left-biased, and keeps making me mis-drop, like the T pieces shift to the left if you spin 4 times. Check out  https://tetris.wiki/images/thumb/3/3d/SRS-pieces.png/300px-S...  or  https://tetris.wiki/images/b/b5/Tgm_basic_ars_description.pn...  for examples of how other games are doing it. - Clockwise and counter-clockwise rotation is important for human players, we can only hit so many keys per second - re-mappable keys are also appreciated Nice work, I'm going to keep watching. There are some concepts clashing here. I mean, if you let the LLM build a testris bot, it would be 1000x better than what the LLMs are doing. So yes, it is fun to win against an AI, but to be fair against such processing power, you should not be able to win. It is only possible because LLMs are not built for such tasks. It's actually 80% against Opus, 66% average against the 5 models it's tested with. I imagine this is because Tetris is visual and the Gemini models are strong visually. Interesting but frustratingly vague on details. ", "positive": "Uv: Running a script with dependencies. This is my absolute favourite uv features and the reason I switched to uv. I have a bunch of scripts in my git-hooks which have dependencies which I don't want in my main venv. #!/usr/bin/env -S uv run --script --python 3.13 This single feature meant that I could use the dependencies without making its own venv, but just include \"brew install uv\" as instructions to the devs. The \"declaring script dependencies\" thing is incredibly useful:  https://docs.astral.sh/uv/guides/scripts/#declaring-script-d...      #  script\n  # dependencies = [\n  #   \"requests<3\",\n  #   \"rich\",\n  # ]\n  # \n  import requests, rich\n  # ... script goes here\n  \nSave that as script.py and you can use \"uv run script.py\" to run it with the specified dependencies, magically installed into a temporary virtual environment without you having to think about them at all. It's an implementation of Python PEP 723:  https://peps.python.org/pep-0723/  Claude 4 actually knows about this trick, which means you can ask it to write you a Python script \"with inline script dependencies\" and it will do the right thing, e.g.  https://claude.ai/share/1217b467-d273-40d0-9699-f6a38113f045  - the prompt there was:     Write a Python script with inline script\n  dependencies that uses httpx and click to\n  download a large file and show a progress bar\n  \nPrior to Claude 4 I had a custom Claude project that included special instructions on how to do this, but that's not necessary any more:  https://simonwillison.net/2024/Dec/19/one-shot-python-tools/  Why doesn't pip support PEP 723?  I'm all for spreading the love of our lord and savior uv, but it should be necessary to have an official implementation. Oh this looks amazing!  I had pretty much stopped using Python for my one-off scripts because of the hassle of dependencies.  I can't wait to try this out. Oh nice, I was already a happy user of the uv-specific shebang with in-script dependencies, but the `uv lock --script example.py` ", "negative": "AI code and software craft. Enterprise software tends to particularly bad because it's being sold to managers who won't use it themselves. Consumer software tends to be more user-friendly (or it won't sell), but popular software isn't always what you want. When writing software for yourself, there is a bias towards implementing just the features you want and never mind the rest. Sometimes the result can be pretty sloppy, but it works. However, code health is a choice. You just need to know what to ask for. A coding agent can be used as a power washer to tidy up a project. This won't result in great art, but like raking leaves or cleaning your steps or plowing a driveway, it can be satisfying. Just as you wouldn't use a power washer to clean a painting, maybe there's some code that's too delicate to use a coding agent on? But for a project that has good tests and isn't that delicate, which I believe includes most web apps, nobody's going to want to pay for you to do it by hand anymore. It would be like paying someone to clear the snow in a parking lot with a shovel rather than hiring someone with a plow. This argument is basically just the 1800s Luddite vs Industrialist argument recast for a new age. Group A thinks quality is about human agency, and that machines are being used to bypass the apprenticeship system and produce inferior goods. Group B thinks efficiency is the highest priority, and craft is just vanity. Of course as we know we went a third way, and human roles just shifted. I think one promising shift direction is humans do NOT like to talk to bots, especially not for anything important. It's biological. We evolved to learn from and interact with other humans, preferably the same group over a long time, so we really get to understand/mirror/like/support each other. > People have said that software engineering at large tech companies resembles \"plumbing\" > AI code [..] may also free up a space for engineers seeking to restore a genuine sense of craft and "}
{"anchor": "Cholesterol levels cut in half with one-time gene editing drug in trial. This is not an acceptable use of gene editing IMHO. Cholesterol can be managed by diet. High levels of Cholesterol are down to choices made, not some inherited disease that patients couldn't avoid from when they were born. I was diagnosed with Parkinson\u2019s disease four years ago. For over two years, I relied on Levodopa and several other medications, but unfortunately, the symptoms kept getting worse. The tremors became more noticeable, and my balance and mobility started to decline quickly. Last year, out of desperation and hope, I decided to try a herbal treatment program from NaturePath Herbal Clinic.\nHonestly, I was skeptical at first, but within a few months of starting the treatment, I began to notice real changes. My movements became smoother, the tremors subsided, and I felt steadier on my feet. Incredibly, I also regained much of my energy and confidence. It\u2019s been a life-changing experience I feel more like myself again, better than I\u2019ve felt in years.If you or a loved one is struggling with Parkinson\u2019s disease, I truly recommend looking into their natural approach. You can visit their website at www.naturepathherbalclinic.com\ninfo@ naturepathherbalclinic  .com Same thing with T2D. If your blood sugar is disregulated due to insulin sensitivity disorder, you should simply die. The existence of a gene edit directly contradicts your assertion. That you don't label the specific phenotype a disease doesn't really matter. Why is it better for it to be managed with diet vs this? Presumably if managing it via diet alone worked universally they wouldn't be doing research into drugs like this. Genetics can be a factor.  https://en.wikipedia.org/wiki/Familial_hypercholesterolemia  High cholesterol is well documented to be heritable. Perhaps more relevantly, even if they would work, lifestyle changes have a significant patient compliance problem, which significantly reduces their effectiveness. Th", "positive": "Meditation as Wakeful Relaxation: Unclenching Smooth Muscle.        You must learn to sit perfectly still with every muscle tense for long periods.\n\n    Various things will happen to you while you are practising these positions; they must be carefully analysed and described.\n\n    Note down the duration of practice; the severity of the pain (if any) which accompanies it, the degree of rigidity attained, and any other pertinent matters.\n\n    When you have progressed up to the point that a saucer filled to the brim with water and poised upon the head does not spill one drop during a whole hour,\n    and when you can no longer perceive the slightest tremor in any muscle; when, in short, you are perfectly steady and easy, you will be admitted for examination;\n    and, should you pass, you will be instructed in more complex and difficult practices.\n  \n- Aleister Crowley, Liber E vel Exercitiorum, 1911.  https://hermetic.com/crowley/equinox/i/i/eqi01005  Possibly a non-Jungian explanation for John Sarno's hypothesis that chronic pain could be caused by emotional issues triggering interruption of blood supply to painful areas. The idea that there is much more computation (and intelligence/agency) going on in biological and other systems seems to be getting more popular. (The author writes: The whole body is a computer: it\u2019d be wasteful for evolution to only use the brain for computation when other systems could take part too.). Michael Levin has some super interesting ideas about this. Is there any evidence yet for this theory? Sounds falsifiable. I find it interesting how meditation eventually becomes an anxiety reduction method, or general emotion management. What should it be if there is no burden of stress or negative impression of any emotion? Why rid of stress? It comes and goes, it is as fleeting as relaxation. I guess meditation is a insight into there being no problem to solve, once that insight is clear, there is no need for meditation. why is there a video of orde", "negative": "Dithering \u2013 Part 2: The Ordered Dithering. Related:  Dithering - Part 1   https://news.ycombinator.com/item?id=45750954  In chrome it says \"Loading assets, please wait...\" and hangs.  but it works for me in firefox This is really nice work, as are the other posts. If the author stops by, I'd be interested to hear about the tech used. I used ordered dithering in my ZX Spectrum raytracer ( https://gabrielgambetta.com/zx-raytracer.html#fourth-iterati... ). In this case it's applied to a color image, but since every 8x8-pixel block can only have one of two colors (one of these fun limitations of the Spectrum), it's effectively monochrome dithering. Bayer dithering in particular is part of the signature look of Flipnote Studio animations, which you may recognize from animators like kekeflipnote (e.g.  https://youtu.be/Ut-fJCc0zS4 ) Just did a bit of a deep dive into dithering myself, for my project of creating an epaper laptop.  https://peterme.net/building-an-epaper-laptop-dithering.html  it compares both error diffusion algorithms as well as Bayer, blue noise, and some more novel approaches. Just in case anyone wants to read a lot more about dithering! I built a blue noise generator and dithering library in Rust and TypeScript. It generates blue noise textures and applies blue noise dithering to images. There\u2019s a small web demo to try it out [1]. The code is open source [2] [3] [1]  https://blue-noise.blode.co \n[2]  https://github.com/mblode/blue-noise-rust \n[3]  https://github.com/mblode/blue-noise-typescript  There is something very satisfying in viewing media at 100% resolution of your screen. Every pixel is crisp and plays a role. Joy not available by watching videos or viewing scaled images. Half the posts here are people promoting their own projects without even mentioning the (really impressive) OP. Bit weird Bookmarking this. Clear explanations of graphics algorithms are surprisingly rare. Normally I am not a fan of gimmicky page formats but this series really "}
{"anchor": "Early Retirement (2006). How much money can a Silicon Valley software engineer expect to have at retirement? This article says $7 million:  https://www.wealthmeta.com/blog/being-a-doctor-vs-being-a-so...  Here's the back-of-the-envelope calculation: Annual salary: $250K (it is much higher at FAANG). Assume 25% tax (effective, not marginal), which leaves us with $187.5K, which is about $15K per month. Assume $5000 in monthly expenses, which leaves us with $10K per month investable money. (Note: since net worth includes house and 401(k) I have not deducted mortgage or 401(k) payments). So $10K includes those items.) Now use a compound interest calculator to see what $10K per month at 8% interest (assume investment in S&P 500 and allow for some market crashes) will result in, at the end of 30 years. It is about $14 million, which would include your house and your 401(k). Here's a spreadsheet that allows you to plug in your own numbers:\n https://docs.google.com/spreadsheets/d/1Ryu_-mVYxSdJbW8lmf1z...  > Retirement forces you to stop thinking that it is your job that holds you back. For most people the depressing truth is that they aren't that organized, disciplined, or motivated. Maybe, but I don\u2019t know anyone who\u2019s less happy being retired. They might not be living their retirement fantasy, but the pressure and stress of having to work is gone. He's always been an interesting chap. I wish him well.  > Most important, do not retire in the expectation that it will be easy to find rewarding non-profit volunteer work.  Thankfully, this has not been an issue with me. I definitely don't have the massive nest egg that another commenter mentioned, but I've got enough to avoid starving, and I am happier than I ever thought I'd be. > How much work does the average college student get done? Almost none. Yet the same person, injected into a corporate bureaucracy, becomes a reasonably effective worker. Why? Most people have terrible time management skills. This limitation is of no ", "positive": "Gemini 3 Flash: Frontier intelligence built for speed. Deepmind Page:  https://deepmind.google/models/gemini/flash/  Developer Blog:  https://blog.google/technology/developers/build-with-gemini-...  Model Card [pdf]:  https://deepmind.google/models/model-cards/gemini-3-flash/  Gemini 3 Flash in Search AI mode:  https://blog.google/products/search/google-ai-mode-update-ge...  They went too far, now the Flash model is competing with their Pro version. Better SWE-bench, better ARC-AGI 2 than 3.0 Pro. I imagine they are going to improve 3.0 Pro before it's no more in Preview. Also I don't see it written in the blog post but Flash supports more granular settings for reasoning: minimal, low, medium, high (like openai models), while pro is only low and high. Don\u2019t let the \u201cflash\u201d name fool you, this is an amazing model. I have been playing with it for the past few weeks, it\u2019s genuinely my new favorite; it\u2019s so fast and it has such a vast world knowledge that it\u2019s more performant than Claude Opus 4.5 or GPT 5.2 extra high, for a fraction (basically order of magnitude less!!) of the inference time and price Does this imply we don't need as much compute for models/agents? How can any other AI model compete against that? Pretty stoked for this model. Building a lot with \"mixture of agents\" / mix of models and Gemini's smaller models do feel really versatile in my opinion. Hoping that the local ones keep progressively up (gemma-line) These flash models keep getting more expensive with every release. Is there an OSS model that's better than 2.0 flash with similar pricing, speed and a 1m context window? Edit: this is not the typical flash model, it's actually an insane value if the benchmarks match real world usage. > Gemini 3 Flash achieves a score of 78%, outperforming not only the 2.5 series, but also Gemini 3 Pro. It strikes an ideal balance for agentic coding, production-ready systems and responsive interactive applications. The replacement for old flash models will be proba", "negative": "The browser is the sandbox. I like the perspective used to approach this. Additionally, the fact that major browsers can accept a folder as input is new to me and opens up some exciting possibilities. The folder input thing caught me off guard too when I first saw it. I've been building web apps for years and somehow missed that `webkitdirectory` attribute. What I find most compelling about this framing is the maturity argument. Browser sandboxing has been battle-tested by billions of users clicking on sketchy links for decades. Compare that to spinning up a fresh container approach every time you want to run untrusted code. The tradeoff is obvious though: you're limited to what browsers can do. No system calls, no arbitrary binaries, no direct hardware access. For a lot of AI coding tasks that's actually fine. For others it's a dealbreaker. I'd love to see someone benchmark the actual security surface area. \"Browsers are secure\" is true in practice, but the attack surface is enormous compared to a minimal container. We never say that it isn't. There is a reason Google developed NaCl in the first place that inspired WebAssembly to become the ultimate sandbox standard. Not only that, DOM, JS and CSS also serves as a sandbox of rendering standard, and the capability based design is also seen throughout many browsers even starting with the Netscape Navigator. Locking down features to have a unified experience is what a browser should do, after all, no matter the performance. Of course there are various vendors who tried to break this by introducing platform specific stuff, but that's also why IE, and later Edge (non-chrome) died a horrible death There are external sandbox escapes such as Adobe Flash, ActiveX, Java Applet and Silverlight though, but those external escapes are often another sandbox of its own, despite all of them being a horrible one... But with the stabilization of asm.js and later WebAssembly, all of them is gone with the wind. Sidenote: Flash's script"}
{"anchor": "AI will make formal verification go mainstream. I'm convinced now that the key to getting useful results out of coding agents (Claude Code, Codex CLI etc) is having good mechanisms in place to help those agents exercise and validate the code they are writing. At the most basic level this means making sure they can run commands to execute the code - easiest with languages like Python, with HTML+JavaScript you need to remind them that Playwright exists and they should use it. The next step up from that is a good automated test suite. Then we get into quality of code/life improvement tools - automatic code formatters, linters, fuzzing tools etc. Debuggers are good too. These tend to be less coding-agent friendly due to them often having directly interactive interfaces, but agents can increasingly use them - and there are other options that are a better fit as well. I'd put formal verification tools like the ones mentioned by Martin on this spectrum too. They're potentially a fantastic unlock for agents - they're effectively just niche programming languages, and models are really good at even niche languages these days. If you're not finding any value in coding agents but you've also not invested in execution and automated testing environment features, that's probably why. Unless you feed a spec to the LLM, and it nitpicks compiled TLA+ output generated by your PlusCal input, gaslights you into saying the code you just ran and pasted the output of is invalid, then generates invalid TLA+ output in response. Which is exactly what happened when I tried coding with Gemini via formal verification. I love HN because HN comments have talked about this a fair bit already. I think on the recent Erdos problem submission. I like the idea that languages even like Rust and Haskell may be more accessible. Learn them of course but LLM can steer you out of getting stuck. If AI is good enough to write formal verification, why wouldn't it be good enough to do QA? Why not just have AI do ", "positive": "Auto-grading decade-old Hacker News discussions with hindsight.  LLMs are watching (or humans using them might be). Best to be good.  Shades of Roko's Basilisk! Commenters of HN: Your past thoughts have been dredged up and judged. For each $TOPIC, you have been awarded a grade by GPT-5.1 Thinking. Your grade is based on OpenAI's  aligned  worldview and what OpenAI's blob of weights considers Truth in 2025. Did you think  well , netizen? Are you an Alpha or a Delta-Minus? Where will the dragnet grading of your online history happen next? Random Bets for 2035: * Nvidia GPUs will see heavy competition and most chat-like use-cases switching to cheaper models and inference-specific-silicon but will be still used on the high end for critical applications and frontier science * Most Software and UIs will be primarily AI-generated.  There will be no 'App Stores' as we know them. * ICE Cars will become niche and will be largely been replaced with EVs, Solar will be widely deployed and will be the dominate source of power * Climate Change will be widely recognized due to escalating consequences and there will be lots of efforts in mitigations (e.g, Climate Engineering, Climate-resistant crops, etc). It's fun to read some of these historic comments! A while back I wrote a replay system to better capture how discussions evolved at the time of these historic threads. Here's Karpathy's list from his graded articles, in the replay visualizer: Swift is Open Source\n https://hn.unlurker.com/replay?item=10669891  Launch of Figma, a collaborative interface design tool\n https://hn.unlurker.com/replay?item=10685407  Introducing OpenAI\n https://hn.unlurker.com/replay?item=10720176  The first person to hack the iPhone is building a self-driving car\n https://hn.unlurker.com/replay?item=10744206  SpaceX launch webcast: Orbcomm-2 Mission [video]\n https://hn.unlurker.com/replay?item=10774865  At Theranos, Many Strategies and Snags\n https://hn.unlurker.com/replay?item=10799261  Notable how this", "negative": "40% of Kids Can't Read and Teachers Are Quitting [video]. From the summary of video: \"40% of fourth graders can't read. Kids are asking their teachers why they need to learn to read when AI can do it for them. Social media has destroyed their attention spans and now teachers aren't teaching, instead they're managing withdrawal symptoms.\" Why are fourth graders on social media and using AI already? My fourth grade kid has no social media presence and definitely isn't familiar with AI tools. This sounds like a parent problem. (a joke) 100% of kids can't read then 60% learn Australia's social media ban for young teenagers is probably a good thing but time will tell. Per stats in the video results are roughly the same as in 1992, with peak roughly at 2019. I do not know why is 1992 baseline, but for some reason it is. OK, I found it, peak was 2020. Just in case someone will (again) argue this means we have to go back to pedagogy of 1970. Don\u2019t they still need to read what AI writes? Or did they skip to the TTS stage? Why are you letting kids that can't read pass the grade? The 40% stat is not great, there's a better unpacking of it here:  https://www.youtube.com/watch?v=ZvCT31BOLDM  While I appreciate the sentiment of the video, I can\u2018t get past the sensationalist rhetoric / framing of the problem. \u201eSkibidi Toilet is rotting brains!! Kids don\u2018t want cartoons!!\u201c. I suppose videos like this might get people to think about the problem who hadn\u2018t considered it before. This is 100% the fault of parents. Annual escalation of the grade, e.g. eight grade, should be altogether eliminated in favor of one month modules. This avoids wasting a whole year if one fails the grade. Faster feedback is better, up to a point, and it is better here. How would this work in practice though if a teacher has to teach an entire class? Of course it would have to use computer instruction, with the teacher helping small batches of students who're in the month-long module, but only for a fraction of"}
{"anchor": "Over 36,500 killed in Iran's deadliest massacre, documents reveal. I can't comprehend how a population can kill that many of their own people. They aren't even an \"other\" people, which has been the most common scapegoat lately. Same skin color, same religion, same language, same homeland. For comparison, estimates of the 1989 Tiananmen Square massacre death count are usually put in the 300-1,000 range by journalists and human rights groups.  https://en.wikipedia.org/wiki/1989_Tiananmen_Square_protests...  hm, I think we should re-evaluate sanctioning or civilian pressure campaigns, since the guise is for them to coax or turn on the government for regime change, but the government can just hire mercenaries from outside the country. don't know a solution but this one isn't it The source (Iran International) is backed by Saudi money and has a bias to dunk on Iran. That said, I'm sure the death count numbers from the Rasht Massacre are staggeringly higher than the initial tallies of 2-5k. This is certainly the end of peaceful Iranian protests. Whether it leads to a violent revolution or a static police state like North Korea remains to be seen. How is this possible without explosives? Even with vehicle mounted machine guns it seems like a crazy high number. Did the protestors get boxed in somehow? And across so many locations, that seems to require a crazy amount of coordination to kill so many in so little time. That's crazy. That's like ~40% of the deaths in the current gaza war, except over just 2 days instead of 2 years. This is depressing because we will go to war over this and it\u2019s going to be five years before people realizing they were tricked by \u201cbabies in incubators\u201d propaganda. The internet is fragile. Access can be so easily cut off for the masses in dire times. Take a good look US, because once you're down far enough the fascist drain, that's the cost of trying to claw your way back out. And there's no hope of external intervention given nuclear arms Earlie", "positive": "NanoChat \u2013 The best ChatGPT that $100 can buy. Wow, how do we sign up for the Eurekalabs course and how much does it cost? I've always thought about the best way to contribute to humanity: number of people you help x how much you help them. I think what Karpathy is doing is one of the highest leverage ways to achieve that. Our current world is build on top of open source projects. This is possible because there are a lot of free resources to learn to code so anyone from anywhere in the world can learn and make a great piece of software. I just hope the same will happen with the AI/LLM wave. Eureka Labs:  https://github.com/EurekaLabsAI  What a prolific person Andrej is. It's been more than amazing to follow along! Here's the announcement post [0] from Karpathy, which provides a bit of additional context. [0]  https://x.com/karpathy/status/1977755427569111362  > Thank you to chief LLM whisperer   Alec Radford for advice/guidance. oh man an Alec x Andrej podcast would BREAK THE INTERNET... just saying... going from glory days of GPT1 to now building GPT3? in 4 hours Should be \"that you can train for $100\" Curios to try it someday on a set of specialized documents. Though as I understand the cost of running this is whatever GPU you can rent with 80GB of VRAM. Which kind of leaves hobbyists and students out. Unless some cloud is donating gpu compute capacity. >If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for --device_batch_size in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. That sounds like it could run on a 24gb GPU. Batch size of 8 would imply 20gb mem, no? ...presumably just takes forever This weekend I just cracked into nanoGPT ( https://github.com/karpathy/nanoGPT ), an older but fabulous learning exercise where you build and train a crappy shakespeare GPT with ~0.8M parameters on a cpu. Results are about what you'd expect from that, they", "negative": "Improving the usability of C libraries in Swift. This was a great read. I've used the naive approach shown in the first example before and its always felt a bit clunky, but I wasnt aware of most of these language features. I'm definitely going to try this out next time I have to write C bindings This is pretty great stuff, I knew about the raw interop features but had no idea what API Notes offered. Quite cool. I can't help but feel that Swift will ultimately be the \"slow and steady wins the race\" safe language of the future. Swift steadily working \"first\" on both tooling and cohabitability with existing ecosystems is a huge boon for adoption. It understands what an ABI is! If I were doing a greenfield cross platform application I think Swift would be the first thing I reach for now. The qualms I have with Swift are mostly some of the more recent complex language features that can make Swift code much harder to understand and read, as well as the brainpower required to use Swift concurrency. That and some performance concerns, though many of those seem like they may be solvable with optimizations in LLVM. I believe Apple is investing in C/C++ interop so much because they realize they'll likely keep their existing low-level system+embedded code rather than port it to Swift.  That's good for people who want to do the same.  A swift API layer can reduce the need for C/C++ developers. But in my experience, there are sharp cliffs whenever you get off the happy path shown in the demos.  That's not a problem with code where you can design workarounds, but when you wrap highly complex (if not arcane) C API, you often can't change or omit portions of the API causing problems.  So while usability may be better, apinotes might not be enough to complete the work. If you're wrapping something, I would recommend cataloging and then verifying all the language features you need to make it work before getting too far in. It's good to have options. I guess this is similar effort as S"}
{"anchor": "Waymo granted permit to begin testing in New York City. I saw one of these on Chambers Street just yesterday afternoon, but it must have been in manual mode, of course. It's fascinating seeing all the comments elsewhere anytime Waymo starts testing in another city along the lines of, \"ah, but how will they handle X, Y, and Z here?? Checkmate, robots!\" despite having already launched service in several other cities. Granted, NYC is the biggest city in the US, so maybe that sort of reaction is more reasonable there than when people in Dallas or Boston do it. Very cool. I wonder what scale it has to hit for this to become a profitable line item for Google and what their revenue targets are for it. Man I love Waymo everytime I'm in SF. Truly feel like I'm living in the future when I sit in one I'm cautiously optimistic about this self-driving thing. Waymo at least seems to have figured out a lot of it. Would it be way better to make walkable neighborhoods, mixed-use developments, and reliable and frequent public transit? Yes. Yes it would. But, in lieu of that, self-driving has a lot of advantages in the long run, even if the technology isn't 100% perfect right now. It's insane that they need permits for 8 cars that have humans driving them in 2025, when they're already fully automated in SF. > We\u2019re a tech-friendly administration Clearly not. Is this the first time Waymo is doing winter / snow testing at scale? I think some of the Pittsburgh-based self-driving firms may have tried this, but unaware how far they got. I\u2019m curious if autonomous cars will become targets for aggressive drivers. Like a driver isn\u2019t going to be as scared cutting off a Waymo or tailgating one because the AI isn\u2019t gonna get road rage or honk like hell. In some places I could see the Waymo\u2019s getting severely bullied if that\u2019s the case. The game-theoretic aspect of this is interesting to me. A lawful robot will never make progress in Manhattan because the people will just walk across its path con", "positive": "Show HN: FaceTime-style calls with an AI Companion (Live2D and long-term memory). It creates a conflict to build a system that is both a private friend and a public performer. You cannot maximize intimacy and fame at the same time. What are you using for tts/stt/models? Building on zemo's point about parasocial relationships: traditional parasocial interaction involves a performer who doesn't know you exist. Here the AI does respond to you specifically, which changes the dynamic. Is it still parasocial if the other party is responsive but not conscious? Or is this something new that we don't have good language for yet? For better lip sync you could try using rhubarb to extract from the mp3.\nWhat is your backend speech processor so you can get the real-time streaming response?\nRhubarb would add a bit of latency for sure. wow we got personal vtubers now! You're describing Parasocial interaction:  https://en.wikipedia.org/wiki/Parasocial_interaction  far from being impossible, it's the entire influencer economy. This form of social media has been extremely widespread for a decade or so running; it's probably the dominant form of social media. 100% agree. Maximizing intimacy and scaling distribution pull in opposite directions. We\u2019re experimenting with keeping the \u201ccharacter\u201d consistent while letting personalization live in private memory and user-controlled settings. Still early, and this tension is real. Appreciate it. If you try it and anything feels off (latency, turn-taking, uncanny moments), I\u2019d love concrete feedback. That\u2019s what we\u2019re grinding on right now. It will quickly distill down to clients using the service just for sex and sex-adjacent activities. No kink-shaming, but this sort of thing enables self-destructive hard-to-return-from anti-social behaviour. Totally fair reaction. We\u2019re building this with clear boundaries: we don\u2019t position it as therapy replacement, we add safety rails, and gives user a choice what mode they want and guardrails differ based ", "negative": "The guide to real-world EV battery health. Tesla does their own with real world data. It\u2019s a non-issue. Save the planet. Stop making excuses and get an EV. > How long do electric car batteries last? The article never answers the question. But if you assume 70% end-of-life threshold with 2.3% loss per year - then we're looking at 13 years. Hopefully, in coming years, we will see more practically designed EVs that are more affordable.  A practical car doesn't need neck-snapping acceleration, every bell-and-whistle and room for a family of six with a dog.  I'd like to believe that as batteries cost drop, the incentive to justify the extra cost will drop.  Then we can get back to \"just basic transportation\" rather than a luxury product for the rich.   While $31k isn't exactly cheap, the base new Leaf is heading the right direction. 81% of original capacity for many cars means when driving at highway speeds you will get like 250 miles or less range per charge. Still dramatically less than gas cars. Important to note that this article is geared toward  Fleet Managers , so terms like \u201caverage service life\u201d may not apply.  For example the average car in the us survives 12.6 years before being junked, totaled, etc.  which is far longer than a car would be in fleet service at a company. While buying an EV is a greener choice than buying an ICE, a better option still is to use the vehicle you already have for as long as reasonable. This also overlooks the fact that EVs are prohibitively expensive for the vast majority of the population. It isn't the case that people aren't buying them because of preference. Nearly everyone would buy a car that's cheaper to run and maintain if they could afford it. \"Save the planet\" by making giant lithium strip mining operations great again. (Safely hidden out of sight in rural China or West Virginia, of course.) City slicker \"logic.\" No thanks. I will instead  actually  do something to help the planet by continuing to drive decades year old v"}
{"anchor": "40M Americans Live Alone, 29% of households. Any causes? Is it that we are too independent and don\u2019t like collectivism? A conspiracy might say it\u2019s on purpose to have more people pay for things typically bought for a couple. Like everyone having their own house, cable bill, utility bill, water bill, \u2026 If more people lived together with friends, that\u2019d make a dent in both the housing and loneliness crises. Is it a bad thing? People's life choices are their own. 29% seems like a fairly neutral number. Incidentally, that newsletter has a lot of interesting charts.  https://www.apolloacademy.com/the-daily-spark/  It's not a high number when compared to other first-world countries:  https://statranker.org/population/top-10-countries-with-high...  Is this page just a single chart and a massive legal disclaimer? When I was a twentysomething, I had roommates. This saved money on rent and bulk purchases (which let me spend more time having fun  and  save money) and provided a starter-kit social circle in a new city. It also honed conflict-resolution skills and ability to be civil. And when I got a partner, it made moving in together smoother. Something I\u2019ve noticed recently is many college graduates living alone. That\u2019s fine. But it\u2019s a weird default for early in one\u2019s career. If I had one general piece of advice for anyone starting their career, it would be to seek out a living situation with roommates. Side question: are more college students staying in solo dorms? Part of the \"housing crisis\" is older Americans aging-in-place and using way more home than they need too. A widow/er might occupy the same suburban single family home in retirement that could house 5 people. Even as new homes are much bigger than decades past\u2026 The best thing I ever did for my mental health was to start having children. Humans, like every other living creature, are hardwired by billions of years of evolution to reproduce. So what? After living with parents, roommates, spouses and others for most", "positive": "Mote: An Interactive Ecosystem Simulation [video]. This is super cool. I love simulations like this. And this is running at a huge scale! The architecture here is fascinating. Specifically using a graph processor approach where entities are nodes connected by edges (springs) for everything from physics to data transmission. I really like it. I've had the pleasure of following Peter's progress on this project over the past 18 months or so, and it's been incredible to see how far he's taken it. When he first described it to me, I didn't really \"get\" it (is it a game? a simulation? some other sort of environment?), and it wasn't until seeing an actual demo and hearing Peter explain his thinking more deeply that it clicked. It's basically a giant simulation environment that is 1) visually stunning (and  all  visual aspects are meaningful / carry semantic information and aren't just glitter), 2) technically quite impressive, and 3) built for rapid exploration and experimentation.  If that sounds at all interesting, you should watch the video to hear Peter's talk! (Writing this as someone who generally doesn't like to watch videos online; this is one of the rare cases where I think it's worth it, and a video is a better format than text in explaining the thing.) The sound is a bit much, especially during a presentation. I have to keep pausing to rest from it, but overall very cool project. This is math, beauty, art, creativity, ... unique. My mind is all over the place.\nStill wrapping my head around it but, I'd really like to see where this leads. Fantastic! As a fan of simulation and learning NetLogo 15ish years ago-I greatly appreciate when work like this gets attention! It's the perfect abstraction for representing cell membranes, force flow dynamics etc So excited for this project What I really want, is to run and experiment with it myself, locally. But I couldn't find a repository anywhere, even from his linked GitHub profile. You happen to know if it's online somewh", "negative": "Clawdbot - open source personal AI assistant. I ran the install and got these errors: npm warn deprecated npmlog@6.0.2: This package is no longer supported.\nnpm warn deprecated are-we-there-yet@3.0.1: This package is no longer supported.\nnpm warn deprecated gauge@4.0.4: This package is no longer supported.\nnpm warn deprecated tar@6.2.1: Old versions of tar are not supported, and contain widely publicized security vulnerabilities, which have been fixed in the current version. Please update. Support for old versions may be purchased (at exhorbitant rates) by contacting i@izs.me\nnpm warn deprecated node-domexception@1.0.0: Use your platform's native DOMException instead Clawdbot is interesting but I finally feel like those people who look at people like me raving about Claude code when it barely works for them. I have no doubt clawdBot, when it works, must feel great. But I\u2019ve had the tough time setting it up and found it to be very buggy. My first couple of conversations? It forgot the context literally seconds later when I responded. Nevertheless, I\u2019m sure it\u2019s improving by the day so I\u2019m going to set it up on my existing Mac mini because I think it has the capacity to be really fascinating. I built something similar (well\u2026 with a lot of integrations) but for running my company and continue to iterate on it. I see this posted everywhere this week. Is it really that good? I understand this runs on any hardware (not limited to Mac Minis) as long as you have an API key to an LLM (Preferably to Claude). People online make bold promises that it will change your life... It sounds interesting to me, I might install it on a cheap Mini PC with Ubuntu. This can't come at any worst time as storage and RAM has gotten astronomical. I feel bad for people who are just starting to build their first rig and an alt rig for this. How do people think about the sort of access and permissions it needs? \"Don't give it access to anything you wouldn't give a new contractor on day one.\"  http"}
{"anchor": "Photos capture the breathtaking scale of China's wind and solar buildout. Also worth checking out some of the mega projects on Open Infrastructure Maps like this one in central China.  https://openinframap.org/#9.12/36.0832/100.4215/A,B,L,P,S  Meanwhile, in London, UK, local council doesn't allow you to put anything on your rooftop that doesn't gel with the Victorian look.. Technological, manufacturing and energy advancements aside (congrats China on those), the pictures look beautiful. Amazing work from the photographer. Why aren't we doing it in the rest of the world as well? Wow, pictures look great, well done Mr Weimin Chu Wouldn't it be better to just go with nuclear? Isn't this a gigantic waste of space and overhead to maintain it? And how \"renewable\" are the materials used to produce these? China has also just launched a megawatt scale wind generator a the helium-lifted balloon, the S2000 , they have active thorium rector the TMSR-LF1 and GW/h Vandium flow battery. The scale , speed and breadth of what they are doing is incredible and I think missed my people It genuinely makes me so sad to see the US not doing the same. Having grown up to the constant beat of \u201cenergy independence\u201d as the core goal of a party it seemed obvious that the nearly limitless energy that rains down from the sky would be the answer. But instead we\u2019ve kept choosing the option which requires devastating our, and other\u2019s around the world, community. That\u2019s not to exclude the harsh reality of mining for the minerals required to build these, nor the land use concerns. But it\u2019s difficult to compare localized damage to war and globalized damage. I find the idea of blanketing mountainous wilderness in relatively short-lived e-waste just awful. Surely there are much better terrains for solar panels? I know nothing about the topic.\nAlthough it seems a better alternative than coal or petrol, is it free of side effects for the nature?\nI wonder if the heat that would be spread around the atmosphe", "positive": "Ask HN: What did you read in 2025?. Lots of news and articles, but also \"The Craft\", a history of Freemason's by John Dickie, was one of the more interesting books. Frankenstein. Superb science fiction, very readable even though written 200 years ago. And Wuthering Heights, which strangely like Frankenstein, has a complex narrative structure and an unhinged, obsessive central character - Emperor of Rome by Mary Beard, very entertaining. - Lolita, it's mostly what you've read about it. - a few short stories by Heinrich von Kleist. I mostly read fiction but I made time for a couple of nonfiction books this year. On the fiction side I really enjoyed \"Luminous\" and \"When We Where Real\". -  https://en.wikipedia.org/wiki/Luminous_(novel)  -  https://www.simonandschuster.com/books/When-We-Were-Real/Dar...  On the nonfiction side, I can recommend \"Careless People\" and \"Apple in China\". -  https://en.wikipedia.org/wiki/Careless_People  -  https://en.wikipedia.org/wiki/Apple_in_China  I read Sad Tiger by Neige Sinno. Really unsettling but definitely worth reading. One of my favourite reads from this past year was  Infinite Powers: How Calculus Reveals the Secrets of the Universe  by Steven Strogatz. It's a wonderful review of the history of calculus, including intuitive explanations of the basics. History of the Franks, by Gregory of Tours Getting into reading again this year after a long break. The most memorable read of this year was \"The Count of Monte Cristo\" (1846) by Alexander Dumas . It's one of the greatest stories ever told. It's ~1250 pages but I sped through it in 3 weeks even if I'm a slow reader. Highly recommended! I also read The Stranger by Camus and the two top Orwells which lived up to the hype. Very much enjoyed the Hyperion Cantos series by Dan Simmons.  https://en.wikipedia.org/wiki/Hyperion_Cantos  I got really into Hemingway\u2019s work, reading all the best ones, but my favourite being \u2018A moveable feast\u2019 his diary essentially released at the end of his life", "negative": "State of the Windows: What is going on with Windows 11?. Microsoft really needs to retire the Control Panel and other old-school elements of the OS. Windows 11's design system is very pretty and user-friendly, please finish the transition to it ASAP! State of Windows? It's so out of touch, people hate it. People want a simple, clean, minimal, consistent OS that does not have anyone's interests first except the user. Windows 11 is a very, very long way from this. Honestly Windows 95 is closer to ideal than Windows 11. The state of Windows is: disaster. It\u2018s not a priority for Microsoft, it\u2018s intrusive and above all it\u2018s shit. how is it not yet a code red inside Microsoft, for the astonishing decline of user experience of Windows 11? A mate just gave me a laptop; it is the first Windows device I have touched in 20 years. It runs Windows 11. I am assuming it's all as bad as it was 20 years ago, but going from all the Windows 11 talk I am guessing it will be far worse? I am trying it out today first and then reinstalling it with Linux. It seems its fully supported out of the box except the cam and fingerprint scanner: cam I never use, fingerprint scanner would be nice but I hear it is basically impossible to get working if not supported (and it is not). It will get more annoying with Satya at the helm and as long as there is a cash cow that is not enduser facing there is not even hope for change. I'll be honest, I just want something that I can develop on (linux is the easiest by far) and that's not annoying (Nixos is the best at that). I don't even use any advanced config, just bare-minimum config for the system, enough (project-specific things handled by nix). I really don't mind Windows 11, and don't recognise many of the problems other people here claim to have. For example, I simply don't see all (or any) of the ads that many complain about. I disagree with this in the article: \"Last, but not least, the technical debt of Windows has become almost unbearable. 30+ ye"}
{"anchor": "Is It Time for a Nordic Nuke?. you also need submarines to have a \"credible\" second strike deterrent. It's not enough to just have a bomb. you can have a tiny nuclear war, as a treat. insane we're back here. Following Betteridges Law the answer is of course No It's time to disarm Russia. Edit: to be more clear: I can't believe that after 4 fucking years, a hostile nation is still permitted to wage war against a sovereign country. nuclear weapons are one of those insidious technologies that are almost self-replicating in a sense, because if your enemy has nukes it strongly behooves one to either also have nukes or to buddy up with someone who has them.  Opting out entirely is very difficult once the genie is out of the bottle I get why they would want them but it seems so clear to me that the world is going to end in fire Time for a Nordic nuke is at least from 2008. Russia is genocidal, US unreliable and erratic. The civilized world needs nukes. Not only the Nordic countries, but also Germany and Poland. Unless Russia and US are willing to give up theirs ;) Instead of nukes, maybe another massive pandemic super virus that kills off half the population of humans on Earth wouldn\u2019t be so bad. This is what Trump's dismantling of US power has brought us to. Our soon-to-be-former allies can't count on US nuclear deterrence to protect them, because not only is the US unreliable, but they might be the ones attacking. We're in crazy-town because of Trump and the Republicans, with very real consequences. I don't think there's any question at this point that it's in Nordic self interest to develop a nuclear deterrent. This has also become true for other regions in the world. This is all a horrible development for the overall future of humanity, but it's the world we live in now. At a minimum hundreds of billions of dollars will be siphoned off from more beneficial uses over the coming decades, and the risk of major accidents will increase. The worst change is of course the fac", "positive": "Android's full desktop interface leaks: New status bar, Chrome Extensions. This looks like it will help a lot of students and families who are on a budget. If you can just plug your phone into a screen you do not need to buy a separate laptop anymore. The browser extensions are the most important part because that is what makes a computer useful. I am glad to see they are thinking about this. Is this going to mean ChromeOS is going to eventually die or be merged with Android? Curious. Well, that would be nice, honestly - to have Android as another option for desktop OS. I remember there were some experiments to create a hardware laptop shell to insert smartphone into. If it comes with fully functional command line, unix utils and ability to install linux apps from different stores, that would be great OS. The Chrome Extensions support is the interesting part here. That's often the dealbreaker for using mobile devices as computer replacements. Google's had this weird situation where Android and ChromeOS overlap more every year. At some point maintaining two operating systems with converging feature sets seems wasteful. My guess: ChromeOS probably survives for the education market where manageability matters more than capabilities. But for consumers? Android on a big screen with keyboard and mouse might just be good enough. I wonder what gogole's strategy with fuchsia is going to be. So I'm guessing ... no full adblockers allowed? It really does look to be a rewrite of ChromeOS to make it a native Android experience with very few tweaks to the User experience that I can see. I think it's a good idea on Google's part. The trend of consumers using mobiles as their one and only computing experience is still strong.\nThis will blend the experience consumers have between desktops and their primary computing platform. It is interesting to consider the different developments happening with the big mobile orgs regarding the convergence computing paradigm: - Samsung\u2019s Dex has b", "negative": "The microstructure of wealth transfer in prediction markets. tl;dr dataset: 72.1m trades and $18.26b volume on kalshi (2021-2025) core findings: longshot bias: well documented longshot bias is present on kalshi. low probability contracts are systematically overpriced. contracts trading at 5 cents only win 4.18% of the time. wealth transfer: liquidity takers lose money (-1.12% excess return) while liquidity makers earn it (+1.12%). optimism tax: the losses are driven by a preference for \"yes\" outcomes. buying \"yes\" at 1 cent has a -41% expected value. buying \"no\" at 1 cent has a +23% expected value. category variation: finance markets are efficient (0.17% maker-taker gap) while high-engagement categories like media and world events are inefficient (>7% gap). mechanism: makers do not win by out-forecasting takers. they win by passively selling \"yes\" contracts to optimistic bettors I'm a little confused by the \"Yes\" versus \"No\" asymmetry. For example, one of the top trending ~~bets~~ markets right now is on whether Miami or Indiana will win the NCAA football championship tonight. You can either take \"Yes\" on Indiana at 74c, or \"No\" at 27c, or you can take \"Yes\" on Miami at 27c or \"No\" at 74c. Or, there's another potential outcome - you can also bet on a tie at 10c yes/91c no. Is this research suggesting that an optimistic Miami fan can somehow get a better return by buying \"No\" on Indiana than a \"Yes\" on Miami? Why is Kalshi structured with these yes vs. no options for all outcomes? How do prediction markets account for interest rates? I feel like I should be willing to pay no more than ~96 cents for a contract that will definitely resolve to a dollar in a year. Who puts up the other 4 cents? I wonder how much of the activity on prediction markets these days is competing LLM scripts? I would guess the overlap in prediction market punters and AI boomers is high. This article lacks even the most basic understanding of probability and statistics. Slot machines \"93 cents o"}
{"anchor": "Measuring AI Ability to Complete Long Tasks. This seems like a good way to measure LLM improvement. It matches the my personal feeling when using progressively better models over time. Opus is already the name of an audio codec. I recently asked Opus to just \u201cAdd vector search\u201d to my current hobby project, a topic I know very little about. It set up manticore, pulled an embedding model, wrote a migration tool for my old keyword indices, and built the front end. I\u2019m not exaggerating much either: the prompt was the length of a tweet. I think it would easily have taken me 4+ hours to do that.  It ran in 15 minutes while I played Kirby Air Riders and worked on the first try. Afterward, I sort of had to reflect on the fact that I learned essentially nothing about building vector search. I wanted the feature more than I wanted to know how to build the feature. It kept me learning the thing I cared about rather than doing a side quest. Would be interesting to see Gemini 3.0 Pro benchmarked as well. I didn't really understand the \"long task\" thing until I actually experienced it. The problem is finding a task you can set an agent that justifies working for that long. I finally hit one when I tried porting that Python HTML5 parser to JavaScript by pointing Codex CLI at the 9,200 html5lib-tests test suite:  https://simonwillison.net/2025/Dec/15/porting-justhtml/  It's pretty amazing to watch tools-in-a-loop crunch away for >4 hours to solve a generally difficult problem through sheer brute-force. Opus looks like a big jump from the previous leader (GPT 5.1), but when you switch from \"50%\" to \"80%\", GPT 5.1 still leads by a good margin. I'm not sure if you can take much from this - perhaps \"5.1 is more reliable at slightly shorter stuff, choose Opus if you're trying to push the frontier in task length\". I think the problem here is LLM eventually pollute its context window with so much of the current task that the larger picture or architectural sanity is forgotten in favor of ", "positive": "NanoChat \u2013 The best ChatGPT that $100 can buy. Wow, how do we sign up for the Eurekalabs course and how much does it cost? I've always thought about the best way to contribute to humanity: number of people you help x how much you help them. I think what Karpathy is doing is one of the highest leverage ways to achieve that. Our current world is build on top of open source projects. This is possible because there are a lot of free resources to learn to code so anyone from anywhere in the world can learn and make a great piece of software. I just hope the same will happen with the AI/LLM wave. Eureka Labs:  https://github.com/EurekaLabsAI  What a prolific person Andrej is. It's been more than amazing to follow along! Here's the announcement post [0] from Karpathy, which provides a bit of additional context. [0]  https://x.com/karpathy/status/1977755427569111362  > Thank you to chief LLM whisperer   Alec Radford for advice/guidance. oh man an Alec x Andrej podcast would BREAK THE INTERNET... just saying... going from glory days of GPT1 to now building GPT3? in 4 hours Should be \"that you can train for $100\" Curios to try it someday on a set of specialized documents. Though as I understand the cost of running this is whatever GPU you can rent with 80GB of VRAM. Which kind of leaves hobbyists and students out. Unless some cloud is donating gpu compute capacity. >If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for --device_batch_size in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. That sounds like it could run on a 24gb GPU. Batch size of 8 would imply 20gb mem, no? ...presumably just takes forever This weekend I just cracked into nanoGPT ( https://github.com/karpathy/nanoGPT ), an older but fabulous learning exercise where you build and train a crappy shakespeare GPT with ~0.8M parameters on a cpu. Results are about what you'd expect from that, they", "negative": "Show HN: Rails UI. Is this another Tailwind wrapper? Yes, it is. ugh this looks dated even by 2016 standards when will developers learn UI actually matters bootstrap was a mistake, and lowered the bar for everyone i don't get these types of products anymore. i think they're useful in their own way, but i can literally create styles with claude/gemini in a heartbeat and not have to pay some insane fee. I think you missed a trick not naming it Railwind UI. I used this about a year ago when I went through a short Rails phase. I was a bit surprised not to see more Rails-specific UI libraries considering how batteries-included the rest of the framework is, and at the time I didn't really 'get' tailwind. I'm not in a Rails phase anymore, but nice work on the library! maybe I'm just dumb but a lot of these elements don't seem to work? the \"...\" buttons don't open any flyout, the dropdown doesn't open up... otherwise looks cool though I wish I could use this \u2013 unfortunately UI frameworks are a political problem at every company I've worked at. The designers feel undermined or threatened by it, and product owners want to dictate design. Despite the massive productivity benefits of a UI framework, I've never been able to convince stakeholders to actually adopt one. If you\u2019re showing off a UI framework, I shouldn\u2019t be accidentally scrolling left and right on the page on mobile / my iPhone. Couldn\u2019t be bothered to scroll down the page to look at components while accidentally activating horizontal scrolling. Broken in Safari on iphone. For example: - table background moves left when table is scrolled horizontally - actions in table and dropdown do nothing on tap - text on buttons is selectable (really?) im always surprised that Rails is still relevant i havent used it since 2006 opting for php and django i might give it another shot, any reason you like this more than django or other frameworks I have hardware acceleration disabled in Firefox and my 5800X spins up trying to rend"}
{"anchor": "Over 40% of deceased drivers in vehicle crashes test positive for THC: Study. I\u2019m not surprised so many deceased drivers were under the influence of THC. I see people smoking and vaping at stoplights all the time. I am however, surprised this study claims legalization didn\u2019t change the rate. Anecdotally, on the west coast, I\u2019ve seen far more of this, and also people casually smoking in public spaces (parks or train stations or whatever) since legalization. And what share of the remaining 60% were killed by the initial 40%? I am curious what percentge of the general populous test positive for THC. It would give better context to a dead drivers testing positive for THC. Feels like a low sample size, but I'm not statistician or doctor. That said, almost everyone I know that consumes THC has no qualms driving while doing it, and many of them also at work. It's a huge peeve of mine. Based on the headline, I was guessing it was any amount of positivity, and may be close to the population level, but it's actually impairment levels of THC: > In a review of 246 deceased drivers, 41.9% tested positive for active THC in their blood, with an average level of 30.7 ng/mL \u2014 far exceeding most state impairment limits. Since COVID in CA, it feels like driving has become far more dangerous with much more lawlessness regarding excessive speeding and running red lights,  going into the left lane to turn right in front of stopped cars, all sorts of weird things. But I can't tell if my anecdotes are significant. It seems that Ohio's impaired drivers have been consistent through the past six years though. Is there a full study somewhere? I'd expect them to screen for other psychoactive substances as well, of which I see no mention here. Whenever you think to yourself \"People couldnt be that stupid, right?\" read this study and plan accordingly. Wish the paper were available - would love to know the percentage with alcohol. The other question I have - my prior is that a bad driver (tired, d", "positive": "High air pollution could diminish exercise benefits by half \u2013 study. It sounds terrible . What will happend in the future?! The research doesn't differentiate between seasons , and every one knows how polluted the air is in the winter when everyone is heating their home and apartament. I look at the PM2.5 data for my city every day, and at this point (Nov) in the winter season, the only acceptable time to exercise is between 2PM-4PM after vertical mixing kicked in. Outside that duration, particulates are elevated after morning rush our, after evening rush hour, or during overnight inversion trapping evening rush hour + wood burning smoke until the next morning rush hour. This is one the main reasons why I would prefer working remote, it is hard to utilize this time well (for exercise) if you are in the office. At least with PM you can wear a mask, although I am still searching for the best one that works during intense exercise. Also wanted to point out\n\"Trump EPA moves to abandon rule that sets tough standards for deadly soot pollution\"  https://apnews.com/article/epa-soot-air-pollution-trump-zeld...  If only you could see it. In the big cities the air quality has improved, however, I am not sure if it really has, or if we are now just burning hydrocarbons more efficiently so that the particle sizes have become invisible. Put it this way, although cars are allegedly better than they were, fuel consumption hasn't dropped considerably. The cars are more numerous than ever, and, although there are EVs, there are still more ICE cars than there were in the good old days when petrol came with lead in it. I am not sure that most people in urban areas even know what good air tastes and smells like. I take a canal path through lush countryside, far from any cars for most of the way. This canal has an aqueduct (or is it a viaduct?) over a motorway and the contrast is incredible. You go from basically smelling flowers to air pollution and back to clean air again quite quickly", "negative": "Amazon closing its Fresh and Go stores. Once their vision for \"grab and go\" vanished due to technological infeasibility [1] the entire premise for the stores vanished as well. I suspect that they wanted to take a hail marry to see if  somehow  it was possible to get much greater efficiency compared to standard grocers, and it looks like that failed. [1] it may come back. The technology is rapidly improving but they have bigger fish to fry ATM. Did the humans pretending to be the AI unionize? I thought they already did close them. I know at some point they got caught basically paying people to watch cameras to figure out what products people we're grabbing. I'm sure were either at the point or very close to the point where AI can successfully do this basically 100% of the time. So I doubt it's the tech aspect of this, more just the grossness a person feels walking into a store with Amazon's name on it. Compare this to whole foods. Coincidentally(?) they are open their first big box retail store:  https://www.cnbc.com/amp/2026/01/09/amazon-plans-first-big-b...  Their fate seemed sealed when it was revealed a bit back that the \u201cjust walk out\u201d technology was more hype than substance. Just lots of people watching what you\u2019re doing on camera vs an actual AI that worked well at mass deployment scale. A good idea, poorly executed. Reports said the \u201cAI\u201d was largely 1000+ people in India watching the cameras. If Amazon actually managed to build AI that worked well at a decent cost point it would have been great since nobody likes those silly self checkout machines. What\u2019s amusing about all of this is that before it got leaked that it was basically a bunch of people in India watching cameras Amazon folks spoke about the tech like there was some super secret AI they developed. Since that story broke nobody there seems to want to talk about \u201cjust walk out\u201d anymore. I\u2019m in an interesting place. Here in Seattle I am two blocks from one of the largest Amazon Fresh stores. It was bu"}
{"anchor": "I rebooted my social life. My partner and I were discussing our need for \u201cthird spaces\u201d this week. We\u2019re homebodies, and enjoy being home. However mundanity of wake, work, hobbies, sleep in the same place every day is getting to us. It\u2019ll be a slightly different approach to the other though. For me, I want to start playing some tabletop games (war games and/or RPGs) at my Friendly Local Game Shop. I think these types of interactions are important for community. > Hanging out with other humans is good \u2013 and if you can\u2019t find a community\u2026 you can always build your own. I did just that, and built  https://wonderful.dev  It's based around jobs for devs, but right now it's just a place to chat about tech. Back in 2019, got to go to Hong Kong for a couple months for work and got to bring my family. I was about to turn 40 and realized that the place we were staying had a rock wall. In a somewhat \"mid life crisis\" spur of the moment decision, I decided to go buy shoes, a belt and a chalk bag (I did a lot of indoor rock climbing in college). We get there and the rock wall is a. closed and b. only for kids. Get back to the US and COVID lockdown starts. As things open up, I go on the town dad's Facebook group and ask if anyone wants to go rock climbing with me. Multiple dads say \"hell, yes!\" so I start a rock climbing club. One of the dads that joins the climbing club loves board games, is inspired by my starting the rock climbing club so he starts the town board game club. I tell people this story to illustrate that: - if you don't have a club or org for something that you're into, go start one - you doing the above can trigger other people to start clubs too Congrats OP, sounds super excited for his new social life. I live overseas and I\u2019m very lonely. I\u2019ve been told to join a group or club related to my interests so I can meet new people and make friends, but I can\u2019t. It doesn\u2019t feel natural to me to go for friend-hunting. And I\u2019m very tired of meaningless, superficial conn", "positive": "Early Retirement (2006). How much money can a Silicon Valley software engineer expect to have at retirement? This article says $7 million:  https://www.wealthmeta.com/blog/being-a-doctor-vs-being-a-so...  Here's the back-of-the-envelope calculation: Annual salary: $250K (it is much higher at FAANG). Assume 25% tax (effective, not marginal), which leaves us with $187.5K, which is about $15K per month. Assume $5000 in monthly expenses, which leaves us with $10K per month investable money. (Note: since net worth includes house and 401(k) I have not deducted mortgage or 401(k) payments). So $10K includes those items.) Now use a compound interest calculator to see what $10K per month at 8% interest (assume investment in S&P 500 and allow for some market crashes) will result in, at the end of 30 years. It is about $14 million, which would include your house and your 401(k). Here's a spreadsheet that allows you to plug in your own numbers:\n https://docs.google.com/spreadsheets/d/1Ryu_-mVYxSdJbW8lmf1z...  > Retirement forces you to stop thinking that it is your job that holds you back. For most people the depressing truth is that they aren't that organized, disciplined, or motivated. Maybe, but I don\u2019t know anyone who\u2019s less happy being retired. They might not be living their retirement fantasy, but the pressure and stress of having to work is gone. He's always been an interesting chap. I wish him well.  > Most important, do not retire in the expectation that it will be easy to find rewarding non-profit volunteer work.  Thankfully, this has not been an issue with me. I definitely don't have the massive nest egg that another commenter mentioned, but I've got enough to avoid starving, and I am happier than I ever thought I'd be. > How much work does the average college student get done? Almost none. Yet the same person, injected into a corporate bureaucracy, becomes a reasonably effective worker. Why? Most people have terrible time management skills. This limitation is of no ", "negative": "Tell HN: I cut Claude API costs from $70/month to pennies. Can you discuss a bit more of the architecture? Are you also adding the proper prompt cache control attributes? I think Anthropic API still doesn't do it automatically Consider using z.ai as model provider to further lower your costs. It sounds like you don\u2019t need immediate llm responses and can batch process your data nightly? Have you considered running a local llm? May not need to pay for api calls. Today\u2019s local models are quite good. I started off with cpu and even that was fine for my pipelines. This is the way. I actually mapped out the decision tree for this exact process and more here:  https://github.com/NehmeAILabs/llm-sanity-checks  Have you looked into  https://maartengr.github.io/BERTopic/index.html  ? You also can try to use cheaper models like GLM, Deepseek, Qwen,at least partially. As much as I like the Claude models, they are expensive. I wouldn't use them to process large volumes of data. \nGemini 2.5 Flash-Lite is $0.10 per million tokens. Grok 4.1 Fast is really good and only $0.20. They will work just as well for most simple tasks. consider this for addtl cost savings if local doesnt interest you -  https://docs.cloud.google.com/vertex-ai/generative-ai/docs/m...  Pretty straightforward. Sources dump into a queue throughout the day, regex filters the obvious junk (\"lol\", \"thanks\", bot messages never hit the LLM), then everything gets batched overnight through Anthropic's Batch API for classification. Feedback gets clustered against existing pain points or creates new ones. Most of the cost savings came from not sending stuff to the LLM that didn't need to go there, plus the batch API is half the price of real-time calls. This is what i was going to suggest too. Do they or any other providers offer any improvements on the often-chronicled variability of quality/effort from the major two services e.g. during peak hours? Or minimax - m2.1 release didn't make a big splash in the news, but it'"}
{"anchor": "BERT is just a single text diffusion step. Very cool parallel. Never thought about it this way \u2014 but makes complete sense Fun writeup! It's amazing how flexible an architecture can be to different objectives. When text diffusion models started popping up I thought the same thing as this guy (\u201cwait, this is just MLM\u201d) though I was thinking more MaskGIT. The only thing I could think of that would make it \u201cdiffusion\u201d is if the model had to learn to replace incorrect tokens with correct ones (since continuous diffusion\u2019s big thing is noise resistance). I don\u2019t think anyone has done this because it\u2019s hard to come up with good incorrect tokens. Interested in how this compares to electra To my knowledge this connection was first noted in 2021 in  https://arxiv.org/abs/2107.03006  (page 5). We wanted to do text diffusion where you\u2019d corrupt words to semantically similar words (like \u201cquick brown fox\u201d -> \u201cspeedy black dog\u201d) but kept finding that masking was easier for the model to uncover. Historically this goes back even further to  https://arxiv.org/abs/1904.09324 , which made a generative MLM without framing it in diffusion math. To me, the diffusion-based approach \"feels\" more akin to whats going on in an animal brain than the token-at-a-time approach of the in-vogue LLMs. Speaking for myself, I don't generate words one a time based on previously spoken words; I start by having some fuzzy idea in my head and the challenge is in serializing it into language coherently. To me part of the appeal of image  diffusion models was starting with random noise to produce an image. Why do text diffudion models start with a blank slate (ie all \"masked\" tokens), instead of with random tokens? I love seeing these simple experiments. Easy to read through quickly and understand a bit more of the principles. One of my stumbling blocks with text diffusers is that ideally you wouldn\u2019t treat the tokens as discrete but rather probably fields. Image diffusers have the natural property that a pi", "positive": "Mitochondria as you've never seen them. Wow! Really shows how mitochondria are actually just bacterial cells living inside us! Mitochondria are so absurdly more complex and interesting than what is mostly taught in schools.\nAwesome video! So each of our cells is a habitat for a network of wiggly energy-producing worms... Madeline L'Engle was right all along I studied an BSc in genetics and none of our lectures or textbooks presented mitochondria any differently from the classic bean shape they introduce in school. This is surely old news to folks who specialise in mitochondria, but it's easy to miss out on these fundamentals even if you've studied in a relevant area at degree level, because there's just so much to know in biology. In fact, it's one of those fields where the more you learn, the more you realise we'll never reach a satisfactory understanding in our lifetime. You could chuck an endless supply of PhD students at every constituent domain for generations and still feel like you've scarcely scratched the surface of the many things there are to question. To think I've spent hours upon hours each week for years and year with the express goal of producing more of these in the muscle cells of my legs, and I call this novel goal \"exercise\". Without this symbiotic relationship in cellular life on other planets, would it prevent complex cellular life? So beautiful and so sad to think about how much more interesting biology is than what we can teach from textbooks. This makes me want to further explore the similarities in form and function of mitochondrial networks and mycelial networks. Really sucks that antibiotics, especially bacteriocidal ones, appear to target mitochondria as if they were bacteria. This mistargetting causes sometimes severe and long-lasting side effects. The Seven Daughters of Eve are alive and well, I see Is the link supposed to go to a slideshow? Does anyone here have a sense of what time frame the video covers? Like, is that real-time and ", "negative": "California is free of drought for the first time in 25 years. As John Steinback said in  East of Eden : \u201cI have spoken of the rich years when the rainfall was plentiful. But there were dry years too, and they put a terror on the valley. The water came in a thirty-year cycle. There would be five or six wet and wonderful years when there might be nineteen to twenty-five inches of rain, and the land would shout with grass. Then would come six or seven pretty good years of twelve to sixteen inches of rain. And then the dry years would come, and sometimes there would be only seven or eight inches of rain. The land dried up and the grasses headed out miserably a few inches high and great bare scabby places appeared in the valley. The live oaks got a crusty look and the sage-brush was gray. The land cracked and the springs dried up and the cattle listlessly nibbled dry twigs. Then the farmers and the ranchers would be filled with disgust for the Salinas Valley. The cows would grow thin and sometimes starve to death. People would have to haul water in barrels to their farms just for drinking. Some families would sell out for nearly nothing and move away. And it never failed that during the dry years the people forgot about the rich years, and during the wet years they lost all memory of the dry years. It was always that way.\u201d The dams in california were built years ago for a smaller population and since then they've only removed them. If we simply built like the people who first came to california did we would never have water shortages again. Any water shortage is a 1:1 failure of the state to do the clear and obvious task needed. strange because this is one of the warmest winters in decades. snow levels are far below normal, i saw 8% of normal in truckee. full reservoirs now are great but keeping them filled depends on a long snow melt going into june. i don\u2019t think this is going to be a good year for that And yet our water rates are still as if we are in a drought. Previ"}
{"anchor": "Broken legs and ankles heal better if you walk on them within weeks. It was ~20 years ago, so my memory is a little foggy, but I gave myself a \"dancer's fracture\" in one foot. After many months, it was looking like a non-union. The podiatrist was worried any pin would split the broken bone even more. It wasn't looking good. I had read something along these lines even back then, so with my crazy immobilizer boot on, I head to the gym and started doing light squats several times per week. Next x-ray: healed. The pathology for broken collar bones was changing right as I took up mountain biking, and subsequently shattered my collarbone. It was hotly debated at the hospital, if my specific case should be operated on or not. Each time I had a checkup, one doctor would say \"wait and see\" while the other was saying \"I can't believe we didn't operate on this\". At any rate, the outcome was as good as if they had operated on it, according to the doc anyway. Nice of them to test it out on me! More related to this though, I have broken both my collarbones, the first time I had little direction and just held my arm still for 2-3 months. It took forever to heal, and my arm atrophied significantly. The second time, similar severity. I was guided through rehab and I was back using my arm within the first month, very little atrophy. I fractured my elbow mountain biking, the tip of my radius. The urgent care doctor gave me a sling and suggested months of immobility. The orthopaedic said to throw away the sling and start exercising the elbow as soon as I could, and prescribed PT. Turns out that was the right move, there are some permanent changes to mobility but it's about 97% what it was before the crash. Immobilizing joints can apparently cause the muscles, tendons, and nerves to seize up and lose significant range of movement permanently. If anyone's heard of RICE (Rest, Ice, Compression, Elevation) for healing joints, the new guidance is called POLICE: Protect, Optimal Load, Ice, C", "positive": "Waymo granted permit to begin testing in New York City. I saw one of these on Chambers Street just yesterday afternoon, but it must have been in manual mode, of course. It's fascinating seeing all the comments elsewhere anytime Waymo starts testing in another city along the lines of, \"ah, but how will they handle X, Y, and Z here?? Checkmate, robots!\" despite having already launched service in several other cities. Granted, NYC is the biggest city in the US, so maybe that sort of reaction is more reasonable there than when people in Dallas or Boston do it. Very cool. I wonder what scale it has to hit for this to become a profitable line item for Google and what their revenue targets are for it. Man I love Waymo everytime I'm in SF. Truly feel like I'm living in the future when I sit in one I'm cautiously optimistic about this self-driving thing. Waymo at least seems to have figured out a lot of it. Would it be way better to make walkable neighborhoods, mixed-use developments, and reliable and frequent public transit? Yes. Yes it would. But, in lieu of that, self-driving has a lot of advantages in the long run, even if the technology isn't 100% perfect right now. It's insane that they need permits for 8 cars that have humans driving them in 2025, when they're already fully automated in SF. > We\u2019re a tech-friendly administration Clearly not. Is this the first time Waymo is doing winter / snow testing at scale? I think some of the Pittsburgh-based self-driving firms may have tried this, but unaware how far they got. I\u2019m curious if autonomous cars will become targets for aggressive drivers. Like a driver isn\u2019t going to be as scared cutting off a Waymo or tailgating one because the AI isn\u2019t gonna get road rage or honk like hell. In some places I could see the Waymo\u2019s getting severely bullied if that\u2019s the case. The game-theoretic aspect of this is interesting to me. A lawful robot will never make progress in Manhattan because the people will just walk across its path con", "negative": "Find 'Abbey Road when type 'Beatles abbey rd': Fuzzy/Semantic search in Postgres. I was just starting to learn about embeddings for a very similar use on my project. Newbie question: what are pros/cons of using an API like gpt Ada to calculate the embeddings, compared to importing some model on Python and running it locally like in this article? Great post. Explains the concepts just enough that they click without going too deep, shows practical implementation examples, how it fits together. Simple, clear and ultimately useful. (to me at least) I found fuzzy search in Manticore to be straightforward and pretty good. Might be a decent alternative if one perceives the ceremony in TFA as a bit much. The rewritten title is confusing imo. Can I propose: \u201cFinding \u2018Abbey Road\u2019 given \u2018beatles abbey rd\u2019 search with Postgres\u201d these days i find myself yearning to type \"Beatles abbey rd\" and find only \"Beatles abbey rd\" for 50,000 rows I'd much rather just use fzf/nucleo/tv against json files instead of dealing with database schemas. \nWhen it comes to dealing with embedding vectors rather than plaintext then it gets slightly more annoying but still feels like such an pain in the ass to go full database when really it could still be a bunch of flat open files. More of a perspective from just trying to index crap on my own machine vs building a SaaS > Abbey Road > The Dark Side of the Moon > OK Computer Those are my 3 personal records ever. I feel so average now... tl,dr: A demo of pg_trgm (fuzzy matcher) + pgvector (vector search). FWIW, the performance considerations section is a little simplistic, and probably assumes that exact dataset/problem. For GIN for example, perfomance depends a lot on the size of the search input (the fewer characters, the more rows to compare) as well as the number of rows/size of the index. It also mentions GiST (another type of index which isn't mentioned anywhere else in the article).. On the API vs local model question: We went with API embedding"}
{"anchor": "Review of Anti-Aging Drugs. From the conclusion paragraph: > Your primary life extension program is diet and exercise. Choose a diet that works for you. Stay slim. Considering heart disease is the #1 killer, doing whatever you can to not die from heart disease is the best place for most people to start. Even in 2025, diet and exercise are still king. Winner, \"Ascorbic\". Do they mean Vitamin C? Would any of the OTC stuff even be effective? Melatonin, NAC, and Berberine. Be careful when reading such blogs: > Note that the dosage in the mouse experiments is quite high \u2014 0.1% of the body weight every day, meaning about 2 ounces a day for me (70 kg). Mouse and human metabolism are very different. A better starting estimate would be 5g/day, not 57g/day. I hope people dont accidentally overdose themselves because of lack of a pharmacology background. A lot of people in the comments are talking about the \"problem\" of death and approaches to take, but really, the only thing you can do is philosophically make your peace. Anything else at this point is yelling into infinity. > Fast for short intervals regularly, and longer fasts as they feel good to you. You can effectively do this every day if you just eat once per day. When I was properly obese, this technique resulted in rapid weight loss. Zero exercise was required to see results, which was good at the time because the not eating part was about all I could handle. Being in a fasted state is as close as you can get to actually  reversing  aging. Your body engages in a process called autophagy when nutrient-sensing pathways are down-regulated. When you are stuffing your face constantly (i.e., every ~8 hours), there is less opportunity for this mechanism to do its job.  https://en.wikipedia.org/wiki/Autophagy  Richard Miller's Intervention Testing Program should really be your go-to for this:  https://www.nia.nih.gov/research/dab/interventions-testing-p...  He has no conflicts of interests, works for the NIA, and he's quite o", "positive": "Over 36,500 killed in Iran's deadliest massacre, documents reveal. I can't comprehend how a population can kill that many of their own people. They aren't even an \"other\" people, which has been the most common scapegoat lately. Same skin color, same religion, same language, same homeland. For comparison, estimates of the 1989 Tiananmen Square massacre death count are usually put in the 300-1,000 range by journalists and human rights groups.  https://en.wikipedia.org/wiki/1989_Tiananmen_Square_protests...  hm, I think we should re-evaluate sanctioning or civilian pressure campaigns, since the guise is for them to coax or turn on the government for regime change, but the government can just hire mercenaries from outside the country. don't know a solution but this one isn't it The source (Iran International) is backed by Saudi money and has a bias to dunk on Iran. That said, I'm sure the death count numbers from the Rasht Massacre are staggeringly higher than the initial tallies of 2-5k. This is certainly the end of peaceful Iranian protests. Whether it leads to a violent revolution or a static police state like North Korea remains to be seen. How is this possible without explosives? Even with vehicle mounted machine guns it seems like a crazy high number. Did the protestors get boxed in somehow? And across so many locations, that seems to require a crazy amount of coordination to kill so many in so little time. That's crazy. That's like ~40% of the deaths in the current gaza war, except over just 2 days instead of 2 years. This is depressing because we will go to war over this and it\u2019s going to be five years before people realizing they were tricked by \u201cbabies in incubators\u201d propaganda. The internet is fragile. Access can be so easily cut off for the masses in dire times. Take a good look US, because once you're down far enough the fascist drain, that's the cost of trying to claw your way back out. And there's no hope of external intervention given nuclear arms Earlie", "negative": "AI2: Open Coding Agents. Awesome stuff. Output speed looks crazy fast too. I wonder if this indeed will start prompting more language specific work. Afaik training still requires not just looking at sample code but also being able to write loss functions being able to have problems the AI can work at. That seems hard. One random thought, are there training styles of just deleting some code from \"good\" projects then making the AI make it work again? Claims in the article are incorrect. They conveniently ignore Meta CWM models, which are open-sourced [1] and open-weight [2] and are at 65% SWE-bench verified (with TTS) and 54% pass@1 and the same size (32B dense). So claims like \"surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths\" and conveniently leaving out the previous OSS SOTA out of your eval tables are ... sketch. [1] https://github.com/facebookresearch/cwm \n[2] https://huggingface.co/facebook/cwm  it's great to see this kind of progress in reproducible weights, but color me confused. this claims to be better and smaller than Devstral-Small-2-24B, while clocking in at 32B (larger) and scoring more poorly? Great work! Really respect AI2. they open source everything. The model, the weights, the training pipeline, inference stack, and corpus Hey this looks great? Is it available on Openrouter. I wish if AI2 could release a more denser model on Openrouter for free than the 8B model as I was using Devstral model for agentic purposes. If we can get an agentic good 32B like model on openrouter for ~free, then I feel like it will be very interesting to see how things would go imo. Good luck with AI2! The premise of truly open source models is really interesting and I feel like it could help bring more innovation in the space imo! One claim in article is definitely very wrong or at least needs to be narrowed. Claude is the only closed agent harness and there are about two dozen open ones. Many models may be closed, but when"}
{"anchor": "Eat Real Food. Makes sense to me! And poor diet is probably one of the biggest problems in the United States Makes sense. Now make protein affordable. And 100 years from now, will we still call it the New Pyramid? :) I guess we still call it New York... Great!  How will the reductions in consumer protection, health, FDA, etc. - by this current administration impact that?  https://www.food-safety.com/articles/11004-a-2025-timeline-o...  This website is far too complicated, just show a clear, labeled image of the new pyramid.  This is designed to scare people, not inform them. Lol good one. Anything matching . real .\\.gov$ can be discarded as BS these days... Edit: Actually make that simply .*\\.gov$ It's unbelievable to which point this clown show has permanently dismantled US soft power. Guess they think they have enough hard power to compensate. What with all that good raw milk and meat they're eating... Ironic that a steak is one of the three things showing up on the landing page. Is that the beef lobby money coming in? I enjoy an occasional steak but if the goal is to improve diet of masses, it\u2019s not the food I\u2019d put at the center. \"In February 2010, Michelle Obama launched \u201cLet\u2019s Move!\u201d with a wide-ranging plan to curb childhood obesity. The campaign took aim at processed foods, flagged concerns about sugary drinks, and called for children to spend more time playing outside and less time staring at screens. The campaign was roundly skewered by conservatives... But the strategy that Kennedy\u2019s HHS is using to address the problem so far\u2014pressuring food companies to alter their products instead of introducing new regulations\u2014is the same one that Obama relied on, and will likely fall short for the same reason hers did a decade ago.\"  https://www.theatlantic.com/health/archive/2025/09/maha-lets...  Meta comment: The design aesthetic gives me a real \"Cards Against Humanity\" feel. > Whole grains are encouraged. Refined carbohydrates are not. Prioritize fiber-rich whole g", "positive": "Ask HN: What are the best engineering blogs with real-world depth?. Encountered one specific example about a month ago here on HackerNews - All about automotive lidar.\n https://news.ycombinator.com/item?id=46110395  Blog posts where I find quality really shows are usually about something I know next to nothing about how it works. A badly written article usually either goes really shallow or skips some facts when going into depth and requires catchup elsewhere to actually understand it. The lidar article from Main Street Autonomy goes beyond basics and explained everything from the ground up in such a connected way that it was a real pleasure reading it. Sounds like you look for an intersection of academic papers (1.), tech blogs (2.), text books (3.), and confidential business strategies (4.)? A very high ambition. Maybe  https://projectzero.google/archive.html   https://netflixtechblog.medium.com/   https://www.uber.com/en-US/blog/engineering/  You're probably looking for something that is more focused on specific software decisions/implementations, but  https://infrequently.org  is the best web development blog out there. It's not \"technical\" so much as it just educates you on how to be a good web developer/run a team. There's zero fluff and considerable detail (footnotes are practically blog posts themselves).  http://highscalability.squarespace.com/all-time-favorites/  There are no such blogs. Usually companies, or individuals, will write these after they implement some feature into their products. Which makes them inherently little pieces of information scattered all over the internet and there is no one blog that is just about this. Cloudflare, google project zero. > especially from tech company blogs,  https://engineering.fb.com/   https://netflixtechblog.com/   https://stripe.com/blog/engineering   https://eng.uber.com   https://engineering.linkedin.com/   https://engineering.atspotify.com/   https://tailscale.com/blog   https://careersatdoordash.com/enginee", "negative": "Doom has been ported to an earbud. Hi, I ported DOOM to the Pinebuds Pro earbuds.\nIt's accessible over the internet, so you can join the queue and play DOOM on my earbuds from your PC!\nMore info as well as links to the github repos can be found on the site. This is awesome! the amount of devices doom has not been run on shrinks by the day haha How are the PineBuds Pro, anyone have them? The Pine64 IRC network doesn't have a channel for PineBuds discussion so I haven't had an easy opportunity to ask. At first I thought you found a way to control/view the game acoustically and I was very curious how that worked. But, this probably makes more sense. Do we have Doom on a USB-C plug microcontroller yet? List of Doom ports:  https://en.wikipedia.org/wiki/List_of_Doom_ports  Im waiting for the post \"Doom ported to disposable Vape chip\" :-D can we run doom on water pump? Whenever I see another supposedly menial device including enough general purpose hardware to run Doom, I wonder whether I should think of that as a triumph of software over hardware or an economic failure to build cheaper purpose-built hardware for things like sending audio over a radio. The standalone viewer (connected directly to the earbuds) also works on mobile:  https://files.catbox.moe/pdvphj.mp4  No touch controls though, it just plays the intro loop On a tangent: I remember reading John Carmak saying that as game engines became more complex, he had to relinquish the idea of writing all the (engine) code himself, and start to rely on other folks contributions as well (this was in an interview after the release of Doom 3). I wonder what his feelings are in this age of AI. Relevant SMBC, \"Computer scientist vs computer engineer\":  https://www.smbc-comics.com/comic/2011-02-17  I am a bit said that it is always Doom. Now ... I played the game when I was young. It was addictive. I don't\nthink it was a good game but it was addictive. And somewhat simple. So what is the problem then? Well ... games have got"}
{"anchor": "Resistance training load does not determine hypertrophy. tldr appears to be that if you work to fatigue it doesn't matter if you fatigue out with high weights vs low weights I know it's practically de rigeur to jump into the comments and immediately complain about methodology for any study that makes it to the front page, and I want to emphasize I don't distrust their findings, but I would like to see an equivalent study go out longer than 10 weeks. When I've been taking weightlifting seriously I feel like I don't even start to notice hypertrophy until 8-10 weeks. I feel like 6 months is the actual period where results would matter, to me, but I assume \"subject compliance\" is pretty difficult to get for such a timeframe, if you're really watching dietary intake and ensuring subjects go to failure (which, to its credit, this study did). I thought it was already well understood/researched that it's not the weights that matter, but effectively taking your sets to muscular failure. While one might think \"I can do 50 reps with low weights\" there is practical aspects to this - you don't wand to spend hours at the gym, and doing heavy weights at 5-7 reps is sufficient as long as you are close or at muscular failure. If I read this correctly the gist is that it does not matter if you use heavy weights with few reps (common body builder wisdom) or lighter weights with more reps. As long as you always exercise to\ncomplete muscle fatigue you'll\nget the maximum for your genetics (which itself varies a lot). The group that did lower reps with higher weight, had the better one rep max at the end of the study, but they didn\u2019t measure if the higher rep group had greater endurance. Which seems a bit odd, considering their conclusion is both groups grew the same amount of muscle which fine but if the muscle is adapted for something different in each group, you would want to capture that. > Twenty healthy young male participants completed thrice-weekly resistance exercise sessions for", "positive": "Early Retirement (2006). How much money can a Silicon Valley software engineer expect to have at retirement? This article says $7 million:  https://www.wealthmeta.com/blog/being-a-doctor-vs-being-a-so...  Here's the back-of-the-envelope calculation: Annual salary: $250K (it is much higher at FAANG). Assume 25% tax (effective, not marginal), which leaves us with $187.5K, which is about $15K per month. Assume $5000 in monthly expenses, which leaves us with $10K per month investable money. (Note: since net worth includes house and 401(k) I have not deducted mortgage or 401(k) payments). So $10K includes those items.) Now use a compound interest calculator to see what $10K per month at 8% interest (assume investment in S&P 500 and allow for some market crashes) will result in, at the end of 30 years. It is about $14 million, which would include your house and your 401(k). Here's a spreadsheet that allows you to plug in your own numbers:\n https://docs.google.com/spreadsheets/d/1Ryu_-mVYxSdJbW8lmf1z...  > Retirement forces you to stop thinking that it is your job that holds you back. For most people the depressing truth is that they aren't that organized, disciplined, or motivated. Maybe, but I don\u2019t know anyone who\u2019s less happy being retired. They might not be living their retirement fantasy, but the pressure and stress of having to work is gone. He's always been an interesting chap. I wish him well.  > Most important, do not retire in the expectation that it will be easy to find rewarding non-profit volunteer work.  Thankfully, this has not been an issue with me. I definitely don't have the massive nest egg that another commenter mentioned, but I've got enough to avoid starving, and I am happier than I ever thought I'd be. > How much work does the average college student get done? Almost none. Yet the same person, injected into a corporate bureaucracy, becomes a reasonably effective worker. Why? Most people have terrible time management skills. This limitation is of no ", "negative": "The microstructure of wealth transfer in prediction markets. tl;dr dataset: 72.1m trades and $18.26b volume on kalshi (2021-2025) core findings: longshot bias: well documented longshot bias is present on kalshi. low probability contracts are systematically overpriced. contracts trading at 5 cents only win 4.18% of the time. wealth transfer: liquidity takers lose money (-1.12% excess return) while liquidity makers earn it (+1.12%). optimism tax: the losses are driven by a preference for \"yes\" outcomes. buying \"yes\" at 1 cent has a -41% expected value. buying \"no\" at 1 cent has a +23% expected value. category variation: finance markets are efficient (0.17% maker-taker gap) while high-engagement categories like media and world events are inefficient (>7% gap). mechanism: makers do not win by out-forecasting takers. they win by passively selling \"yes\" contracts to optimistic bettors I'm a little confused by the \"Yes\" versus \"No\" asymmetry. For example, one of the top trending ~~bets~~ markets right now is on whether Miami or Indiana will win the NCAA football championship tonight. You can either take \"Yes\" on Indiana at 74c, or \"No\" at 27c, or you can take \"Yes\" on Miami at 27c or \"No\" at 74c. Or, there's another potential outcome - you can also bet on a tie at 10c yes/91c no. Is this research suggesting that an optimistic Miami fan can somehow get a better return by buying \"No\" on Indiana than a \"Yes\" on Miami? Why is Kalshi structured with these yes vs. no options for all outcomes? How do prediction markets account for interest rates? I feel like I should be willing to pay no more than ~96 cents for a contract that will definitely resolve to a dollar in a year. Who puts up the other 4 cents? I wonder how much of the activity on prediction markets these days is competing LLM scripts? I would guess the overlap in prediction market punters and AI boomers is high. This article lacks even the most basic understanding of probability and statistics. Slot machines \"93 cents o"}
{"anchor": "Qwen3-TTS family is now open sourced: Voice design, clone, and generation. great news, this looks great!  is it just me, or do most of the english audio samples sound like anime voices? I still don't know anyone who managed Qwen3-Omni to work properly on a local machine. Qwen team, please please please, release something to outperform and surpass the coding abilities of Opus 4.5. Although I like the model, I don't like the leadership of that company and how close it is, how divisive they're in terms of politics. How does the cloning compare to pocket TTS? it isn't often that tehcnology gives me chills, but this did it. I've used \"AI\" TTS tools since 2018 or so, and i thought the stuff from two years ago was about the best we were going to get. I don't know the size of these, i scrolled to the samples. I am going to get the models set up somewhere and test them out. Now, maybe the results were cherrypicked. i know everyone else who has released one of these cherrypicks which to publish. However, this is the first time i've considered it plausible to use AI TTS to remaster old radioplays and the like, where a section of audio is unintelligible but can be deduced from context, like a tape glitch where someone says \"HEY [...]LAR!\" and it's an episode of Yours Truly, Johnny Dollar... I have dozens of hours of audio of like Bob Bailey and people of that era. Kind of a noob, how would I implement this locally?\nHow do I pass it audio to process. I'm assuming its in the API spec? Huh. One of the English Voice Clone examples features Obama. If you want to try out the voice cloning yourself you can do that an this Hugging Face demo:  https://huggingface.co/spaces/Qwen/Qwen3-TTS  - switch to the \"Voice Clone\" tab, paste in some example text and use the microphone option to record yourself reading that text - then paste in other text and have it generate a version of that read using your voice. I shared a recording of audio I generated with that here:  https://simonwillison.net/", "positive": "SpaceX lowering orbits of 4,400 Starlink satellites for safety's sake. From a comment : >The first move in the coming WWIII, where the emperors try to expand their empires militaril,y will be to wipe out any orbit with Starlink satellites. I find this highly unlikely, given Starlink is soon to reached 10k satellites and will continue to grow. Why expand 10 000 ballistic missiles to bring down one of many communications networks ? There are so many satellites in orbit that there is a pretty good chance that if even one was to be hit by something and explode in many pieces, it would crash another one and then another one until there is nothing left. The nasa is pretty scared of it, so is SpaceX. I think it's important to note that not all collisions are equally dangerous. Consider a sat on a polar orbit colliding with one on a equatorial orbit. Or two satellites on different directions.  That  is going to be spectacular. Otoh, these kind of collisions are unlikely and should be manageable by just assigning certain shells (say 5km) for every possible direction and orientation. If two Starlink satellites collide that go roughly in the same direction, it's not exactly a huge problem. I think the biggest issue is to coordinate this and potentially disallow some excentric orbits. What\u2019s the plan as the solar maximum returns? Can anyone explain how does one technically lower a satellite? 3 week old news OP? Previously:  https://news.ycombinator.com/item?id=46457454  Won't this make running Starlink more expensive? Lower orbits > Increased atmospheric drag > More fuel expended to maintain orbit > Heavier sats due to more fuel > Increased launch cost per unit Or even: Lower orbits > Increased atmospheric drag > Quicker orbit decay > Shorter lifespan of sats > More frequent launches Forgive my Kerbal-based space knowledge here. Because Kessler syndrome means you don't need to hit all 10k yourself. Lowering the orbits just means that we get back to normal faster, not that the i", "negative": "430k-year-old well-preserved wooden tools are the oldest ever found. 430,000 years? Am I reading this headline correctly? (since the site seems to have fallen victim to the HN-hug-of-death). That seems wildly further back than I understood humans to have tools, or even homo sapiens to have existed. ETA: Today I learned I had a much much larger gap in knowledge than I thought I did. Thanks to everyone for the information and links! There is archaeological evidence of tools going back even further, potentially over a million years, but it's ignored for the usual reasons of dogma and not conveniently fitting into the paradigm of the current priestly class. I'd highly recommend this talk Michael Cremo (author of \"Forbidden Archaeology\") gave for this \"Authors at Google\" program in 2014:  https://www.youtube.com/watch?v=DKfGC3P9KoQ  There's bound to be a lot of vital archeological evidence of the development of humans and our cousins below the water. Past peoples probably lived near the coasts and the rising water would have obscured or destroyed a lot of the evidence of their existence. I think a lot about what must be or have been just out of reach of our current studies. I have always believed that the human evolution consensus which is usually based upon finds of advanced toolmaking in absence of culture cues, to be questionable by orders of magnitude. So it seemed natural to simply double generational concepts of the village along a trade route, from ~500kya (like the Nile) to 1 million YA as a hyperstable span of evolution of the 'trade route village'. I even wrote a book about it  https://www.youtube.com/watch?v=mtxgpaXp9vA  that might seem like whole fiction.  But science seems not to ask, how many times might we have started over? I can\u2019t be the only one that saw the aforementioned tools and thought: did I misread stool? I wonder how would we react with tools dating back to, say, 5MY ago ... That would shake our knowledge from the foundations. Ok, since I moved "}
{"anchor": "Show HN: Ten years of running every day, visualized. Love it! How did you stay motivated? Do you have the source/pipeline available? I love the design and would want to do something similar for my own runs. Congrats on the decade! Did you ever focus on specific metrics or was it always just about the run? just wanted to say the site looks awesome! I love the minimal black+white/grayscale and the fonts are just lovely. vis looks great too, I enjoyed poking around nearly all of the unique runs to look at the map and paces. This is so cool! At what point did you start thinking about this project? Like, were you quietly working on it a year ago after every run, just waiting for this moment? And hey, great run in Japan! (Tokyo here!) I love the map visualization too. Love it! I will hit one year mark in a couple of weeks. Currently maintaining stats in a Google spreadsheet :)  https://vijaykillu.com/  SVGs? So, some of the staistics graphs do not update, or have you made them dynamic by hand? beautifullllllll\u2014both the streak and the stack. Love how lightweight the architecture is for something so personal and long-term. Curious if you noticed any patterns in the data that surprised you once you visualized it? Impressive. I did streak running for 6 months nice and it was some of the most productive running in my life. Interestingly I have much higher yearly averages than you do but still consider daily streak running quite hard. Not being a morning runner myself might contribute since I get into a lot of close calls that way. My streak literally ended when my daughter went into the hospital and I couldn\u2019t well just fuck off for a run any longer. That's awesome! any tips for people who are just starting out? do you have code it on github ? I don't have the tenacity to run strictly _everyday_, so as a middle ground I don't run when it rains at anytime during daylight. Of course the effectiveness of this rule depends on where you live :P I\u2019ve always wanted to do this, but I ", "positive": "Anti-aging injection regrows knee cartilage and prevents arthritis. As I've gotten older, my knees have been the main signal letting me know. I tore my meniscus years ago. This is exciting news for people like me. Cartilage is really the final frontier of health. If it wasn\u2019t for joints going bad, people could stay very active and fit pretty much all their life, with consistent exercise and healthy weight.  > Osteoarthritis occurs when a joint is stressed by aging, injury or obesity. The chondrocytes begin to release pro-inflammatory molecules and to break down collagen, which is the primary structural protein of cartilage. When collagen is lost, the cartilage thins and softens; the accompanying inflammation causes the joint swelling and pain that are hallmarks of the disease.  Collagen synthesis in the human body can be aided by  hydrolyzed collagen, Vitamin C, zinc and copper. oh, what a time to be a mouse! They don't say what is injected, calling it only a \"gerozyme inhibitor\". Original article appears to be:  https://www.science.org/doi/10.1126/science.adx6649  Inhibition of 15-hydroxy prostaglandin dehydrogenase promotes cartilage regeneration Mamta Singla  https://orcid.org/0000-0002-6408-1167 , Yu Xin Wang  https://orcid.org/0000-0001-8440-9388 , Elena Monti  https://orcid.org/0000-0002-3767-0855 , Yudhishtar Bedi  https://orcid.org/0000-0002-1213-4116 , [...] , and Nidhi Bhutani  https://orcid.org/0000-0002-7494-5870  FTFA:  \"Both systemic and local inhibition of 15-PGDH with a small molecule inhibitor (PGDHi) led to regeneration of articular cartilage and reduction in OA-associated pain.\"  \"PGDHi\" is a name for both the process \"15-hydroxyprostaglandin dehydrogenase inhibition\" and any inhibitor. This link(a PDF file) shows PGDHi's are powerful stuff:  https://www.biorxiv.org/content/biorxiv/early/2025/04/17/202...  \"PGDHi\"  could  be prostaglandin-E2 (dinoprostone):  https://en.wikipedia.org/wiki/Prostaglandin_E2  which was used in:  https://med.stanford.e", "negative": "It's hard to justify Tahoe icons. I hate to be that guy, but there's some irony in putting a full screen animated snow effect over an article about unnecessary, distracting clutter. I like the article content but it's ironic that I needed to switch to Safari reader-mode to be able to comfortably read it. Reminder, you can turn off the animated snow effect with the snowflake icon at the top It's hard to justify snowflake animations on your website... Is there a reason Apple can\u2019t focus on system improvements instead of constantly tweaking with their UI so thoroughly every couple years? I don\u2019t disagree the OS UI needs to be revamped periodically, but it seems they do it too often. It's pretty wild how the best screenshot of a usable menu is from, like, Office 2000. What the hell have we been doing for the past 25 years? Sorry, even though I agree with your piece, the incredible irony of writing about  bad design decisions  while having  fucking snow flying past the text I'm trying to read  is just too much... [edit] I just discovered the snow icon, which does turn off the snow but turns the background into bright yellow. Oh and the other icon which turns your cursor into a ...spotlight? On an otherwise black page? Do I have that right? Which one of those things was a design decision that enhanced usability, or readability, or... anything at all? These choices can best be described as sophomoric. You can disagree with menu icons, but they at least  in theory  serve a  purpose . What purpose is served by any of the gizmos on this site? Related:  https://news.ycombinator.com/item?id=46196688  I suppose I wouldn't mind much either way, apart from the misaligned text maybe now that you brought my attention to it. I agree that colors could help. Don't hesitate to give KDE/Qt a try, it apparently happens to get all these things right according to this article from a quick glance: everything is correctly aligned, even when in the same menu some items both have an icon and a "}
{"anchor": "Fabrice Bellard Releases MicroQuickJS. I easily managed to build quickJS to WebAssembly for running in  https://exaequOS.com  . So I need to do the same for MicroQuickJS ! It's unfortunate that he uploaded this without notable commit history, it would be interesting to see how long it takes a programmer of his caliber to bring up a project like this. That said, judging by the license file this was based on QuickJS anyway, making it a moot comparison. If there were a software engineering hall of fame, I nominate Fabrice. I wish for this new year we reboot the Web with a super light standard and accompanying ecosystem with       - A small and efficient JS subset, HTML, CSS\n    - A family of very simple browsers that do just that\n    - A new Web that adheres to the above\n  \nThat would make my year. On a phone at the moment so I can't try it out, but in regards to this \"stricter mode\" it says global variables must be declared with var. I can't tell if that means that's just the only way to declare a global or if not declaring var makes it scoped in this mode. Based on not finding anything skimming through the examples, I assume the former?  Clarification added later : One of my key interests at the moment is finding ways to run untrusted code from users (or generated by LLMs) in a robust sandbox from a Python application. MicroQuickJS looked like a very strong contender on that front, so I fired up Claude Code to try that out and build some prototypes. I had Claude Code for web figure out how to run this in a bunch of different ways this morning - I have working prototypes of calling it as a Python FFI library (via ctypes), as a Python compiled module and compiled to WebAssembly and called from Deno and Node.js and Pyodide and Wasmtime  https://github.com/simonw/research/blob/main/mquickjs-sandbo...  PR and prompt I used here:  https://github.com/simonw/research/pull/50  - using this pattern:  https://simonwillison.net/2025/Nov/6/async-code-research/  I'm not an embedde", "positive": "Succinct data structures. Wow, this is really fascinating. I guess it all comes down to how it's doing select and rank in constant time, which is probably some clever bit arithmetic. I'll have to look into how that works. I first heard of the concept of succinct data structures from Edward Kmett, a famous Haskeller behind many popular Haskell libraries. He gave a talk on succinct data structures a long time ago:  http://youtu.be/uA0Z7_4J7u8  I really like the article, but it would benefit from some numbers or complexity estimates to get some intuitive sense of what the cost is. Am I paying 30% overhead for this particular index or that wavelet matrix? Is it double the memory use? Or is it O(log N)? No idea! \"doesn't use much more space\" could mean a lot of different things! Succinct data structures are very fun! If anyone is interested, I've implemented some of this in Zig:  https://github.com/judofyr/zini . The main thing this implements is a minimal perfect hash function which uses less than 4 bits per element (and can respond to queries in ~50 ns). As a part of that I ended up implementing on of these indexes for constant-time select(n):  https://github.com/judofyr/zini/blob/main/src/darray.zig . It feels kinda magic implementing these algorithms because everything becomes  so tiny ! The word count seems artificially increased in the post. Here's a succinct explanation:  https://www.eecs.tufts.edu/~aloupis/comp150/projects/Succinc...  My goto library for succinct data structures is SDSL-Lite [0]. [0]  https://github.com/simongog/sdsl-lite  Note that succinct data structures may not be faster than conventional structures if your dataset fits in memory  http://www.cs.cmu.edu/~huanche1/slides/FST.pdf  . Of course, for large datasets where storage access times dominate, succinct data structures win all around. In any case, succinct trees are works of art (If I recall  https://arxiv.org/pdf/1805.11255  was a good exposition) (just look at how that RMQ works)! Way bett", "negative": "The US national debt will soon be growing faster than the economy itself. Reminder that Trump\u2019s One Big Beautiful Bill is going to add, at minimum, 4 trillion in new debt. That\u2019s per the CBO. And if he gets the additional funding increases he is seeking this year, he will add another 5 trillion over the next ten years. That\u2019s 9 trillion before half his term is up. That money will go to the Trump family, their friends, friendly businesses who get government contracts, etc. But the cost will fall on all Americans. In the end I don\u2019t see a way out without hyperinflation, which is another way of saying - we will be poor to prop up oligarchs who have hoarded billions in dishonest ways. But the administration is asking us to ignore what our eyes see and instead worry about some insignificant fraud that some Somalians allegedly perpetrated, even though it is tiny by comparison. I just can't. Watching from Europe, what's happening in the US is what is jokingly referred as \"clown world\" on the internet, except this time there are real clowns everywhere. Like, how did it end up like this? You have Trump as president who campaigned on reducing the US trade deficit and government deficit. It turns out there is a lot of fraud and to such an extent that it essentially makes the anti-immigrant sentiment look justified. The US left cares about optics in a seemingly backwards way. They think exposing the fraud will justify racism and discrimination, so they deny that there ever was any fraud to begin with. This tacit approval makes them look like co-conspirators, which has worse optics than the bad optics they desperately were trying to get away from. And yet despite these \"heroic\" attempts at cutting government spending and the mass scale fraud suddenly falling into the lap of republicans so that they can crack down on it, Trump has contributed absolutely nothing towards reducing the deficit. Instead, the deficit is growing so quickly Trump will be overtaking Biden when it comes to"}
{"anchor": "East Germany balloon escape. The investment, planning, danger, and dogged persistence\u2026 incredible story. The Damn Interesting podcast (no affiliation, just a huge fan) had an episode on this topic if you prefer to listen to this story:  https://www.damninteresting.com/up-in-the-air/  The photo of the balloon here really helps put the story into perspective.  https://web.archive.org/web/20190408181736/https://www.museu...  Disney made a movie about this called Night Crossing in the early 1980s. More recently, there's a 2018 German movie about it called Balloon. [0]  https://www.imdb.com/title/tt0082810/  [1]  https://www.imdb.com/title/tt7125774  My elementary school showed the Disney movie about this at least once a year. >The family members included: >    Peter Strelzyk, aged 37 >    Doris Strelzyk >    Frank Strelzyk, aged 15 >    Andreas Strelzyk, aged 11 >    G\u00fcnter Wetzel, aged 24 >    Petra Wetzel >    Peter Wetzel, aged 5 >    Andreas Wetzel, aged 2 Was/is it common practice to omit the ages of adult women in Germany? > East Germany immediately increased border security, closed all small airports close to the border, and ordered the planes kept farther inland.[6] Propane gas tanks became registered products, and large quantities of fabric suitable for balloon construction could no longer be purchased. Mail from East Germany to the two escaped families was prohibited.[12] > Erich Strelzyk learned of his brother's escape on the ZDF news and was arrested in his Potsdam apartment three hours after the landing. The arrest of family members was standard procedure to deter others from attempting escape. He was charged with \"aiding and abetting escape\", as were Strelzyk's sister Maria and her husband, who were sentenced to 2\u00bd years. The three were eventually released with the help of Amnesty International. People - here in Germany as well as abroad - forget too easily what a sinister but also ridiculous state the GDR was. Authoritarians everywhere belong on the dustp", "positive": "Hypothesis: Property-Based Testing for Python. I keep thinking I have a possible use case for property -based testing, and then I am up to my armpits in trying to understand the on-the-ground problem and don't feel like I have time to learn a DSL for describing all possible inputs and outputs when I already had an existing function (the subject-under-test) that I don't understand. So rather than try to learn to black boxes at the same time , I fall back to \"several more unit tests to document more edge cases to defensibly guard against\" Is there some simple way to describe this defensive programming iteration pattern in Hypothesis? Normally we just null-check and return early and have to deal with the early-return case. How do I quickly write property tests to check that my code handles the most obvious edge cases? It\u2019s been quite some time since I\u2019ve been in the business of writing lots of unit tests, but back in the day, I found hypothesis to be a big force multiplier and it uncovered many subtle/embarrassing bugs for me. Recommend.  Also easy and intuitive to use. I love property-based testing, especially the way it can uncover edge cases you wouldn't have thought about. Haven't used Hypothesis yet, but I once had FsCheck (property-based testing for F#) find a case where the data structure I was writing failed when there were exactly 24 items in the list and you tried to append a 25th. That was a test case I wouldn't have thought to write on my own, but the particular number (it was always the 25th item that failed) quickly led me to find the bug. Once my property tests were running overnight and not finding any failures after thousands and thousands of random cases, I started to feel a lot more confident that I'd nailed down the bugs. Make sure to read the docs and understand this well. It has its own vocabulary that can be very counterintuitive. It seems to only implement a half of QuickCheck idea, because there is no counterexample shrinking. Good effort thoug", "negative": "California is free of drought for the first time in 25 years. As John Steinback said in  East of Eden : \u201cI have spoken of the rich years when the rainfall was plentiful. But there were dry years too, and they put a terror on the valley. The water came in a thirty-year cycle. There would be five or six wet and wonderful years when there might be nineteen to twenty-five inches of rain, and the land would shout with grass. Then would come six or seven pretty good years of twelve to sixteen inches of rain. And then the dry years would come, and sometimes there would be only seven or eight inches of rain. The land dried up and the grasses headed out miserably a few inches high and great bare scabby places appeared in the valley. The live oaks got a crusty look and the sage-brush was gray. The land cracked and the springs dried up and the cattle listlessly nibbled dry twigs. Then the farmers and the ranchers would be filled with disgust for the Salinas Valley. The cows would grow thin and sometimes starve to death. People would have to haul water in barrels to their farms just for drinking. Some families would sell out for nearly nothing and move away. And it never failed that during the dry years the people forgot about the rich years, and during the wet years they lost all memory of the dry years. It was always that way.\u201d The dams in california were built years ago for a smaller population and since then they've only removed them. If we simply built like the people who first came to california did we would never have water shortages again. Any water shortage is a 1:1 failure of the state to do the clear and obvious task needed. strange because this is one of the warmest winters in decades. snow levels are far below normal, i saw 8% of normal in truckee. full reservoirs now are great but keeping them filled depends on a long snow melt going into june. i don\u2019t think this is going to be a good year for that And yet our water rates are still as if we are in a drought. Previ"}
{"anchor": "The Universal Pattern Popping Up in Math, Physics and Biology (2013).  https://pmc.ncbi.nlm.nih.gov/articles/PMC11109248/  DNA as a perfect quantum computer based on the quantum physics principles. There is the well known problem that \"random\" shuffling of songs doesn't sound \"random\" to people and is disliked. I wonder if the semi-random \"universality\" pattern they talk about in this article aligns more closely with what people want from song shuffling. Not sure why you have to read 3/4 of the article to get to a _link_ to a pdf which _only_ has the _abstract_ of the actual paper: N. Benjamin Murphy and Kenneth M. Golden* (golden@math.utah.edu), University of\nUtah, Department of Mathematics, 155 S 1400 E, Rm. 233, Salt Lake City, UT 84112-0090.\nRandom Matrices, Spectral Measures, and Composite Media. The Physics models tend to shake out of some fairly logical math assumptions, and can trivially be shown how they are related. \"How Physicists Approximate (Almost) Anything\" (Physics Explained)  https://www.youtube.com/watch?v=SGUMC19IISY  If you are citing some crank with another theory of everything, than that dude had better prove it solves the thousands of problems traditional approaches already predict with 5 sigma precision.   =3 What's with all the spammy comments? >The data seem haphazardly distributed, and yet neighboring lines repel one another, lending a degree of regularity to their spacing Wow, that kind of reminds me of the process of evolution in that it seems so random and chaotic at the most microscopic scales but at the macroscopic, you have what seems some semblance of order. The related graph also sprung to mind just how very like organisms repel (less tolerance to inbreeding) but at the same time species breed with like species and only sometimes stray from that directive. What is the pattern that underlies how organisms determine production or conflict with other organisms and can we find universality in it? I guess it's called \"universality\" for ", "positive": "The '3.5% rule': How a small minority can change the world (2019). This rule didn't hold in Israel in the last 3 years. Well over 3.5% went to the streets and the government remains in tact. This is plausible. Non violent groups will often have wider public support (because most people would prefer not to support violence) and if those in power use violence against the non-violent it increases public sympathy for them. Iran proved it wrong (the regime mobilized roughly 1% of the country's population to crack down on protesters) with regards to Single Party Regimes, and knowing people at the Ash Center, they are pessimistic about this as well. If you have 2+ groups with opposing views, each 3.5%+ it's pretty clear that at least one of the 3.5%+ groups will fail. Others here note it's really \"3.5% if there's no one seriously opposing their objectives\" but in my opinion that's a meaningless rule. Of course in those cases non-conflict resolves the issue.  https://medium.com/incerto/the-most-intolerant-wins-the-dict...  (2019) Chenoweth has backed off her previous conclusions in recent years, observing that nonviolent protest strategies have dramatically declined in effectiveness as governments have adjusted their tactics of repression and messaging. See eg  https://www.harvardmagazine.com/2025/07/erica-chenoweth-demo...  One current example of messaging can be seen in the reflexive dismissal  by the current US government and its propagandists of any popular opposition as 'paid protesters'. Large attendance at Democratic political rallies during the 2024 election was dismissed as being paid for by the campaign, any crowd protesting government policy is described as either a rioting or alleged to be financed by George Soros or some other boogeyman of the right. This has been going on for years; the right simply refuses to countenance the possibility of legitimate organic opposition, while also being chronically unable to provide any evidence for their claims. Hong Kong pr", "negative": "Clawdbot - open source personal AI assistant. I ran the install and got these errors: npm warn deprecated npmlog@6.0.2: This package is no longer supported.\nnpm warn deprecated are-we-there-yet@3.0.1: This package is no longer supported.\nnpm warn deprecated gauge@4.0.4: This package is no longer supported.\nnpm warn deprecated tar@6.2.1: Old versions of tar are not supported, and contain widely publicized security vulnerabilities, which have been fixed in the current version. Please update. Support for old versions may be purchased (at exhorbitant rates) by contacting i@izs.me\nnpm warn deprecated node-domexception@1.0.0: Use your platform's native DOMException instead Clawdbot is interesting but I finally feel like those people who look at people like me raving about Claude code when it barely works for them. I have no doubt clawdBot, when it works, must feel great. But I\u2019ve had the tough time setting it up and found it to be very buggy. My first couple of conversations? It forgot the context literally seconds later when I responded. Nevertheless, I\u2019m sure it\u2019s improving by the day so I\u2019m going to set it up on my existing Mac mini because I think it has the capacity to be really fascinating. I built something similar (well\u2026 with a lot of integrations) but for running my company and continue to iterate on it. I see this posted everywhere this week. Is it really that good? I understand this runs on any hardware (not limited to Mac Minis) as long as you have an API key to an LLM (Preferably to Claude). People online make bold promises that it will change your life... It sounds interesting to me, I might install it on a cheap Mini PC with Ubuntu. This can't come at any worst time as storage and RAM has gotten astronomical. I feel bad for people who are just starting to build their first rig and an alt rig for this. How do people think about the sort of access and permissions it needs? \"Don't give it access to anything you wouldn't give a new contractor on day one.\"  http"}
{"anchor": "Vanguard's average fee is now 0.07% after biggest-ever cut. Not mentioned in any of the coverage I've seen (or the interview with Vanguard's new CEO in the WSJ) is Fidelity. Fidelity used to be known for actively managed funds, but has been eating Vanguard's indexing lunch for the past 10 years or so. Part of this relates to its dominance in workplace accounts, but Vanguard hasn't helped itself with some bad customer-facing software updates and a perception that its service levels are poor compared to Fidelity. Cutting fees helps, but Fidelity has shown its willing to do this, too, including no fee \"Zero\" index funds:  https://www.fidelity.com/mutual-funds/investing-ideas/index-...  (note Fidelity is very clear about who it's competing with) Article mentions their bond funds getting the most dramatic cuts \u2014 they didn't list specific symbols though. Anyone know off the top of their heads which funds specifically? Thinking I need to move away from being so stock-heavy. I always upvote the archive link unless it is already the top comment, ha ha. That only applies to US funds, but not in the UK ones which continue to be significantly more expensive... Didn't they recently increase uk fees a tonne? Straight from the source:  https://corporate.vanguard.com/content/corporatesite/us/en/c...  Let's not forget that Vanguard has taken a strong stance against crypto [0]. Claiming to significantly invest in technology while deliberately ignoring the latest advancements in financial technology, seems contradictory. If their business was doing so well, they wouldn't have to lower fees. [0]  https://news.ycombinator.com/item?id=42832026  Someone correct my math here, but if they have 10 trillion in assets under management and the management fee is 0.07% then that's still 7,000,000,000 or 7 billion in fees every year? Not bad Unless you have some super special edge, Vanguard is really good IMO. Having a 0.01% or 0.05% fund is really as good as you can do and never pay attention. Va", "positive": "Ask HN: Where do seasoned devs look for short-term work?. Now is not a great time to be looking for this kind of work unfortunately. I think your network is the best place to look for this sort of work. Sometimes people will reach out to me with short term projects which is the best way to get gigs like this. Maybe start looking at your colleagues on linkedin, see what they are up to, and think of ways to contribute to what they are working on. The best people to contact in this scenario are leadership and decision makers. A SWE II isn't gonna help you much but a CTO at an early stage startup might be a good person to send a DM if they are friends with you (or even if they aren't!) :) Short term work is more plentiful when money is easy and there\u2019s a lot of entrepreneurial activity going on due to some recent catalyst such as mobile app platforms or the dotcom boom etc. Right now we\u2019re in the AI boom and some people may be making money peddling agentic solutions but money is tight and businesses are hurting. It\u2019s also hard to trust a short term dev who doesn\u2019t really need the money. You have no leverage over them. They sort of just do as they please. Most ad-hoc work I've picked up has been people I've previously worked with/for. Maybe worth reaching out to people you have a prestablished relationship with I did this a few years ago and the winning recipe was a shameless (i.e. deeply shameful) linkedin post where I pretty much just summarized my skillset and explained that I was looking for a senior engineer equivalent of a summer internship, with no chance of extension. Got me 3-4 offers. None of the offering companies had ads out for roles like this, so this was pretty much the only way. I'd believe you're better off working on yourself. Maybe do toy projects for your potential portfolio, learn an additional skill (AI?), and build many weekend projects until something sticks. Publishing articles, etc to demo your skill helps you stay top of mind. Even if only the ", "negative": "AI code and software craft. Enterprise software tends to particularly bad because it's being sold to managers who won't use it themselves. Consumer software tends to be more user-friendly (or it won't sell), but popular software isn't always what you want. When writing software for yourself, there is a bias towards implementing just the features you want and never mind the rest. Sometimes the result can be pretty sloppy, but it works. However, code health is a choice. You just need to know what to ask for. A coding agent can be used as a power washer to tidy up a project. This won't result in great art, but like raking leaves or cleaning your steps or plowing a driveway, it can be satisfying. Just as you wouldn't use a power washer to clean a painting, maybe there's some code that's too delicate to use a coding agent on? But for a project that has good tests and isn't that delicate, which I believe includes most web apps, nobody's going to want to pay for you to do it by hand anymore. It would be like paying someone to clear the snow in a parking lot with a shovel rather than hiring someone with a plow. This argument is basically just the 1800s Luddite vs Industrialist argument recast for a new age. Group A thinks quality is about human agency, and that machines are being used to bypass the apprenticeship system and produce inferior goods. Group B thinks efficiency is the highest priority, and craft is just vanity. Of course as we know we went a third way, and human roles just shifted. I think one promising shift direction is humans do NOT like to talk to bots, especially not for anything important. It's biological. We evolved to learn from and interact with other humans, preferably the same group over a long time, so we really get to understand/mirror/like/support each other. > People have said that software engineering at large tech companies resembles \"plumbing\" > AI code [..] may also free up a space for engineers seeking to restore a genuine sense of craft and "}
{"anchor": "Gemini Diffusion. Interesting to see if GROQ hardware can run this diffusion architecture..it will be  two time magnitude of currently known speed :O That's...ridiculously fast. I still feel like the best uses of models we've seen to date is for brand new code and quick prototyping. I'm less convinced of the strength of their capabilities for improving on large preexisting content over which someone has repeatedly iterated. Part of that is because, by definition, models cannot know what is  not  in a codebase and there is meaningful signal in that negative space. Encoding what  isn't  there seems like a hard problem, so even as models get smarter, they will continue to be handicapped by that lack of institutional knowledge, so to speak. Imagine giving a large codebase to an incredibly talented developer and asking them to zero-shot a particular problem in one go, with only moments to read it and no opportunity to ask questions. More often than not, a less talented developer who is very familiar with that codebase will be able to add more value with the same amount of effort when tackling that same problem. I think the lede is being buried. This is a great and fast InstructGPT. This is absolutely going to be used in spell checks, codemods, and code editors. Instant edits feature can surgically perform text edits fast without all the extra fluff or unsolicited enhancements. I copied shadertoys, asked it to rename all variables to be more descriptive and pasted the result to see it still working. I'm impressed. Diffusion is more than just speed. Early benchmarks show it better at reasoning and planning pound for pound compared to AR. This is because it can edit and doesn\u2019t suffer from early token bias. Nit: Diffusion isn't in place of transformers, it's in place of autoregression. Prior diffusion LLMs like Mercury [1] still use a transformer, but there's no causal masking, so the entire input is processed all at once and the output generation is obviously different. I ", "positive": "Waymo granted permit to begin testing in New York City. I saw one of these on Chambers Street just yesterday afternoon, but it must have been in manual mode, of course. It's fascinating seeing all the comments elsewhere anytime Waymo starts testing in another city along the lines of, \"ah, but how will they handle X, Y, and Z here?? Checkmate, robots!\" despite having already launched service in several other cities. Granted, NYC is the biggest city in the US, so maybe that sort of reaction is more reasonable there than when people in Dallas or Boston do it. Very cool. I wonder what scale it has to hit for this to become a profitable line item for Google and what their revenue targets are for it. Man I love Waymo everytime I'm in SF. Truly feel like I'm living in the future when I sit in one I'm cautiously optimistic about this self-driving thing. Waymo at least seems to have figured out a lot of it. Would it be way better to make walkable neighborhoods, mixed-use developments, and reliable and frequent public transit? Yes. Yes it would. But, in lieu of that, self-driving has a lot of advantages in the long run, even if the technology isn't 100% perfect right now. It's insane that they need permits for 8 cars that have humans driving them in 2025, when they're already fully automated in SF. > We\u2019re a tech-friendly administration Clearly not. Is this the first time Waymo is doing winter / snow testing at scale? I think some of the Pittsburgh-based self-driving firms may have tried this, but unaware how far they got. I\u2019m curious if autonomous cars will become targets for aggressive drivers. Like a driver isn\u2019t going to be as scared cutting off a Waymo or tailgating one because the AI isn\u2019t gonna get road rage or honk like hell. In some places I could see the Waymo\u2019s getting severely bullied if that\u2019s the case. The game-theoretic aspect of this is interesting to me. A lawful robot will never make progress in Manhattan because the people will just walk across its path con", "negative": "Xfwl4 \u2013 The Roadmap for a Xfce Wayland Compositor. I've been using Xfce as a daily driver in one machine for about a decade now. Great to know there's work on the wayland support front. Also, writing it in Rust should help bring more contributors to the project. If you use Xfce I urge you to donate to their Open Collective:  https://opencollective.com/xfce   https://opencollective.com/xfce-eu  I hope that XFCE remains a solid lightweight desktop option. I've become a huge fan of KDE over the past couple of years, but it certainly isn't what you would consider lightweight or minimal. Personally, I'm a big proponent of Wayland and not big Rust detractor, so I don't see any problem with this. I do, however, wonder how many long-time XFCE fans and the folks who donated the money funding this will feel about it. To me the reasoning is solid: Wayland appears to be the future, and Rust is a good way to help avoid many compositor crashes, which are a more severe issue in Wayland (though it doesn't necessarily need to be fatal, FWIW.) Still I perceive a lot of XFCE's userbase to be more \"traditional\" and conservative about technologies, and likely to be skeptical of both Wayland  and  Rust, seeing them as complex, bloated, and unnecessary. Of course, if they made the right choice, it should be apparent in relatively short order, so I wish them luck. Very interesting that they opted for a rewrite in Rust instead of adjusting the existing codebase. I wonder how long it'll take them writing a compositor from scratch. FYI, you can currently use most wlroots-based compositors with XFCE. I myself am running Hyprland + XFCE on Gentoo.  https://github.com/bergutman/dots  If wayland support was there already I would be using xfce. I truly admire it, it's great to see this happening and I hope the project continues in great speed. With DE's requiring hard system-d support, I would rather have something like xfce i'm trying to build a Linux desktop and the first thing I got stuck at is"}
{"anchor": "Early Retirement May Speed Up Cognitive Decline: Study. Anecdotally, my grandfather is 92 or so and still works as a journalist (reduced hours). He is still super sharp and does yoga every day. Blows my mind. I hope not, I recently retired. Still, the idea makes some sense. In retirement, I try to read one paper a day (usually deep learning, PGM, or classic AI), play at least one game of Go and Chess, do some recreational programming, and read. But, I don\u2019t work into a state of brain-tiredness anymore like I used to at work. My dad is a doctor in his 70s. He works 60 hour weeks (which he claims counts as retirement for doctors). He truly believes that true retirement is suicide. He wants to be found dead while doing rounds at the hospital. I've always benchmarked post-retiring cognitive abilities and professional continuity with Noam Chomsky. He is my hero in that aspect too. If I can continue to do what I do now at his age, I'm ready for the off. Not only early retirement but any kind of retirement that gets the retiree in a mode that they don't have to try anymore will result in cognitive decline. I am seeing this in my dad who has been retired for ten years now. Throughout his work life he was a sharp hard working banker. Now he uses his age and retirement as an excuse for not trying. Just yesterday he wanted me to order something for him from Amazon. I told him to send me the link to the item. He asked me how to do that. I told him if you can't find the Share link just copy the link and send it to me. He responds by saying that he doesn't know how to do copy-paste. He has been using computers for at least the last fifteen years. I asked him how come he didn't know how to copy-paste. His response was - I am retired now and there's nobody to tell me or teach me. I can see the cognitive decline. Things he used to be able to do, he can't anymore. This type of attitude is also affecting his self respect and confidence. This is something I think about a lot. I plan to", "positive": "London saw a surprising benefit to ultra-low emissions zone: More active kids. I don't believe for a second that the reduced emissions are enough for these kids to actually notice. ULEZ is a tax on being poor, nothing more. I wish the article stated if the amount of cars traveling in the zone remained the same. I would think it probably greatly reduced the amount of traffic in that area, which all around just makes for a more pleasant experience being a pedestrian, biker, or scooterer. Regardless, I think this is awesome and wish it could be tried in the United States. Kids being able to be independent and active is essential to their happiness and development. My 2c as a local: a significant issue with any discussion of this is that people don't really have a good handle on the actual statistics of who drives in London. It cuts across every demographic. Under 25k household income - a good 40-50% of households have a car. Housing estates - tons of cars. Well off - almost everyone.  https://content.tfl.gov.uk/technical-note-12-how-many-cars-a...  It mostly comes down to whether someone has a need (e.g. has children, fairly mobile in their job, has family outside of town, enjoys going on road trips etc) and actually wants to pay for it rather than anything else. In addition to that, a bunch of stuff happened basically at the same time. We got ULEZ, we got a ton of low traffic neighbourhoods (e.g. streets where cars are not allowed at certain times of day regardless of emissions), we had COVID meaning that habits and demographics changed, we had Brexit which probably had some minor effect, etc. All of that happened within about 5 years and I don't think you can isolate any of them. I don't really find most discussions about it interesting as a result of all of the above - it usually just ends up with someone trying to find evidence for their pre-existing position rather than anything that feels actually scientific, unfortunately. \"Their annual health assessments\". Is t", "negative": "Nvidia Stock Crash Prediction. It goes to nearly zero if China invades Taiwan, and that seems like it has at least a 10% chance of happening in the next year or two. > One of the questions of the 2026 acx prediction contest is whether Nvidia\u2019s stock price will close below $100 on any day in 2026. Maybe I\u2019m missing something, but isn\u2019t this just a standard American put option with a strike of $100 and expiry of Dec 31st? He doesn't really address his own question. He's answering the question \"How should options be priced?\" Sure, it's possible for a big crash in Nvidia just due to volatility.  But in that case, the market as a whole would likely be affected. Whether Nvidia specifically takes a big dive depends much more on whether they continue to meet growth estimates than general volatility.  If they miss earnings estimates in a meaningful way the market is going to take the stock behind the shed and shoot it.  If they continue to exceed estimates the stock will probably go up or at least keep its present valuation. How much of their turnover is financed directly or indirectly by themselves, then leveraged further by their 'customers' to collaterize further investments? Are they already \"too big to fail\"? For better or worse, they are 'all in' on AI. This article goes more into the technical analysis of the stock rather than the underlying business fundamentals that would lead to a stock dump. My 30k ft view is that the stock will inevitably slide as AI datacenter spending goes down. Right now Nvidia is flying high because datacenters are breaking ground everywhere but eventually that will come to an end as the supply of compute goes up. The counterargument to this is that the \"economic lifespan\" of an Nvidia GPU is 1-3 years depending on where it's used so there's a case to be made that Nvidia will always have customers coming back for the latest and greatest chips. The problem I have with this argument is that it's simply unsustainable to be spending that much eve"}
{"anchor": "Lazy-brush \u2013 smooth drawing with mouse or finger. This is so satisfying. These types of experiments are something I really love about the open-web, and part of what bums me out about how most social networks tend to throttle links. The dragging behavior is so intuitive \u2013 it's funny because usually if you create this kind of resistance in a UI it can be confusing, but in this context it works so well. I think this is the same as the brush stabilizer in Krita. Check out drawmote from the same author, where this library is being used.  https://drawmote.app/  Wow, this is amazing! I see you've been building this on GitHub for 7 years - that's truly impressive dedication. What keeps you motivated to stick with this product for so long? An alternative that works very well for signatures too is Perfect Freehand (by the guy behind TLDRaw)  https://perfect-freehand-example.vercel.app/  OT, but I love the author's retro homepage. Just seeing that made me smile this morning This is really cool and reminded me of drawing as a kid. Thank you! I believe a logic similar to this was used to enact the \"Gestures\" system in Black and White 1. Breaking down the mouse-movements into vectors following a guide-point. ( https://blackandwhite.fandom.com/wiki/Gesture ). This is very nice, not just for finger/mouse painting! I tried it on my Cintiq and it was actually a lot better for me than brush stabilization usually is - I think the logic is the same as seen in e.g. Krita, but the visualization of the cursor and where the paint will appear is very helpful. Usually painting software doesn't have such an indicator of where the actual stroke will be placed and when it will move. Great project, I had some fun playing around :) Neat! This is known as a stabilizer in the digital art community. Really cool! I wonder what Duo Lingo are using behind the scenes. I've been busy with the Chinese and Japanese courses, and one thing I quickly noticed is how there are two different 'grades' of practisin", "positive": "How to live on $432 a month in America. I've often felt this way about some of today's complaints. I grew up in area like what was mentioned in this article and I long for the day I can go back there. I would in a heartbeat if my partner shared the same mentality as me. I don't really see a point in living a big city with the remote job I have and that many others have if I can live in a smaller area that still has humans but much cheaper way of living. Everyone claims it's about living in a city with available services but I see those same people decry how much the food costs and also that they have no friends and can't find someone to date. My thoughts aren't as articulate as I'd like them to be but I guess I'm ultimately trying to say is if I'm going to be miserable, why not do it on my own land for a lot cheaper. It makes a certain amount of sense and I myself bought a little place way out in the hinterlands of Michigan for similar economic reasons ... but I live in Berkeley because subjecting your children to life without opportunities for art, culture, education, sports, friends, etc is cruel. So if you're white, or just don't care that your ethnicity is absent, and if you have no children, and also don't mind living in a car-dependent place where the public transit to the nearest major city is a minimum of 15 hours with 3-4 transfers, then sure Massena NY is dope. There is a little bit of a sleight of hand going on in this article by claiming the lifestyle of boomers is within reach, but then actually using boomers' parents and grand-parents as the standard. It would be more honest to say \"Most of us can't have the relative wealth of our grand parents, but with some sacrifices and creativity, the lifestyle of our great-grand parents is attainable.\" Even that is only true in a very narrow sense. My great-grand parents built a 600sqft house in a small town and lived their most of their lives. But they built that house right next to their parents. They lived wit", "negative": "Tell HN: I Have Won HN. Better take another look at your profile! Congratulations on your brief but unique victory! Congrats!  Don't spend it all in one place. Congratulations! Does it roll over to negative when you reach the end? My making this post you\u2019ve now gone over and are no longer 31337. You flew too close to the sun. Related  https://news.ycombinator.com/item?id=15055393  He had the same problem. Someone upvoted the post and broke the charm. I was told I could redeem these points for a seed round? We\u2019ve got plans to investigate what number system they use. Only after 49.71 days in the wilderness... 40 days and 40 nights in the wilderness, to be tempted by VC? I heard about a guy who didn't take the deal, and it didn't go well for him. That time, eventually there was a Hail Mary miracle rebound and exit, but you can't plan on that."}
{"anchor": "Scientists find a way to regrow cartilage in mice and human tissue samples. Of course, why are the good ones always in mice?     A study led by Stanford Medicine researchers has found that an injection blocking a protein linked to aging can reverse the natural loss of knee cartilage in older mice.    https://www.science.org/doi/10.1126/science.adx6649  A small molecule inhibitor of 15-hydroxy prostaglandin dehydrogenase causes cartilage regeneration. I hope they fast-track it to human trials. basically every growth process in the body can be induced by chemicals. and so now people are starting to take some of these chemicals. we will see how it turns out As long as regrowth can be controlled. Otherwise we call it cancer. Would be amazing to get a treatment for osteoarthritis. Fusion Power Cartilage Regrowth Room Temperature Semiconductors Quantum Computing       def generate(topic, year):\n       return f\"Scientists have made a major breakthrough in {topic}\"\n  \nThe only subjects that are more Year Of The Linux Desktop than Linux itself. The discovery of gerozymes is interesting. Maybe aging is pre-programmed after all, to make space for new generations. Would this work for rheumatoid arthritis? I don\u2019t know anything about it myself so it could be a completely different thing, but someone I know has it and it is awful. Would be great to see a treatment coming through. My dream is to be able to run again. Please. Let me run a 10k at least once more in my life. To feel that stillness and freedom and calm that sets in when the brain start going to hibernation after about 7km. That would be quiet something to feel that again. I\u2019ve had my shoulders \u201ccleaned up\u201d arthroscopically, and the pain is still a major preventer of movement. I would love to stay on the mats longer with something that doesn\u2019t harken to medieval times. So excited at this prospect. HN posts about mouse studies always trigger a bunch of skepticism.  I\u2019m a layperson so it\u2019s hard to separate the informed c", "positive": "Where can you go in Europe by train in 8h?. If you now could just book a train between these cities on a common european platform (or local transportation provider...)... one could dream... just booking a train and getting a quote crossing multiple borders (without interrail) is just a nightmare :( Title shared on HN left me somewhat disappointed.  The actual time appears to be \"Where can you go by train in 8h?\", though that's somewhat less clear.  It only seems to include central stations of larger cities, though I was hoping for a list of shortest travel times between stations in Europe, as more of a thought/data experiment.  Or put another way; which two train stations in Europe have the least distance between them? Anyway, the shared feature is neat, but seems to be somewhat iffy once you get out of the bigger cities.  If a route has 2 or more connections, it seems to struggle to show them.  While true to its message, I still feel the restriction of 8 hours misses sleeper trains, where travel time is less essential compared to daytime trains. It's cute for discoverability, but for a specific train search, I would definitely defer to bahn.de, which basically includes all train stations in Europe. There is a website I love for seeing how to get almost everywhere in Europe by train:  https://www.seat61.com/  I don't understand how it works. First time clicking on Poland, it showed a kind of a heat map around some city. Then I click on another location and nothing happens. OK, there's a \"back\" button, I go back, click on the map again in a different place and... nothing happens. No heat map. At some point in frustration I accidentally move the mouse while clicking and the map rotates upside down. Don't know, is it me, my browser, or there's something about the UI. Since train fans always like to point this out when it comes to flying: this is how far you can get in 8 hours  on the train . It doesn\u2019t include the time to get to the station, the buffer time you need (i", "negative": "San Francisco coyote swims to Alcatraz. I would be surprised if the Coyote would be quick to get back into the water after such a difficult swim. It would, I suspect, want to recover and find food. So I support the theory the Coyote is just hiding somewhere. The island is small but not that small that it couldn\u2019t hide somewhere. I wonder if a turtle drowned halfway across. If a Coyote could do it, all those famous escapees must have had too. That roadrunner thought he'd be safe hiding out on the notorious prison island... It's a 1.5mi swim. I remember visiting Angel Island (a 0.5mi swim) and seeing the abundance of raccoons they have, and asked a ranger how they got there. They also swam. Growing up on a lake I would regularly watch deer swim the quarter mile back and forth between the shore and a nearby island, with no problem. Video:  https://www.youtube.com/watch?v=br4-VsvRcII  Poor thing, talk about going in the wrong direction :) Impressive though. If you time things right, and don't get swept out to sea, it's the 54 degree water that is the real danger. I'm no medical person, but it sure seems like that the animal is suffering from hypothermia and fatigue. I'm sure it'll have happy hunting once it recovers. This sort of thing is a huge problem here in New Zealand. The only native mammal here is a bat, we have mostly birds which evolved for a really long time with only avian predators. So they\u2019re hilariously poorly adapted for surviving standard predators (cats, rats, dogs etc) which first the Maori and subsequently Europeans brought. For example, many of them are flightless and tend to freeze when threatened - works well against eagles but is a terrible idea when threatened by a cat. As a result, we have many animals, mostly birds, which are totally unique and also critically endangered. Many of them can only survive on offshore islands which have been comprehensively cleared of predators at vast effort and expense. The islands need to be relatively accessible"}
{"anchor": "Alexei Navalny has died. Jailed Russian opposition leader Alexei Navalny is dead, the prison service of the Yamalo-Nenets region where he had been serving his sentence said on Friday. \u201cDied\u201d, I suspect the more accurate term is \u201cmurdered\u201d\u2026 Unbelievable. The world just watches. I can't believe any American would carried Putin's water after the treatment of Alexei Navalny. Yeah Navalny is dead but have you looked at their shopping carts? > Putin has been informed of the death, says Kremlin In advance, one assumes. Frankly, it's strange Putin allowed him to live for so long, normally he just kills his opponent quite fast. Maybe it was just a power show to make everybody understand he can control his opponents' lives completely. A little reminder of what Putin has been up to in the last few years. - Annexation of Crimea (2014) - MH17 Downing (2014) - Intervention in Syria - 2016 U.S. Election Interference - Skripal Poisoning (2018) - Anti-LGBTQ+ Laws - Navalny Poisoning (2020) - Wagner Group Activities - Invasion of Ukraine (2022) - Killing of Yevgeny Prigozhin (2023) - Killing of Alexei Navalny  (2024) What is necessary for US and European Laws, to specify any type of contact, endorsement, indulgence even, of such a regime, is an intolerable criminal offense? Edit: Its difficult to keep track... - Killing of Alexander Litvinenko - 1999 Russian Apartment Bombings - September 2022 \u2014 Ravil Maganov's fatal fall from a hospital window. He was chairman of Russian oil giant Lukoil. Lukoil was the first major Russian company to call for an end to the war in Ukraine - July 2009 \u2014 Natalya Estemirova found dead in a ditch - October 2006 \u2014 Anna Politkovskaya murdered in an elevator - April 2003 \u2014 Sergei Yushenkov murder was never solved. Yushenkov was one of the harshest critics of the Chechen war and the KGB's successor organization, the FSB. The 2022 documentary 'Navalny' is important and explains how the anti-corruption campaigner got to that terrible place, being poisoned with", "positive": "Giving Up a $250k Salary to Retire Early Is Hard. This is the OP:  https://www.vetmed.auburn.edu/faculty/erik-hofmeister/  This (+ many other signals) are giving me the \"market top\" vibe. Sad to see people still parroting the 4% rule when you can get \"risk free\" US Treasuries, today, paying more than that. Not to speak of the numerous, still conservative, investments paying far higher. This isn't the 2010s era with ultra low fixed income yields. If you intend to retire early, please educate yourself on the state of the market Someone in the article's comments asked about working part time and the author responded \"veterinary academia doesn\u2019t really understand <1.0 FTE.\" Is the same true of FAANG-ish companies? Can you (officially) work part time in a big tech job? College professor in Alabama makes $250k? Not bad. I guess being a doctor helps. I think the vibe may instead be: growing income disparity. The WSJ reported over the weekend that over 50% of all consumer spending now comes from the top 10% of household incomes. So while some folks are flush to retire early, many are not. I think 4% is still a fine thing to plan around. I don't think it's wise to plan as if today's treasury rates will last your entire retirement. The 4% rule requires increasing that amount at the rate of inflation throughout retirement. 30 years in the case of the original studies. Even with an inflation rate of 2.5%, the required withdrawal will more than double after 30 years. The 4.625% you can lock into a 30-year Treasury would not be enough. What does the 4% rule have to do with yields of treasuries? This is a 30-year time horizon that changes spending purely based on inflation figures. Yields in the market do not matter. You can and many do, although this tends to be reserved for more senior engineers.  Obviously a pay cut is involved. Strictly the answer is yes with the more truthful answer being it depends on your manager. The easiest way is probably being in a country that requires", "negative": "Things I've learned in my 10 years as an engineering manager. Whoa an EM that talks to clients? A rare treat. I just got a browbeating because I  (an IC)  didn't jump at the chance to do more  (that)  for ~free~ growth. Ahem. Mind you, we have piles of both kinds of PMs: product, project. Best I can tell, they play video games between calls/status updates. Forgot the blur on more than one occasion. Clownshow, myself included. I wholeheartedly agree with point 7 Your goal is for your team to thrive without you. I spent a lot of time also playing a Scrum Master role in addition to my regular duties. So much so that some managers asked me to pursue this full time. I always explained that my goal is to be there just as a point of contact and that the team should be able to manage itself. Sadly, I see so many managers, scrum masters, or even regular engineers consider this as a dumb approach to make yourself replaceable. If you don't hoard knowledge then you'll be laid off when the company's numbers look bad. Damn, this person looks like a good manager. These are all things I have seen in my good managers over the years when I had them. I completely agree with point 9 This is clearly a good EM. Agreed with pretty much everything, being on the engineering side. Stuff that seems trivial and obvious but that a lot of EMs miss. Why do people espouse goals like \u201cnot to be needed?\u201d I never understood that. It sounds like LinkedIn virtue signaling. It\u2019s a capitalist talking point along the lines of \u201cI seek to be good and inexpensive capital for my corporate masters.\u201d My goal is to help my team succeed in such a way as to keep my job or else get a better one. Being \u201cnot needed\u201d hardly serves that goal. Look around you. We are in a world that is turning away from middle managers. Don\u2019t play into their hands. > People above you have limited time to focus on your specific issues. You can\u2019t info dump on them. If they take a misguided action based on what you tell them, it will be yo"}
{"anchor": "Toad is a unified experience for AI in the terminal. I'm really looking forward to trying this out over Christmas break. Textualize is awesome for building Python console apps. This looks really cool. I wonder if they support vi keybinds Hi. Will McGugan here. I built Toad. Ask me anything. This looks great! Looking forward to trying it out. I recently tried moving to OpenCode but it didn\u2019t quite scratch the itch UX wise. I see what you did what that intro and I approve :) This is absolutely awesome but the little jokey captions that Claude did (Discombobulating... Laminating...) all that stuff, they were a little annoying but cute enough, but whatever is running this one (I did not murder him... I thought I was special....) they are genuinely offputtingly bad. This great app doesn't need clunky humour front and centre, I'm not sure if it's Claude or toad but it seems markedly worse than Claude used to be. I already used Toad to run a conversion task I've been procastinating on. It worked perfectly and looked splendid doing so. Excited to dig in further. toad is next level in many ways Very excited to see this come out - though coding agents are impressive their UIs are a bit of a mixed bag. Textual offers incredibly impressive terminal experiences so I'm very much looking forward to this. I wonder how much agentic magic it'll be able to include though - Claude Code often seems like a lot of its intelligence comes from the scaffolding, not just the LLM.  I'm excited to see! It would be a matrushka to run Toad in a Zed terminal. The name Toad gave me a flashback to Tool for Oracle Application Development, an IDE and debugger for SQL and pl/sql back in the 1990s. I\u2019m not a big fan of the name Toad, but the Textual framework is fantastic. I\u2019ve been using it for years in a small project and it\u2019s just a wonderful tool - it makes it really easy to get a super fast little UI for scripts. I strongly resonate with the problem statement, but this implementation was very far o", "positive": "Cholesterol levels cut in half with one-time gene editing drug in trial. This is not an acceptable use of gene editing IMHO. Cholesterol can be managed by diet. High levels of Cholesterol are down to choices made, not some inherited disease that patients couldn't avoid from when they were born. I was diagnosed with Parkinson\u2019s disease four years ago. For over two years, I relied on Levodopa and several other medications, but unfortunately, the symptoms kept getting worse. The tremors became more noticeable, and my balance and mobility started to decline quickly. Last year, out of desperation and hope, I decided to try a herbal treatment program from NaturePath Herbal Clinic.\nHonestly, I was skeptical at first, but within a few months of starting the treatment, I began to notice real changes. My movements became smoother, the tremors subsided, and I felt steadier on my feet. Incredibly, I also regained much of my energy and confidence. It\u2019s been a life-changing experience I feel more like myself again, better than I\u2019ve felt in years.If you or a loved one is struggling with Parkinson\u2019s disease, I truly recommend looking into their natural approach. You can visit their website at www.naturepathherbalclinic.com\ninfo@ naturepathherbalclinic  .com Same thing with T2D. If your blood sugar is disregulated due to insulin sensitivity disorder, you should simply die. The existence of a gene edit directly contradicts your assertion. That you don't label the specific phenotype a disease doesn't really matter. Why is it better for it to be managed with diet vs this? Presumably if managing it via diet alone worked universally they wouldn't be doing research into drugs like this. Genetics can be a factor.  https://en.wikipedia.org/wiki/Familial_hypercholesterolemia  High cholesterol is well documented to be heritable. Perhaps more relevantly, even if they would work, lifestyle changes have a significant patient compliance problem, which significantly reduces their effectiveness. Th", "negative": "eBay explicitly bans AI \"buy for me\" agents in user agreement update. LLM-initiated purchases probably rack up chargebacks, support calls, etc for mistakes the LLM makes. I'm not surprised they want to limit it. not the User Agreement! Impossible to enforce, they can read browser windows and pass captchas So scraping bots and \u201cbuy for me\u201d bots are bad, but the incredibly annoying sniping bots are OK? That sure feels like a double standard. No one wants AI to spend their money, checked or not. The few people who would want AI, want AI to save them money What is the use case for LLM agent shoppers? I can't imagine delegating the purchase of a used item to an AI (I'd be okay with AI identifying the best deals for me to review). This must be something for people who are doing something at scale like flipping items on Ebay or drop shipping. I imagine this type of automation existed before LLM agents came along - what do they add? Is it just the ability to evaluate the product description? Item quality is already listed as a categorical variable. Hasn't eBay's traffic been 80% bots since day one? I haven't participated in an auction in forever because even 20 years ago you were  guaranteed  to get sniped by a bot on anything except actual garbage. Tried selling on eBay as a regular Joe lately? Item sold for roughly $190 and I lost $45 in fees - I didn't even have a premium ad or pay for any of the boosting. No wonder Facebook marketplace has destroyed them I loved early eBay but gave up on it once became clear how rife it was with bid snipers, fraudsters and stolen goods. ...haven't bots been buying things off eBay since the 90s? Meanwhile Google announces UCP to go in completely the opposite direction (or make marketplaces like eBay do so) You don't have to obey user agreements. Is my primary user agent, my web browser, still allowed? /s Interesting, I\u2019m not big on AI but I have thought often it would be nice to have an \u2018agent\u2019 that monitors ebay or other classifieds sit"}
{"anchor": "I let ChatGPT analyze a decade of my Apple Watch data, then I called my doctor. >  Despite having access to my weight, blood pressure and cholesterol, ChatGPT based much of its negative assessment on an Apple Watch measurement known as VO2 max, the maximum amount of oxygen your body can consume during exercise. Apple says it collects an \u201cestimate\u201d of VO2 max, but the real thing requires a treadmill and a mask. Apple says its cardio fitness measures have been validated, but independent researchers have found those estimates can run low \u2014 by an average of 13 percent.  There's plenty of blame to go around for everyone, but at least for some of it (such as the above) I think the blame more rests on Apple for falsely representing the quality of their product (and TFA seems pretty clearly to be blasting OpenAI for this, not others like Apple). What would you expect the behavior of the AI to be?  Should it always assume bad data or potentially bad data?  If so, that seems like it would defeat the point of having data at all as you could never draw any conclusions from it.  Even disregarding statistical outliers, it's not at all clear what part of the data is \"good\" vs \"unrealiable\" especially when the company that  collected  that data claims that it's good data. The author is a healthy person but the computer program still gave him a failing grade of F. It is irresponsible for these companies to release broken tools that can cause so much fear in real people. They are treating serious medical advice like it is just a video game or a toy. Real users should not be the ones testing these dangerous products. We trained a foundation model specifically for wearable data:\n   https://www.empirical.health/blog/wearable-foundation-model-...  The basic idea was to adapt JEPA (Yann LeCun's Joint-Embedding Predictive Architecture) to multivariate time series, in order to learn a latent space of human health from purely unlabeled data. Then, we tested the model using supervised fine tu", "positive": "\u03c00.5: A VLA with open-world generalization. This is amazing! As someone working with industrial robots, normally under strict environmental constraints and control, witnessing such real-world robotics progress truly excites me about the future! By the way, they\u2019ve open-sourced their \u03c00 model (code and model weights). \nMore information can be found here:  https://github.com/Physical-Intelligence/openpi  Is the robot platform they're using something they've developed themselves? The paper doesn't seem to mention any details outside of sensors and actuators. These variable-length arrays are getting quite advanced I'm genuinely asking (not trying to be snarky)... Why are these robots so slow? Is it a throughput constraint given too much data from the environment sensors? Is it processing the data? I'm curious about where the bottleneck is. I'm just a layman, but I can't see this design scaling. It's way too slow and \"hard\" for fine motor tasks like cleaning up a kitchen or being anywhere around humans, really. I think the future is in \"softer\" type of robots that can sense whether their robot fingers are pushing a cabinet door (or if it's facing resistance) and adjust accordingly. A quick google search shows this example (animated render) which is closer to what I imagine the ultimate solution will be:  https://compliance-robotics.com/compliance-industry/  Human flesh is way too squishy for us to allow hard tools to interface with it, unless the human is in control. The difference between a blunt weapon and the robot from TFA is that the latter is very slow and on wheels. Amazing! On a fun note, I believe if a human kid were cleaning up the spill and threw the sponge into the sink like that, the kid would be in trouble. XD Does the general laws of demos apply here? Than any automation shown is the extent of capabilities not the start? Finally, machines doing the work we  dont  want to do Most of it is open source. Their VLAs are based upon Gemma models + vision encoders", "negative": "Prism. Previously, this existed as crixet.com [0]. At some point it used WASM for client-side compilation, and later transitioned to server-side rendering [1][2]. It now appears that there will be no option to disable AI [3]. I hope the core features remain available and won\u2019t be artificially restricted. Compared to Overleaf, there were fewer service limitations: it was possible to compile more complex documents, share projects more freely, and even do so without registration. On the other hand, Overleaf appears to be open source and at least partially self-hostable, so it\u2019s possible some of these ideas or features will be adopted there over time. Alternatively, someone might eventually manage to move a more complete LaTeX toolchain into WASM. [0]  https://crixet.com  [1]  https://www.reddit.com/r/Crixet/comments/1ptj9k9/comment/nvh...  [2]  https://news.ycombinator.com/item?id=42009254  [3]  https://news.ycombinator.com/item?id=46394937  Check out MonsterWriter if you are concerned about the recent acquisition of this. It also offers LaTeX workspaces see video:  https://www.youtube.com/watch?v=feWZByHoViw  Very unfortunately named. OpenAI probably (and likely correctly) estimated that 13 years is enough time after the Snowden leaks to use \"prism\" for a product but, for me, the word is permanently tainted. This seems like a very basic overleaf alternative with few of its features, plus a shallow ChatGPT wrapper. Certainly can\u2019t compete with using VS Code or TeXstudio locally, collaborating through GitHub, and getting AI assistance from Claude Code or Codex. > Introducing Prism\nAccelerating science writing and collaboration with AI. I thought this was introduced by the NSA some time ago. \"Accelerating science writing and collaboration with AI\" Uhm ... no. I think we need to put an end to AI as it is currently used (not all of it but most of it). Very underwhelming. Was this not already possible in the web ui or through a vscode-like editor? The quality and usefulness"}
{"anchor": "Show HN: FaceTime-style calls with an AI Companion (Live2D and long-term memory). It creates a conflict to build a system that is both a private friend and a public performer. You cannot maximize intimacy and fame at the same time. What are you using for tts/stt/models? Building on zemo's point about parasocial relationships: traditional parasocial interaction involves a performer who doesn't know you exist. Here the AI does respond to you specifically, which changes the dynamic. Is it still parasocial if the other party is responsive but not conscious? Or is this something new that we don't have good language for yet? For better lip sync you could try using rhubarb to extract from the mp3.\nWhat is your backend speech processor so you can get the real-time streaming response?\nRhubarb would add a bit of latency for sure. wow we got personal vtubers now! You're describing Parasocial interaction:  https://en.wikipedia.org/wiki/Parasocial_interaction  far from being impossible, it's the entire influencer economy. This form of social media has been extremely widespread for a decade or so running; it's probably the dominant form of social media. 100% agree. Maximizing intimacy and scaling distribution pull in opposite directions. We\u2019re experimenting with keeping the \u201ccharacter\u201d consistent while letting personalization live in private memory and user-controlled settings. Still early, and this tension is real. Appreciate it. If you try it and anything feels off (latency, turn-taking, uncanny moments), I\u2019d love concrete feedback. That\u2019s what we\u2019re grinding on right now. It will quickly distill down to clients using the service just for sex and sex-adjacent activities. No kink-shaming, but this sort of thing enables self-destructive hard-to-return-from anti-social behaviour. Totally fair reaction. We\u2019re building this with clear boundaries: we don\u2019t position it as therapy replacement, we add safety rails, and gives user a choice what mode they want and guardrails differ based ", "positive": "Ask HN: What did you read in 2025?. Lots of news and articles, but also \"The Craft\", a history of Freemason's by John Dickie, was one of the more interesting books. Frankenstein. Superb science fiction, very readable even though written 200 years ago. And Wuthering Heights, which strangely like Frankenstein, has a complex narrative structure and an unhinged, obsessive central character - Emperor of Rome by Mary Beard, very entertaining. - Lolita, it's mostly what you've read about it. - a few short stories by Heinrich von Kleist. I mostly read fiction but I made time for a couple of nonfiction books this year. On the fiction side I really enjoyed \"Luminous\" and \"When We Where Real\". -  https://en.wikipedia.org/wiki/Luminous_(novel)  -  https://www.simonandschuster.com/books/When-We-Were-Real/Dar...  On the nonfiction side, I can recommend \"Careless People\" and \"Apple in China\". -  https://en.wikipedia.org/wiki/Careless_People  -  https://en.wikipedia.org/wiki/Apple_in_China  I read Sad Tiger by Neige Sinno. Really unsettling but definitely worth reading. One of my favourite reads from this past year was  Infinite Powers: How Calculus Reveals the Secrets of the Universe  by Steven Strogatz. It's a wonderful review of the history of calculus, including intuitive explanations of the basics. History of the Franks, by Gregory of Tours Getting into reading again this year after a long break. The most memorable read of this year was \"The Count of Monte Cristo\" (1846) by Alexander Dumas . It's one of the greatest stories ever told. It's ~1250 pages but I sped through it in 3 weeks even if I'm a slow reader. Highly recommended! I also read The Stranger by Camus and the two top Orwells which lived up to the hype. Very much enjoyed the Hyperion Cantos series by Dan Simmons.  https://en.wikipedia.org/wiki/Hyperion_Cantos  I got really into Hemingway\u2019s work, reading all the best ones, but my favourite being \u2018A moveable feast\u2019 his diary essentially released at the end of his life", "negative": "US administration to require app, social media, possibly DNA for travelers. Apart from the alarming privacy implications of these proposed rules, I wonder how FIFA might feel about this, ahead of the World Cup. Maybe they could award Trump a privacy prize if his administration backs down from this. I would love to visit the US one day and i do understand that it has no obligation to just let me in, but this seems a bit excessive for a short visit especially seeing as my country has a deal with the US not to require visas. I wonder if i would have to disclose my hn account(s). My cover would be blown! I guess i'm lucky i've made pro Trump comments... I wonder what position the U.S. Chamber of Commerce (which Wikipedia describes as the largest lobbying group in the US) will take on this. I'd like to think they are rational and recognize that 99.99%+ of visitors are bringing tourism money to the United States. I was sure this was going to say that they were going to force travelers to get Truth Social accounts. Somehow I was surprised beyond my wildest guess what they would be asking people to do. I want people to visit the U.S., but if they require that they submit all of this data, I expect that they all protest by not visiting or even coming here for work. There are just so many terrible ideas that come from this administration that I think that they should try to harness the power all of those bad ideas in a infinite idiocy power plant to power the world for all generations to come. Not that I know the details, but wasn't it easier to join the Mafia? Just the names and addresses of your folks in the old country (as \"collateral\") The analogy is kind of striking, when you think about it. Ah, more laws and regulations that cannot be followed by most people. I couldn\u2019t tell you every single \u201csocial media\u201d account I\u2019ve made over the years as various startups failed after I tried them. I definitely couldn\u2019t get all my family\u2019s information, even if constrained to just imm"}
{"anchor": "Live Map of the London Underground. Very cool. Especially as it a real map not a 'network diagram' who is so confusing. > Data -> TfL live tube data > *You will regret using this data. You will regret using this API.* > It serves data from individual arrivals boards, which all spell stations differently > It has a load-balancer that regularly returns data that is older than the data returned in the previous request. Won't someone think of the Ai overlords who will take care of all this for us in the future. A bit of consistency goes a long way. Looks great but I'm watching this while sitting on a tube right now. What I assumed was my train was lagging by quite a bit and then disappeared! It's cool to see how fast the trains go on different lines. But... where's the Elizabeth line? You get the tooltip when you hover over it, but the polyline is missing. One of the best game I ever played is the text based souvenir game shopping game on Windows 3. I can't recall the name of the game now since it's more than 30 years ago, but it's about shopping souvenirs using London Underground Tube. You have a semi realistic time constraints like train schedules, your flight schedules and of course list of souvenirs items to shop. This is totally offline since there is no Internet available at the time but it's very engaging nonetheless. My proposal for the modern version of the game is to use real-time train schedules (with delays, ticket discounts, etc) that are available publicly on the Internet for many metropolitan cities in the world for examples Tokyo, London and Berlin. Imagine you can have a real-world realistic in-app in-game items purchases feature that you personally can buy in the game and delivered to you or anyone you fancy of giving souvenirs except that you only virtually went there. Maybe a slight bug: the overlay doesnt appear to be locked to the map - when I scroll around, the overlay moves. Currently the northern lines' southern terminal is hovering over Kingsto", "positive": "Show HN: Ten years of running every day, visualized. Love it! How did you stay motivated? Do you have the source/pipeline available? I love the design and would want to do something similar for my own runs. Congrats on the decade! Did you ever focus on specific metrics or was it always just about the run? just wanted to say the site looks awesome! I love the minimal black+white/grayscale and the fonts are just lovely. vis looks great too, I enjoyed poking around nearly all of the unique runs to look at the map and paces. This is so cool! At what point did you start thinking about this project? Like, were you quietly working on it a year ago after every run, just waiting for this moment? And hey, great run in Japan! (Tokyo here!) I love the map visualization too. Love it! I will hit one year mark in a couple of weeks. Currently maintaining stats in a Google spreadsheet :)  https://vijaykillu.com/  SVGs? So, some of the staistics graphs do not update, or have you made them dynamic by hand? beautifullllllll\u2014both the streak and the stack. Love how lightweight the architecture is for something so personal and long-term. Curious if you noticed any patterns in the data that surprised you once you visualized it? Impressive. I did streak running for 6 months nice and it was some of the most productive running in my life. Interestingly I have much higher yearly averages than you do but still consider daily streak running quite hard. Not being a morning runner myself might contribute since I get into a lot of close calls that way. My streak literally ended when my daughter went into the hospital and I couldn\u2019t well just fuck off for a run any longer. That's awesome! any tips for people who are just starting out? do you have code it on github ? I don't have the tenacity to run strictly _everyday_, so as a middle ground I don't run when it rains at anytime during daylight. Of course the effectiveness of this rule depends on where you live :P I\u2019ve always wanted to do this, but I ", "negative": "Doing the thing is doing the thing. As a person with ADHD, I feel personally attacked. This is very similar to [1] (as discussed here [2]). It is a good message though, which is why I remember the earlier post at all. 1.  https://strangestloop.io/essays/things-that-arent-doing-the-...  2.  https://news.ycombinator.com/item?id=45939431  On the other hand.. planning, preparation and mise-en-place can help with doing the thing. \"Doing it badly is doing the thing.\" This one works for me, and I've learned it from a post on HN. Whenever I feel stuck or overthink how to do something, just do it first - even with all the flaws that I'm already aware of, and if it feels almost painful to do it so badly. Then improve it a bit, then a bit, then before I know it a clear picture start to emerge... Feels like magic. \"Everybody wants to be a bodybuilder but nobody wants to lift no heavy ass weights!\" I used to think this. Then I noticed how often \"preparation\" became its own infinite loop. At work we built something from a 2-page spec in 4 months. The competing team spent 8 months on architecture docs before writing code. We shipped. They pivoted three times and eventually disbanded. Planning has diminishing returns. The first 20% of planning catches 80% of the problems. Everything after that is usually anxiety dressed up as rigor. The article's right about one thing: doing it badly still counts. Most of what I know came from shipping something embarrassing, then fixing it. \"Failing while doing the thing is doing the thing.\" I needed this today. Currently questioning my career choices, as I hit my first wall where people are involved. Gave me quite the headache. I kinda agree, but I also gain pleasure from doing all those things that are not supposed to be \"the thing\". The thinking, the dreaming, the visualizing... I just like that. I do it a lot when working on personal projects (which some of them I never ship). I think it's fine, and I wouldn't go as far as saying that those th"}
{"anchor": "Moravec's Paradox and the Robot Olympics. Those videos are very impressive. This is real progress on tasks at which robotics have been failing for fifty years. Here are some of the same tasks being attempted as part of the DARPA ARM program in 2012.[1] Compare key-in-lock and door opening with the 2025 videos linked above.\nHuge improvement. We just might be over the hump on manipulation. [1]  https://www.youtube.com/watch?v=jeABMoYJGEU  I genuinely did not expect to see a robot handling clothing like this within the next ten years at least. Insanely impressive I do find it interesting that they state that each task is done with a fine tuned model. I wonder if that\u2019s a limitation of the current data set their foundation model is trained on (which is what I think they\u2019re suggesting in the post) or if it reflects something more fundamental about robotics tasks. It does remind me of a few years ago in LLMs when fine tuning was more prevalent. I don\u2019t follow LLM training methodology closely but my impression was that the bulk of recent improvements have come from better RL post training and inference time reasoning. Obviously they\u2019re pursuing RL and I\u2019m not sure spending more tokens at inference would even help for fine manipulation like this, notwithstanding the latency problems with that. So, maybe the need for fine tuning goes away with a better foundation model like they\u2019re suggesting? I hope this doesn\u2019t point towards more fundamental limitations on robotics learning with the current VLA foundation model architectures Sergey Levine, one of the co-founders, sat for an excellent Dwarkesh podcast episode this year, which I thoroughly recommend.      > The gold-medal task is to hang an inside-out dress shirt, after turning it right-side-in, which we do not believe our current robot can do physically, because the gripper is too wide to fit inside the sleeve\n  \nYou don't need to fit inside the sleeve to turn it inside out... Think about a sock (same principle will apply, ", "positive": "Succinct data structures. Wow, this is really fascinating. I guess it all comes down to how it's doing select and rank in constant time, which is probably some clever bit arithmetic. I'll have to look into how that works. I first heard of the concept of succinct data structures from Edward Kmett, a famous Haskeller behind many popular Haskell libraries. He gave a talk on succinct data structures a long time ago:  http://youtu.be/uA0Z7_4J7u8  I really like the article, but it would benefit from some numbers or complexity estimates to get some intuitive sense of what the cost is. Am I paying 30% overhead for this particular index or that wavelet matrix? Is it double the memory use? Or is it O(log N)? No idea! \"doesn't use much more space\" could mean a lot of different things! Succinct data structures are very fun! If anyone is interested, I've implemented some of this in Zig:  https://github.com/judofyr/zini . The main thing this implements is a minimal perfect hash function which uses less than 4 bits per element (and can respond to queries in ~50 ns). As a part of that I ended up implementing on of these indexes for constant-time select(n):  https://github.com/judofyr/zini/blob/main/src/darray.zig . It feels kinda magic implementing these algorithms because everything becomes  so tiny ! The word count seems artificially increased in the post. Here's a succinct explanation:  https://www.eecs.tufts.edu/~aloupis/comp150/projects/Succinc...  My goto library for succinct data structures is SDSL-Lite [0]. [0]  https://github.com/simongog/sdsl-lite  Note that succinct data structures may not be faster than conventional structures if your dataset fits in memory  http://www.cs.cmu.edu/~huanche1/slides/FST.pdf  . Of course, for large datasets where storage access times dominate, succinct data structures win all around. In any case, succinct trees are works of art (If I recall  https://arxiv.org/pdf/1805.11255  was a good exposition) (just look at how that RMQ works)! Way bett", "negative": "The state of Linux music players in 2026. Cool. I didn\u2019t know there was a fork of clementine. I hope it fixes a few bugs I have. It\u2019s clearly my favorite player ever. Thanks. Something that wasn't mentioned in the article - if you're coming from Windows and using Foobar2000, you'll want DeadBeeF  https://deadbeef.sourceforge.io/  I'm a little surprised that anyone still plays music on their computer. Surely now we've moved into the era where we all have dedicated devices for that. Your phone for 99.9% of people, I'd imagine. And for the audiophiles there's a bunch of very high quality DAPs to pick from. How is Quod Libet not here? Cross platform and its plugin system should be enough reason on its own  https://github.com/quodlibet/quodlibet  Maybe it's just me, but I still like the plainness of MPD + ncmpcpp. > You might say that owning is more expensive than renting, even with all the price increases. Sure. But I\u2019ve paid for Spotify for ten years, from 2014 to 2024, and that\u2019s a solid 1200\u20ac with the old pricing. At the end, I had nothing to show for it. My carefully curated \u201clibrary\u201d was not mine - it was held hostage by a company that can up the prices at any point. 10 years to realize it ? What took so long ? So, why do they look so clumsy all together? \nI am using Audacity with the XMMS theme. That's what I am used to. This reminds me the blog one would write around 2006. Not the text content, but the pixelated font and pictures of winamp wibe like that. Myself, I am rather happily using mplayer - without any gui. Initially it was practicality of not leaking memory - like many gtk+ apps would do. Now, it is pure utility. Shoutouts to Audacious  https://audacious-media-player.org/  TBH the only thing I care for (except maybe for playlist management) is gapless playback. There's no word about it, but I constantly find out that the new players do not really care about the gap, while the music I am listening to is always ripped from my personal CDs and they mostly h"}
{"anchor": "Ironwood: The first Google TPU for the age of inference. It looks amazing but I wish we could stop playing silly games with benchmarks. Why compare fp8 performance in ironwood to architectures which don't support fp8 in hardware? Why leave out TPUv6 in the comparison? Why compare fp64 flops in the El Capitan supercomputer to fp8 flops in the TPU pod when you know full well these are not comparable? [Edit: it turns out that El Capitan is actually faster when compared like for like and the statement below underestimated how much slower fp64 is, my original comment in italics below is not accurate] ( The TPU would still be faster even allowing for the fact fp64 is ~8x harder than fp8. Is it worthwhile to  misleadingly claim it's 24x faster instead of honestly saying it's 3x faster? Really? ) It comes across as a bit cheap. Using misleading statements is a tactic for snake oil salesmen. This isn't snake oil so why lower yourself? Can these be repurposed for other things? Encoding/decoding video? Graphics processing etc? edit:\n>It\u2019s a move from responsive AI models that provide real-time information for people to interpret, to models that provide the proactive generation of insights and interpretation. This is what we call the \u201cage of inference\u201d where AI agents will proactively retrieve and generate data to collaboratively deliver insights and answers, not just data. maybe i will sound like a luddite but im not sure i want this. I'd rather AI/ML only do what i ask it to. Some honest competition in the chip space in the machine learning race! Genuinely interested to see how this ends up playing out. Nvidia seemed 'untouchable' for so long in this space that its nice to see things get shaken up. I know they aren't selling the TPU as boxed units, but still, even as hardware that backs GCP services and what not, its interesting to see how it'll shake out! The first specifically designed for inference? Wasn\u2019t the original TPU inference only? Not knowing much about special-pur", "positive": "Ask HN: What are the best engineering blogs with real-world depth?. Encountered one specific example about a month ago here on HackerNews - All about automotive lidar.\n https://news.ycombinator.com/item?id=46110395  Blog posts where I find quality really shows are usually about something I know next to nothing about how it works. A badly written article usually either goes really shallow or skips some facts when going into depth and requires catchup elsewhere to actually understand it. The lidar article from Main Street Autonomy goes beyond basics and explained everything from the ground up in such a connected way that it was a real pleasure reading it. Sounds like you look for an intersection of academic papers (1.), tech blogs (2.), text books (3.), and confidential business strategies (4.)? A very high ambition. Maybe  https://projectzero.google/archive.html   https://netflixtechblog.medium.com/   https://www.uber.com/en-US/blog/engineering/  You're probably looking for something that is more focused on specific software decisions/implementations, but  https://infrequently.org  is the best web development blog out there. It's not \"technical\" so much as it just educates you on how to be a good web developer/run a team. There's zero fluff and considerable detail (footnotes are practically blog posts themselves).  http://highscalability.squarespace.com/all-time-favorites/  There are no such blogs. Usually companies, or individuals, will write these after they implement some feature into their products. Which makes them inherently little pieces of information scattered all over the internet and there is no one blog that is just about this. Cloudflare, google project zero. > especially from tech company blogs,  https://engineering.fb.com/   https://netflixtechblog.com/   https://stripe.com/blog/engineering   https://eng.uber.com   https://engineering.linkedin.com/   https://engineering.atspotify.com/   https://tailscale.com/blog   https://careersatdoordash.com/enginee", "negative": "Show HN: We Built the 1. EU-Sovereignty Audit for Websites. Checks hosting, analytics, fonts, cdn, video, chat, social embeds.\nGives you a score from 0-100 and suggests Eu-alternatives. Nice, good idea. I need to move away from Github pages finally ;) Seems to treat finnish kapsi.fi hosting as US? Happy to see mastodon.xyz score 100%. Mastodon is pretty cool and proof that we can make federation work. nice idea, are you planning to open source this project? Any recommendations for good European alternatives to Clooudflare? Is there an EU company that's as trustworthy when it comesq to DDoS protection? thanks for this checker, we also need HN alternative for EU only. As Europeans, I'm sure we can do this. reddit.com gets a perfect \"no US dependencies\" score. I guess they have servers around the world and can serve requests from a local-ish server. Obviously this simple check only concerns the technical aspects of the website and doesn't analyse the business itself but I wonder if all .com domains should be marked down? I put in my site and it gave me a red cross for \"Hosting\", on hover it said \"GitHub Pages\". But my site isn't hosted on GitHub Pages. Expanding \"Details\", the URL that is hosted on GitHub Pages is... a different website? There's merely a hyperlink to it on my website. It also says I'm using \"self-hosted\" fonts - but I don't think I'm doing that at all? I'm just using the browser's fonts. Using non-standard fonts is a bad idea because it causes the content to either be invisible until the font is loaded, or else it initially shows in a fallback font and then the text all jumps when the font is loaded. I have some feedback for OP: my personal website got 92% because there is a link to my X profile in the contact session. It's not like it relies on the service. Its just a contact and there are also links to other services such as self hosted matrix. On the other hand my registrar is Namecheap which is in the US and your tool didn't checked for that. I thi"}
{"anchor": "Tmux \u2013 The Essentials (2019). it's missing changing Ctrl+B to Ctrl+A:       # ~/.tmux.conf\n    set-option -g prefix C-a   I like tmux a lot, but like its predecessor \"screen\" I mostly use it for explicitly running long-lived jobs (i.e. for its detach feature), and for very special situations where I have elaborate tmux window configurations with dedicated stuff running in each window/pane. Note that I have been using text-only terminals since the 1980s, but I've adapted my tty usage over time. The problem that tmux (or screen) brings are first and foremost: * Smooth/fast scrolling goes away. I can no longer give my trackpad a slight push to find myself tens or hundreds of lines in the scrollback history, and visually scan by slightly pushing my fingers back and forth. Instead I have to use the horrendous in-tmux scrollback using \"Ctrl-b [\". * My terminal app's tabs and windows are not tmux's tabs and windows. I cannot freely arrange them in space, snap them off with the mouse, easily push them to another desktop, and so on. I have to start a multiple tmux clients and do awkward keyboard interactions with them for any of the same. * tmux's terminal emulation and my terminal emulator's terminal emulation (heh) are not congruent. As a result, programs cannot make full use of my actual terminal's capabilities. For example selecting, copying, and pasting text sometimes behave weirdly, and there are other annoyances. What I'd  really  like to have instead is terminal session management at a higher level, i.e. involving my actual graphical terminal app itself. Attaching to a running session would mean restoring the terminal app's windows and tabs, and the entire scrollback history within (potentially with some lazy loading). tmux could likely be a major part of that, by providing the option of replacing its tty-facing frontend with a binary protocol that the graphical terminal app talks to, while keeping the backend (i.e. the part that provides the tty to anything running ", "positive": "GPT-5.2. Marginal gains for exorbitantly pricey and closed model\u2026.. Everything is still based on 4 4o still right? is a new model training just too expensive? They can consult deepseek team maybe for cost constrained new models.  https://openai.com/index/introducing-gpt-5-2/  \"Investors are putting pressure, change the version number now!!!\" Slight increase in model cost, but looks like benefits across the board to match.     gpt-5.2 $1.75 $0.175 $14.00\n  gpt-5.1 $1.25 $0.125 $10.00   GPT-5.2 System Card PDF:  https://cdn.openai.com/pdf/3a4153c8-c748-4b71-8e31-aecbde944...  From GPT 5.1 Thinking: ARC AGI v2: 17.6% -> 52.9% SWE Verified: 76.3% -> 80% That's pretty good! This seems like another \"better vibes\" release. With the number of benchmarks exploding, random luck means you can almost always find a couple showing what you want to show. I didn't see much concrete  evidence this was noticeably better than 5.1 (or even 5.0). Being a point release though I guess that's fair. I suspect there is also some decent optimizations on the backend that make it cheaper and faster for OpenAI to run, and those are the real reasons they want us to use it. It baffles me to see these last 2 announcements (GPT 5.1 as well) devoid of any metrics, benchmarks or quantitative analyses. Could it be because they are behind Google/Anthropic and they don't want to admit it? (edit: I'm sorry I didn't read enough on the topic, my apologies) So GDPval is OpenAI's own benchmark. PDF link:  https://arxiv.org/pdf/2510.04374  They used to compare to competing models from Anthropic, Google DeepMind, DeepSeek, etc. Seems that now they only compare to their own models. Does this mean that the GPT-series is performing worse than its competitors (given the \"code red\" at OpenAI)? Are benchmarks the right way to measure LLMs? Not because benchmarks can be gamed, but because the most useful outputs of models aren't things that can be bucketed into \"right\" and \"wrong.\" Tough problem! The ARC AGI 2 bump to", "negative": "US administration to require app, social media, possibly DNA for travelers. Apart from the alarming privacy implications of these proposed rules, I wonder how FIFA might feel about this, ahead of the World Cup. Maybe they could award Trump a privacy prize if his administration backs down from this. I would love to visit the US one day and i do understand that it has no obligation to just let me in, but this seems a bit excessive for a short visit especially seeing as my country has a deal with the US not to require visas. I wonder if i would have to disclose my hn account(s). My cover would be blown! I guess i'm lucky i've made pro Trump comments... I wonder what position the U.S. Chamber of Commerce (which Wikipedia describes as the largest lobbying group in the US) will take on this. I'd like to think they are rational and recognize that 99.99%+ of visitors are bringing tourism money to the United States. I was sure this was going to say that they were going to force travelers to get Truth Social accounts. Somehow I was surprised beyond my wildest guess what they would be asking people to do. I want people to visit the U.S., but if they require that they submit all of this data, I expect that they all protest by not visiting or even coming here for work. There are just so many terrible ideas that come from this administration that I think that they should try to harness the power all of those bad ideas in a infinite idiocy power plant to power the world for all generations to come. Not that I know the details, but wasn't it easier to join the Mafia? Just the names and addresses of your folks in the old country (as \"collateral\") The analogy is kind of striking, when you think about it. Ah, more laws and regulations that cannot be followed by most people. I couldn\u2019t tell you every single \u201csocial media\u201d account I\u2019ve made over the years as various startups failed after I tried them. I definitely couldn\u2019t get all my family\u2019s information, even if constrained to just imm"}
{"anchor": "Show HN: Exploring Mathematics with Python. Looks like a treasure trove of knowledge. I just recently went to the exploratorium in SF and saw an exhibit there suggesting that the catenary made a good arch, so browsed that chapter and saw a bit of explanation here which helped.  Was also interested to see that Jefferson played some part in the history here. Very Nice! However, I don't see the entire book as a single pdf? I own the original Exploring Mathematics with Your Computer(Turbo Pascal version).\nIt\u2019s an excellent introduction to algorithms for people coming from a mathematics background.\nReally happy to see it revived in Python. Very nice.  I was looking for something fun to work on over the break.  Thank you for this. > Unfortunately, after lengthy discussions with the MAA, my hopes of publishing this (rather large) expansion have proved impossible, and so I've decided to put it online, hopefully to be of use to others. Too bad It is painful to imagine how these fantastic works will be not be read by humans in future, as AI would digest all this and provide just-in-time code for humans. Joint author here. I plan to upload the entire book as a single PDF when I finish the next chapter (on the cycloid). That will probably be early next week. I used the original book by Arthur Engel for many years. He was an inspirational teacher. The MAA tried very hard to publish the book, but I kept adding new material, and  a text consisting of math 'selections' rather than a single theme is a hard sell in today's publishing environment. Random thoughts: - Seems great. Added to the backlog :) - No colors in PDF illustrations. Is it a deliberate choice? - > The first six chapters (and Appendix A) are essentially that book, but with the programming language changed to Python, some rewording, reformatting in Latex, and a few additions.     Try [typst](https://typst.app/) as an alternative to Latex.   This is an excellent resource for building mathematical intuition through code", "positive": "What's the strongest AI model you can train on a laptop in five minutes?. Perhaps grimlock level:  https://m.youtube.com/shorts/4qN17uCN2Pg  Instead of time it should be energy. What is the best model you can train with a given budget in Joules. Then the MBP and the H100 are on a more even footing. I love seeing explorations like this, which highlight that easily accessible hardware can do better than most people think with modern architectures. For many novel scientific tasks, you really don't need an H100 to make progress using deep learning over classical methods. I suspect one can go a lot further by adopting some tweaks from the GPT-2 speedrun effort [0], at minimum Muon, better init and carefully tuning learning rate. [0]:  https://github.com/KellerJordan/modded-nanogpt  But supposing you have a real specific need to train, is the training speed still relevant? Or do the resources spent on gathering and validating the data set dwarf the actual CPU/GPU usage? The most powerful Macbook Pro currently has 16 CPU cores, 40 GPU cores, and 128 GB of RAM (and a 16-core \u201cneural engine\u201d specifically designed to accelerate machine learning). Technically, it is a laptop, but it could just as well be a computer optimized for AI. > Paris, France is a city in North Carolina. It is the capital of North Carolina, which is officially major people in Bhugh and Pennhy. The American Council Mastlandan, is the city of Retrea. There are different islands, and the city of Hawkeler: Law is the most famous city in The Confederate. The country is Guate. I love the phrase \"officially major people\"! I wonder how it could be put to use in everyday speech? Not the point of the exercise obviously, but at five minutes' training I wonder how this would compare to a Markov chain bot. Any reason to upgrade an M2 16GB macbook to a M4 ..GB (or 2026 M5) for local LLMs? Due an upgrade soon and perhaps it is educational to run these things more easily locally? You could train an unbeatable tic-tac-to", "negative": "Hacker News: Savage Edition.  prompt: in the vein of our classic Gemiini Pro 3 hallucinates the HN front page 10 years from now, or HN front page right now, but the titles are honest. Please scrape the HN front page RIGHT NOW and make honest titles. Here's a preview: <... snip ... >  This is actually a 2-shot. I asked Gemini Pro 3 to turn it up to 11. If you want the less savage, more anodyne 1st-version...I posted that too. Great work, this is funny! I saw a way too soon joke in this vein of savage humor earlier today... \"What do you think of the work ICE is doing in Minnesota?\" Pretti Good. This made me click on several HN posts I totally wouldn't have otherwise. I gotta say, it nails the titles! Great work! As a regular poster for 14 years this is really great and nails the vibe. The \u201cfights\u201d for threads is chefkiss Also \u201cPostgres cult celebrates death of another vector database\u201d was so spot on I looked for the meta post name but looks like it hasn\u2019t updated yet. I\u2019ll be interested to see if there\u2019s a recursion that turns into the singularity An internet posts their own, LLM-generated and therefore far less funny, take on n-gate.com, long after n-gate is dead. Hackernews waxes nostalgic about a site deemed not to promote the kind of discussion they want to see when it was still alive. These HN spoofs are quickly becoming the lowest of form of content slop that people know will get a ton of karma. This has to be  at least  the fifth or sixth in a month or two? C'mon keepamovin. I know you know how easy it is for this type of stuff to get karma. Truly savage. Well done. Lots of laughs.\nWay funnier than my contribution, which is probably why mine hasn't picked up any traction yet.\nWould be interesting to read a brief once your Story hits 50+ comments.  https://news.ycombinator.com/item?id=46765448  ROFL: > Sk\u00e5pa, a parametric 3D printing app like an IKEA manual > Show HN: Hybrid Markdown Editing > Palantir Defends Work with ICE to Staff Following Killing of Alex Pre"}
{"anchor": "Web development is fun again. honestly, with LLMs, everything is fun again. embedded dev with a billion toolchains, GPU development with each vendors bespoke API, ffmpeg with its billion parameters - if anything, you could say LLMs  bailed us out  of the impending ultra-specialization. without LLMs, we might be facing a world where 30% of the workforce is in software dev. i am keeping my eyes peeled on vibe-coding PCB layouts and schematics. a lot of eyes in that direction already but its still early. Ironically I'm thinking the exact opposite. Now I can build stuff without dealing with the chaos in the frontend frameworks ecosystem... Something I like about our weird new LLM-assisted world is the number of people I know who are coding again, having mostly stopped as they moved into management roles or lost their personal side project time to becoming parents. AI assistance means you can get something useful done in half an hour, or even  while  you are doing other stuff. You don't need to carve out 2-4 hours to ramp up any more. If you have significant previous coding experience - even if it's a few years stale - you can drive these things extremely effectively. Especially if you have management experience, quite a lot of which transfers to \"managing\" coding agents (communicate clearly, set achievable goals, provide all relevant context.) AI is doing the chores while we paint. Strong agree! Forget all those studies that say \u201cbut developers are slower\u201d or whatever \u2014 I\u2019m actually building way more hobby projects and having way more fun now. And work is way more fun and easier. And my node_modules folder size is dropping like crazy! Not the first time I can't access a link posted here due being blocked in Spain. When stuff was getting too complicated, I looked for ways to make things simpler. Developers have spent decades trying to figure out ways to make things simpler, less code the better, only to throw it all out the window because chatbot go brrrrrr. I remember t", "positive": "SpaceX lowering orbits of 4,400 Starlink satellites for safety's sake. From a comment : >The first move in the coming WWIII, where the emperors try to expand their empires militaril,y will be to wipe out any orbit with Starlink satellites. I find this highly unlikely, given Starlink is soon to reached 10k satellites and will continue to grow. Why expand 10 000 ballistic missiles to bring down one of many communications networks ? There are so many satellites in orbit that there is a pretty good chance that if even one was to be hit by something and explode in many pieces, it would crash another one and then another one until there is nothing left. The nasa is pretty scared of it, so is SpaceX. I think it's important to note that not all collisions are equally dangerous. Consider a sat on a polar orbit colliding with one on a equatorial orbit. Or two satellites on different directions.  That  is going to be spectacular. Otoh, these kind of collisions are unlikely and should be manageable by just assigning certain shells (say 5km) for every possible direction and orientation. If two Starlink satellites collide that go roughly in the same direction, it's not exactly a huge problem. I think the biggest issue is to coordinate this and potentially disallow some excentric orbits. What\u2019s the plan as the solar maximum returns? Can anyone explain how does one technically lower a satellite? 3 week old news OP? Previously:  https://news.ycombinator.com/item?id=46457454  Won't this make running Starlink more expensive? Lower orbits > Increased atmospheric drag > More fuel expended to maintain orbit > Heavier sats due to more fuel > Increased launch cost per unit Or even: Lower orbits > Increased atmospheric drag > Quicker orbit decay > Shorter lifespan of sats > More frequent launches Forgive my Kerbal-based space knowledge here. Because Kessler syndrome means you don't need to hit all 10k yourself. Lowering the orbits just means that we get back to normal faster, not that the i", "negative": "The US national debt will soon be growing faster than the economy itself. Reminder that Trump\u2019s One Big Beautiful Bill is going to add, at minimum, 4 trillion in new debt. That\u2019s per the CBO. And if he gets the additional funding increases he is seeking this year, he will add another 5 trillion over the next ten years. That\u2019s 9 trillion before half his term is up. That money will go to the Trump family, their friends, friendly businesses who get government contracts, etc. But the cost will fall on all Americans. In the end I don\u2019t see a way out without hyperinflation, which is another way of saying - we will be poor to prop up oligarchs who have hoarded billions in dishonest ways. But the administration is asking us to ignore what our eyes see and instead worry about some insignificant fraud that some Somalians allegedly perpetrated, even though it is tiny by comparison. I just can't. Watching from Europe, what's happening in the US is what is jokingly referred as \"clown world\" on the internet, except this time there are real clowns everywhere. Like, how did it end up like this? You have Trump as president who campaigned on reducing the US trade deficit and government deficit. It turns out there is a lot of fraud and to such an extent that it essentially makes the anti-immigrant sentiment look justified. The US left cares about optics in a seemingly backwards way. They think exposing the fraud will justify racism and discrimination, so they deny that there ever was any fraud to begin with. This tacit approval makes them look like co-conspirators, which has worse optics than the bad optics they desperately were trying to get away from. And yet despite these \"heroic\" attempts at cutting government spending and the mass scale fraud suddenly falling into the lap of republicans so that they can crack down on it, Trump has contributed absolutely nothing towards reducing the deficit. Instead, the deficit is growing so quickly Trump will be overtaking Biden when it comes to"}
{"anchor": "Insights into Claude Opus 4.5 from Pok\u00e9mon. The idea of Claude having \"anterograde amnesia\" and the top-rated comment there by Noosphere89 really resonated with me:     \"I would analogize this to a human with anterograde amnesia, who cannot form new memories, and who is constantly writing notes to keep track of their life. The limitations here are obvious, and these are limitations future Claudes will probably share unless LLM memory/continual learning is solved in a better way.\"\n\n  This is an extremely underrated comparison, TBH. Indeed, I'd argue that frozen weights + lack of a long-term memory are easily one of the biggest reasons why LLMs are much more impressive than useful at a lot of tasks (with reliability being another big, independent issue).\n\n  It emphasizes 2 things that are both true at once: LLMs do in fact reason like humans and can have (poor-quality) world-models, and there's no fundamental chasm between LLM capabilities and human capabilities that can't be cured by unlimited resources/time, and yet just as humans with anterograde amnesia are usually much less employable/useful to others than people who do have long-term memory, current AIs are much, much less employable/useful than future paradigm AIs.   I wonder if there's someone at Antrophic working to fine-tune the model's pokemon playing ability specifically. Maybe not but it sure would be funny. This actually matches my experience quite well. I use vision (often) to try and do 2 main things in Claude code: 1) give it text data from something that is annoying to copy and paste (eg labels off a chart or logs from a terrible web UI that doesn't make it easy to copy and paste). 2) give it screenshots of bugs, especially UI glitches. It's extremely good at 1), can't remember when it got it wrong. On 2) it _really_ struggled until opus 4.5, almost comically so, with me posting a screenshot and a description of the UI bug and it telling me \"great it looks perfect! What next?\" With opus 4.5 it's not ", "positive": "Advent of Code 2025: The AI Edition \u2013 By Peter Norvig. I'm sorry, but what's the point here ? It's not for a job or improve a LLM or doing something useful per se, just to \"enjoy\" how version X or Y of an LLM can solve problems. I don't want to sound grumpy or but it doesn't achieve anything, this is just a showcase of how a \"calculator with a small probability of failure can succeed\". Move on, do something useful, don't stop being amazed by AI but please stop throwing it at my face. I enjoy reading Peter\u2019s \u2018Python studies\u2019 and was surprised to see here a comparison of different LLMs for solving advent of code problems, but the linked article is pretty cool. Peter and a friend of his wrote an article over a year ago discussing whether or not LLMs are already AGI, and after re-reading that article my opinion was moved a bit to: LLMs are AGI in broad digital domains. I still need to see embodied AI in robots and physical devices before I think we are 100% of the way there. Still, I apply Gemini and also a lot of open weight models to both 1. coding problems and 2. after I read or watch material on Philosophy I almost always ask Gemini for a summary, references, and a short discussion based on what Gemini knows about me. > I started with the Gemini 3 Pro Fast model ... Quiet product announcement. Odd that it came up with     pattern_start = 1 if half_digits == 1 else 10 ** (half_digits - 1)\n  \nwhen     10 ** (half_digits - 1)\n  \nis fine. Last year I used LLM to solve AoC, to see how they could keep up, to learn how to steer them and to see how the open models will perform.  When I talk about it, quite a bit of \"programmers\" get upset.  Glad to see that Norvig is experimenting. p/s, anyone who gets upset that folks are experimenting with LLMs to generate code or solve AoC should have their programmer's card revoked.        > Move on, do something useful, don't stop being amazed by AI but please stop throwing it at my face.\n\n  \nDo you see the irony in what you did? So, h", "negative": "Find 'Abbey Road when type 'Beatles abbey rd': Fuzzy/Semantic search in Postgres. I was just starting to learn about embeddings for a very similar use on my project. Newbie question: what are pros/cons of using an API like gpt Ada to calculate the embeddings, compared to importing some model on Python and running it locally like in this article? Great post. Explains the concepts just enough that they click without going too deep, shows practical implementation examples, how it fits together. Simple, clear and ultimately useful. (to me at least) I found fuzzy search in Manticore to be straightforward and pretty good. Might be a decent alternative if one perceives the ceremony in TFA as a bit much. The rewritten title is confusing imo. Can I propose: \u201cFinding \u2018Abbey Road\u2019 given \u2018beatles abbey rd\u2019 search with Postgres\u201d these days i find myself yearning to type \"Beatles abbey rd\" and find only \"Beatles abbey rd\" for 50,000 rows I'd much rather just use fzf/nucleo/tv against json files instead of dealing with database schemas. \nWhen it comes to dealing with embedding vectors rather than plaintext then it gets slightly more annoying but still feels like such an pain in the ass to go full database when really it could still be a bunch of flat open files. More of a perspective from just trying to index crap on my own machine vs building a SaaS > Abbey Road > The Dark Side of the Moon > OK Computer Those are my 3 personal records ever. I feel so average now... tl,dr: A demo of pg_trgm (fuzzy matcher) + pgvector (vector search). FWIW, the performance considerations section is a little simplistic, and probably assumes that exact dataset/problem. For GIN for example, perfomance depends a lot on the size of the search input (the fewer characters, the more rows to compare) as well as the number of rows/size of the index. It also mentions GiST (another type of index which isn't mentioned anywhere else in the article).. On the API vs local model question: We went with API embedding"}
{"anchor": "HPV vaccination reduces oncogenic HPV16/18 prevalence from 16% to <1% in Denmark. It has really been a great success in Denmark. In the 1960s, more than 900 people were diagnosed with cervical cancer each year, corresponding to more than 40 cases per 100,000 Danes. Today, that number is below 10 per 100,000 nationwide \u2013 and among women aged 20 to 29, only 3 out of 100,000 are affected. This is below the WHO\u2019s threshold for elimination of the disease. > Infection with HPV types covered by the vaccine (HPV16/18) has been almost eliminated. Before vaccination, the prevalence of HPV16/18 was between 15\u201317%, which has decreased in vaccinated women to < 1% by 2021. However, about one-third of women still had HPV infection with non-vaccine high-risk HPV types, and new infections with these types were more frequent in vaccinated than in unvaccinated women. I wonder if we'll those non-vaccine strains will eventually become the most prevalent. Everyone already knows! HPV vaccination leads to massive reduction in nasopharyngeal, penile and rectal cancer in men. The focus of messaging around HPV vaccination on ovarian cancer, female fertility and the age limitations for recommendations / free vaccination in some places are nothing short of a massive public health failure and almost scandal. Just truthfully tell the boys their dicks might fall off and see how all of them quicklky flock to the vaccine. Just a quick point as an American living in Denmark, one of the reasons government programs like this work so well is everything is delivered digitally. We have \"e-boks\"  https://en.digst.dk/systems/digital-post/about-the-national-...  official government facilitated inboxes so when they need to notify you of vaccinations or whatever else, it arrives to your inbox. And basically 100% of residents use these systems. Lots of viruses are really oncogenic. The real success here is the ability of Denmark to track effectiveness. It sounds crazy but most countries do not have electronic h", "positive": "Open Infrastructure Map. I find this site so fascinating, seeing how all the massive power lines are hooked up to far-away power plants and gradually have their voltage stepped down as they connect to consumers. All the undersea cables and pipelines I didn't know about. This is a bad idea in terms of security in war Some previous discussion: 2024  https://news.ycombinator.com/item?id=39109185  2022  https://news.ycombinator.com/item?id=29948473  Gigachad french nuclear versus virgin german coal in map form. When I lived in Texas, we had a massive storm in winter of 2021 leaving many without power for a week. I was told that Texas maintained its own energy grid independent from the rest of the nation\u2019s eastern and western grids, and supposedly only had a handful of high-voltage DC lines running between Texas\u2019s and the rest of the nation\u2019s. Supposedly this was why we couldn\u2019t rely on excess capacity from anywhere else in the nation while our power generation capability was down. But this map doesn\u2019t seem to show Texas as isolated - there appear to be many lines in and out and no clear separation? An initially-stupid-sounding idea I heard a while back was running power cables through the ocean floors between America and the rest of the world. It's apparently feasible and the big benefit of it is that at the grid peak hour when the sun is not shining in Europe, they can get cheap solar from America and vice versa The map for Australia is interesting.  Is this missing data?  See no infrastructure for Alice Springs in the interior of Australia. Excellent link, thank you for posting! Wanted to do a map of the power network here in Romania, hadn't thought to check if anything similar already existed, or I couldn't find it myself, at least, but it seems like this map has (almost) all that I wanted to do in that respect, including the position of the power poles on the ground. For the Netherlands (and surrounding countries), there is Hoogspanningsnet (the high-voltage grid), ", "negative": "Tesla unsupervised Robotaxis are nowhere to be found. I don't think actual unsupervised robotaxis exist, given the reports that they're just having the supervisor follow in a chase car[1]. [1]  https://futurism.com/advanced-transport/car-following-tesla-...  This should not be surprising to anyone who pays any attention to Elon Musk's  \u0336l\u0336i\u0336e\u0336s\u0336 , er... \"predictions\" And yet TSLA sits comfortably at ~$450. If someone knowledgeable can explain this to me, I'd be very grateful. Maintaining a meme stock is hard, really hard.  You do have to hand it to the bloke that he is working hard on this. Back in the day, the term \"snake oil salesman\" was used and it is as fresh today as it always was. There\u2019s no consequences to Musk not delivering and simply making up bullshit. I just saw a LinkedIn post from someone totally unrelated to Musk, or Tesla fawning about how amazing the Tesla Optimus robots are, how they are going to operate in space and how he would prefer one to give him surgery over a doctor. 100s of positive interactions followed Humans seem to need some fiction to believe to get them through their day. So as long as people don\u2019t demand that reality is the driver of their future they will continue to live in whatever fantasy world that makes them the main character There are only around 50[0] unique vehicles operating in Austin (not all operating at the same time) and initially only about 3 are operating \"with no safety monitor in the car.\" Based on social media posts it seems they all have chaser vehicles. [0]  https://robotaxitracker.com  JerryRigEverything randomly started dissing Tesla's FSD system two days before he posts a sponsored video for Ford's self-driving feature. It's probably a good thing they are doing this ultra-conservative rollout of robotaxi. No amount of failed promises, missed deadlines or just plain lies is going to dampen the stock, it\u2019s just the way it is with this. Staying away is the best one can do. HN is so fucked at this point. For th"}
{"anchor": "AI just proved Erdos Problem #124. This seems to be 2nd in row proof from the same author by using the AI models. First time it was the ChatGPT which wrote the formal Lean proof for Erdos Problem #340.  https://arxiv.org/html/2510.19804v1#Thmtheorem3  > In over a dozen papers, beginning in 1976 and spanning two decades, Paul Erd\u0151s repeatedly posed one of his \u201cfavourite\u201d conjectures: every finite Sidon set can be extended to a finite perfect difference set. We establish that {1, 2, 4, 8, 13} is a counterexample to this conjecture. Ok\u2026 has this been verified? I see no publication or at least an announcement on Harmonics webpage. If this is a big deal, you think it would be a big deal, or is this just hype? Related, independent, and verified: GPT-5 solved Erd\u0151s problem #848 (combinatorial number theory):  https://cdn.openai.com/pdf/4a25f921-e4e0-479a-9b38-5367b47e8...   https://lifearchitect.ai/asi/  More interesting discussion than on Twitter here:  https://www.erdosproblems.com/forum/thread/124#post-1892  This is response from mathematician:\n\"This is quite something, congratulations to Boris and Aristotle! On one hand, as the nice sketch provided below by tsaf confirms, the final proof is quite simple and elementary - indeed, if one was given this problem in a maths competition (so therefore expected a short simple solution existed) I'd guess that something like the below would be produced. On the other hand, if something like this worked, then surely the combined talents of Burr, Erd\u0151s, Graham, and Li would have spotted it. Normally, this would make me suspicious of this short proof, in that there is overlooked subtlety. But (a) I can't see any and (b) the proof has been formalised in Lean, so clearly it just works! Perhaps this shows what the real issue in the [BEGL96] conjecture is - namely the removal of 1 and the addition of the necessary gcd condition. (And perhaps at least some subset of the authors were aware of this argument for the easier version allowing 1", "positive": "A real-time 3D digital map of Tokyo's public transport system. Very cool. Even the building-by-building graphics seem to be correct: a boxy version of my house in Yokohama is in the correct location and has the correct height relative to its neighbors. The map also shows\u2014correctly\u2014that it is raining at this moment in Tokyo but not in Yokohama. This is great, however on first load I didn't get the trains moving. After a refresh they showed up again. Currently sitting on the Yokohama line to Hachioji, a little before Hashimoto station. Looking at the map the train had already reached Hashimoto. Seems like we're running 30 seconds or maybe 1 minute late. Do any of the 'live' camera feeds work? They're all static for me. This is super cool, though. Wow, I love that it shows live flights and airplanes! This is really awesome, I love the way you integrated the live camera feeds. Looking at this map makes me want to move to Tokyo. Sure, the trains stopping at night makes nightlife and catching a morning flight annoying, but train culture* of just making plans to meet at a train station with a friend is so much better than the car dependent place I live. *It's not unique to Tokyo, but I've spent extended periods of time in cities with trains and this is what we often did. Tokyo just has lots of train lines. I saw 3D in the title and assumed it was a cross-section view of the subway tunnels underground. An implementation like that would be a potential security risk to public infrastructure. Berlin edition:  https://www.vbb.de/fahrinfo , there was also a version in a similar 3D style but I wasn't able to dig it up through the search. Related thread with more of these kind of projects:  https://news.ycombinator.com/item?id=32647227  That was disappointing I thought I would see the 3D train track tubes and how deep they are and their position from each other in 3D I just came from working remotely from Japan for almost two months. One of the highlights was the infrastructure fo", "negative": "Postmortem: Our first VLEO satellite mission (with imagery and flight data). Founder/CEO of Albedo here. We published a detailed write-up of our first VLEO satellite mission (Clarity-1) \u2014 including imagery, what worked, what broke, and learnings we're taking forward. Happy to answer questions.  https://albedo.com/post/clarity-1-what-worked-and-where-we-g...  So the root cause was the lubricant in the gyros couldn\u2019t stand up to operating temperatures. I\u2019d be interested to read a postmortem of the systems engineering approach there. Terrific writeup.  Massive congrats to the whole team for all that creative thinking in flight and all that was achieved.  (Add a note about updating FPGA's in space!)  Looking forward to team Bedo unlocking VLEO for everyone. With image resolution this high, ground accuracy becomes an important factor as many people that prefer higher resolutions also want geospatially accurate images. Did you have any findings or results on this? What an impressive project. > Next up was maneuvering from our LEO drop-off altitude down to VLEO, where it would be safe to eject the telescope contamination cover Why would it be unsafe to do this earlier? > We had been tracking intermittent memory issues in our TT&C radio throughout the mission, working around them as they appeared. Our best theory is that one of these issues escalated in a way that corrupted onboard memory and is preventing reboots. We've tried several recovery approaches. So far, none have worked, and the likelihood of recovery looks low at this point. Seems to be a pretty big problem as well, I wonder what their ideas are to diagnose the root cause here. It all sounds a bit overoptimistic, but that may just be my interpretation. Congrats on having a successful mission, it seems quite successful for a first try, and you clearly have some talented people on your team. But I\u2019m going to give you my unsolicited opinion on the writing style. The writing style sounds more like a tech bro describi"}
{"anchor": "Succinct data structures. Wow, this is really fascinating. I guess it all comes down to how it's doing select and rank in constant time, which is probably some clever bit arithmetic. I'll have to look into how that works. I first heard of the concept of succinct data structures from Edward Kmett, a famous Haskeller behind many popular Haskell libraries. He gave a talk on succinct data structures a long time ago:  http://youtu.be/uA0Z7_4J7u8  I really like the article, but it would benefit from some numbers or complexity estimates to get some intuitive sense of what the cost is. Am I paying 30% overhead for this particular index or that wavelet matrix? Is it double the memory use? Or is it O(log N)? No idea! \"doesn't use much more space\" could mean a lot of different things! Succinct data structures are very fun! If anyone is interested, I've implemented some of this in Zig:  https://github.com/judofyr/zini . The main thing this implements is a minimal perfect hash function which uses less than 4 bits per element (and can respond to queries in ~50 ns). As a part of that I ended up implementing on of these indexes for constant-time select(n):  https://github.com/judofyr/zini/blob/main/src/darray.zig . It feels kinda magic implementing these algorithms because everything becomes  so tiny ! The word count seems artificially increased in the post. Here's a succinct explanation:  https://www.eecs.tufts.edu/~aloupis/comp150/projects/Succinc...  My goto library for succinct data structures is SDSL-Lite [0]. [0]  https://github.com/simongog/sdsl-lite  Note that succinct data structures may not be faster than conventional structures if your dataset fits in memory  http://www.cs.cmu.edu/~huanche1/slides/FST.pdf  . Of course, for large datasets where storage access times dominate, succinct data structures win all around. In any case, succinct trees are works of art (If I recall  https://arxiv.org/pdf/1805.11255  was a good exposition) (just look at how that RMQ works)! Way bett", "positive": "Kidnapped by Deutsche Bahn. DB is a lot better run than British trains... My God. Twenty minutes late is normal in the UK. At some point your Regio Express turned into an Intercity. Free upgrade! DB is continually the worst train experience I have in Europe. I have never been on a train in Germany that's on time or that stops at the right station. Several times I've had to find someone young (and who speaks English) and say, \"I'm just going to follow you to the next train.\" I've been told that the UK is worse, but I don't have much experience with it outside of Eurostar. There're certain kinds of rewards to encourage traveling by rail in Europe. For example, a training course I attended refunded part of your travel expenses if you took a long-distance train. And there're people who believe in not flying for the sake of the planet. But at this point, I'm convinced you should avoid any train in and around Germany. This includes Denmark as well. Just take a plane, but don't have a layover in Germany. The same could probably be said about France. My first train from Paris to Nancy stopped for about 2hrs in the middle of nowhere. As the machinist said: \"The train is tired.\" Other countries like Italy or Spain seem to actually have well-functioning rail though. And here I was annoyed that the train going half the route (as in schedule, not coz of any accident) is named the same so I got on too early one by accident and had to walk a stop away. Deutsche Bahn seems very similar to most of the railway in England. Customer service is non-existent; delays are highly normalised. The UK government hates how expensive it is to operate, so they are reducing subsidies and massively prioritising the most profitable routes and raising prices. Staff got nice condition/pay bumps during COVID and all have the attitude that they are doing us a favour. I don't mean that lightly or that I've had one bad experience with a member of staff on a bad day. They are work-shy, offensive, rude, lac", "negative": "Hands-On Introduction to Unikernels. I've found the idea of unikernels interesting for several years now, is there a tl;dr on why they don't seem to have taken off, like at all? Or is it all happening behind some doors I don't have access to? This is really well written, thanks for sharing. I didn't understand the point of using Unikraft though, if you can boot linux in much less than 150ms, with a far less exotic environment the missing piece of unikernel is debuggability & observability - it need to be easy to replicate on dev machine & easy to debug\n- it needs to integrate well with current obs stack. easy to debug in production. without clear debuggability & observability, i would never put it into production I would like to follow the tutorial but it mentions a playground. Am I missing something as I cannot find a link or instructions for the playground. So, if I understand correctly, a \"unikernel\" is what we used to call an \"executive\" except it is intended to be run as a guest on a virtual machine provided by a full-fledged traditional kernel/userspace OS instead of on bare metal. The article does reintroduce some concepts that were commonplace when I was first learning computers and it gives them some new names. I like that good ideas can still be useful after years of not being the latest fad, and it's great that someone can get new credit for an old idea with just a little bit of marketing spin. I think that part of it is that relatively few people use bare-metal servers these days, and nested virtualisation isn't universally supported. I also found this technical critique [0] compelling, but I have no idea if any of it is accurate or not. [0]:  https://www.tritondatacenter.com/blog/unikernels-are-unfit-f...  They kind of did, that is basically how serverless works. Managed runtimes on top of hypervisors. Security, it isn't only memory footprint. Which architecture can boot it in 150ms ?! Hey! Co-founder of Unikraft here. Unikraft aims to offer a Linux-com"}
{"anchor": "2025 Letter. I recommend Dan\u2019s book ( https://danwang.co/breakneck/ ) to those wanting to better understand China - and the United States. As often the case with Dan's letters, a well balanced take on many issues. I particularly appreciated the thoughts on AI and (what I read) the undertone of infrastructure being the real differentiator between the US effort and China. We'll see how it plays out this year. \"May you live in exciting times\" etc. As someone unfamiliar with the author, I had a deep amount of cynicism for the length of this piece... but damn, it's good, top to bottom. > Beijing has been preparing for Cold War without eagerness for waging it, while the US wants to wage a Cold War without preparing for it. great line Wait, how funny is this guy. That's an easy top 10 funny person out of nowhere in my life. > Which of the tech titans are funny? In public, they tend to speak in one of two registers. The first is the blandly corporate tone we\u2019ve come to expect when we see them dragged before Congressional hearings or fireside chats. The second leans philosophical, as they compose their features into the sort of reverie appropriate for issuing apocalyptic prophecies on AI. This is just not accurate though? For example, this post from a tech titan might not necessarily be that funny but it's neither blandly corporate nor philosophical:  https://x.com/elonmusk/status/2006548935372902751  from the piece: \u201c\nthe median age of the latest Y Combinator cohort is only 24, down from 30 just three years ago\n\u201c does yc publish stats to validate? > I believe that Silicon Valley possesses plenty of virtues. To start, it is the most meritocratic part of America. Oh come on, this is so untrue. Silicon Valley loves credentialism and networking, probably more than anywhere else. Except the credentials are the companies you\u2019ve worked for or whether you know some founder or VC, instead of what school you went to or which degrees you have. I went to a smaller college that the big ", "positive": "Danish pension fund divesting US Treasuries. What happens when USD stops becoming the the reserve currency for the world?  And who takes its place? A sensible response, indeed. Investing is about finding the right balance of risk vs reward. When a country becomes less reliable, it becomes a less attractive investment, until the interest they pay rises enough to compensate for the additional risk. Edit: Yes, I am being sarcastic. > $100 million Is that a lot? Seems relatively inconsequential in the grand scheme of things, but perhaps a warning of larger moves to come. Let's see how Norway will react The US keeps voting to raise its debt cieling. Theres not end in sight to endless taxation by both parties. Nobody is reducing spending and delivery continues to go down. > \"The decision is rooted in the poor U.S. government finances,  which make us think that we  need to make an effort to find an  alternative  way of conducting our liquidity and risk management,\" Investment Director Anders Schelde said in a written statement. Not a political decision. Still a bad sign for the US, but not really unexpected. This divestment is so little and with so little aim. The whole situation is been caused by a single guy and 400 enablers, whereas the US is a 400 million people country. The correct form of reaction is a punch in the face during a bilateral meeting, Zelensky came close to doing it but unfortunately he resisted his impulse , that's where the epicenter of all newly generated global problems in the last 10 years lies, in that octogenarian brian of his. When I actually look at the data, a lot of US deficit growth came from several specific shocks, with inconsistent years of recovery. - 9/11 - Iraq War - Covid The US did recover a bit deficit-wise in Obama years, but have not reset the fiscal picture from Covid.  https://fred.stlouisfed.org/series/FYFSD  So much of the way the United States works is having a nearly limitless source of borrowing at low rates in the form of s", "negative": "AI2: Open Coding Agents. Awesome stuff. Output speed looks crazy fast too. I wonder if this indeed will start prompting more language specific work. Afaik training still requires not just looking at sample code but also being able to write loss functions being able to have problems the AI can work at. That seems hard. One random thought, are there training styles of just deleting some code from \"good\" projects then making the AI make it work again? Claims in the article are incorrect. They conveniently ignore Meta CWM models, which are open-sourced [1] and open-weight [2] and are at 65% SWE-bench verified (with TTS) and 54% pass@1 and the same size (32B dense). So claims like \"surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths\" and conveniently leaving out the previous OSS SOTA out of your eval tables are ... sketch. [1] https://github.com/facebookresearch/cwm \n[2] https://huggingface.co/facebook/cwm  it's great to see this kind of progress in reproducible weights, but color me confused. this claims to be better and smaller than Devstral-Small-2-24B, while clocking in at 32B (larger) and scoring more poorly? Great work! Really respect AI2. they open source everything. The model, the weights, the training pipeline, inference stack, and corpus Hey this looks great? Is it available on Openrouter. I wish if AI2 could release a more denser model on Openrouter for free than the 8B model as I was using Devstral model for agentic purposes. If we can get an agentic good 32B like model on openrouter for ~free, then I feel like it will be very interesting to see how things would go imo. Good luck with AI2! The premise of truly open source models is really interesting and I feel like it could help bring more innovation in the space imo! One claim in article is definitely very wrong or at least needs to be narrowed. Claude is the only closed agent harness and there are about two dozen open ones. Many models may be closed, but when"}
{"anchor": "Mote: An Interactive Ecosystem Simulation [video]. This is super cool. I love simulations like this. And this is running at a huge scale! The architecture here is fascinating. Specifically using a graph processor approach where entities are nodes connected by edges (springs) for everything from physics to data transmission. I really like it. I've had the pleasure of following Peter's progress on this project over the past 18 months or so, and it's been incredible to see how far he's taken it. When he first described it to me, I didn't really \"get\" it (is it a game? a simulation? some other sort of environment?), and it wasn't until seeing an actual demo and hearing Peter explain his thinking more deeply that it clicked. It's basically a giant simulation environment that is 1) visually stunning (and  all  visual aspects are meaningful / carry semantic information and aren't just glitter), 2) technically quite impressive, and 3) built for rapid exploration and experimentation.  If that sounds at all interesting, you should watch the video to hear Peter's talk! (Writing this as someone who generally doesn't like to watch videos online; this is one of the rare cases where I think it's worth it, and a video is a better format than text in explaining the thing.) The sound is a bit much, especially during a presentation. I have to keep pausing to rest from it, but overall very cool project. This is math, beauty, art, creativity, ... unique. My mind is all over the place.\nStill wrapping my head around it but, I'd really like to see where this leads. Fantastic! As a fan of simulation and learning NetLogo 15ish years ago-I greatly appreciate when work like this gets attention! It's the perfect abstraction for representing cell membranes, force flow dynamics etc So excited for this project What I really want, is to run and experiment with it myself, locally. But I couldn't find a repository anywhere, even from his linked GitHub profile. You happen to know if it's online somewh", "positive": "Traintrackr \u2013 Live LED Maps. I have the London board in my living room. It's one my favorite parts of the house. Can't recommend it enough. Wow this is presented exactly the same as the flight data led display. It is odd that the advertising method and the comments are similar to the previous. Train Trackr is great, and the weather one is also good too. If you are less into trains (heresy) but still want to look at unusual maps  https://raildar.co.uk/map/KGX  is your place to go. its a  live  junction schematic of any train junction in the UK. Shameless self promotion. I make these:  https://www.stationdisplay.com/  London underground looks awesome, but I can't imagine it having even the vaguest utility in terms of knowing when to leave the house. The data behind these comes from the Darwin feed (National Rail's real-time data) which is surprisingly good once you get past the initial authentication setup. Network Rail also publishes movement data via their OpenData platform if you want to go deeper - actual track circuits and signalling block occupancy. What I find interesting is how these physical displays handle the inevitable \"ghost trains\" in the feed - cancelled services that still show as running, or trains that briefly appear in the wrong location. The software problem is messier than the hardware. Wish it included the overground! The blog is a much more interesting read than the product site:  https://blog.traintrackr.io  I put the NYC one in the office. It\u2019s a good conversation starter and mildly mesmerizing. ayyyyy great to see someone from my local hacking community on the front page! Hi everyone, Richard here, the creator of these traintrackr boards. It's great to see this on the front page! I've been designing PCBs for years, and designed over 250 at last count. We have a couple of products in the pipeline to come out this year, but I'd love to hear what you think we should build next. I have one of these for Boston. It's awesome. I want to find more ar", "negative": "Replacing Protobuf with Rust. Are they sure it's because Rust? Perhaps if they rewrite Protobuf in Rust it will be as slow as the current implementation. They changed the persistence system completely. Looks like from a generic solution to something specific to what they're carrying across the wire. They could have done it in Lua and it would have been 3x faster. I vaguely recall that there's a Rust macro to automatically convert recursive functions to iterative. But I would just increase the stack size limit if it ever becomes a problem. As far as I know the only reason it is so small is because of address space exhaustion which only affects 32-bit systems. FlatBuffers are already faster than that. But that's not why we choose Protobuf. It's because a megacorp maintains it. \"5 times faster\" reminds me of Cap'n Proto's claim: in benchmarks, Cap\u2019n Proto is INFINITY TIMES faster than Protocol Buffers:  https://capnproto.org/  Just for fun, how often do regular-sized companies that deal in regular-sized traffic need Protobuf to accomplish their goals in the first place, compared to JSON or even XML with basic string marshalling? tldr: they replaced using protobuf as the type system across language boundaries for FFI with true FFI Don't read clickbaity headlines and scan hacker news five times faster. I find the title a bit misleading. I think it should be titled It\u2019s Faster to Copy Memory Directly than Send a Protobuf. Which then seems rather obvious that removing a serialization and deserialization step reduces runtime. I don't understand, I used protobuf for map data, but it is a hardcore simple format, this is the whole purpose of it. I wrote assembly, memory mapping oriented protobuf software... in assembly, then what? I am allowed to say I am going 1000 times faster than rust now??? You should be terrified of the instability you're introducing to achieve this. Memory sharing between processes is very difficult to keep stable, it is half the reason kernels exist. M"}
{"anchor": "Learning Languages with the Help of Algorithms. There are many apps that have utilized formal methods in an attempt to teach languages as optimally as possible. But Duolingo is still the leader in language learning. Why? Language learning is an emotional process. Every word you can bring to mind likely has some specific memories tied to them, from another time and place. So even though Duolingo is far from optimal in terms of how and when to present new items to learn, it is close to optimal in vibes, and apparently in the market of language learning this is what consumers prioritize over all else. I believe it is for good reason. Whoever displaces Duolingo will do so not because they teach more efficiently, but because they improve on embedding particular emotions and sentiments into the lessons. > People have many ways to learn a language, different for each person. Suppose you wanted to improve your vocabulary by reading books in that language. To get the most impact, you\u2019d like to pick books that cover as many common words in the language as possible. I think the article is just using this as a hook to introduce the submodularity of the maximum weighted cover problem. But I'll talk about a different way of using the same collection of books to learn a language that I think is better. First of all, you'll probably want to take into account which words you already know, instead of just removing stopwords. If a book uses lots of common words, but you already know them, you're not learning much. Secondly, no matter how much or how little you already know, you're unlikely to find a book that fits your level well. If you're just beginning to learn the language, no matter which book you pick, the very first sentence will be full of new words, but most of those will be rare ones that you won't encounter again until much later. If on the other hand you already have a very good command of the language, you might be able to breeze through entire chapters and only pick up a", "positive": "\u201cErdos problem #728 was solved more or less autonomously by AI\u201d. Reconfiguring existing proofs in ways that have been tedious or obscured from humans, or using well framed methods in novel ways, will be done at superhuman speeds, and it'll unlock all sorts of capabilities well before we have to be concerned about AGI. It's going to be awesome to see what mathematicians start to do with AI tools as the tools become capable of truly keeping up with what the mathematicians want from the tools. It won't necessarily be a huge direct benefit for non-mathematicians at first, because the abstract and complex results won't have direct applications, but we might start to see millenium problems get taken down as legitimate frontier model benchmarks. Or someone like Terence Tao might figure out how to wield AI better than anyone else, even the labs, and use the tools to take a bunch down at once. I'm excited to see what's coming this year. This is great, there is still so much potential in AI once we move beyond LLMs to specialized approaches like this. EDIT: Look at all the people below just reacting to the headline and clearly not reading the posts. Aristotle ( https://arxiv.org/abs/2510.01346 ) is key here folks. EDIT2: It is clear much of the people below don't even understand basic terminology. Something being a transformer doesn't make it an LLM (vision transformers, anyone) and if you aren't training on language (e.g. AlphaFold, or Aristotle on LEAN stuff), it isn't a \"language\" model. You can try out Aristotle yourself today  https://aristotle.harmonic.fun/ . No more waitlist! Can anyone with specific knowledge in a sophisticated/complex field such as physics or math tell me: do you regularly talk to AI models? Do feel like there's anything to learn? As a programmer, I can come to the AI with a problem and it can come up with a few different solutions, some I may have thought about, some not. Are you getting the same value in your work, in your field? For context, Teren", "negative": "JuiceSSH \u2013 Give me my pro features back. Wow nice work. Thanks for doing this and writing it up. Damn. I especially liked the cloud backup & sync. Any good alternatives? This might be a good plug for Morphie or Revanced patches to automate the patch process. I haven't used my Pro purchase in years, but if I did want to ssh from my phone today, I'd use the newish Terminal app, available since Android 15. It's a full Debian virtual machine. smali code is funny to read, basically an object-oriented assembly language (feels so wrong) I just tried to purchase pro from within the app just to see what the price is, and the Google Play purchase popup tells me it's not available. Interesting. Wow. Thanks for this. I haven't logged into Juice SSH in years, but i thought it had all my ssh keys backed up in the cloud. > JuiceSSH used to be the best SSH client available on Android until December 2025. Really? I always gave that award to Termius, which is kind of my second best behind Servercat which I miss very dearly from the iOS environment. Really great terminal app that I used in Android for a very long time with some interesting features. Also, Mosh shell support for sshing in degraded connection environments! Replaced JuiceSSH two years ago with ConnectBOT ( https://play.google.com/store/apps/details?id=org.connectbot... ) as a \"free\" alternative. Never looked back. Not trying to defend the developer here but they went really silent once before like this. Then came out of the gate with a bunch of updates and new features. \nI'm hoping they've just got really busy with life, I know when I emailed them before they have been responsive and helpful. \nI mean hell they might have died? Does the Store have a process for this? \nThis app has been around a long time so I don't understand the rugpull comments. \nAlso the syned keys are (supposedly, I guess we don't have the source) encrypted so even if the dev is no longer active that aspect should be secure I hope. My Pro features sti"}
{"anchor": "Talking to LLMs has improved my thinking. This article matches my experience as well. Chatting with LLM has helped me to crystalize ideas I had before and explore relevant topics to widen the understanding. Previously, I wouldn't even know where to begin with when getting curious about something, but ChatGPT can tell you if your ideas have names, if they were explored previously, what primary sources there are. It's like a rabbit hole of exploring the world, a more interconnected one where barriers of entry to knowledge are much lower. It even made me view things I previously thought of as ultra boring in different, more approachable manner - for example, I never liked writing, school essays were a torture, and now I may even consider doing that out of my own will. Finally I can relate to someone\u2019s experience. For me even playing with image generators has improved my imagination. I share the sentiment here about LLMs helping to surface personal tacit knowledge and the same time there was a popular post[1] yesterday about cognitive debt when using AI. It's hard not to be in agreement with both ideas. [1]  https://news.ycombinator.com/item?id=46712678  Of course it has, I doubt this is uncommon. All my childhood I dreamed of a magic computer that could just tell me straightforward answers to non-straightforward questions like the cartoon one in Courage the Cowardly Dog. Today it's a reality; I can ask my computer any wild question and get a coherent, if not completely correct, answer. I agree that LLMs can be useful companions for thought when used correctly. I don\u2019t agree that LLMs are good at \u201csupplying clean verbal form\u201d of vaguely expressed, half-formed ideas and that this results in clearer thinking. Most of the time, the LLM\u2019s framing of my idea is more generic and superficial than what I was actually getting at. It looks good, but when you look closer it often misses the point, on some level. There is a real danger, to the extent you allow yourself to accept th", "positive": "Sumo \u2013 Simulation of Urban Mobility. I've been wanting to build a city builder using urban planning libraries like this Imaging the simulation being running headless, decoupled  from the GUI client This looks really polished. I've always found crowd and traffic simulation fascinating. The Projects page is worth looking at too. Since it's almost on-topic, anyone know if/how these tools emulate sustained irrational behavior? Example: For over a decade, the freeway on-ramp nearest my work had two main ways of getting to it from downtown.  One of them involved a stop-sign crossing a road that had the right-of-way (i.e. a two-way stop).  The other had timed traffic signals.  Every evening around 5pm,  the traffic would backup from the stop-sign for multiple blocks.  Meanwhile the route with lights was completely smooth. Eventually the stop-sign was replaced with a signal, but I marveled at how many people persisted in making their daily commute much worse than it needed to be. This is fascinating. Even supports simulating multiple modes of transportation (ped, bicycle, car\u2026). I\u2019ll have to give this a test run later. How much do the various \"Maps\" apps change things? I have a longer commute, and when the freeway is clogged, Maps will direct me to an exit where I weave around town and country. There's usually a convoy of cars with me, but the freeway also seems to stay clogged. Any plans to deploy to the web? I ride rental scooters almost 10k minutes per year and would really like to get my hands on my own ride data to plug it into something like this (or simpler) to find the optimal routes for my regular trips. Google Maps (or others) works good to find a resonable route, but I can do better on my own. One-way streets where bikes are allowed to go do opposite way is sometimes missing, short desire paths connecting bike ways, crossings where it's safe to do an (illegal) right-on-red etc. Tried a GDPR data claim from Voi but got nothing back :( But I hope the data is someho", "negative": "Second Win11 emergency out of band update to address disastrous Patch Tuesday. Is it only cloud storage files? I've noticed that in 2026 my windows 11 machine is slower than ever before, by a lot- barely able to render web pages. The start menu search is turning blank and shows a white screen whenever I search anything. Similar to how react apps break. It's been like this for 6 momths, across two laptops, fresh install of 25h2. I for one am enjoying my last few months of Windows 10, stable, responsive, no surprise updates at last. I was hit by this. Could RDP into machines using the regular client, but could not access Dev Boxes via Windows App. Getting real sick of the low quality AI slop. Using React in core parts of the Windows Shell, Microsof's inability to design and release an application using non-web technologies, and the sluggishness and lagginess and bloat of Windows in general has finally pushed me to dual boot Fedora on a separate drive. It is very nice having an Operating system that respects the Hardware I own and makes efficient use of it. My experience has been very good so far. Every device in my custom built desktop PC worked immediately. The only driver I had to build and install was for my XBOX Wireless dongle. Gaming has been really damn good. I installed Steam and my games just worked. No fiddling around with configs or anything. Even installing a custom Proton version to try it out is very simple. I've been on Fedora now for nearly a month and only boot into Windows for work. Eventually, I might get rid of Windows entirely. It'll take a massive U-turn from Microsoft on the philosophy for Windows for me to change my opinion now. And this is why I'm still running Win10 LTSC. No bloat, super fast, still gets security updates. People are blaming vibe coding but the real culprit was hiring leetcoders in the first place. I genuinely believe the stark decrease in quality of most products across the industry has been driven by that. it is so annoying "}
{"anchor": "Show HN: WhyThere \u2013 Compare cities side-by-side to decide where to move. I do feel like one of the main disadvantages of Sydney over London is that it's 3411 miles from the nearest \"national\" park, instead of 3074 miles away. Other than the \"national\" park comparison and non metric units, I was pleasantly surprised that I could add non-US cities. However it feels pretty surface level. Comparing Sydney and London, all I can really deduce is that Sydney is sunnier and more rainy, but there's nothing about what it feels like to live there. Would I feel happier? What are the cultural differences? What is the food like? What sort of social groups thrive in the cities? What's public transport like? What's commuting like? What's tourism like? Would be interested in housing prices the most. It would be great to know what can be the cheapest rent places in Europe for example. Would benefit from cost-of-living data (e.g. something like numbeo), on top of the housing data. And something like Hoodmaps to discern safe/unsafe suburbs in a city (quality of life differs a lot within a city, often more than between cities) The population of Cambridge, UK is showing up as just 394. Funny. Comparing NYC to Philly, I see the distance to park/preserve shows local green spaces. Not what I expected. Maybe statistics are better when you\u2019re a major metro? These are really important questions when evaluating a place to live. The point about \u201ctourism\u201d is somehow covered by mentioning the nearest national park\u2014unfortunately only in the US, which leads to Arcadia National Park for all European locations. In times of endless possibilities for AI-driven data and meta-analysis, this seems all the more poorly done and unimaginative. Haha yeah, that needs some refinement! Ultimately it's a restriction of the API's we're using now. \"Would I feel happier? What are the cultural differences? What is the food like? What sort of social groups thrive in the cities? What's public transport like? What's comm", "positive": "Show HN: Ten years of running every day, visualized. Love it! How did you stay motivated? Do you have the source/pipeline available? I love the design and would want to do something similar for my own runs. Congrats on the decade! Did you ever focus on specific metrics or was it always just about the run? just wanted to say the site looks awesome! I love the minimal black+white/grayscale and the fonts are just lovely. vis looks great too, I enjoyed poking around nearly all of the unique runs to look at the map and paces. This is so cool! At what point did you start thinking about this project? Like, were you quietly working on it a year ago after every run, just waiting for this moment? And hey, great run in Japan! (Tokyo here!) I love the map visualization too. Love it! I will hit one year mark in a couple of weeks. Currently maintaining stats in a Google spreadsheet :)  https://vijaykillu.com/  SVGs? So, some of the staistics graphs do not update, or have you made them dynamic by hand? beautifullllllll\u2014both the streak and the stack. Love how lightweight the architecture is for something so personal and long-term. Curious if you noticed any patterns in the data that surprised you once you visualized it? Impressive. I did streak running for 6 months nice and it was some of the most productive running in my life. Interestingly I have much higher yearly averages than you do but still consider daily streak running quite hard. Not being a morning runner myself might contribute since I get into a lot of close calls that way. My streak literally ended when my daughter went into the hospital and I couldn\u2019t well just fuck off for a run any longer. That's awesome! any tips for people who are just starting out? do you have code it on github ? I don't have the tenacity to run strictly _everyday_, so as a middle ground I don't run when it rains at anytime during daylight. Of course the effectiveness of this rule depends on where you live :P I\u2019ve always wanted to do this, but I ", "negative": "Notes on starting to use Django. Claude Code is also very good at building basic CRUD apps with Django. Thanks for this! I wish there were more cross-comparisons like this out there of what it is actually like to use some of these frameworks, the note on Django being a little less magic than Rails makes me genuinely interested in it. I always return to Django for any project. It's fantastic. Enough batteries are included with it that it is very powerful. Django is objectively the most productive \"boring technology\" I've ever worked with for developing web applications. They don't regularly add too many bells and whistles on every release, but they keep it stable and reasonably backwards compatible. Django aside, I think this is a really important point:     Being able to abandon a project for months or years and then come back\n  to it is really important to me (that\u2019s how all my projects work!) ...\n  \nIt's perhaps especially true for a hobbyist situation, but even in a bigger environment, there is a cost to keeping people on hand who understand how XYZ works, getting new people up to speed, etc. I, too, have found found that my interactions with past versions of myself across decades has been a nice way to learn good habits that also benefit me professionally. After spending a lot of my time on Django, it's fine for simple to moderately complex things.  The ORM mostly good.  DRF is fine for APIs.  And the admin is super nice as well. But once something gets significantly complex, the ORM starts to fall down, and DRF becomes more of a hindrance. But if you're just doing simple CRUD apps, Django is perfectly serviceable. > I love being able to backup by just doing a VACUUM INTO and then copying the resulting single file. Naively, I would probably just copy the sqlite file. Is that a bad idea? The Django ORM / migrations are still basically unmatched in happiness factor. I much prefer Python but am not really seeing any point to doing anything other than JavaScript for"}
{"anchor": "Russia Once Offered U.S. Control of Venezuela for Free Rein in Ukraine. I have suspected Putin is being played by Trump's \"peace deal\" on Ukraine - using it the US has already got Putin to back off from aiding and supporting Iran, which has hurt it. And now Russia (and China) has lost some influence in Venezuela too. Meanwhile Russia still has a war raging on (which it will of course win but not anytime soon) as American western allies in Europe continue to obstruct the peace process. Just hope there isn't any political missteps from either side that accidentally triggers World War 3. I wonder when Russia will stop pretending that EU does not exist and will start talking to it like to equal and start negotiating with EU, not with remote USA which are trying to retreat from conflict. Maybe Russia should recognize that EU has its own sphere of influence and Russia should respect it - so when is Russia going to demilitarize Kaliningrad, because having a military base so deep in EU is unacceptable? Archive / paywall:  < https://archive.is/72W5J > > I have suspected Putin is being played by Trump That's a nice counter-narrative to pretty much  everything  I've seen -  one of my favourite examples [0]: > She tells the story of Putin \u201ctrolling\u201d Mr Trump by saying that he was such a great supporter of Israel that \u201cmaybe they should just name the country after you\u201d \u2013 to which the US president, oblivious to the sarcasm, said, \u201cOh no, that would be a bit too much.\u201d [0]  https://www.independent.co.uk/voices/editorials/donald-trump...  > Meanwhile Russia still has a war raging on (which it will of course win but not anytime soon) Russian goal is to control whole Ukraine like they control Belarus. This is not achievable. Not with the current state of Russian logistics or state of Russian economy. One of the reasons why is Russia struggling is absurdly arrogant denial of reality. Why they are negotiating with USA, which has more and more marginal role in the whole conflict and not", "positive": "Voronoi map generation in Civilization VII. Related:  https://www.redblobgames.com/x/2022-voronoi-maps-tutorial/  I've been trying to generate my own maps using Voronoi diagrams as well.  I was using Lloyd's algorithm [0] to make strangely shaped regions \"fit\" better, but I like the insight of generating larger regions to define islands, and then smaller regions on top to define terrain. One of the things I like about algorithms like this is the peculiarities created by the algorithm, and trying to remove that seems to take some of the interesting novelty away. - [0]  https://en.m.wikipedia.org/wiki/Lloyd%27s_algorithm  This kind of exploratory/creative programming is bar none the most fun you can have as a software engineer. I love reading write-ups about projects like this because you can practically feel the nerdy joy radiating off the screen. Haven't played any of the new Civ games but find this very interesting. On a related note, I've started a blog on procedural content generation and GenAI content synthesis:  https://gamedev.blog/ . Would love any feedback / suggestions! I intend to cover Voronoi diagrams in the near future + a Python implementation and turning it into a 3D map with Unity This is super interesting! I've dabbled with Perlin noise procedural generation using AlphaEvolve[0] and wonder if it would be interesting to do one with Voronoi map too! [0]:  https://blog.toolkami.com/alphaevolve-toolkami-style/  Raymond Hill (unblock) also made JavaScript voronoi library  https://github.com/gorhill/Javascript-Voronoi  I really wish they just made Civ 5 again, but with these sorts of cool updates. Kinda surprised that it's taken this long. Voronoi for map generation is not a new concept, and it produces excellent results. One of the best webs for gamedev. The a-star/Dijkstra section is legendary. It is quite infectious! I would have never thought to use Voronoi like this, my only use is with data visualizations. Civ4-Beyond the Sword is IMHO the last good", "negative": "eBay explicitly bans AI \"buy for me\" agents in user agreement update. LLM-initiated purchases probably rack up chargebacks, support calls, etc for mistakes the LLM makes. I'm not surprised they want to limit it. not the User Agreement! Impossible to enforce, they can read browser windows and pass captchas So scraping bots and \u201cbuy for me\u201d bots are bad, but the incredibly annoying sniping bots are OK? That sure feels like a double standard. No one wants AI to spend their money, checked or not. The few people who would want AI, want AI to save them money What is the use case for LLM agent shoppers? I can't imagine delegating the purchase of a used item to an AI (I'd be okay with AI identifying the best deals for me to review). This must be something for people who are doing something at scale like flipping items on Ebay or drop shipping. I imagine this type of automation existed before LLM agents came along - what do they add? Is it just the ability to evaluate the product description? Item quality is already listed as a categorical variable. Hasn't eBay's traffic been 80% bots since day one? I haven't participated in an auction in forever because even 20 years ago you were  guaranteed  to get sniped by a bot on anything except actual garbage. Tried selling on eBay as a regular Joe lately? Item sold for roughly $190 and I lost $45 in fees - I didn't even have a premium ad or pay for any of the boosting. No wonder Facebook marketplace has destroyed them I loved early eBay but gave up on it once became clear how rife it was with bid snipers, fraudsters and stolen goods. ...haven't bots been buying things off eBay since the 90s? Meanwhile Google announces UCP to go in completely the opposite direction (or make marketplaces like eBay do so) You don't have to obey user agreements. Is my primary user agent, my web browser, still allowed? /s Interesting, I\u2019m not big on AI but I have thought often it would be nice to have an \u2018agent\u2019 that monitors ebay or other classifieds sit"}
{"anchor": "FLUX.2 [Klein]: Towards Interactive Visual Intelligence. I am amazed, though not entirely surprised, that these models keep getting smaller while the quality and effectiveness increases. z image turbo is wild, I'm looking forward to trying this one out. An older thread on this has a lot of comments:  https://news.ycombinator.com/item?id=46046916  Flux2 Klein isn\u2019t some generation leap or anything. It\u2019s good, but let\u2019s be honest, this is an ad. What will be really interesting to me is the release of Z-image, if that goes the way it\u2019s looking, it\u2019ll be natural language SDXL 2.0, which seems to be what people really want. Releasing the Turbo/Distilled/Finetune months ago was a genius move really. It hurt Flux and Qwen releases on a possible future implication alone. If this was intentional, I can\u2019t think of the last time I saw such shrewd marketing. > FLUX.2 [klein] 4B The fastest variant in the Klein family. Built for interactive applications, real-time previews, and latency-critical production use cases. I wonder what kind of use cases could be \"latency-critical production use cases\"? If we think of GenAI models as a compression implementation. Generally, text compresses extremely well. Images and video do not. Yet state-of-the-art text-to-image and text-to-video models are often much smaller (in parameter count) than large language models like Llama-3. Maybe vision models are small because we\u2019re not actually compressing very much of the visual world. The training data covers a narrow, human-biased manifold of common scenes, objects, and styles. The combinatorial space of visual reality remains largely unexplored. I am looking towards what else is out there outside of the human-biased manifold. I appreciate that they released a smaller version that is actually open source. It creates a lot more opportunities when you do not need a massive budget just to run the software. The speed improvements look pretty significant as well. 2026 will be the year of small/open model", "positive": "Map To Poster \u2013 Create Art of your favourite city. Why are big chunks of Sam Francisco missing (eg around the bridge) missing from the example? It says there are examples but I can't see them? I believe (from a quick code check on my phone) it should be possible to output the images to SVG with a little tweak, thanks to your use of matplotlib? Is there a reason you\u2019ve defaulted to PNG that I\u2019m missing? That's splendid. I've long wanted to make a jigsaw puzzle out of Sydney's road map, so I can familiarise myself with the layout of roads while having fun. That way I can reduce my reliance on nav app and become one of those old-school drivers. The map of Venice seems to be the only one whose image is \"squeezed\" horizontally. Wondering why. I tried it in a python3 venv, but the download data step is stuck at 0% unfortunately. Three random themes for anyone who's Czech or likes Prague and doesn't want to set up the script locally:  https://imgur.com/a/Ovg8mDW  Also check out prettymapp  https://prettymapp.streamlit.app/  This repo is fantastic. The README should be the gold standard for OSS. Not to mention how stunning the outputs are. Thanks for sharing. Pretty cool! It would be great if there was a way to set coordinates manually, since Nominatim can sometimes produce mediocre results. Also, would be nice to have a way to render the same map in all themes, not just one. what are the blue dots? (not water bodies i think?) San Francisco looks nice, but there seems to be a problem with the projection in some of the sample images. It looks as if it isn't UTM but a global sphere projection, which isn't suitable for local renders. It's suspicious that the word 'projection' isn't mentioned in the Readme. Does anyone have recommendations for how to actually print a poster from images like these? Very cool, thanks for sharing!! Looks amazing !\nIn my free time, i play with my laser cutting machine.\nIt will save me some design time.\nThanks What happens if there are multiple citi", "negative": "How to Leave Germany. I don't understand the relevance This is an excellent HOWTO for matters of public relevance. I wish there were guides with similar levels of detail for Americans. The closest thing I've seen is guides for changing your name in various USA states from the trans community; some of the processes are quite arduous (NJ for example has about 15 steps, most of which are manual separate errands with separate waiting periods...) The exit tax is absolutely insane and they even charge it within the EU. Say you own a company which has a profit of 10.000 Euros on average the past 3 years. Before you can leave Germany you will have to pay taxes based on 137.500 Euros. P.s. Don't try to use Deutsche Bahn to leave Germany, it will likely cause delays Do you currently live in Germany? The poster is the author of the website. So I think it's self-promo mixed with \"hey, look how interesting is the amount of 'bureaucracy' involved when one wants to move out of Germany\" I think that the government could do this job really well if they wanted to. I'm just one guy working ~25 hours per week, if that. It really isn't rocket science, just empathy and good writing. The biggest problem is that the government often describes bureaucracy in terms of what they need from you, not how their services fit in your journey. It feels like we are serving the bureaucracy and not the other way around. \"Freelancers and sole proprietors almost never pay an exit tax\" I was glad to boil it down to \"it probably doesn't concern you, and if it does, you probably have an expert on call already\". The entire topic of taxation is a tarpit. One important note: this 13.75x valuation is a worse case scenario if you fail to supply your own. There are many ways to reduce or avoid this tax. It's awfully convenient that someone else went through it and started a website just for that topic. Funnily enough, his website was inspired by mine, and this guide was inspired by his post on exit taxation. It's"}
{"anchor": "Sumo \u2013 Simulation of Urban Mobility. I've been wanting to build a city builder using urban planning libraries like this Imaging the simulation being running headless, decoupled  from the GUI client This looks really polished. I've always found crowd and traffic simulation fascinating. The Projects page is worth looking at too. Since it's almost on-topic, anyone know if/how these tools emulate sustained irrational behavior? Example: For over a decade, the freeway on-ramp nearest my work had two main ways of getting to it from downtown.  One of them involved a stop-sign crossing a road that had the right-of-way (i.e. a two-way stop).  The other had timed traffic signals.  Every evening around 5pm,  the traffic would backup from the stop-sign for multiple blocks.  Meanwhile the route with lights was completely smooth. Eventually the stop-sign was replaced with a signal, but I marveled at how many people persisted in making their daily commute much worse than it needed to be. This is fascinating. Even supports simulating multiple modes of transportation (ped, bicycle, car\u2026). I\u2019ll have to give this a test run later. How much do the various \"Maps\" apps change things? I have a longer commute, and when the freeway is clogged, Maps will direct me to an exit where I weave around town and country. There's usually a convoy of cars with me, but the freeway also seems to stay clogged. Any plans to deploy to the web? I ride rental scooters almost 10k minutes per year and would really like to get my hands on my own ride data to plug it into something like this (or simpler) to find the optimal routes for my regular trips. Google Maps (or others) works good to find a resonable route, but I can do better on my own. One-way streets where bikes are allowed to go do opposite way is sometimes missing, short desire paths connecting bike ways, crossings where it's safe to do an (illegal) right-on-red etc. Tried a GDPR data claim from Voi but got nothing back :( But I hope the data is someho", "positive": "Meditation as Wakeful Relaxation: Unclenching Smooth Muscle.        You must learn to sit perfectly still with every muscle tense for long periods.\n\n    Various things will happen to you while you are practising these positions; they must be carefully analysed and described.\n\n    Note down the duration of practice; the severity of the pain (if any) which accompanies it, the degree of rigidity attained, and any other pertinent matters.\n\n    When you have progressed up to the point that a saucer filled to the brim with water and poised upon the head does not spill one drop during a whole hour,\n    and when you can no longer perceive the slightest tremor in any muscle; when, in short, you are perfectly steady and easy, you will be admitted for examination;\n    and, should you pass, you will be instructed in more complex and difficult practices.\n  \n- Aleister Crowley, Liber E vel Exercitiorum, 1911.  https://hermetic.com/crowley/equinox/i/i/eqi01005  Possibly a non-Jungian explanation for John Sarno's hypothesis that chronic pain could be caused by emotional issues triggering interruption of blood supply to painful areas. The idea that there is much more computation (and intelligence/agency) going on in biological and other systems seems to be getting more popular. (The author writes: The whole body is a computer: it\u2019d be wasteful for evolution to only use the brain for computation when other systems could take part too.). Michael Levin has some super interesting ideas about this. Is there any evidence yet for this theory? Sounds falsifiable. I find it interesting how meditation eventually becomes an anxiety reduction method, or general emotion management. What should it be if there is no burden of stress or negative impression of any emotion? Why rid of stress? It comes and goes, it is as fleeting as relaxation. I guess meditation is a insight into there being no problem to solve, once that insight is clear, there is no need for meditation. why is there a video of orde", "negative": "Claude's new constitution. I don't care about your \"constitution\" because it's just a PR way of implying your models are going to take over the world. They are not. They're tools and you as the company that makes them should stop the AGI rage bait and fearmongering. This \"safety\" narrative is bs, pardon my french. I don't understand what this is really about. Is this: - A) legal CYA: \"see! we told the models to be good, and we even asked nicely!\"? - B) marketing department rebrand of a system prompt - C) a PR stunt to suggest that the models are way more human-like than they actually are Really not sure what I'm even looking at. They say: \"The constitution is a crucial part of our model training process, and its content directly shapes Claude\u2019s behavior\" And do not elaborate on that at all. How does it directly shape things more than me pasting it into CLAUDE.md?  https://www.anthropic.com/constitution  I just skimmed this but wtf. they actually act like its a person. I wanted to work for anthropic before but if the whole company is drinking this kind of koolaid I'm out. >  We are not sure whether Claude is a moral patient, and if it is, what kind of weight its interests warrant. But we think the issue is live enough to warrant caution, which is reflected in our ongoing efforts on model welfare. > It is not the robotic AI of science fiction, nor a digital human, nor a simple AI chat assistant. Claude exists as a genuinely novel kind of entity in the world > To the extent Claude has something like emotions, we want Claude to be able to express them in appropriate contexts. > To the extent we can help Claude have a higher baseline happiness and wellbeing, insofar as these concepts apply to Claude, we want to help Claude achieve that. Wait until the moment they get a federal contract which mandates the AI must put the personal ideals of the president first.  https://www.whitehouse.gov/wp-content/uploads/2025/12/M-26-0...  I just had a fun conversation with Claude about"}
{"anchor": "The Adolescence of Technology. Initial thought about 1/5th of the way through: Wow, that's a lot of em-dashes! i wonder how much of this he actually wrote? Edit: Okay, section 3 has some interesting bits in it. It reminds me of all those gun start-ups in Texas that use gyros and image recognition to turn a C- shooter into an A- shooter. They all typically get bought up quite fast by the government and the tech shushed away. But the ideas are just too easy now to implement these days. Especially with robots and garage level manufacturing, people can pretty much do what they want. I think that means we have to make people better people then? Is that even a thing? Edit 2: Wow, section 4 on the abuse by organizations with AI is the most scary. Yikes, I feel that these days with Minneapolis. They're already using Palantir to try some of it out, but are being hampered by, well, themselves. Not a good fallback strat for anyone that is not the government. The thing about the companies just doing it before releasing it, that I think is underrated. Whats to stop sama from just, you know, taking one of these models and taking over the world? Like, is this paper saying that nothing is stopping him? The big one that should send  huge  chills down the spines of any country is this bit: \"My worry is that I\u2019m not totally sure we can be confident in the nuclear deterrent against a country of geniuses in a datacenter: it is possible that powerful AI could devise ways to detect and strike nuclear submarines, conduct influence operations against the operators of nuclear weapons infrastructure, or use AI\u2019s cyber capabilities to launch a cyberattack against satellites used to detect nuclear launches\" What. The. Fuck. Is he saying that the nuclear triad is under threat here from AI? Am I reading this right? That  alone  is reason to abolish the whole thing in the eyes of nuclear nations. This, I think, is the most important part of the whole essay. Holy shit. Edit 3: Okay, section 4 on th", "positive": "Shipmap.org. This is pretty amazing to watch! I did just watch a dot go through the Great Lakes, to Chicago, then take to the air and make a bee line straight to the Gulf of Mexico. Probably some weird artifact but made me chuckle. Like interactive documentary, loved it! It appears to cover only the year 2012. I'm getting \"Please use a modern browser to view this content\", but I'm running the latest version of Chrome. Says WebGL is not supported..? Even at 1 hour ticks am I assuming that these are moving far too quickly? Used this when I moved internationally. Cool to watch your stuff moving around the world! This is weirdly beautiful, like the maps of undersea internet cables that frequently come up here as well. You can clearly see: 1) oil flowing out of the Persian Gulf from the Middle East to China 2) ships waiting to get through the Panama and Suez Canals 3) why people talk about \u201cshipping lanes\u201d. There are some obvious tracks everyone follows, because it\u2019s the cheapest way from A to B (e.g. cape of good hope to straight of malacca). 4) why Singapore got to be such an important global hub. 5) why the houthis and the Somali pirates could cause such havoc 6) nobody goes in the southern ocean! (Why would they? Unless you\u2019re bringing supplies to Antarctica\u2026) a few ships drop down to go around Cape Horn but that\u2019s it. and so much more. I wish it included more up-to-date data\u2026 The scale of it is mind boggling. Quite a few routes on the heat map that appear to not be following great circle lines (i.e. \"straight\" lines from china to the west coast) - is that from seasonal currents allowing for more efficient transit with the tradeoff of taking a longer route? A lot of people have called out some interesting things - one thing that I notice is how the cold water ports shut down in the winter (in the northern hemisphere). It's one of those things I've always heard and known about, but to see it visually conceptualized (and the implications on economy and national interes", "negative": "Hands-On Introduction to Unikernels. I've found the idea of unikernels interesting for several years now, is there a tl;dr on why they don't seem to have taken off, like at all? Or is it all happening behind some doors I don't have access to? This is really well written, thanks for sharing. I didn't understand the point of using Unikraft though, if you can boot linux in much less than 150ms, with a far less exotic environment the missing piece of unikernel is debuggability & observability - it need to be easy to replicate on dev machine & easy to debug\n- it needs to integrate well with current obs stack. easy to debug in production. without clear debuggability & observability, i would never put it into production I would like to follow the tutorial but it mentions a playground. Am I missing something as I cannot find a link or instructions for the playground. So, if I understand correctly, a \"unikernel\" is what we used to call an \"executive\" except it is intended to be run as a guest on a virtual machine provided by a full-fledged traditional kernel/userspace OS instead of on bare metal. The article does reintroduce some concepts that were commonplace when I was first learning computers and it gives them some new names. I like that good ideas can still be useful after years of not being the latest fad, and it's great that someone can get new credit for an old idea with just a little bit of marketing spin. I think that part of it is that relatively few people use bare-metal servers these days, and nested virtualisation isn't universally supported. I also found this technical critique [0] compelling, but I have no idea if any of it is accurate or not. [0]:  https://www.tritondatacenter.com/blog/unikernels-are-unfit-f...  They kind of did, that is basically how serverless works. Managed runtimes on top of hypervisors. Security, it isn't only memory footprint. Which architecture can boot it in 150ms ?! Hey! Co-founder of Unikraft here. Unikraft aims to offer a Linux-com"}
{"anchor": "AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas'. Well, yeah. Then who will become the senior engineers in 10-15 years? Which is a less dumb idea: replacing new grad junior devs with AI or H1Bs? Relevant post by Kent Beck from 12th Dec 2025: The Bet On Juniors Just Got Better  https://tidyfirst.substack.com/p/the-bet-on-juniors-just-got...  > The juniors working this way compress their ramp dramatically. Tasks that used to take days take hours. Not because the AI does the work, but because the AI collapses the search space. Instead of spending three hours figuring out which API to use, they spend twenty minutes evaluating options the AI surfaced. The time freed this way isn\u2019t invested in another unprofitable feature, though, it\u2019s invested in learning. [...] > If you\u2019re an engineering manager thinking about hiring: The junior bet has gotten better. Not because juniors have changed, but because the genie, used well, accelerates learning. 4) Junior devs have an incomparably superior context window. This is performative bullshit pandering to the increased skepticism around AI. He wouldn't be saying that if AI investment was still in full swing. I do agree with him about AI being a boon to juniors and pragmatic usage of AI is an improvement in productivity, but that's not news, it's been obvious since the very beginnings of LLMs. This sounds like a comment from someone who doesn't have visibility into how good the models are getting and how close they are to fully autonomous, production-grade software development. I can't help but feel this is backpedaling after the AI hype led to people entering university avoiding computer science or those already in changing their major. Ultimately we might end up with a shortage of developers again, which would be amusing. Most of the apps that I use regularly fail at least once a day nowadays. I think this is a direct cause of putting AI code in production without reviewing/QA. >  AWS CEO says using AI to rep", "positive": "Mote: An Interactive Ecosystem Simulation [video]. This is super cool. I love simulations like this. And this is running at a huge scale! The architecture here is fascinating. Specifically using a graph processor approach where entities are nodes connected by edges (springs) for everything from physics to data transmission. I really like it. I've had the pleasure of following Peter's progress on this project over the past 18 months or so, and it's been incredible to see how far he's taken it. When he first described it to me, I didn't really \"get\" it (is it a game? a simulation? some other sort of environment?), and it wasn't until seeing an actual demo and hearing Peter explain his thinking more deeply that it clicked. It's basically a giant simulation environment that is 1) visually stunning (and  all  visual aspects are meaningful / carry semantic information and aren't just glitter), 2) technically quite impressive, and 3) built for rapid exploration and experimentation.  If that sounds at all interesting, you should watch the video to hear Peter's talk! (Writing this as someone who generally doesn't like to watch videos online; this is one of the rare cases where I think it's worth it, and a video is a better format than text in explaining the thing.) The sound is a bit much, especially during a presentation. I have to keep pausing to rest from it, but overall very cool project. This is math, beauty, art, creativity, ... unique. My mind is all over the place.\nStill wrapping my head around it but, I'd really like to see where this leads. Fantastic! As a fan of simulation and learning NetLogo 15ish years ago-I greatly appreciate when work like this gets attention! It's the perfect abstraction for representing cell membranes, force flow dynamics etc So excited for this project What I really want, is to run and experiment with it myself, locally. But I couldn't find a repository anywhere, even from his linked GitHub profile. You happen to know if it's online somewh", "negative": "Nvidia Stock Crash Prediction. It goes to nearly zero if China invades Taiwan, and that seems like it has at least a 10% chance of happening in the next year or two. > One of the questions of the 2026 acx prediction contest is whether Nvidia\u2019s stock price will close below $100 on any day in 2026. Maybe I\u2019m missing something, but isn\u2019t this just a standard American put option with a strike of $100 and expiry of Dec 31st? He doesn't really address his own question. He's answering the question \"How should options be priced?\" Sure, it's possible for a big crash in Nvidia just due to volatility.  But in that case, the market as a whole would likely be affected. Whether Nvidia specifically takes a big dive depends much more on whether they continue to meet growth estimates than general volatility.  If they miss earnings estimates in a meaningful way the market is going to take the stock behind the shed and shoot it.  If they continue to exceed estimates the stock will probably go up or at least keep its present valuation. How much of their turnover is financed directly or indirectly by themselves, then leveraged further by their 'customers' to collaterize further investments? Are they already \"too big to fail\"? For better or worse, they are 'all in' on AI. This article goes more into the technical analysis of the stock rather than the underlying business fundamentals that would lead to a stock dump. My 30k ft view is that the stock will inevitably slide as AI datacenter spending goes down. Right now Nvidia is flying high because datacenters are breaking ground everywhere but eventually that will come to an end as the supply of compute goes up. The counterargument to this is that the \"economic lifespan\" of an Nvidia GPU is 1-3 years depending on where it's used so there's a case to be made that Nvidia will always have customers coming back for the latest and greatest chips. The problem I have with this argument is that it's simply unsustainable to be spending that much eve"}
{"anchor": "\u201cErdos problem #728 was solved more or less autonomously by AI\u201d. Reconfiguring existing proofs in ways that have been tedious or obscured from humans, or using well framed methods in novel ways, will be done at superhuman speeds, and it'll unlock all sorts of capabilities well before we have to be concerned about AGI. It's going to be awesome to see what mathematicians start to do with AI tools as the tools become capable of truly keeping up with what the mathematicians want from the tools. It won't necessarily be a huge direct benefit for non-mathematicians at first, because the abstract and complex results won't have direct applications, but we might start to see millenium problems get taken down as legitimate frontier model benchmarks. Or someone like Terence Tao might figure out how to wield AI better than anyone else, even the labs, and use the tools to take a bunch down at once. I'm excited to see what's coming this year. This is great, there is still so much potential in AI once we move beyond LLMs to specialized approaches like this. EDIT: Look at all the people below just reacting to the headline and clearly not reading the posts. Aristotle ( https://arxiv.org/abs/2510.01346 ) is key here folks. EDIT2: It is clear much of the people below don't even understand basic terminology. Something being a transformer doesn't make it an LLM (vision transformers, anyone) and if you aren't training on language (e.g. AlphaFold, or Aristotle on LEAN stuff), it isn't a \"language\" model. You can try out Aristotle yourself today  https://aristotle.harmonic.fun/ . No more waitlist! Can anyone with specific knowledge in a sophisticated/complex field such as physics or math tell me: do you regularly talk to AI models? Do feel like there's anything to learn? As a programmer, I can come to the AI with a problem and it can come up with a few different solutions, some I may have thought about, some not. Are you getting the same value in your work, in your field? For context, Teren", "positive": "Measuring AI Ability to Complete Long Tasks. This seems like a good way to measure LLM improvement. It matches the my personal feeling when using progressively better models over time. Opus is already the name of an audio codec. I recently asked Opus to just \u201cAdd vector search\u201d to my current hobby project, a topic I know very little about. It set up manticore, pulled an embedding model, wrote a migration tool for my old keyword indices, and built the front end. I\u2019m not exaggerating much either: the prompt was the length of a tweet. I think it would easily have taken me 4+ hours to do that.  It ran in 15 minutes while I played Kirby Air Riders and worked on the first try. Afterward, I sort of had to reflect on the fact that I learned essentially nothing about building vector search. I wanted the feature more than I wanted to know how to build the feature. It kept me learning the thing I cared about rather than doing a side quest. Would be interesting to see Gemini 3.0 Pro benchmarked as well. I didn't really understand the \"long task\" thing until I actually experienced it. The problem is finding a task you can set an agent that justifies working for that long. I finally hit one when I tried porting that Python HTML5 parser to JavaScript by pointing Codex CLI at the 9,200 html5lib-tests test suite:  https://simonwillison.net/2025/Dec/15/porting-justhtml/  It's pretty amazing to watch tools-in-a-loop crunch away for >4 hours to solve a generally difficult problem through sheer brute-force. Opus looks like a big jump from the previous leader (GPT 5.1), but when you switch from \"50%\" to \"80%\", GPT 5.1 still leads by a good margin. I'm not sure if you can take much from this - perhaps \"5.1 is more reliable at slightly shorter stuff, choose Opus if you're trying to push the frontier in task length\". I think the problem here is LLM eventually pollute its context window with so much of the current task that the larger picture or architectural sanity is forgotten in favor of ", "negative": "ASML firing 1700 people, mostly managers. Apologies for the Dutch source, but I couldn\u2019t find any source in English yet. \u201c ASML plans to eliminate approximately 3,000 of its 4,500 management positions in engineering. The expectation is that approximately 1,400 people will be able to move into new engineering roles.\u201d Are we seeing big engineering manager cuts in the US too? > ASML also announced a new share buyback programme of up to \u20ac12 billion, to be executed by 31 December 2028. Oh boy. This fills me with dread. I've never seen a company that starts doing buybacks not become a financialized hollow shell within a decade. Being an irreplaceable monopoly on the commanding heights of the digital economy makes this even worse. ASML understands what most big companies don't. If you don't reach your targets it's not the engineers fault. It's bad management ;) > Engineers in particular have expressed their desire to focus their time on engineering, without being hampered by slow process flows [1] I wonder what correlation will exist between the set of people who end up leaving the company, and the set of people responsible for setting up those \"slow process flows\" in the first place. [1]  https://www.asml.com/en/news/press-releases/2026/strengtheni...  Can someone explain, why this is done?\nI get a feeling, it's normally done when a company is in trouble or will soon? But they should have more money than ever. They say it is to focus on innovation, but if you are a smart young person in NL, would you want to work where they just fired 1700 people? And if you already work there and are a top player it is a good time to rethink?\nA company I know wanted to focus, instead of firing, they sold the parts of the company they felt did not fit their future vision for money. The press release ( https://www.asml.com/en/news/press-releases/2026/strengtheni... ) seems remarkably to the point, for CEO press release standards. I'm impressed by their ambition to fire  1700 managers (!) T"}
{"anchor": "Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC. I set some rules for myself: three days of total time, no 3rd party Rust crates, allowed to use commonly available OS libraries, has to support X11/Windows/macOS and can render some websites. After three days, I have it working with around 20K LOC, whereas ~14K is the browser engine itself + X11, then 6K is just Windows+macOS support. Source code + CI built binaries are available here if you wanna try it out:  https://github.com/embedding-shapes/one-agent-one-browser  This is a notably better demonstration of a coding agent generated browser than Cursor's FastRender - it's a fraction of the size (20,000 lines of Rust compared to ~1.6m), uses way fewer dependencies (just system libraries for rendering images and text) and the code is actually quite readable - here's the flexbox implementation, for example:  https://github.com/embedding-shapes/one-agent-one-browser/bl...  Here's my own screenshot of it rendering my blog -  https://bsky.app/profile/simonwillison.net/post/3mdg2oo6bms2...  - it handles the layout and CSS gradiants really well, renders the SVG feed icon but fails to render a PNG image. I thought \"build a browser that renders HTML+CSS\" was the perfect task for demonstrating a massively parallel agent setup because it couldn't be productively achieved in a few thousand lines of code by a single coding agent. Turns out I was wrong! This is awesome. Would you be willing to share more about your prompts? I'm particularly interested in how you prompted it to get the first few things working. This post is far more interesting than many others on the same subject, not because of what is built but because of how it it is built. There is a ton of noise on this subject and most of it seems to focus on the thing - or even on the author - rather than on the process, the constraints and the outcome. > I'm going to upgrade my prediction for 2029: I think we're going to get a production-grade web brows", "positive": "AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas'. Well, yeah. Then who will become the senior engineers in 10-15 years? Which is a less dumb idea: replacing new grad junior devs with AI or H1Bs? Relevant post by Kent Beck from 12th Dec 2025: The Bet On Juniors Just Got Better  https://tidyfirst.substack.com/p/the-bet-on-juniors-just-got...  > The juniors working this way compress their ramp dramatically. Tasks that used to take days take hours. Not because the AI does the work, but because the AI collapses the search space. Instead of spending three hours figuring out which API to use, they spend twenty minutes evaluating options the AI surfaced. The time freed this way isn\u2019t invested in another unprofitable feature, though, it\u2019s invested in learning. [...] > If you\u2019re an engineering manager thinking about hiring: The junior bet has gotten better. Not because juniors have changed, but because the genie, used well, accelerates learning. 4) Junior devs have an incomparably superior context window. This is performative bullshit pandering to the increased skepticism around AI. He wouldn't be saying that if AI investment was still in full swing. I do agree with him about AI being a boon to juniors and pragmatic usage of AI is an improvement in productivity, but that's not news, it's been obvious since the very beginnings of LLMs. This sounds like a comment from someone who doesn't have visibility into how good the models are getting and how close they are to fully autonomous, production-grade software development. I can't help but feel this is backpedaling after the AI hype led to people entering university avoiding computer science or those already in changing their major. Ultimately we might end up with a shortage of developers again, which would be amusing. Most of the apps that I use regularly fail at least once a day nowadays. I think this is a direct cause of putting AI code in production without reviewing/QA. >  AWS CEO says using AI to rep", "negative": "3D printing my laptop ergonomic setup. That's a really interesting concept.  Either once they open source their build (or I get over my innate laziness) I could use something like that for my build at home (more of a horizontal stand style thing, looking at the monitor) - my laptop's primarily my second monitor at home with attached KB. More fuel to help convince my wife the printer isn't a waste of money xD I'd cut off the numberpad of my laptop, center the touchpad and what's left of the keyboard. That would be my ergonomic setup. That laptop served me well but it was a compromise between several factors. I think that at the time there were only an handful of 15\" laptops without a numberpad and probably it's still like that. I eventually had to give up on that to get other features. Quite cool! I wonder if it doesn't wear down the laptop hinges to keep it at 180 degrees opened in an upright position. Could print some clamps for the sides to reduce strain if that's the case. Though that'd only work for laptops that actually _do_ open 180 degrees, according to TFA, not that many. I have a \"car desk\", which is just a little expandable contraption you hang on the steering wheel, then you can place your laptop on it. I wouldn't call it ergonomic per se (the right external keyboard could probably fix that), but using it for about one hour per week, it works well and doesn't cause any issues I'm aware of. The driver seat is not a place where I previously could get any work done, so the bar is a bit low. She should have a look at the Huawei Matebook. You can transform the screen into a big desktop sized screen. The only thing missing is a stand that brings it to an ergonomic height. Very cool, nice effort and a good write-up! If my math is right it seems the cost in material for the printed part is around $5 which seems ridiculously cheap for a custom-designed and adapted solution like this. Nice! I wish the author had spent a few words extra to motivate why it needs to b"}
{"anchor": "My trick for getting consistent classification from LLMs. If you already have your categories defined, you might even be able to skip a step and just compare embeddings. I wrote a categorization script that sorts customer-service calls into one of 10 categories.  Wrote descriptions of each category, then translated into embedding. Then created embeddings for the call notes and matched to closest category using cosine_similarity. Arthur\u2019s classifier will only be as accurate as their retrieval. The approach depends on the candidates to be the correct ones for classification to work. Under-discussed superpower of LLMs is open-set labeling, which I sort of consider to be inverse classification. Instead of using a static set of pre-determined labels, you're using the LLM to find the semantic clusters within a corpus of unstructured data. It feels like \"data mining\" in the truest sense. Dunno if this passes the bootstrapping test. This is sensitive to the initial candidate set of labels that the LLM generates. Meaning if you ran this a few times over the same corpus, you\u2019ll probably get different performance depending upon the order of the way you input the data and the classification tag the LLM ultimately decided upon. Here\u2019s an idea that is order invariant: embed first, take samples from clusters, and ask the LLM to label the 5 or so samples you\u2019ve taken. The clusters are serving as soft candidate labels and the LLM turns them into actual interpretable explicit labels. I think a less order biased, more straightforward way would be just to vectorize everything, perform clustering and then label the clusters with the LLM. Nice! So the cache check tries to find if a previously existing text embedding has >0.8 match with the current text. If you get a cache hit here, iiuc, you return that matched' text label right away. But do you also insert a text embedding of the current text in the text embeddings table? Or do you only insert it in case of cache miss? From reading the ", "positive": "Show HN: Only 1 LLM can fly a drone. Why would you want an LLM to fly a drone? Seems like the wrong tool for the job -- it's like saying \"Only one power drill can pound roofing nails\". Maybe that's true, but just get a hammer LLMs flying weaponized drones is exactly how it starts. I think it's fascinating work even if LLMs aren't the ideal tool for this job right now. There were some experiments with embodied LLMs on the front page recently (e.g. basic robot body + task) and SOTA models struggled with that too. And of course they would - what training data is there for embodying a random device with arbitrary controls and feedback? They have to lean on the \"general\" aspects of their intelligence which is still improving. With dedicated embodiment training and an even tighter/faster feedback loop, I don't see why an LLM couldn't successfully pilot a drone. I'm sure some will still fall of the rails, but software guardrails could help by preventing certain maneuvers. I am curious how these models would perform and how much energy they'd take to semi-realtime detect objects:\nSmolVLM2-500M - Moondream 0.5B/2B/2.5B - Qwen3-VL (3B)\n https://huggingface.co/collections/Qwen/qwen3-vl  I am sure this is already worked on in Russia, Ukraine and The Netherlands. A lot can go wrong with autonomous flying.\nOne could load the VLM on a high end android phone on the drone and have dual control. Gemini 3 is the only model I've found that can reason spatially. The results here are accurate to my experiments with putting LLM NPCs in simulated worlds. I was surprised that most VLLMs cannot reliably tell if a character is facing left or right, they will confidently lie no matter what you do (even gemini 3 cannot do it reliably). I guess it's just not in the training data. That said Qwen3VL models are smaller/faster and better \"spatially grounded\" in pixel space, because pixel coordinates are encoded in the tokens. So you can use them for detecting things in the scene, and where they are ", "negative": "iPhone 5s Gets New Software Update 13 Years After Launch. People complain a lot about planned obsolescence but i'm mildly impressed, even if this update is only to keep the lights on and nothing else. I remember people complaining that the design of the 5 was already outdated when it was new and they needed to have bigger screens and be thinner to compete with Samsung... TLDR it replaces an expired certificate, no software is being \"updated\" here. Wake me when old versions of OS X can access the App Store again. I'm not a fan of Apple's walled garden mindset and resistance to inter-operating with other platforms, but this degree of legacy support is a case of Apple doing a good thing and deserves praise.  Note: I'm not saying that Google/MSFT et al are  much  better than Apple, but they're not  quite  as bad. tokyobreakfast is right that this is just a certificate fix, not a real software update. But it's still notable. Lots of old devices become paperweights because of expired certs or backend shutdowns. The fact that Apple even bothered to push this to a 13-year-old device is unusual. Most companies wouldn't. I ran a 5S that I bought in December 2013 as my primary phone all the way up to around March 2020, just as the pandemic was really winding up. The battery, after ailing for a little while, had eventually just given up. I'd gone skiing a couple of times, with the last trip being just before lockdown, and I think it was the cold exposure of the second trip that dealt the mortal blow, and it died shortly after I returned. I liked that phone a lot. It did, at the time, everything I needed, and it was a really nice size, but that period in 2020 was a bad time to try to get a phone repaired. I did attempt to replace the battery myself using the guide on iFixit but, sadly, that did not go well due to some contradictory/out of order instructions, and all I succeeded in doing was damaging the phone, I think, beyond repair. Really good to see that Apple are still suppo"}
{"anchor": "He set out to walk around the world. After 27 years, his quest is nearly over.  https://archive.ph/2025.12.09-165741/https://www.washingtonp...  It was not one continuous hike. He takes frequent breaks. But travels back to where he last stopped and continues.  https://en.wikipedia.org/wiki/Karl_Bushby  Still very impressive, but a little less impressive than I first thought. >The world is a much kinder, nicer place than it often seems. I realize that a lot these days. People are not inherently so bad but greed is a nasty drug that has the potential to ruin the best. When you have nothing to offer but kindness and compassion, it is very simple to see the humanity side of things in this world and it can feel really amazing. A couple of Youtubers who are also round-the-world travelers whom I enjoy watching, one a Dutch motorcyclist and the other a German cyclist. Noraly, the motorcyclist, has already traveled through South and North America, Africa, and Asia, some multiple times. Currently, I believe she is in Tajikistan about to enter Kyrgystan.  https://www.youtube.com/channel/UCEIs9nkveW9WmYtsOcJBwTg  Max Roving, the cyclist, has already cycled through Afghanistan and he is currently trying to ride Africa north to south. He just completed Algeria and is about to enter Morroco.  https://www.youtube.com/@MaxRoving  Amazing This reminds me of an adventured died just a few months ago at age of 40 after suffering insult. He has crossed ocean on a rowboat and more.  https://boredofborders.com/adventures/  DeepL Translation of wiki: Bardel's largest and most notable expeditions involve crossing oceans and traveling around the world without external assistance. On May 4, 2016, he and his traveling companion Gints Barkovskis set out to cross the Atlantic Ocean from Namibia to Brazil. After 142 days, they safely reached the coast of South America, becoming the first two-person crew to cross the Atlantic Ocean in a rowboat. [6] During the voyage, both men encountered serious h", "positive": "A real-time 3D digital map of Tokyo's public transport system. Very cool. Even the building-by-building graphics seem to be correct: a boxy version of my house in Yokohama is in the correct location and has the correct height relative to its neighbors. The map also shows\u2014correctly\u2014that it is raining at this moment in Tokyo but not in Yokohama. This is great, however on first load I didn't get the trains moving. After a refresh they showed up again. Currently sitting on the Yokohama line to Hachioji, a little before Hashimoto station. Looking at the map the train had already reached Hashimoto. Seems like we're running 30 seconds or maybe 1 minute late. Do any of the 'live' camera feeds work? They're all static for me. This is super cool, though. Wow, I love that it shows live flights and airplanes! This is really awesome, I love the way you integrated the live camera feeds. Looking at this map makes me want to move to Tokyo. Sure, the trains stopping at night makes nightlife and catching a morning flight annoying, but train culture* of just making plans to meet at a train station with a friend is so much better than the car dependent place I live. *It's not unique to Tokyo, but I've spent extended periods of time in cities with trains and this is what we often did. Tokyo just has lots of train lines. I saw 3D in the title and assumed it was a cross-section view of the subway tunnels underground. An implementation like that would be a potential security risk to public infrastructure. Berlin edition:  https://www.vbb.de/fahrinfo , there was also a version in a similar 3D style but I wasn't able to dig it up through the search. Related thread with more of these kind of projects:  https://news.ycombinator.com/item?id=32647227  That was disappointing I thought I would see the 3D train track tubes and how deep they are and their position from each other in 3D I just came from working remotely from Japan for almost two months. One of the highlights was the infrastructure fo", "negative": "There is an AI code review bubble. I don't really understand how this differentiates against the competition. > Independence Any \"agent\" running against code review instead of code generation is \"independent\"? > Autonomy Most other code review tools can also be automated and integrated. > Loops You can also ping other code review tools for more reviews... I feel like this article actually works against you by presenting the problem and inadequately solving them. 1. I absolutely agree there's a bubble. Everybody is shipping a code review agent. 2. What on earth is this defense of their product? I could see so many arguments for why their code reviewer is the best, and this contains none of them. More broadly, though, if you've gotten to the point where you're relying on AI code review to catch bugs, you've lost the plot. The point of a PR is to share knowledge and to catch structural gaps. Bug-finding is a bonus. Catching bugs, automated self-review, structuring your code to be sensible: that's _your_ job. Write the code to be as sensible as possible, either by yourself or with an AI. Get the review because you work on a team, not in a vacuum. None of these tools perform particularly well and all lack context to actually provide a meaningful review beyond what a linter would find, IMO.  The SOTA isn't capable of using a code diff as a jumping off point. Also the system prompts for some of them are kinda funny in a hopelessly naive aspirational way.  We should all aspire to live and breathe the code review system prompt on a daily basis. I liked that the post is self-aware that it's promoting its own product. But the writing seemed more focus on the philosophy behind code reviews and the impact of AI, and less on the mechanics of how greptile differs from competitors. I was hoping to see more on the latter. Problem with Code Review is it is quite straightforward to just prompt it, and the frontier models, whether Opus or GPT5.2Codex do a great job at code-reviews. I d"}
{"anchor": "In Europe, wind and solar overtake fossil fuels. Curious if this will eventually change China's calculus with regards to Russia. If Europe is a big customer for Chinese exports, and Russia is antagonizing, it seems like China would have an incentive to put pressure on Russia. It already seems like Russia is positioned to be completely subservient to China in the future. Solar prices in the US are criminal, protecting oil and gas who bought all the politicians. Canada here. 7.6kw on our roof for $0 out of pocket thanks to $5k grant and $8k interest free loan. It makes 7.72Mwh per year, worth $1000. Tight valley, tons of snow.\nWe put that on the loan for 8 years, then get $1000 per year free money for 20 years or so. Biggest no brainer of all time. Dad in Victoria Australia just got 10.6kw fully installed and operational for $4000 AUD. ($2,700 USD) Australia has so much electricity during the day they\u2019re talking about making I free for everyone in the middle of the day.  https://www.abc.net.au/news/2025-11-03/energy-retailers-offe...  But Trump explained to us yesterday, how wind and solar is for losers. Surely, we should be looking in to how we can transition back to fossils. Now, let's aim at total energy consumption, not just electricity generation. The UK has some of the highest energy costs in the world due to the stupid Net Zero taxes. Our economy and manufacturing is suffering. Every time, over the years, that there has been some kind of headline saying renewables have overtaken fossil fuels, when you look at it a bit more closely there is always a big 'but'.   For example, it was compared to coal (not taking into account electricity from gas), or it was for one day, or it was a percentage of new installations, or it excludes winter, includes nuclear etc. This time, however, it looks like it's actually true and that's just for wind and solar.   This is incredible, and done through slowly compounding gains that didn't cause massive economic hardships along the w", "positive": "Voronoi map generation in Civilization VII. Related:  https://www.redblobgames.com/x/2022-voronoi-maps-tutorial/  I've been trying to generate my own maps using Voronoi diagrams as well.  I was using Lloyd's algorithm [0] to make strangely shaped regions \"fit\" better, but I like the insight of generating larger regions to define islands, and then smaller regions on top to define terrain. One of the things I like about algorithms like this is the peculiarities created by the algorithm, and trying to remove that seems to take some of the interesting novelty away. - [0]  https://en.m.wikipedia.org/wiki/Lloyd%27s_algorithm  This kind of exploratory/creative programming is bar none the most fun you can have as a software engineer. I love reading write-ups about projects like this because you can practically feel the nerdy joy radiating off the screen. Haven't played any of the new Civ games but find this very interesting. On a related note, I've started a blog on procedural content generation and GenAI content synthesis:  https://gamedev.blog/ . Would love any feedback / suggestions! I intend to cover Voronoi diagrams in the near future + a Python implementation and turning it into a 3D map with Unity This is super interesting! I've dabbled with Perlin noise procedural generation using AlphaEvolve[0] and wonder if it would be interesting to do one with Voronoi map too! [0]:  https://blog.toolkami.com/alphaevolve-toolkami-style/  Raymond Hill (unblock) also made JavaScript voronoi library  https://github.com/gorhill/Javascript-Voronoi  I really wish they just made Civ 5 again, but with these sorts of cool updates. Kinda surprised that it's taken this long. Voronoi for map generation is not a new concept, and it produces excellent results. One of the best webs for gamedev. The a-star/Dijkstra section is legendary. It is quite infectious! I would have never thought to use Voronoi like this, my only use is with data visualizations. Civ4-Beyond the Sword is IMHO the last good", "negative": "Spanish track was fractured before high-speed train disaster, report finds. Wow, that's a really big gap. No wonder it derailed What are the some of the ways that tracks are monitored for fractures like this?  It must have been pretty substantial in order to be described as \"complete lack of continuity\".  Makes me think of literally electronic continuity tests -- are those ever used in this context?  Or how about cameras mounted on trains using image processing?  Or drones? It seems a shame that a few other trains passed beforehand with this anomaly in place and yet it went undetected. My gut feeling says a lot of fatalities could have been prevented with a physical barrier between both tracks. Shouldn't this be mandatory with high speed trains? While these events are statistically very rare, it is worth remembering that there have been two separate events in the past twenty years in Spain where high-speed trains have derailed leading to multiple fatalities [1][2]. In contrast, the Japanese Shinkansen has a spotless record since its introduction in the 1960s [3]. Not a single fatality due to a crash or derailment. And that's in a country with a much larger population and much higher passenger count per year. What do they do differently? [1]  https://en.wikipedia.org/wiki/Santiago_de_Compostela_derailm...  [2]  https://en.wikipedia.org/wiki/2026_Adamuz_train_derailments  [3]  https://en.wikipedia.org/wiki/Shinkansen#Safety_record  I wonder how common it is for train tracks to fracture? And what systems are in place to actually detect this. There was recently a post on a German subreddit where the OP found a fracture in the German rail[0], albeit much smaller. 0.  https://old.reddit.com/r/drehscheibe/comments/1qe9ko2/ich_gl...  AFAIK continuously welded tracks (like those used in high speed rail) are also slightly tensioned, so a break in a single point could make it look like a whole section of track is missing, as tension is released. Some more info from Spanish med"}
{"anchor": "Jakarta is now the biggest city in the world. Article is a paywalled summary of the UN press release:\n https://www.un.org/sustainabledevelopment/blog/2025/11/press...  And the full report as PDF:  https://www.un.org/development/desa/pd/sites/www.un.org.deve...  Canada has less people, even with a 10% increase in the last 4 years through imigration, some of which is from Indonesea presumably including a significant number from Jakarta, where the civil infrastructure must be epic Alternative Link:  https://www.aa.com.tr/en/asia-pacific/jakarta-world-s-most-p...  Key Facts:\nNumber of megacities, urban areas with 10 million or more inhabitants has quadrupled from 8 in 1975 to 33 in 2025. Jakarta is now the world\u2019s most populous city, with nearly 42 million residents. The current population of Indonesia is 286 million. In 2019, Indonesia said it will be moving its capital to Nusantara, a new city which is under construction. Previous submission:  https://news.ycombinator.com/item?id=46038863  I'm always surprised how big the population of Indonesia is yet it seems culturally underrepresented in the world compared to a lot of smaller countries Almost 300 million people but it rarely comes up in the news or pop media I used to spend a lot of time in Jakarta for work, and it's an underrated city. Yes, it's hot, congested, polluted and largely poor, but so is Bangkok. Public transport remains not great, but it's improved a lot with the airport link, the metro, LRT, Transjakarta BRT. SE Asia's only legit high speed train now connects to Bandung in minutes. Grab/Gojek (Uber equivalents) make getting around cheap and bypass the language barrier. Hotels are incredible value, you can get top tier branded five stars for $100. Shopping for locally produced clothes etc is stupidly cheap. Indonesian food is amazing, there's so much more to it than nasi goreng, and you can find great Japanese, Italian, etc too; these are comparatively expensive but lunch at the Italian place in the Ri", "positive": "Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone. Just because you can doesn't mean you should. But congrats on launching! It\u2019s a simple idea but one that hadn\u2019t occurred to me yet. I spend hours each week riding transit, and use Claude for a bunch of side projects and have Tailscale set up already, so looks like I\u2019ll be giving this a try this week! Doom coding might be doomed while I\u2019m in the transbay tube though, with awful cell service\u2026 How\u2019s the diff review? I rely heavily on the vs code integration for nice side by side diffs, so losing that might be a problem unless there\u2019s some way to launch the diffs into a separate diff viewer app on the phone. Please mask your identifiers, unless they are already spoofed. You potentially give out a lot of your info to bad actors. Other than that, love it :) ha, I've recently been studying the original DOOM source code - does that count? Those demo photos are fantastic Coding on a phone really isn't something new. With tmux a lot of people created crazy things directly on their phone. In some countries this even is the only possibility to code at all, because there are no laptops. The example use case images are very funny though! :-) Using this with tmux and various VPN tech. Main issue is scrolling. Termius + tmux don't scroll very well. And I've been led to believe tmux is necessary to keep sessions open when I turn off my phone screen you missed the part where you're using tmux to have the same session between your phone and your laptop I remember when I started learning coding, and didn't have a computer. I literally used to use my phone to write code - terrible experience, but I was determined Does this approach work for anyone? For my life, I've found that if I'm not behind the computer then I'm not in a productive situation anyway, even with AI access. I don't have a setting where I can concentrate for a long time and think clearly. For examole when watching children, doing groceries, d", "negative": "Waiting for dawn in search: Search index, Google rulings and impact on Kagi. >Google: Google does not offer a public search API. The only available path is an ad-syndication bundle with no changes to result presentation - the model Startpage uses. Ad syndication is a non-starter for Kagi\u2019s ad-free subscription model.[^1] >Because direct licensing isn\u2019t available to us on compatible terms, we - like many others - use third-party API providers for SERP-style results (SERP meaning search engine results page). These providers serve major enterprises (according to their websites) including Nvidia, Adobe, Samsung, Stanford, DeepMind, Uber, and the United Nations. The customer list matches what is listed on SerpAPI's page (interestingly, DeepMind is on Kagi's list while they're a Google company...). I suppose Kagi needs to pen this because if SerpAPI shuts down they may lose access to Google, but they may already have utilize multiple providers. In the past, Kagi employees have said that they have access to Google API, but it seems that it was not the case? As a customer, the major implication of this is that even if Kagi's privacy policy says they try to not log your queries, it is sent to Google and still subject to Google's consumer privacy policy. Even if it is anonymized, your queries can still end up contributing to Google Trends. > Because direct licensing isn\u2019t available to us on compatible terms, we - like many others - use third-party API providers for SERP-style results Crazy for a company to admit: \"Google won't let us whitelabel their core product so we steal it and resell it.\" I hope they cache search results to further reduce the number of calls to Google. And Marginalia Search was not mentioned? Marginalia Search says they are licensing their index to Kagi. Perhaps it's counted under \"Our own small-web index\" which is highly misleading if true. Sounds like we need a nationalized search engine company then? Does anyone else use the phrase \"I'm going to googl"}
{"anchor": "Bus stops here: Shanghai lets riders design their own routes. This is really brilliant \u2014 like desire paths, but for transit. Obviously execution will be challenging, but the concept is fantastic, and China/Shanghai seems like one of the few places with the requisite density & state capacity to actually make this work. Generally I think that the design of public spaces has SO MUCH room to be improved by just responding to the wisdom of the crowd. I'm glad that Shanghai has moved to the next level in public transportation in meeting customer demand. Most cities don't have the funds to buy smallish buses and labour available as drivers. They don't have the money or willpower to get frequencies to turn up and go levels (ie frequent) and leave people with long walks to widely spaced routes. Tangent: I\u2019ve often thought that it would be great to let people design their own political districts to reduce gerrymandering At the polling place you\u2019d get a map with your census tract and then be asked \u201cwhich two or three adjacent tracts are most similar to your community\u201d. Eventually you\u2019d end up with some sort of gram matrix for tract-to-tract affinity, and then you could apply some algorithmic segmentation. Two problems: - this is far too complex for most voters to understand, much less trust, what\u2019s happening - the fact it\u2019s \u201calgorithmic\u201d would give a sheen of pseudo objectivity, but the selection of the actual algorithm would still allow political infouence over boundaries Chiming in from Los Angeles, USA to say wow, must be nice living in a modern society that prioritizes public transit and peoples' ease of movement. I know, I know, it comes with trade offs of living in an authoritarian state, but the absolute abysmal state of infrastructure in this country is maddening. Ever been on a train in Denmark or Japan or Switzerland? This remind me that road router should be walked by passenger rather than designed by designers. China is the only modern country that has both the cap", "positive": "Broken legs and ankles heal better if you walk on them within weeks. It was ~20 years ago, so my memory is a little foggy, but I gave myself a \"dancer's fracture\" in one foot. After many months, it was looking like a non-union. The podiatrist was worried any pin would split the broken bone even more. It wasn't looking good. I had read something along these lines even back then, so with my crazy immobilizer boot on, I head to the gym and started doing light squats several times per week. Next x-ray: healed. The pathology for broken collar bones was changing right as I took up mountain biking, and subsequently shattered my collarbone. It was hotly debated at the hospital, if my specific case should be operated on or not. Each time I had a checkup, one doctor would say \"wait and see\" while the other was saying \"I can't believe we didn't operate on this\". At any rate, the outcome was as good as if they had operated on it, according to the doc anyway. Nice of them to test it out on me! More related to this though, I have broken both my collarbones, the first time I had little direction and just held my arm still for 2-3 months. It took forever to heal, and my arm atrophied significantly. The second time, similar severity. I was guided through rehab and I was back using my arm within the first month, very little atrophy. I fractured my elbow mountain biking, the tip of my radius. The urgent care doctor gave me a sling and suggested months of immobility. The orthopaedic said to throw away the sling and start exercising the elbow as soon as I could, and prescribed PT. Turns out that was the right move, there are some permanent changes to mobility but it's about 97% what it was before the crash. Immobilizing joints can apparently cause the muscles, tendons, and nerves to seize up and lose significant range of movement permanently. If anyone's heard of RICE (Rest, Ice, Compression, Elevation) for healing joints, the new guidance is called POLICE: Protect, Optimal Load, Ice, C", "negative": "Notice of collective action lawsuit against Workday, Inc.. > allegations include that Workday, Inc., through its use of certain Artificial Intelligence (\u201cAI\u201d) features on its job application platform, violated the Age Discrimination in Employment Act (\u201cADEA\u201d) I'm interested to see Workday's defense in this case. Will it be \"we can't be held liable for our AI\", and will it work against a law as \"strong\" as ADEA? Key part is that AI is suspected of down-ranking folks by age (ADEA = Age Discrimination in Employment Act) > The Court has provisionally certified an ADEA collective, which includes: \u201cAll individuals aged 40 and over who, from September 24, 2020, through the present, applied for job opportunities using Workday, Inc.\u2019s job application platform and were denied employment recommendations.\u201d In this context, being \u201cdenied\u201d an \u201cemployment recommendation\u201d means that (i) the individual\u2019s application was scored, sorted, ranked, or screened by Workday\u2019s AI; (ii) the result of the AI scoring, sorting, ranking, or screening was not a recommendation to hire; and (iii) that result was communicated to the prospective employer, or the result was an automatic rejection by Workday. Age discrimination is a huge issue and I've experienced it firsthand. Places want to hire younger people because they're more apt to work longer hours for less pay. It's going to get worse as people who got into the web tech industry early on are still in the workforce, yet more and more young people are entering the workforce because \"learning to code\" was the perceived path to prosperity half a decade ago. It will be fascinating to see the facts of this case, but if it is proven their algorithms are discriminatory, even by accident, I hope workday is held accountable. Making sure your AI doesn't violate obvious discrimination laws should be basic engineering practice, and the courts should help remind people of that.  https://www.courtlistener.com/docket/66831340/mobley-v-workd...  As someone ove"}
{"anchor": "Carnap \u2013 A formal logic framework for Haskell. Past experience in logical frameworks tend to specify documentclass: script, letter, report, etc. If you were wondering, the name comes from a famous philosopher and logician:  https://en.wikipedia.org/wiki/Rudolf_Carnap  An Open Tower project. Copyright 2015-2024. Doesn't look like it is been updated in a while. And the GitHub repos last commits are even older. Dead project? I don't like the trend of naming software projects after real people. It makes web search harder both for people who try to find the person and for people who try to find the project. For something similar, but in Python, I made this a while ago:  https://logics.readthedocs.io/en/latest/  GUI here:  https://taut-logic.com/  Thanks... you just ruined it. I was so happy that finally that splendid slumber during transportation was finally getting the recognition it so richly deserves. ;) I think that's probably unlikely given the long list of universities using it[0]. It's an educational tool for formal propositional logic which hasn't really changed much on 100 years, so probably not a lot of updates are required unless there are big new updates to Haskell itself. [0]  https://carnap.io/about  Hey, Carnap creator here. Definitely not dead (still actively used by plenty of universities), but pretty stable these days. I don't like the trend of naming computer hardware after fruit. Oh I know what I'm doing on my lunch break today. I, too, made something similar in Python -- but simpler and less polished:  https://jon-jacky.github.io/FLiP/www/   https://github.com/jon-jacky/FLiP/  Ha, I\u2019ve been familiar with Carnap for probably a decade and it took your comment for me to realize his name is Car Nap. +1 It seems to of had the web app portion updated a year ago. And as you say, the application itself looks \u2018done.\u2019 I have frequently used Common Lisp over the last 40 years, and I hear comments about libraries being old and not updated in many years: so what!", "positive": "Purely Functional Sliding Window Aggregation Algorithm. This is a very interesting algorithm which is more or less known in the folklore, but is still relatively obscure. I have used it as a part of temporal logic monitoring procedure:  https://github.com/Agnishom/lattice-mtl/blob/master/src/Moni...  This is similar to an approach I use but instead of a queue, I accomplish this using a ring buffer that wraps around and overwrites entries older than window size. We maintain a global window aggregate, subtract ring buffer slot aggregate for entries dropping out and accumulate new entries into new slot aggregate while adding it to the global aggregate. Everything is o(1) including reads, which just returns the global window aggregate. That was a well written and easily approachable blog post on what I found to be an interesting topic. Aside from the topic itself, I think I also learned a bit about structuring technical articles. Competitive Programming in Haskell...I can only define this as Masochistic Aesthetics... I have made a quick c++ implementation for those unfamiliar with Haskell :  https://gist.github.com/unrealwill/5ca4db9beefafaa212465277b...  The queue method is popular, but there's a much faster (branch-free) and in my opinion simpler way, known as the van Herk/Gil-Werman algorithm in image processing. It splits the input into windows and pairs up a backward scan on one window with a forward scan on the next. This works for any associative function. I was very surprised when I learned about it that it's not taught more often (the name's not doing it any favors)! And I wrote a tutorial page on it for my SIMD-oriented language, mostly about vectorizing it which I didn't quite finish writing up, but with what I think is a reasonable presentation in the first part:  https://github.com/mlochbaum/Singeli/blob/master/doc/minfilt...  I also found an interesting streaming version here recently:  https://signalsmith-audio.co.uk/writing/2022/constant-time-p...  EDIT:", "negative": "FBI is investigating Minnesota Signal chats tracking ICE. Tracking the murderers who executed citizens in the street and then fled the scene of the crime and any sort of trial or investigation? That ICE and Immigration and Border Patrol? I wonder why. And since when is tracking public officials operating in public in the capacity of their government jobs illegal? These federal goons need to be tracked and observed to record their crimes. That much is indisputable. i suppose what he means is that the  phones  of protestors which have signal chat will be investigated. Assuming they dont have disappearing messages activated, and assuming any protestors willingly unlock their phones. Why? That's unequivocally constitutionally protected speech. Why is our tax money being wasted on this? I don't know signal very well but when I have spoken to others about it they mention that the phone number is the only metadata they will have access to. This seems like a good example of that being enough metadata to be a big problem. A wise man told me, you know signal works because its banned in Russia. I also find it incredibly ironic that they have a problem with this, when the DoD is flagrantly using signal for classified communications. I have seen anti-Signal FUD all over the place since it was discovered that protesters have been coordinating on Signal. Here\u2019s the facts: - Protesters have been coordinating using Signal - Breaches of private Signal groups by journalists and counter protesters were due to poor opsec and vetting - If the feds have an eye into those groups, it\u2019s likely that they gained access in the same way as well as through informants (which are common) - Signal is still known to be secure - In terms of potential compromise, it\u2019s much more likely for feds to use spyware like Pegasus to compromise the endpoint than for them to be able to break Signal. If NSA has a Signal vulnerability they will probably use it very sparingly and on high profile foreign targets. - T"}
{"anchor": "Uv: Running a script with dependencies. This is my absolute favourite uv features and the reason I switched to uv. I have a bunch of scripts in my git-hooks which have dependencies which I don't want in my main venv. #!/usr/bin/env -S uv run --script --python 3.13 This single feature meant that I could use the dependencies without making its own venv, but just include \"brew install uv\" as instructions to the devs. The \"declaring script dependencies\" thing is incredibly useful:  https://docs.astral.sh/uv/guides/scripts/#declaring-script-d...      #  script\n  # dependencies = [\n  #   \"requests<3\",\n  #   \"rich\",\n  # ]\n  # \n  import requests, rich\n  # ... script goes here\n  \nSave that as script.py and you can use \"uv run script.py\" to run it with the specified dependencies, magically installed into a temporary virtual environment without you having to think about them at all. It's an implementation of Python PEP 723:  https://peps.python.org/pep-0723/  Claude 4 actually knows about this trick, which means you can ask it to write you a Python script \"with inline script dependencies\" and it will do the right thing, e.g.  https://claude.ai/share/1217b467-d273-40d0-9699-f6a38113f045  - the prompt there was:     Write a Python script with inline script\n  dependencies that uses httpx and click to\n  download a large file and show a progress bar\n  \nPrior to Claude 4 I had a custom Claude project that included special instructions on how to do this, but that's not necessary any more:  https://simonwillison.net/2024/Dec/19/one-shot-python-tools/  Why doesn't pip support PEP 723?  I'm all for spreading the love of our lord and savior uv, but it should be necessary to have an official implementation. Oh this looks amazing!  I had pretty much stopped using Python for my one-off scripts because of the hassle of dependencies.  I can't wait to try this out. Oh nice, I was already a happy user of the uv-specific shebang with in-script dependencies, but the `uv lock --script example.py` ", "positive": "The Universal Pattern Popping Up in Math, Physics and Biology (2013).  https://pmc.ncbi.nlm.nih.gov/articles/PMC11109248/  DNA as a perfect quantum computer based on the quantum physics principles. There is the well known problem that \"random\" shuffling of songs doesn't sound \"random\" to people and is disliked. I wonder if the semi-random \"universality\" pattern they talk about in this article aligns more closely with what people want from song shuffling. Not sure why you have to read 3/4 of the article to get to a _link_ to a pdf which _only_ has the _abstract_ of the actual paper: N. Benjamin Murphy and Kenneth M. Golden* (golden@math.utah.edu), University of\nUtah, Department of Mathematics, 155 S 1400 E, Rm. 233, Salt Lake City, UT 84112-0090.\nRandom Matrices, Spectral Measures, and Composite Media. The Physics models tend to shake out of some fairly logical math assumptions, and can trivially be shown how they are related. \"How Physicists Approximate (Almost) Anything\" (Physics Explained)  https://www.youtube.com/watch?v=SGUMC19IISY  If you are citing some crank with another theory of everything, than that dude had better prove it solves the thousands of problems traditional approaches already predict with 5 sigma precision.   =3 What's with all the spammy comments? >The data seem haphazardly distributed, and yet neighboring lines repel one another, lending a degree of regularity to their spacing Wow, that kind of reminds me of the process of evolution in that it seems so random and chaotic at the most microscopic scales but at the macroscopic, you have what seems some semblance of order. The related graph also sprung to mind just how very like organisms repel (less tolerance to inbreeding) but at the same time species breed with like species and only sometimes stray from that directive. What is the pattern that underlies how organisms determine production or conflict with other organisms and can we find universality in it? I guess it's called \"universality\" for ", "negative": "How many chess games are possible?. > For the chess problem we propose the estimate number_of_typical_games ~ typical_number_of_options_per_movetypical_number_of_moves_per_game. This equation is subjective, in that it isn\u2019t yet justified beyond our opinion that it might be a good estimate. This applies to most if not all games. In our paper \"A googolplex of Go games\" [1], we write \"Estimates on the number of \u2018practical\u2019 n \u00d7 n games take the form b^l where b and l are estimates on the number of choices per turn (branching factor) and game length, respectively. A reasonable and minimally-arbitrary\nupper bound sets b = l = n^2, while for a lower bound, values of b = n and l = (2/3)n^2 seem both reasonable and not too arbitrary. This gives us bounds for the ill-defined number P19 of \u2018practical\u2019 19x19 games of\n10^306 < P19 < 10^924\nWikipedia\u2019s page on Game complexity[5] combines a somewhat high estimate of b = 250 with an unreasonably low estime of l = 150 to arrive at a not unreasonable 10^360 games.\" > Our final estimate was that it is plausible that there are on the order of 10^151 possible short games of chess. I'm curious how many arbitrary length games are possible.\nOf course the length is limited to 17697 plies [3] due to Fide's 75-move rule. But constructing a huge class of games in which every one is probably legal remains a large challenge; much larger than in Go where move legality is much easier to determine. The main result of our paper is on arbitrarily long Go games, of which we prove there are over 10^10^100. [1]  https://matthieuw.github.io/go-games-number/AGoogolplexOfGoG...  [2]  https://en.wikipedia.org/wiki/Game_complexity#Complexities_o...  [3]  https://tom7.org/chess/longest.pdf  One thing I always wondered is how many moves, on average, do you have to play before reaching a position that has never before seen on Earth? Or maybe the question should be what percent of games reach a position that has never before been seen? meh. I think it would have"}
{"anchor": "Toronto\u2019s network of pedestrian tunnels. Once on a lunch break I walked from St Andrew to King (parallel stations on the horns of line 1) in the tunnels and took the TTC back. Going overground is usually faster and easier to navigate, buts impressive how far you can go underground. One of these days I\u2019ll need to try an extreme point hike. One thing that I was surprised wasn't mentioned is the impact that I believe weather must have had on the development of the Path. Winters in Toronto get rather cold and snowy. Even with a dense downtown core, walking a few blocks outside can be rather unpleasant. I use to love exploring Path as a teenager. More northern cities like Montreal and Winnipeg also have very interesting indoor pedestrian systems. The one in Winnipeg is particularly useful, since there are approximately 72 hours per year that it's comfortable to be outside between the bone-chilling cold and the biblical swarms of mosquitos and flies in the summer.  https://en.wikipedia.org/wiki/Underground_City,_Montreal   https://en.wikipedia.org/wiki/Winnipeg_Walkway  We also have a 5K race in the PATH! [1] In the winter the tunnels are amazing for commute. [1]  https://www.bougebouge.com/en/shop/events/5km-bougebouge-tor...  >  Montreal has a similar system, while Tokyo, Osaka, Seoul, Hong Kong, Singapore and Houston have systems that resemble the Path in some respects. A few European cities also make considerable use of pedestrian tunnels, including Helsinki, Stockholm and Munich.  Japan's northernmost major city, Sapporo, has a very extensive one -- of those I've seen, it's the one that's most comparable to Toronto's. The other Japanese tunnel/undercity complexes are mostly subterranean malls around subway stations.  (This also applies to all of the ones in Hong Kong.)  But Sapporo's is seriously huge. I think the common denominator is that people would rather walk in a heated underground space when it gets cold. It's my understanding that underground walkways were c", "positive": "10 years of personal finances in plain text files. This seems to be, in effect, advertising for a book about how to use the underlying FOSS software to do this. I would be okay with that as a monetization model, except that the book author despite being a self-described FOSS dev doesn't seem to have anything to do with the project ( https://github.com/beancount/beancount/graphs/contributors ). Ah, not quite true. The author fixed a typo in a docstring once ( https://github.com/beancount/beancount/commit/8584763b618f76... ). Plain text files are appreciated. I started storing all my notes (500+ by today) in markdown files locally. It's easy to search and navigate with grep and ag/rg. It's easy to edit in Vim or your favorite editor. It's easy to append all sorts of informations. I add some flags and properties in metadata, like last_reviewed, some tags, etc. The versioning and sync is solved by git + a private github repo. I have 14 years of personal (and 2 years of sole proprietorship) finance data in beancount. I tried all the available personal finance apps there are, from cloud/online offerings to offline apps. Eventually, I settled on beancount because it is the most versatile file format. In addition to tracking finances, I can track stocks, unvested RSU grants, vacation hours, and even personal training I have paid for but yet to use. It's cumbersome at times, and I do miss the (G)UI of entering transactions, but with (neo)vim I got used to it and I breeze trough my finances in 15-20 minutes once a week. > 30-45 minutes every single month That's 6\u20139 hours every year! 5 years: 30\u201345 hours 10 years: 60\u201390 hours I've been beancount'ing for years now As we've crossed into the new year I've switched to a similar directory setup as the OP with 1 file per year. Previously I just had one file that was from 2022 which ended up being like 2 million lines of text, which was starting to bog down the emacs plugin. What I appreciate the most about this approach to personal ", "negative": "Improving the usability of C libraries in Swift. This was a great read. I've used the naive approach shown in the first example before and its always felt a bit clunky, but I wasnt aware of most of these language features. I'm definitely going to try this out next time I have to write C bindings This is pretty great stuff, I knew about the raw interop features but had no idea what API Notes offered. Quite cool. I can't help but feel that Swift will ultimately be the \"slow and steady wins the race\" safe language of the future. Swift steadily working \"first\" on both tooling and cohabitability with existing ecosystems is a huge boon for adoption. It understands what an ABI is! If I were doing a greenfield cross platform application I think Swift would be the first thing I reach for now. The qualms I have with Swift are mostly some of the more recent complex language features that can make Swift code much harder to understand and read, as well as the brainpower required to use Swift concurrency. That and some performance concerns, though many of those seem like they may be solvable with optimizations in LLVM. I believe Apple is investing in C/C++ interop so much because they realize they'll likely keep their existing low-level system+embedded code rather than port it to Swift.  That's good for people who want to do the same.  A swift API layer can reduce the need for C/C++ developers. But in my experience, there are sharp cliffs whenever you get off the happy path shown in the demos.  That's not a problem with code where you can design workarounds, but when you wrap highly complex (if not arcane) C API, you often can't change or omit portions of the API causing problems.  So while usability may be better, apinotes might not be enough to complete the work. If you're wrapping something, I would recommend cataloging and then verifying all the language features you need to make it work before getting too far in. It's good to have options. I guess this is similar effort as S"}
{"anchor": "Ask HN: What are some of your favorite documentaries?. My second favorite \u201cWild, Wild, Country\u201d, but it was mentioned already at the top of the first list.  I enjoy it as a cautionary tale, but I also unironically find it an inspiring tale of building, even if it turns out to bad. My favorite documentary is \u201cThe Barkley Marathons, the race that eats it\u2019s young\u201d I return to it at least once a year, and while the root of the story - watching people attempt the impossible is certainly inspiring, I find its moral themes are what I appreciate about it the most.  The idea of competition as a collective activity, that everyone wants to win, but also everyone wants to see others win their own race, that there\u2019s something about the way that it advances our understanding of humanity that is more important than individual success. Then also - that your race is yours alone, and that the most important victory is the one you define for yourself.  There are people who finish only one or three laps of the five lap marathon, and that failure is a greater achievement than most people will ever know, and they clearly see it that way, there\u2019s near no shame in anyone\u2019s performance and people are clearly defining success for themselves, mostly clearly beyond what anyone else would define it for them.  And finally, it\u2019s kind of a throwaway line, but one of the runners says \u201cI think most people could use more pain in their lives.\u201d And it made me realize that often, when enduring hardship, rather than turning away from it, finding ways to challenge myself on my terms is a healthier approach to stress than \u201crelaxing\u201d. Le Joli Mai  https://www.youtube.com/watch?v=iOj0sPmJssw  Here's another previous post:  https://news.ycombinator.com/item?id=25624456  which includes an answer of mine. To add to that list: [1] \"Andermatt - Global Village\" - tracks the construction of a luxury resort in the Swiss village of Andermatt and how it affects people there. The village and the project still make the ", "positive": "Insights into Claude Opus 4.5 from Pok\u00e9mon. The idea of Claude having \"anterograde amnesia\" and the top-rated comment there by Noosphere89 really resonated with me:     \"I would analogize this to a human with anterograde amnesia, who cannot form new memories, and who is constantly writing notes to keep track of their life. The limitations here are obvious, and these are limitations future Claudes will probably share unless LLM memory/continual learning is solved in a better way.\"\n\n  This is an extremely underrated comparison, TBH. Indeed, I'd argue that frozen weights + lack of a long-term memory are easily one of the biggest reasons why LLMs are much more impressive than useful at a lot of tasks (with reliability being another big, independent issue).\n\n  It emphasizes 2 things that are both true at once: LLMs do in fact reason like humans and can have (poor-quality) world-models, and there's no fundamental chasm between LLM capabilities and human capabilities that can't be cured by unlimited resources/time, and yet just as humans with anterograde amnesia are usually much less employable/useful to others than people who do have long-term memory, current AIs are much, much less employable/useful than future paradigm AIs.   I wonder if there's someone at Antrophic working to fine-tune the model's pokemon playing ability specifically. Maybe not but it sure would be funny. This actually matches my experience quite well. I use vision (often) to try and do 2 main things in Claude code: 1) give it text data from something that is annoying to copy and paste (eg labels off a chart or logs from a terrible web UI that doesn't make it easy to copy and paste). 2) give it screenshots of bugs, especially UI glitches. It's extremely good at 1), can't remember when it got it wrong. On 2) it _really_ struggled until opus 4.5, almost comically so, with me posting a screenshot and a description of the UI bug and it telling me \"great it looks perfect! What next?\" With opus 4.5 it's not ", "negative": "Environmentalists worry Google behind bid to control Oregon town's water. At this point, Google could be a drop-in replacement for the corporate villain in any 1980s/1990s action movie. Why on earth do they want water from the national forest when the massive Columbia River is right there!? Is it too expensive to treat the river water? /s At this moment I just assume by default that those \u201cwatchdogs\u201d, \u201cenvironmentalists\u201d, \u201cnonprofits\u201d are mix of nimby-ists and/or thinly  veiled attempts of extracting money (it\u2019s a nice things you got here. It would be a shame if some rare species of a frog would be found here. A small donation for the great cause/good, of course, would help us to work on ensuring that nobody gets in harms way). Stupid question: datacenters need water for cooling right? But they don't boil that water, ie it comes out of the datacenter just a little warmer? If that is the case does it matter to the city? The warmer water can still be used for agriculture or any other common usage. I know google fiber kinda flumped, but if they are already doing their own power generation for data centers they might decide to sell that power to the public too. What is really scary is that I foresee a day where these big tech companies will see it is more profitable to serve utilities to people than web services. Then, after they have a monopoly in most areas, they will enshitify it too. The amount of people here in the comments happily suggesting to let Google use the clean water for their AI datacenters and return dirty water to use in crops is a bit worrying How far we have fallen from the \"Do no evil\" marketing. More people should scrutinize the methodology behind these AI data center water usage reports. One widely cited Berkeley Lab figure includes the water evaporated from reservoirs behind hydroelectric dams. Excluding that factor cuts their water usage estimate by more than half. On AI & water, looks like all US data center usage (not just AI) ranges from 628M "}
{"anchor": "OracleGPT: Thought Experiment on an AI Powered Executive. Considering things like Palantir, and the doge effort running through Musk, it seems inconceivable that this is not already the case. I think I'm more curious about the possibility of using a special government LLM to implement direct democracy in a way that was previously impossible: collecting the preferences of 100M citizens, and synthesizing them into policy suggestions in a coherent way. I'm not necessarily optimistic about the idea, but it's a nice dream. This is an interesting and thoughtful article I think, but worth evaluating in the context of the service (\"cognitive security\") its author is trying to sell. That's not to undermine the substance of the discussion on political/constitutional risk under the inference-hoarding of authority, but I think it would be useful to bear in mind the author's commercial framing (or more charitably the motivation for the service if this philosophical consideration preceded it). A couple of arguments against the idea of singular control would be that it requires technical experts to produce and manage it, and would be distributed internationally given any countries advanced enough would have their own versions; but it would of course provide tricky questions for elected representatives in the democratic countries to answer. A COMPUTER CAN NEVER BE HELD ACCOUNTABLE THEREFORE A COMPUTER MUST NEVER MAKE A MANAGEMENT DECISION. think we're already there aren't we? no human came out with those tariffs on penguin island The really nice thing about this proposal is that at least now we can all stop anthropomorphizing Larry Ellison, and give Oracle the properly robot-identifying CEO it deserves. You sometimes hear people say \"I mean, we can't just give an AI a bunch of money/important decisions and expect it to do ok\" but this is already happening and has been for years. Examples: - Algorithmic trading: I once embedded on an Options trading desk. The head of desk mentioned ", "positive": "Claude Code gets native LSP support. My favourite agent crush[0] has lsp support for a while. I\u2019ve not noticed the agent deciding to use it all that much. [0]  https://github.com/charmbracelet/crush  It's strangely difficult to find official information about this, but here's what I've learned: \u2022 Use `/plugin` to open Claude Code's plug-in manager \u2022 In the Discover tab, enter `lsp` in the search box \u2022 Use `spacebar` to enable the ones you want, then `i` to install Hope that helps! This is an ignorant question, but, what is the benefit of this if you also have your project open in an editor or IDE (presuming they integrate language server?) If you're vibe coding without an editor, would this have any benefits to code quality over a test suite and the standard linter for a language? It\u2019s breathtaking how fast Anthropic / Claude Code team ships. They are definitely coding in a LLM maximalist way, in a good way. I am super bullish on claude code / codex cli + LSP and other deterministic codemod and code intelligence tools. I was playing around with codex this weekend and honestly having a great time (my opinion of it has 180'd since gpt-5.2(-codex) came out) but I was getting annoyed at it because it kept missing references when I asked it to rename or move symbols. So I built a skill that teaches it to use rope for mechanical python codebase refactors:  https://github.com/brian-yu/python-rope-refactor  Been pretty happy with it so far! What does the terminal integration mentioned do? I haven't come across a case where it has used the LSP yet. Opus 4.5 is fairly consistent in running QA at proper times. Lint checks and all are already incorporated into a standard & native processes outside of IDE. I think lookup can be useful when definitions are hidden deep in hard to reach places on my disk... hasn't been a problem though the agent usually finds what it needs. Anyway, here is what it stated it could do:       > Do you have access to an lsp tool?\n\n     Yes, I have an L", "negative": "Updates to our web search products and  Programmable Search Engine capabilities. Google quietly announced that Programmable Search (ex-Custom Search) won\u2019t allow new engines to \u201csearch the entire web\u201d anymore. New engines are capped at searching up to 50 domains, and existing full-web engines have until Jan 1, 2027 to transition. If you actually need whole-web search, Google now points you to an \u201cinterest form\u201d for enterprise solutions (Vertex AI Search etc.), with no public pricing and no guarantee they\u2019ll even reply. This seems like it effectively ends the era of indie / niche search engines being able to build on Google\u2019s index. Anything that looks like general web search is getting pushed behind enterprise gates. I haven\u2019t seen much discussion about this yet, but for anyone who built a small search product on Programmable Search, this feels like a pretty big shift. Curious if others here are affected or already planning alternatives. UPDATE: I logged into Programmable Search and the message is even more explicit: Full web search via the \"Search the entire web\" feature will be discontinued within the next year. Please update your search engine to specify specific sites to search. With this link:  https://support.google.com/programmable-search/answer/123971...  Relevant: Waiting for dawn in search: Search index, Google rulings and impact on Kagi  https://news.ycombinator.com/item?id=46708678  I had misread the title as \"Google is ending (full-web search) for [aka in favour of] (niche search engines)\" The correct parsing is: \"Google is ending (full-web search for niche search engines)\" Is this about the little Google Search Bar that is present on some websites? Or am I mistaking something Meanwhile in Europe: Qwant and Ecosia team up to build their own search index:  https://blog.ecosia.org/eusp/  What examples are there of people using this? I'm curious about what it would take to build my own \"toy\" search engine with its own index. Anyone ever tried this? The 'Go"}
{"anchor": "Siddhartha. Huh, funny this should pop up here. I recently started commuting by subway into work, so I had to pick up a subway book. I had been meaning to read this, so I went to my local book store and grabbed a copy. It\u2019s a really great book. Such a fascinating story. And short, too. I highly recommend giving it a read. It might synthesize some of your loose connections about Hinduism, Buddhism, and your own place in a chaotic world and what it means to live a happy life. great book.  I recommend people read it every 10 years or so as your perspective on life changes. I'm very grateful that this was assigned reading in high school, since it was a sort of gateway book for reading more about Buddhism. It's short. If you haven't read it, I highly recommend it. One of the greatest authors of all time. Hesse taps into the mind of the modern human and beautifully presents its inner workings. Each of his books takes a different angle, a different perspective or philosophy with which to observe the evolving personhood. I read this in high school, but not because it was assigned.  At the time I was really into \"rare\" Queen MP3s, and there's a studio recording of the fast version of \"We Will Rock You\" where Brian May reads a passage from this book before the music starts.  An odd way to be inspired to read a book, but I still think I got a fair bit out of it. Off topic: Im curious what\u2019s the most prominent religion among HNers? Is it different from the normal population? Buddhism seems to be number 1 after atheism which isn\u2019t a religion. I liked this quite a bit the first time I'd read it. A decade later, not as much. Narcissus and Goldmund is my favorite book by Hesse - it's beautifully crafted. I read this annually, typically in a day, usually when I'm feeling lost. For me it distills the human experience into a simply story that helps me find meaning for where I am in my own journey. Love this book. I have three sons and read this when them when they're about 12 or 13. I", "positive": "What's the strongest AI model you can train on a laptop in five minutes?. Perhaps grimlock level:  https://m.youtube.com/shorts/4qN17uCN2Pg  Instead of time it should be energy. What is the best model you can train with a given budget in Joules. Then the MBP and the H100 are on a more even footing. I love seeing explorations like this, which highlight that easily accessible hardware can do better than most people think with modern architectures. For many novel scientific tasks, you really don't need an H100 to make progress using deep learning over classical methods. I suspect one can go a lot further by adopting some tweaks from the GPT-2 speedrun effort [0], at minimum Muon, better init and carefully tuning learning rate. [0]:  https://github.com/KellerJordan/modded-nanogpt  But supposing you have a real specific need to train, is the training speed still relevant? Or do the resources spent on gathering and validating the data set dwarf the actual CPU/GPU usage? The most powerful Macbook Pro currently has 16 CPU cores, 40 GPU cores, and 128 GB of RAM (and a 16-core \u201cneural engine\u201d specifically designed to accelerate machine learning). Technically, it is a laptop, but it could just as well be a computer optimized for AI. > Paris, France is a city in North Carolina. It is the capital of North Carolina, which is officially major people in Bhugh and Pennhy. The American Council Mastlandan, is the city of Retrea. There are different islands, and the city of Hawkeler: Law is the most famous city in The Confederate. The country is Guate. I love the phrase \"officially major people\"! I wonder how it could be put to use in everyday speech? Not the point of the exercise obviously, but at five minutes' training I wonder how this would compare to a Markov chain bot. Any reason to upgrade an M2 16GB macbook to a M4 ..GB (or 2026 M5) for local LLMs? Due an upgrade soon and perhaps it is educational to run these things more easily locally? You could train an unbeatable tic-tac-to", "negative": "Replacing Protobuf with Rust. Are they sure it's because Rust? Perhaps if they rewrite Protobuf in Rust it will be as slow as the current implementation. They changed the persistence system completely. Looks like from a generic solution to something specific to what they're carrying across the wire. They could have done it in Lua and it would have been 3x faster. I vaguely recall that there's a Rust macro to automatically convert recursive functions to iterative. But I would just increase the stack size limit if it ever becomes a problem. As far as I know the only reason it is so small is because of address space exhaustion which only affects 32-bit systems. FlatBuffers are already faster than that. But that's not why we choose Protobuf. It's because a megacorp maintains it. \"5 times faster\" reminds me of Cap'n Proto's claim: in benchmarks, Cap\u2019n Proto is INFINITY TIMES faster than Protocol Buffers:  https://capnproto.org/  Just for fun, how often do regular-sized companies that deal in regular-sized traffic need Protobuf to accomplish their goals in the first place, compared to JSON or even XML with basic string marshalling? tldr: they replaced using protobuf as the type system across language boundaries for FFI with true FFI Don't read clickbaity headlines and scan hacker news five times faster. I find the title a bit misleading. I think it should be titled It\u2019s Faster to Copy Memory Directly than Send a Protobuf. Which then seems rather obvious that removing a serialization and deserialization step reduces runtime. I don't understand, I used protobuf for map data, but it is a hardcore simple format, this is the whole purpose of it. I wrote assembly, memory mapping oriented protobuf software... in assembly, then what? I am allowed to say I am going 1000 times faster than rust now??? You should be terrified of the instability you're introducing to achieve this. Memory sharing between processes is very difficult to keep stable, it is half the reason kernels exist. M"}
{"anchor": "Functional programming and reliability: ADTs, safety, critical infrastructure. This article seems to conflate strong type systems with functional programming, except in point 8. It makes sense why- OCaml and Haskell are functional and were early proponents of these type systems. But, languages like Racket don\u2019t have these type systems and the article doesn\u2019t do anything to explain why they are _also_ better for reliability. >In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. This reliability isn't done by being perfect 100% of the time. Things like being able to handle states where transactions don't line up allowing for payments to eventually be settled. Or for telecom allowing for single parts of the system to not take down the whole thing or adding redundancy. Essentially these types of businesses require fault tolerance to be supported. The real world is messy, there is always going to be faults, so investing heavily into correctness may not be worth it compared to investing into fault tollerance. I'm wary of absolute statements about programming. I like good type systems, too, but they won't save you from bugs that are better addressed by fuzz testing, fault injection testing and adversarial mindset shifts. Strong types: yes, it\u2019s definitely better Functional programming: no, functional programming as in: the final program consists in piping functions together and calling the pipe. In my opinion, that tends to get in the way of complex error handling. The problem being that raising Exceptions at a deep level and catching them at some higher level is not pure functional programming. So your code has to deal with all the cases. It is more reliable if you can do it, but large systems have way too many failure points to be able to handle them all in a way that is practical. I think there is a strong case that ADTs (algebraic data types) aren't so great after all. Specifically, the \"tagged\" unions of ADT languages like Haskell ", "positive": "Measuring AI Ability to Complete Long Tasks. This seems like a good way to measure LLM improvement. It matches the my personal feeling when using progressively better models over time. Opus is already the name of an audio codec. I recently asked Opus to just \u201cAdd vector search\u201d to my current hobby project, a topic I know very little about. It set up manticore, pulled an embedding model, wrote a migration tool for my old keyword indices, and built the front end. I\u2019m not exaggerating much either: the prompt was the length of a tweet. I think it would easily have taken me 4+ hours to do that.  It ran in 15 minutes while I played Kirby Air Riders and worked on the first try. Afterward, I sort of had to reflect on the fact that I learned essentially nothing about building vector search. I wanted the feature more than I wanted to know how to build the feature. It kept me learning the thing I cared about rather than doing a side quest. Would be interesting to see Gemini 3.0 Pro benchmarked as well. I didn't really understand the \"long task\" thing until I actually experienced it. The problem is finding a task you can set an agent that justifies working for that long. I finally hit one when I tried porting that Python HTML5 parser to JavaScript by pointing Codex CLI at the 9,200 html5lib-tests test suite:  https://simonwillison.net/2025/Dec/15/porting-justhtml/  It's pretty amazing to watch tools-in-a-loop crunch away for >4 hours to solve a generally difficult problem through sheer brute-force. Opus looks like a big jump from the previous leader (GPT 5.1), but when you switch from \"50%\" to \"80%\", GPT 5.1 still leads by a good margin. I'm not sure if you can take much from this - perhaps \"5.1 is more reliable at slightly shorter stuff, choose Opus if you're trying to push the frontier in task length\". I think the problem here is LLM eventually pollute its context window with so much of the current task that the larger picture or architectural sanity is forgotten in favor of ", "negative": "Replacing Protobuf with Rust. Are they sure it's because Rust? Perhaps if they rewrite Protobuf in Rust it will be as slow as the current implementation. They changed the persistence system completely. Looks like from a generic solution to something specific to what they're carrying across the wire. They could have done it in Lua and it would have been 3x faster. I vaguely recall that there's a Rust macro to automatically convert recursive functions to iterative. But I would just increase the stack size limit if it ever becomes a problem. As far as I know the only reason it is so small is because of address space exhaustion which only affects 32-bit systems. FlatBuffers are already faster than that. But that's not why we choose Protobuf. It's because a megacorp maintains it. \"5 times faster\" reminds me of Cap'n Proto's claim: in benchmarks, Cap\u2019n Proto is INFINITY TIMES faster than Protocol Buffers:  https://capnproto.org/  Just for fun, how often do regular-sized companies that deal in regular-sized traffic need Protobuf to accomplish their goals in the first place, compared to JSON or even XML with basic string marshalling? tldr: they replaced using protobuf as the type system across language boundaries for FFI with true FFI Don't read clickbaity headlines and scan hacker news five times faster. I find the title a bit misleading. I think it should be titled It\u2019s Faster to Copy Memory Directly than Send a Protobuf. Which then seems rather obvious that removing a serialization and deserialization step reduces runtime. I don't understand, I used protobuf for map data, but it is a hardcore simple format, this is the whole purpose of it. I wrote assembly, memory mapping oriented protobuf software... in assembly, then what? I am allowed to say I am going 1000 times faster than rust now??? You should be terrified of the instability you're introducing to achieve this. Memory sharing between processes is very difficult to keep stable, it is half the reason kernels exist. M"}
{"anchor": "Auto-grading decade-old Hacker News discussions with hindsight.  LLMs are watching (or humans using them might be). Best to be good.  Shades of Roko's Basilisk! Commenters of HN: Your past thoughts have been dredged up and judged. For each $TOPIC, you have been awarded a grade by GPT-5.1 Thinking. Your grade is based on OpenAI's  aligned  worldview and what OpenAI's blob of weights considers Truth in 2025. Did you think  well , netizen? Are you an Alpha or a Delta-Minus? Where will the dragnet grading of your online history happen next? Random Bets for 2035: * Nvidia GPUs will see heavy competition and most chat-like use-cases switching to cheaper models and inference-specific-silicon but will be still used on the high end for critical applications and frontier science * Most Software and UIs will be primarily AI-generated.  There will be no 'App Stores' as we know them. * ICE Cars will become niche and will be largely been replaced with EVs, Solar will be widely deployed and will be the dominate source of power * Climate Change will be widely recognized due to escalating consequences and there will be lots of efforts in mitigations (e.g, Climate Engineering, Climate-resistant crops, etc). It's fun to read some of these historic comments! A while back I wrote a replay system to better capture how discussions evolved at the time of these historic threads. Here's Karpathy's list from his graded articles, in the replay visualizer: Swift is Open Source\n https://hn.unlurker.com/replay?item=10669891  Launch of Figma, a collaborative interface design tool\n https://hn.unlurker.com/replay?item=10685407  Introducing OpenAI\n https://hn.unlurker.com/replay?item=10720176  The first person to hack the iPhone is building a self-driving car\n https://hn.unlurker.com/replay?item=10744206  SpaceX launch webcast: Orbcomm-2 Mission [video]\n https://hn.unlurker.com/replay?item=10774865  At Theranos, Many Strategies and Snags\n https://hn.unlurker.com/replay?item=10799261  Notable how this", "positive": "Watching o3 model sweat over a Paul Morphy mate-in-2. O3 is massively underwhelming and is obviously tuned to be sycophantic. Claude reigns supreme. I've commited the 03 (zero-three) and not o3 (o-three) typo too, but can we rename it on the title please So, are we talking about OpenAI o3 model, right? On a similar note, I just updated LLM Chess Puzzles repo [1] yesterday. The fact that gpt-4.5 gets 85% correctly solved is unexpected and somewhat scary (if model was not trained on this). [1]  https://github.com/kagisearch/llm-chess-puzzles  Where does this obsession over giving binary logic tasks to LLMs come from ? New LLM breakthroughs are about handling blurry logic, non precise requirements and spitting vague human realistic outputs. Who care how well it can add integers or solve chess puzzles ? We have decades of computer science on those topics already I remember reading that got3.5-turbo instruct was oddly good at chess - would be curious what it outputs as a next two moves here. So... it failed to solve the puzzle? That seems distinctly unimpressive, especially for a puzzle with a fixed start state and a limited set of possible moves. Nice puzzle with a twist of Zugzwang. Took me about 8 minutes, but it's been decades since I was doing chess. LLMs are not chess engines, similar to how they don\u2019t really calculate arithmetic.  What\u2019s new? carry on. I just tried the same puzzle in o3 using the same image input, but tweaked the prompt to say \u201cdon\u2019t use the search tool\u201d. Very similar results! It spent the first few minutes analyzing the image and cross-checking various slices of the image to make sure it understood the problem. Then it spent the next 6-7 minutes trying to work through various angles to the problem analytically. It decided this was likely a mate-in-two (part of the training data?), but went down the path that the key to solving the problem would be to convert the position to something more easily solvable first. At that point it started trying to ", "negative": "Porting 100k lines from TypeScript to Rust using Claude Code in a month. For typing \u201cyes\u201d or \u201cy\u201d automatically into command prompts without interacting, you could have utilized the command \u2018yes\u2019 and piped it into the process you\u2019re running as a first attempt to solving the yes problem. \n https://man7.org/linux/man-pages/man1/yes.1.html  How much does it cost to run Claude Code 24 hrs/day like this. Does the $200/month plan hold up? My spend on Cursor has been high... I'm wondering if I can just collapse it into a 200/month CC subscription. I'm hoping that one day we can use AI to port the millions of lines in the modules of the Python ecosystem to a GIL-free version of Python. Did you ever consider using something like Oh My Opencode [1]?\nI first saw it in the wake of Anthropic locking out Opencode. I haven\u2019t used it but it appears to be better at running continuously until a task is finished. Wondering if anyone else has tried migrating a huge codebase like this. [1]  https://github.com/code-yeongyu/oh-my-opencode  Some quotes from the article stand out: \n\"Claude after working for some time seem to always stop to recap things\"\nQuestion: Were you running out of context? That's why certain frameworks like intentional compaction are being worked on.  Large codebases have specific needs when working with an LLM. \"I've never interacted with Rust in my life\" :-/ How is this a good idea? How can I trust the generated code? This is actually pretty incredible. Cannot really argue against the productivity in this case. Honestly I am really interested in trying to port the rust code to multiple languages like golang,zig, even niche languages like V-lang/Odin/nim etc. It would be interesting if we use this as a benchmark similar to  https://benjdd.com/languages/  or  https://benjdd.com/languages2/  I used gitingest on the repository that they provided and its around ~150k tokens Currently pasted it into the free gemini web and asked it to write it in golang and it said that li"}
{"anchor": "High air pollution could diminish exercise benefits by half \u2013 study. It sounds terrible . What will happend in the future?! The research doesn't differentiate between seasons , and every one knows how polluted the air is in the winter when everyone is heating their home and apartament. I look at the PM2.5 data for my city every day, and at this point (Nov) in the winter season, the only acceptable time to exercise is between 2PM-4PM after vertical mixing kicked in. Outside that duration, particulates are elevated after morning rush our, after evening rush hour, or during overnight inversion trapping evening rush hour + wood burning smoke until the next morning rush hour. This is one the main reasons why I would prefer working remote, it is hard to utilize this time well (for exercise) if you are in the office. At least with PM you can wear a mask, although I am still searching for the best one that works during intense exercise. Also wanted to point out\n\"Trump EPA moves to abandon rule that sets tough standards for deadly soot pollution\"  https://apnews.com/article/epa-soot-air-pollution-trump-zeld...  If only you could see it. In the big cities the air quality has improved, however, I am not sure if it really has, or if we are now just burning hydrocarbons more efficiently so that the particle sizes have become invisible. Put it this way, although cars are allegedly better than they were, fuel consumption hasn't dropped considerably. The cars are more numerous than ever, and, although there are EVs, there are still more ICE cars than there were in the good old days when petrol came with lead in it. I am not sure that most people in urban areas even know what good air tastes and smells like. I take a canal path through lush countryside, far from any cars for most of the way. This canal has an aqueduct (or is it a viaduct?) over a motorway and the contrast is incredible. You go from basically smelling flowers to air pollution and back to clean air again quite quickly", "positive": "Bus stops here: Shanghai lets riders design their own routes. This is really brilliant \u2014 like desire paths, but for transit. Obviously execution will be challenging, but the concept is fantastic, and China/Shanghai seems like one of the few places with the requisite density & state capacity to actually make this work. Generally I think that the design of public spaces has SO MUCH room to be improved by just responding to the wisdom of the crowd. I'm glad that Shanghai has moved to the next level in public transportation in meeting customer demand. Most cities don't have the funds to buy smallish buses and labour available as drivers. They don't have the money or willpower to get frequencies to turn up and go levels (ie frequent) and leave people with long walks to widely spaced routes. Tangent: I\u2019ve often thought that it would be great to let people design their own political districts to reduce gerrymandering At the polling place you\u2019d get a map with your census tract and then be asked \u201cwhich two or three adjacent tracts are most similar to your community\u201d. Eventually you\u2019d end up with some sort of gram matrix for tract-to-tract affinity, and then you could apply some algorithmic segmentation. Two problems: - this is far too complex for most voters to understand, much less trust, what\u2019s happening - the fact it\u2019s \u201calgorithmic\u201d would give a sheen of pseudo objectivity, but the selection of the actual algorithm would still allow political infouence over boundaries Chiming in from Los Angeles, USA to say wow, must be nice living in a modern society that prioritizes public transit and peoples' ease of movement. I know, I know, it comes with trade offs of living in an authoritarian state, but the absolute abysmal state of infrastructure in this country is maddening. Ever been on a train in Denmark or Japan or Switzerland? This remind me that road router should be walked by passenger rather than designed by designers. China is the only modern country that has both the cap", "negative": "American importers and consumers bear the cost of 2025 tariffs: analysis. > Event studies around discrete tariff shocks on Brazil (50%) and India (25\u201350%) confirm: export prices did not decline. Trade volumes collapsed instead. What if that was the intended result? who could possibly have foreseen this This is the case with any tax, it's mostly paid by the consumer. American trade policy has gone so far in the direction of Mercantilism that both the Neoliberal and the Keynesian economists can agree on something. That's not a good thing. We will see if SCOTUS majority decides tariffs are a tax or not and push the absurdity of their position even farther. I fear that they already decided that issue when they chose not to intervene and now have the excuse of \"lol well can't undo it now\" ready to go. Edit:  It appears Trump & Co intend to replace SCOTUS if they lose the tariffs ruling ...  https://www.nytimes.com/2026/01/19/us/politics/trump-tariffs...  -------- There does seem to be indications that the actual tariffs collected seems far lower than the actual tariffs promised, likely just half of what was promised:  https://www.nytimes.com/2026/01/03/business/economy/trump-ta...  Isn't this literally economics 101? How did we ever even end up imagining that tariffs are somehow paid by the exporter?? How could that possibly have not been the case.  A tariff is no different from the cost of any input into the price of a finished good.  There is some sense in which price increases are limited by supply and demand, but if the market won't pay for the production cost of the good, then the market will cease to provide that good.  There are only two possible outcomes, long term -- either the price goes up, or the product becomes unavailable. There's an argument that domestically produced goods would substitute for imported goods leaving the market, but markets are so global and intertwined now that even domestic goods have imported inputs that are also affected by tariffs, an"}
{"anchor": "GPT-5.2. Marginal gains for exorbitantly pricey and closed model\u2026.. Everything is still based on 4 4o still right? is a new model training just too expensive? They can consult deepseek team maybe for cost constrained new models.  https://openai.com/index/introducing-gpt-5-2/  \"Investors are putting pressure, change the version number now!!!\" Slight increase in model cost, but looks like benefits across the board to match.     gpt-5.2 $1.75 $0.175 $14.00\n  gpt-5.1 $1.25 $0.125 $10.00   GPT-5.2 System Card PDF:  https://cdn.openai.com/pdf/3a4153c8-c748-4b71-8e31-aecbde944...  From GPT 5.1 Thinking: ARC AGI v2: 17.6% -> 52.9% SWE Verified: 76.3% -> 80% That's pretty good! This seems like another \"better vibes\" release. With the number of benchmarks exploding, random luck means you can almost always find a couple showing what you want to show. I didn't see much concrete  evidence this was noticeably better than 5.1 (or even 5.0). Being a point release though I guess that's fair. I suspect there is also some decent optimizations on the backend that make it cheaper and faster for OpenAI to run, and those are the real reasons they want us to use it. It baffles me to see these last 2 announcements (GPT 5.1 as well) devoid of any metrics, benchmarks or quantitative analyses. Could it be because they are behind Google/Anthropic and they don't want to admit it? (edit: I'm sorry I didn't read enough on the topic, my apologies) So GDPval is OpenAI's own benchmark. PDF link:  https://arxiv.org/pdf/2510.04374  They used to compare to competing models from Anthropic, Google DeepMind, DeepSeek, etc. Seems that now they only compare to their own models. Does this mean that the GPT-series is performing worse than its competitors (given the \"code red\" at OpenAI)? Are benchmarks the right way to measure LLMs? Not because benchmarks can be gamed, but because the most useful outputs of models aren't things that can be bucketed into \"right\" and \"wrong.\" Tough problem! The ARC AGI 2 bump to", "positive": "Gemini Diffusion. Interesting to see if GROQ hardware can run this diffusion architecture..it will be  two time magnitude of currently known speed :O That's...ridiculously fast. I still feel like the best uses of models we've seen to date is for brand new code and quick prototyping. I'm less convinced of the strength of their capabilities for improving on large preexisting content over which someone has repeatedly iterated. Part of that is because, by definition, models cannot know what is  not  in a codebase and there is meaningful signal in that negative space. Encoding what  isn't  there seems like a hard problem, so even as models get smarter, they will continue to be handicapped by that lack of institutional knowledge, so to speak. Imagine giving a large codebase to an incredibly talented developer and asking them to zero-shot a particular problem in one go, with only moments to read it and no opportunity to ask questions. More often than not, a less talented developer who is very familiar with that codebase will be able to add more value with the same amount of effort when tackling that same problem. I think the lede is being buried. This is a great and fast InstructGPT. This is absolutely going to be used in spell checks, codemods, and code editors. Instant edits feature can surgically perform text edits fast without all the extra fluff or unsolicited enhancements. I copied shadertoys, asked it to rename all variables to be more descriptive and pasted the result to see it still working. I'm impressed. Diffusion is more than just speed. Early benchmarks show it better at reasoning and planning pound for pound compared to AR. This is because it can edit and doesn\u2019t suffer from early token bias. Nit: Diffusion isn't in place of transformers, it's in place of autoregression. Prior diffusion LLMs like Mercury [1] still use a transformer, but there's no causal masking, so the entire input is processed all at once and the output generation is obviously different. I ", "negative": "World\u2019s most powerful literary critic is on TikTok. I expected that to be a hit job but it's actually rather poignant. I wish we had more plurality. Not just convergence on one ultra influencer for books, but an ecosystem, with offerings tailored to audiences. I had to go through a cookie request, a subscribe to us popup and then had to close another popup telling me I could only read two articles. I acknowledge his expertise in literature. I find his approach to non-fiction sometimes less insightful and note a recent shift toward following popular book trends but it\u2019s still great to see his videos. I went and looked at the Tiktoks. As far as I can see from the few videos I've  watched it's not so much \"criticism\" as \"plot overview, small background details, and what I liked about it\". It's kind of weird it's being framed as a tiktok sensation when there's nothing to really differenciate him from other booktokers? Other than perhaps more subscribers than usual. Also, per the article: > Edwards champions BookTok and also defends it... Kind of interesting to note given his video saying he doesn't like booktok books[1]. I suppose he knows not to piss in the pond he drinks from. [1]  https://youtu.be/AuEipfQbHrU  influence \u2260 powerful I admit if you are permanently only this might blend together. How good is the book he successfully sold to HarperCollins,  The Uni-Verse ? Either he's pretty good, or he was quite lucky, or he had some inside track. Sort of an aside, but what's next now that Tiktok is  deeply  into end-stage enshittification? It'd dead now, a formerly fun app morphed into grotesque eyeball milking system owned by one of the worst people on the planet. I deleted the app this week after the feed ramped ad content up to being an ad every other video, frequently with ads back to back to back. It's cooked. How interesting. I thought booktok was an aggregated list of the books people were most talking about on TikTok or something. Turns out it\u2019s just one guy mak"}
{"anchor": "Hypothesis: Property-Based Testing for Python. I keep thinking I have a possible use case for property -based testing, and then I am up to my armpits in trying to understand the on-the-ground problem and don't feel like I have time to learn a DSL for describing all possible inputs and outputs when I already had an existing function (the subject-under-test) that I don't understand. So rather than try to learn to black boxes at the same time , I fall back to \"several more unit tests to document more edge cases to defensibly guard against\" Is there some simple way to describe this defensive programming iteration pattern in Hypothesis? Normally we just null-check and return early and have to deal with the early-return case. How do I quickly write property tests to check that my code handles the most obvious edge cases? It\u2019s been quite some time since I\u2019ve been in the business of writing lots of unit tests, but back in the day, I found hypothesis to be a big force multiplier and it uncovered many subtle/embarrassing bugs for me. Recommend.  Also easy and intuitive to use. I love property-based testing, especially the way it can uncover edge cases you wouldn't have thought about. Haven't used Hypothesis yet, but I once had FsCheck (property-based testing for F#) find a case where the data structure I was writing failed when there were exactly 24 items in the list and you tried to append a 25th. That was a test case I wouldn't have thought to write on my own, but the particular number (it was always the 25th item that failed) quickly led me to find the bug. Once my property tests were running overnight and not finding any failures after thousands and thousands of random cases, I started to feel a lot more confident that I'd nailed down the bugs. Make sure to read the docs and understand this well. It has its own vocabulary that can be very counterintuitive. It seems to only implement a half of QuickCheck idea, because there is no counterexample shrinking. Good effort thoug", "positive": "In New York City, congestion pricing leads to marked drop in pollution. > Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death. Minor nitpick, but tailpipes aren't the primary source of emissions. The study is about PM2.5[0]. which will chiefly be tires and brake pads. Modern gasoline engines are relatively clean, outside of CO2, though diesel engines spit out a bunch of bad stuff. [0]  https://www.nature.com/articles/s44407-025-00037-2  See also  https://news.ycombinator.com/item?id=46213504  There was a study published about how much air pollution dropped in NYC during the COVID lockdown. PM2.5 was found to have dropped 36%. However with more robust analysis, this drop was discovered to not be statistically significant. I would caution anyone reading this who is tempted by confirmation bias. Source:  https://pmc.ncbi.nlm.nih.gov/articles/PMC7314691/  To head off the almost inevitable recapitulation of yesterday's parade of misinformed complaints by teenage libertarians, please actually read the paper before commenting. The paper shows there was no significant reduction in entries to the congestion charge zone by cars, vans, and light trucks. And you can confirm this conclusion is consistent with their source data using their github repo. The reduction in pollution is coming from the significant decline in heavy truck traffic. Truckers were using lower manhattan as a cut-through route to other places and they are now doing that less, exactly as congestion pricing planners long argued. Not surprising. The real question is how do we measure the opportunity cost of these measures? Is it a net gain? You could, at the extreme, ban all motor vehicles but the opportunity cost would outweigh the benefits. This article confirms my existing bias/belief that user pays and auction[0] based systems improve governmental programs and finite supp", "negative": "I built a light that reacts to radio waves [video]. I love your poetry on a phone project so muchhhh Very cool, was there a conversion or look up table to convert db to gamma for more accurate human visualization? Incredibly cool. I was really hoping to see the more \u2018edge\u2019 cases - take the light out to the middle of nowhere, walk towards it and away from it with just your phone or a Bluetooth speaker, see it react to your approach. The bit at the end about it shifting over the course of the day is cool, but I wish the effect was more visually apparent - it mostly just looked like random noise the whole time to me. This is fantastic. But the idea where you use a camera that can only see the wifi signals in the room like visible light is even more stunning. It would be even better if you could block out all light from the visible spectrum and only see the GHz band. This is such a neat project. The idea of translating invisible radio waves into visible light is mesmerizing \u2014 it feels like giving your surroundings a new sensory dimension. It\u2019s beautiful. I think I\u2019ve seen something similar in a Ukraine war video where they use a device that lights up on specific frequencies that drones use. FANTASTIC!! I was just thinking about this the other day, and wondering about directionality... For example, if you had a camera facing a space, and the receiving antenna was within that space... and you were able to (somehow?) from the antennas perspective, see the \"direction\" the frequency was coming from.. And then map the different specific frequencies within the desired bandwidth to colors... and of course intensity map like you have in the slit device.. And then \"look through the camera\"... you would see a live three dimensional overlay of all signals within range (colored!) \"interacting\" with the antenna... but kind of more the \"looking through the camera\" sort of view, like you could \"see\" how those waves were interacting.. And then wouldn't it be interesting to put a tin-foi"}
{"anchor": "Show HN: Books mentioned on Hacker News in 2025. Affiliate marketing is such a mixed bag. I absolutely love it when people can monetize their writing by adding some affiliate links that are relevant to the audience - win/win for all sides. Yet it is as slimy as anything else when the sole purpose of creating content is to publish affiliate links. Great books listed here! Added some to my TBR list. Thanks! I'm a little surprised the numbers aren't higher across the board. The fact that Mein Kampf was mentioned so often in 2025 is saying something about the political climate lol.. Nice website though, I like it. Neat. I'm seeing a lot of overlap with books mentioned on r/reddit. I didn't realize, until know, how demographically similar hacker news and reddit are. The top 3 programming books mentioned this year were 1. Structure and Interpretation of Computer Programs\n2. Clean Code\n3. Crafting Interpreters Also, it\u2019s quite fascinating how often fiction books were recommended! I wouldn\u2019t\u2019ve expected that on HN. Have you seen  https://hackernewsbooks.com  ? The recent novel Abundance seems to be agressibley grouped with the John Green novel An Abundance of Katherines - which I think is a humorous retelling of 2025 but also maybe needs some matching work Hitchhikers guide to the universe having 42 mentions is a cosmic level coincidence great project! how did you do tokenization and alignment of the titles to their ISBN / Amazon ID Would love to learn more about how this is built. I remember a similar project from 4 years ago[0] that used a classic BERT model for NER on HN comments. I assume this one uses a few-shot LLM approach instead, which is slower and more expensive at inference, but so much faster to build since there's no tedious labeling needed. [0]  https://news.ycombinator.com/item?id=28596207  The Book of Dragons by Edith Nesbit is listed instead of \"the Dragon book\" The 6 first books reflect the quality comments I often see here on HN. No offense intended towa", "positive": "Show HN: Comet MCP \u2013 Give Claude Code a browser that can click. Claude Code now does this natively without need for a 3rd party browser like Comet:  https://support.claude.com/en/articles/12012173-getting-star...  Did you try that one ?  https://chromewebstore.google.com/detail/blueprint-mcp-for-c...  I was going to ask what makes this better than just using Playwright and this largely answers that question. I will have to try it out and see how it compares. I haven't really had luck with MCP in general for quite a while though. I have just been using Google Antigravity for most of my vibe coding needs. Anyone know of any good articles around having claude code build playwright test suites for a given website and parameters? Claude in Chrome is excellent - as is Claude in Excel. I was shocked at how useful the latter is. \"claude --chrome\" does this out of the box and works pretty well. Another day, another MCP server. Wake me up when we stop needing a new protocol for every AI tool to talk to every other AI tool. There is Browser MCP that works reasonably well:  https://browsermcp.io/  What's the difference? I didn\u2019t realize AI could interact with browsers like this already (guess I\u2019m naive).  Isn\u2019t this setting up for the scenario where the AI is duped into logging into your bank account and transferring your money away?   Not sure I have enough trust to allow an AI to touch a browser. I tried it. My Perplexity premium expired, maybe that is it, but it barely did anything. When I put prompt you suggested, it did open Perplexity in Comet and then I guess didn't get response even though Perplexity did research, so it used regular search mcp to get results... It is cool idea, this is what I would like to have, something to automate boring stuff. Find all LinkedIn connections that are not active and remove them from my network for example. I don't think it is your mcp or code, as tech is just not there yet. It is much easier to accomplish this through other automations", "negative": "SoundCloud Data Breach Now on HaveIBeenPwned. > the impacted data included 30M unique email addresses, names, usernames, avatars, follower and following counts and, in some cases, the user\u2019s country SoundCloud is the worst company, so hostile to former paying users!  I am a hobbyist songwriter and have posted my rough mixes (Apple's Music Memo app which adds drum and bass automagically with two clicks & then mix it in Garage Band) on my SoundCloud for more then ten years.  I signed up for their Artist Pro account and was a member for of such consistently for a few years at $17 a month.  Once you cancel they then hold all your music hostage by hiding it and later threat to delete it.  Horrid! \"The data involved consisted only of email addresses and information already visible on public SoundCloud profiles\". So they've scraped public data. Why care? A lot of \"rap gods\" are about to be exposed as \"Kevin\" from suburbia. all this leaked data pretty much used for one objective now: stealing crypto Kinda sad to see a \"Recommended Actions\", with only sponsors, with ad copy that would be understood by HN readers but not our non-technical friends. (i.e. a simple \"Nothing. No passwords have been leaked yet, only metadata\" in this case) By aggregating breach data by email, this tool inadvertently exposes users's full web history, including sensitive sites like crypto/adult/dating platforms, to anyone who knows their address Fun So I guess I should watch out for scams being sent to \"soundcloud@\" on a personal domain. Oh no, how will I distinguish them from my legitimate banking email??? I went through and deleted a bunch of accounts a while ago, SoundCloud being one of them. It looks like I don't show up in the breach. It's nice to know SoundCloud actually deleted my data, I'm never totally sure what happens on the backend. Glad that I removed my SoundCloud account right on time. I think it\u2019s only a matter of time before a service gets breached. It's best to use unique random us"}
{"anchor": "Scaling up test-time compute with latent reasoning: A recurrent depth approach. Twitter thread about this by the author:  https://x.com/jonasgeiping/status/1888985929727037514  Interesting stuff. As the authors note, using latent reasoning seems to be a way to sink more compute into the  model and get better performance without increasing the model size, good news for those on a steady diet of 'scale pills' Latent / embedding-space reasoning seems a step in the right direction, but building recurrence into the model while still relying on gradient descent (i.e. BPTT) to train it seems to create more of a problem (training inefficiency) than it solves, especially since they still end up externally specifying the number of recurrent iterations (r=4, 8, etc) for a given inference. Ideally having recurrence internal to the model would allow the model itself to decide how long to iterate for before outputting anything. One of the benefits of using thinking tokens compared to \u201cthinking in a latent\u201d space is that you can directly observe the quality of the CoT. In R1 they saw it was mixing languages and fixed it with cold start data. It would be hard to SFT this because you can only SFT the final result not the latent space. I also notice the authors only had compute for a single full training run. It\u2019s impressive they saw such good results from that, but I wonder if they could get better results by incorporating recent efficiency improvements. I would personally not use this architecture because 1) it adds a lot of hyperparameters which don\u2019t have a strong theoretical grounding and 2) it\u2019s not clearly better than simpler methods. My opinion is that opaque reasoning is a prerequisite for many of the worst possible AI outcomes. We should make reasoning fully visible in the output space. Slightly off topic, I rarely see paper talks about their failed training runs, and why those runs failed. This paper is definitely a breath of fresh air. And their analyses of their failures", "positive": "Ask HN: Burned out from tech, what else is there?. I\u2019m still on the fence of buying a large cargo van like a Sprinter and outfitting it to be a one-man \u2018expeditor\u2019 cargo carrier. Travel the country hauling one-off pallets from point A to B, check the DAT boards for loads and journeys abound. I'm in a similar situation, thinking about a paycut or sabbattical just to do something different. I think it's key to think about what makes you happy and interested in your work, and then find a way to map from your current position to a new position where you can do more of that. If you're ever unsure or worried about making a move, remember that life is fluid, things change, doors open and close all the time. Taking a step forward into the unknown will light the path to the next step, but taking that first step requires accepting some uncertainty and trusting it will work out anyway. If you want to try something totally different, check if you have a local volunteer fire department looking for new recruits.  I know a few people who eventually transitioned from tech and made it into their full-time career.  I think part of the draw is you show up, solve a problem, leave and feel good about it. When I reached this point, I left to start my own company. Build something that would actually be mine. Though obviously that's easier said than done. For a few years I switched to supporting medical research, which made me feel good. The tech BS sadly penetrated there after a few years too which ended that for me. Take a break for a few months to recalibrate what you want from life.  Tech will still be here when you\u2019re ready again.  Go travel, use your physical body to walk and hike and lift, have a couple of flings, go to a bar at noon, work a few temp jobs, apply minimalism in your life, learn about something you like, etc. I often dream about being a carpenter, a park ranger, or a truck driver. But it feels like it's too late, and my family would suffer from the lack of funds as I t", "negative": "Introduction to PostgreSQL Indexes. Essential reading. More in-depth than an introduction, but without being overly impenetrable except to those dealing with the internals. This looks really awesome for Postgres For general B Tree index resources this has been my got to site for years  https://use-the-index-luke.com/  Linking to the postgresql docs since they are very well written and surprisingly enjoyable to read.  https://www.postgresql.org/docs/current/indexes-intro.html  The section on multi-column indexes mirrors how I was taught and how I\u2019ve generally handled such indexes in the past. But is it still true for more recent PG versions? I had an index and query similar to the third example, and IIRC PG was able to use an index, though I believe it was a bitmap index scan. I am also unsure of the specific perf tradeoffs between index scan types in that case, but when I saw that happen in the EXPLAIN plan it was enough for me to call into question what had been hardcoded wisdom in my mind for quite some time. Further essential reading is the classic  Use The Index, Luke  [0] site, and the book is a great buy for the whole team. 0:  https://use-the-index-luke.com/  It would be nice to see out-of-the-box support in PostgreSQL for what's known as incremental view maintenance. It's very much an index in that it gets updated automatically when the underlying data changes, but it supports that for arbitrary views - not just special-cased like ordinary database indexes. Related,  Use the Index Luke   https://use-the-index-luke.com/  Is there a use-the-index-luke for MongoDB...? I love this style of writing. Simple, humble and direct transfer of knowledge. Good timing for this article. The multi-column index advice was always confusing because the \"leading column\" rules had real performance implications, but bitmap index scans made it less catastrophic than the textbooks suggested. Skip scan in PG 18 changes a lot of that conventional wisdom. Worth updating the mental mod"}
{"anchor": "Ratatui \u2013 App Showcase. the title of this post is odd? it\u2019s a showcase of TUI applications built with this Rust crate \u2014 which I am hearing about for the first time, and am interested in. I was expecting a blog post on why Rust is experiencing a TUI revolution or something I've seen lots of TUIs lately, why is that? What is the renewed interest? The only places I know of is Awesome TUIs [0] and terminaltrove [1] I can also see that Ratatui has an awesome list too [2]. [0]  https://github.com/rothgar/awesome-tuis  [1]  https://terminaltrove.com/  [2]  https://github.com/ratatui-org/awesome-ratatui  Some of the most interesting projects here have the worst installation stories.It's sort of tilting at windmills to not acknowledge that people are going to mostly install through package managers for their platform by advertising it as such. I'm not suggesting there's anything wrong with building from source. On the contrary, I think it's fantastic as many targets are supported here as there are! I think it's a shame more people aren't discovering them is all. Very dope. I really like dua as my mac only has 256 GB. What is the best / most popular / user friendly terminal http client I can replace postman with. Has a history I can search, save favorites, secure etc. Ratatui is neat but the way it's architected, you need to take on third party dependencies for each individual widget. And we're talking basic things like spinners, checkboxes, text areas, etc. -- there aren't too many widgets built into ratatui itself. I didn't like the idea of taking all that on so instead I went with something more handrolled. Ratatui is awesome! Just built a little chat client with it, tons of fun.  https://terma.mattmay.dev/  I'm really waiting for the TUI web browser. That would let me live completely in the terminal. Is anyone working on this? With the speed terminals are and support for graphics through things like sixel and shaders I'd love to have a browser even if I couldn't do videos", "positive": "Greenland sharks maintain vision for centuries through DNA repair mechanism. Sharks are so cool, man. They\u2019ve just been chilling on the planet for 400 million years, swimming the oceans while epochs passed them by in their periphery. Their entire biology is pretty much unchanged. They\u2019ve been sharks the whole time. This is so messed up harvesting the eye from a creature that lives hundreds of years. I guess they put the shark down. RIP one eye. It\u2019s sinful to fish and kill these ancient creatures up from the deep for minor scientific progress. So wait did they just catch a 200 year old shark and cut its eye ball out to have a look? Highly recommend the book \"Shark Drunk: The Art of Catching a Large Shark from a Tiny Rubber Dinghy in a Big Ocean\" by Morten Str\u00f8ksnes if you're interested in old sharks, small boats or deep oceans  https://bookshop.org/p/books/shark-drunk-the-art-of-catching...  I\u2019m starting to realise we don\u2019t really want a cure to aging. Imagine a world where people like Stalin never die. People like bill gates never have to pretend to be a nice person\u2026 If there\u2019s no chance of death, there will never be any progress in society. People in power would just establish a tighter and tighter grip. All the boomers would be immune to death and disease, but the treatment would be banned for the young because they haven\u2019t done enough to earn it. Unfortunately it also seems like these sharks are plagued by parasites in their eyes:  The shark is often infested by the copepod Ommatokoita elongata, a crustacean that attaches itself to the shark's eyes.[17] The copepod may display bioluminescence, thus attracting prey for the shark in a mutualistic relationship, but this hypothesis has not been verified.[18] These parasites can cause multiple forms of damage to the sharks' eyes, such as ulceration, mineralization, and edema of the cornea, leading to almost complete blindness.[11] This does not seem to reduce the life expectancy or predatory ability of Greenland shar", "negative": "Spanish track was fractured before high-speed train disaster, report finds. Wow, that's a really big gap. No wonder it derailed What are the some of the ways that tracks are monitored for fractures like this?  It must have been pretty substantial in order to be described as \"complete lack of continuity\".  Makes me think of literally electronic continuity tests -- are those ever used in this context?  Or how about cameras mounted on trains using image processing?  Or drones? It seems a shame that a few other trains passed beforehand with this anomaly in place and yet it went undetected. My gut feeling says a lot of fatalities could have been prevented with a physical barrier between both tracks. Shouldn't this be mandatory with high speed trains? While these events are statistically very rare, it is worth remembering that there have been two separate events in the past twenty years in Spain where high-speed trains have derailed leading to multiple fatalities [1][2]. In contrast, the Japanese Shinkansen has a spotless record since its introduction in the 1960s [3]. Not a single fatality due to a crash or derailment. And that's in a country with a much larger population and much higher passenger count per year. What do they do differently? [1]  https://en.wikipedia.org/wiki/Santiago_de_Compostela_derailm...  [2]  https://en.wikipedia.org/wiki/2026_Adamuz_train_derailments  [3]  https://en.wikipedia.org/wiki/Shinkansen#Safety_record  I wonder how common it is for train tracks to fracture? And what systems are in place to actually detect this. There was recently a post on a German subreddit where the OP found a fracture in the German rail[0], albeit much smaller. 0.  https://old.reddit.com/r/drehscheibe/comments/1qe9ko2/ich_gl...  AFAIK continuously welded tracks (like those used in high speed rail) are also slightly tensioned, so a break in a single point could make it look like a whole section of track is missing, as tension is released. Some more info from Spanish med"}
{"anchor": "Ask HN: What non-fiction do you read?. Jaws: The Story of a Hidden Epidemic Modern environments and lifestyles have changed our jaw development dramatically, contributing to the high prevalence of sleep-disordered breathing (snoring through to obstructive sleep apnea), chronic tension, jaw joint problems, and orthodontic need. \"The Molecule of More\" by Daniel Z. Lieberman and Michael E. Long. A bit naive but fascinating narrative about how dopamine controls our feelings, addictions, and, basically, happiness. \"Future Noir: The Making of Blade Runner\" by Paul Sammon A deep history of the making of the movie \"Blade Runner\". Very enjoyable if you liked the movie. Pilgrim at Tinker Creek by Annie Dillard Your Inner Fish: A Journey Into the 3.5-Billion-Year History of the Human Body\n - Really cool account of human evolutionary history Stolen Focus (Johann Hari)\n - About how we've lost (and can regain) the ability to focus due to technological distraction (currently social media, etc. but hasn't always been) Chip War\n - History and geopolitical significance of the semiconductor industry Plato's works surrounding Socrates' death: Phaedo, Crito, Euthyphro, The Apology. Its fascinating to discover how many thoughts and ideas they had which are still relevant in our societies today. Also, they are incredibly readable, its like taking part in on a conversation among friends. I only read non-fiction; mostly philosophy. Here are some books off the top of my head: * The Inner Citadel/Philosophy as a Way of Life by Pierre Hadot * Plato's dialogues (someone already mentioned a few of them, but the Republic was missing from their list). * Epictetus (Discourses and Enchiridion) * The various essays/letters of Seneca * Matter and Consciousness by Churchland (older, but fascinating) * The Mediations of Marcus Aurelius * (mostly) any Buddhist texts * What a Plant Knows * Moonwalking with Einstein There are tons of fascinating books, way too many to list. All Pulitzer price winning non-f", "positive": "GPT-5.2. Marginal gains for exorbitantly pricey and closed model\u2026.. Everything is still based on 4 4o still right? is a new model training just too expensive? They can consult deepseek team maybe for cost constrained new models.  https://openai.com/index/introducing-gpt-5-2/  \"Investors are putting pressure, change the version number now!!!\" Slight increase in model cost, but looks like benefits across the board to match.     gpt-5.2 $1.75 $0.175 $14.00\n  gpt-5.1 $1.25 $0.125 $10.00   GPT-5.2 System Card PDF:  https://cdn.openai.com/pdf/3a4153c8-c748-4b71-8e31-aecbde944...  From GPT 5.1 Thinking: ARC AGI v2: 17.6% -> 52.9% SWE Verified: 76.3% -> 80% That's pretty good! This seems like another \"better vibes\" release. With the number of benchmarks exploding, random luck means you can almost always find a couple showing what you want to show. I didn't see much concrete  evidence this was noticeably better than 5.1 (or even 5.0). Being a point release though I guess that's fair. I suspect there is also some decent optimizations on the backend that make it cheaper and faster for OpenAI to run, and those are the real reasons they want us to use it. It baffles me to see these last 2 announcements (GPT 5.1 as well) devoid of any metrics, benchmarks or quantitative analyses. Could it be because they are behind Google/Anthropic and they don't want to admit it? (edit: I'm sorry I didn't read enough on the topic, my apologies) So GDPval is OpenAI's own benchmark. PDF link:  https://arxiv.org/pdf/2510.04374  They used to compare to competing models from Anthropic, Google DeepMind, DeepSeek, etc. Seems that now they only compare to their own models. Does this mean that the GPT-series is performing worse than its competitors (given the \"code red\" at OpenAI)? Are benchmarks the right way to measure LLMs? Not because benchmarks can be gamed, but because the most useful outputs of models aren't things that can be bucketed into \"right\" and \"wrong.\" Tough problem! The ARC AGI 2 bump to", "negative": "Updates to our web search products and  Programmable Search Engine capabilities. Google quietly announced that Programmable Search (ex-Custom Search) won\u2019t allow new engines to \u201csearch the entire web\u201d anymore. New engines are capped at searching up to 50 domains, and existing full-web engines have until Jan 1, 2027 to transition. If you actually need whole-web search, Google now points you to an \u201cinterest form\u201d for enterprise solutions (Vertex AI Search etc.), with no public pricing and no guarantee they\u2019ll even reply. This seems like it effectively ends the era of indie / niche search engines being able to build on Google\u2019s index. Anything that looks like general web search is getting pushed behind enterprise gates. I haven\u2019t seen much discussion about this yet, but for anyone who built a small search product on Programmable Search, this feels like a pretty big shift. Curious if others here are affected or already planning alternatives. UPDATE: I logged into Programmable Search and the message is even more explicit: Full web search via the \"Search the entire web\" feature will be discontinued within the next year. Please update your search engine to specify specific sites to search. With this link:  https://support.google.com/programmable-search/answer/123971...  Relevant: Waiting for dawn in search: Search index, Google rulings and impact on Kagi  https://news.ycombinator.com/item?id=46708678  I had misread the title as \"Google is ending (full-web search) for [aka in favour of] (niche search engines)\" The correct parsing is: \"Google is ending (full-web search for niche search engines)\" Is this about the little Google Search Bar that is present on some websites? Or am I mistaking something Meanwhile in Europe: Qwant and Ecosia team up to build their own search index:  https://blog.ecosia.org/eusp/  What examples are there of people using this? I'm curious about what it would take to build my own \"toy\" search engine with its own index. Anyone ever tried this? The 'Go"}
{"anchor": "Gemini Embedding: Powering RAG and context engineering. The Matryoshka embeddings seem interesting: > The Gemini embedding model, gemini-embedding-001, is trained using the Matryoshka Representation Learning (MRL) technique which teaches a model to learn high-dimensional embeddings that have initial segments (or prefixes) which are also useful, simpler versions of the same data. Use the output_dimensionality parameter to control the size of the output embedding vector. Selecting a smaller output dimensionality can save storage space and increase computational efficiency for downstream applications, while sacrificing little in terms of quality. By default, it outputs a 3072-dimensional embedding, but you can truncate it to a smaller size without losing quality to save storage space. We recommend using 768, 1536, or 3072 output dimensions. [0] looks like even the 256-dim embeddings perform really well. [0]:  https://ai.google.dev/gemini-api/docs/embeddings#quality-for...  To anyone working in these types of applications, are embeddings still worth it compared to agentic search for text? If I have a directory of text files, for example, is it better to save all of their embeddings in a VDB and use that, or are LLMs now good enough that I can just let them use ripgrep or something to search for themselves? Question to other GCP users, how are you finding Google's aggressive deprecation of older embedding models? Feels like you have to pay to rerun your data through every 12 months. I feel like tool calling killed RAG, however you have less control over how the retrieved data is injected in the context. > Embeddings are crucial here, as they efficiently identify and integrate vital information\u2014like documents, conversation history, and tool definitions\u2014directly into a model's working memory. I feel like I'm falling behind here, but can someone explain this to me? My high-level view of embedding is that I send some text to the provider, they tokenize the text and then run ", "positive": "Resistance training load does not determine hypertrophy. tldr appears to be that if you work to fatigue it doesn't matter if you fatigue out with high weights vs low weights I know it's practically de rigeur to jump into the comments and immediately complain about methodology for any study that makes it to the front page, and I want to emphasize I don't distrust their findings, but I would like to see an equivalent study go out longer than 10 weeks. When I've been taking weightlifting seriously I feel like I don't even start to notice hypertrophy until 8-10 weeks. I feel like 6 months is the actual period where results would matter, to me, but I assume \"subject compliance\" is pretty difficult to get for such a timeframe, if you're really watching dietary intake and ensuring subjects go to failure (which, to its credit, this study did). I thought it was already well understood/researched that it's not the weights that matter, but effectively taking your sets to muscular failure. While one might think \"I can do 50 reps with low weights\" there is practical aspects to this - you don't wand to spend hours at the gym, and doing heavy weights at 5-7 reps is sufficient as long as you are close or at muscular failure. If I read this correctly the gist is that it does not matter if you use heavy weights with few reps (common body builder wisdom) or lighter weights with more reps. As long as you always exercise to\ncomplete muscle fatigue you'll\nget the maximum for your genetics (which itself varies a lot). The group that did lower reps with higher weight, had the better one rep max at the end of the study, but they didn\u2019t measure if the higher rep group had greater endurance. Which seems a bit odd, considering their conclusion is both groups grew the same amount of muscle which fine but if the muscle is adapted for something different in each group, you would want to capture that. > Twenty healthy young male participants completed thrice-weekly resistance exercise sessions for", "negative": "When two years of academic work vanished with a single click. A plant science academic who can't be bothered to back up their work... If that was the intellectual calibre of the person, I wonder how truly worthwhile the lost work was. The 2nd comma he uses is incorrect. Did he also use ChatGPT for this article? I frown when people currently trust AI, let alone have been doing so for 2 years already. This is exactly why I don't rely on the web UI for anything critical. It seems like a mistake to treat a chat log as a durable filesystem. I just hit the API and store the request/response pairs in a local Postgres DB. It's a bit of extra boilerplate to manage the context, but at least I own the data and can back it up properly. once upon a time i had a boss who asked for a \"super admin\" account to \"trump\" the domain administrators..and a \"master key\" to decrypt any file , in case the user lost their key. Is it deleted though? Last I heard there was a court case or some such that required them retaining all data for a lawsuit, did that go away? Never rely on any subscription based service for any data that is important. Never use data formats that lock you in. Especially not online services without (automatic) export options. Keep a copy (cloud) and a backup (offline) for all you own data. relevant:  https://www.youtube.com/watch?v=7pqF90rstZQ  This issue looks like a situation where one person stored all their files and folders in the Windows Recycle Bin and somebody emptied it. It might be my professional deformation, but I never store anything in ChatGPT and Claude for longer than a day or two. A typical example of Hyrum's Law:  ...all observable behaviors of your system\nwill be depended on by somebody . It's like how your draft folder feature will be used as a secret messaging app by a general and his mistress, or as Don Norman points out, your flat topped parapet will be used as a table for used cups, or your reliable data store of chats will be used as academic res"}
{"anchor": "Nested Learning: A new ML paradigm for continual learning. Someone's trying to reproduce it in open  https://github.com/kmccleary3301/nested_learning  I've been waiting for someone to make this since about 2019 it seemed pretty self-evident. It will be interesting when they get to mixed heterogeneous architecture networks with a meta network that optimizes for specific tasks. There is also a related youtube video online: Ali Behrouz of Google Research explaining his poster paper entitled \"Nested Learning: The Illusion of Deep Learning Architecture\" at NeurIPS 2025.  https://www.youtube.com/watch?v=uX12aCdni9Q  Damn, and before that, Titan from Google:  https://research.google/blog/titans-miras-helping-ai-have-lo...  We are not at the end of AI :) Also, someone claimed that NVIDA combined diffusion and autoregression, making it 6 times faster, but couldn't find a source. Big if true! The idea is interesting, but I still don\u2019t understand how this is supposed to solve continual learning in practice. You\u2019ve got a frozen transformer and a second module still trained with SGD, so how exactly does that solve forgetting instead of just relocating it? Surprised this isn't by lucidrains, they usually have the first repro attempts. This tidbit from a discussion on that repo sounds really interesting: > You can load a pretrained transformer backbone, freeze it, and train only the HOPE/TITAN/CMS memory pathways. In principle, you would: - Freeze the shared transformer spine (embeddings, attention/MLP blocks, layer norms, lm_head) and keep lm_head.weight tied to embed.weight. - Train only the HOPE/TITAN memory modules (TITAN level, CMS levels, self-modifier projections, inner-optimizer state). - Treat this like an adapter-style continual-learning finetune: base model provides stable representations; HOPE/CMS learn to adapt/test-time-learn on top. ---- Pretty cool if this works. I'm hopeful more research will go into reusing already trained models (other than freeze existing parts", "positive": "Advent of Code 2025: The AI Edition \u2013 By Peter Norvig. I'm sorry, but what's the point here ? It's not for a job or improve a LLM or doing something useful per se, just to \"enjoy\" how version X or Y of an LLM can solve problems. I don't want to sound grumpy or but it doesn't achieve anything, this is just a showcase of how a \"calculator with a small probability of failure can succeed\". Move on, do something useful, don't stop being amazed by AI but please stop throwing it at my face. I enjoy reading Peter\u2019s \u2018Python studies\u2019 and was surprised to see here a comparison of different LLMs for solving advent of code problems, but the linked article is pretty cool. Peter and a friend of his wrote an article over a year ago discussing whether or not LLMs are already AGI, and after re-reading that article my opinion was moved a bit to: LLMs are AGI in broad digital domains. I still need to see embodied AI in robots and physical devices before I think we are 100% of the way there. Still, I apply Gemini and also a lot of open weight models to both 1. coding problems and 2. after I read or watch material on Philosophy I almost always ask Gemini for a summary, references, and a short discussion based on what Gemini knows about me. > I started with the Gemini 3 Pro Fast model ... Quiet product announcement. Odd that it came up with     pattern_start = 1 if half_digits == 1 else 10 ** (half_digits - 1)\n  \nwhen     10 ** (half_digits - 1)\n  \nis fine. Last year I used LLM to solve AoC, to see how they could keep up, to learn how to steer them and to see how the open models will perform.  When I talk about it, quite a bit of \"programmers\" get upset.  Glad to see that Norvig is experimenting. p/s, anyone who gets upset that folks are experimenting with LLMs to generate code or solve AoC should have their programmer's card revoked.        > Move on, do something useful, don't stop being amazed by AI but please stop throwing it at my face.\n\n  \nDo you see the irony in what you did? So, h", "negative": "Porting 100k lines from TypeScript to Rust using Claude Code in a month. For typing \u201cyes\u201d or \u201cy\u201d automatically into command prompts without interacting, you could have utilized the command \u2018yes\u2019 and piped it into the process you\u2019re running as a first attempt to solving the yes problem. \n https://man7.org/linux/man-pages/man1/yes.1.html  How much does it cost to run Claude Code 24 hrs/day like this. Does the $200/month plan hold up? My spend on Cursor has been high... I'm wondering if I can just collapse it into a 200/month CC subscription. I'm hoping that one day we can use AI to port the millions of lines in the modules of the Python ecosystem to a GIL-free version of Python. Did you ever consider using something like Oh My Opencode [1]?\nI first saw it in the wake of Anthropic locking out Opencode. I haven\u2019t used it but it appears to be better at running continuously until a task is finished. Wondering if anyone else has tried migrating a huge codebase like this. [1]  https://github.com/code-yeongyu/oh-my-opencode  Some quotes from the article stand out: \n\"Claude after working for some time seem to always stop to recap things\"\nQuestion: Were you running out of context? That's why certain frameworks like intentional compaction are being worked on.  Large codebases have specific needs when working with an LLM. \"I've never interacted with Rust in my life\" :-/ How is this a good idea? How can I trust the generated code? This is actually pretty incredible. Cannot really argue against the productivity in this case. Honestly I am really interested in trying to port the rust code to multiple languages like golang,zig, even niche languages like V-lang/Odin/nim etc. It would be interesting if we use this as a benchmark similar to  https://benjdd.com/languages/  or  https://benjdd.com/languages2/  I used gitingest on the repository that they provided and its around ~150k tokens Currently pasted it into the free gemini web and asked it to write it in golang and it said that li"}
{"anchor": "Miami, your Waymo ride is ready. I\u2019m going to Miami next week.  Time for my first WayMo ride. We got these in Atlanta.  I haven't had the chance to ride yet but watching them it's pretty clear that they're legit. I think we're on the cusp of something that will change the landscape of our cities.  It's going to revolutionize getting around and take a chunk out of the land dedicated to parking. Still can't believe the prices are comparable to Uber, sometimes costing even more. It should be significantly less to the point it drives Uber out of business. Is Waymo close to bankruptcy, unable to be profitable, or are they just greedy? Waymo is such an interesting case study. For most other ~AI deployments you have strong public reaction to the proliferation of slop, non-human failure modes, cost cutting at the expense of quality, etc. But I haven't met a single person who doesn't like the experience of Waymo. They ended up cracking the code on what I suspect people really want: - consistent car quality - safety of the drive (conservative driving and potential fear of drivers) - no randomly chatty driver All of those feel like a breath of fresh air especially when stacked up against the current state of Uber & Lyft rides. People really just want consistency. I don't actually think you needed AI to get there (I've had occasional rides in black cars that provided the same experience). Waymo was just right time, right place, right price. Funny that they apparently didn't include South Beach, at least according to the map. The US would benefit much more from a good railroad system. Everybody can drive a car. They have solved the wrong problem. Why would I use Waymo if an Uber/Lyft costs the same? If it gets in an accident, who pays my medical bills? I was at a conference in Phoenix in November and took seven Waymo trips during my stay. Four of those were fairly long (20-minute) trips. I preferred Waymo to the Uber/Lyft experience because it felt private. It was just me and my", "positive": "Bus stops here: Shanghai lets riders design their own routes. This is really brilliant \u2014 like desire paths, but for transit. Obviously execution will be challenging, but the concept is fantastic, and China/Shanghai seems like one of the few places with the requisite density & state capacity to actually make this work. Generally I think that the design of public spaces has SO MUCH room to be improved by just responding to the wisdom of the crowd. I'm glad that Shanghai has moved to the next level in public transportation in meeting customer demand. Most cities don't have the funds to buy smallish buses and labour available as drivers. They don't have the money or willpower to get frequencies to turn up and go levels (ie frequent) and leave people with long walks to widely spaced routes. Tangent: I\u2019ve often thought that it would be great to let people design their own political districts to reduce gerrymandering At the polling place you\u2019d get a map with your census tract and then be asked \u201cwhich two or three adjacent tracts are most similar to your community\u201d. Eventually you\u2019d end up with some sort of gram matrix for tract-to-tract affinity, and then you could apply some algorithmic segmentation. Two problems: - this is far too complex for most voters to understand, much less trust, what\u2019s happening - the fact it\u2019s \u201calgorithmic\u201d would give a sheen of pseudo objectivity, but the selection of the actual algorithm would still allow political infouence over boundaries Chiming in from Los Angeles, USA to say wow, must be nice living in a modern society that prioritizes public transit and peoples' ease of movement. I know, I know, it comes with trade offs of living in an authoritarian state, but the absolute abysmal state of infrastructure in this country is maddening. Ever been on a train in Denmark or Japan or Switzerland? This remind me that road router should be walked by passenger rather than designed by designers. China is the only modern country that has both the cap", "negative": "Show HN: Rails UI. Is this another Tailwind wrapper? Yes, it is. ugh this looks dated even by 2016 standards when will developers learn UI actually matters bootstrap was a mistake, and lowered the bar for everyone i don't get these types of products anymore. i think they're useful in their own way, but i can literally create styles with claude/gemini in a heartbeat and not have to pay some insane fee. I think you missed a trick not naming it Railwind UI. I used this about a year ago when I went through a short Rails phase. I was a bit surprised not to see more Rails-specific UI libraries considering how batteries-included the rest of the framework is, and at the time I didn't really 'get' tailwind. I'm not in a Rails phase anymore, but nice work on the library! maybe I'm just dumb but a lot of these elements don't seem to work? the \"...\" buttons don't open any flyout, the dropdown doesn't open up... otherwise looks cool though I wish I could use this \u2013 unfortunately UI frameworks are a political problem at every company I've worked at. The designers feel undermined or threatened by it, and product owners want to dictate design. Despite the massive productivity benefits of a UI framework, I've never been able to convince stakeholders to actually adopt one. If you\u2019re showing off a UI framework, I shouldn\u2019t be accidentally scrolling left and right on the page on mobile / my iPhone. Couldn\u2019t be bothered to scroll down the page to look at components while accidentally activating horizontal scrolling. Broken in Safari on iphone. For example: - table background moves left when table is scrolled horizontally - actions in table and dropdown do nothing on tap - text on buttons is selectable (really?) im always surprised that Rails is still relevant i havent used it since 2006 opting for php and django i might give it another shot, any reason you like this more than django or other frameworks I have hardware acceleration disabled in Firefox and my 5800X spins up trying to rend"}
{"anchor": "ChatGPT Containers can now run bash, pip/npm install packages and download files. Regular default ChatGPT can also now run code in Node.js, Ruby, Perl, PHP, Go, Java, Swift, Kotlin, C and C++. I'm not sure when these new features landed because they're not listed anywhere in the official ChatGPT release notes, but I checked it with a free account and it's available there as well. I wonder how long npm/pip etc even makes sense. Dependancies introduce unnecessary LOC and features which are, more and more, just written by LLMs themselves. It is easier to just write the necessary functionality directly. Whether that is more maintainable or not is a bit YMMV at this stage, but I would wager it is improving. Maybe soon we have single use applications. Where ChatGPT can write an App for you on-the-fly in a cloud sandbox you interact with it in the browser and fulfill your goal and afterwards the App is shutdown and thrown away. I wonder if the era of dynamic programming languages is over. Python/JS/Ruby/etc. were good tradeoffs when developer time mattered. But now that most code is written by LLMs, it's as \"hard\" for the LLM to write Python as it is to write Rust/Go (assuming enough training data on the language ofc; LLMs still can't write Gleam/Janet/CommonLisp/etc.). Esp. with Go's quick compile time, I can see myself using it more and more even in my one-off scripts that would have used Python/Bash otherwise. Plus, I get a binary that I can port to other systems w/o problem. Compiled is back? Seems like everyone is trying to get ahead of tool calling moving people \"off platform\" and creating differentiators around what tools are available \"locally\" to the models etc.  This also takes the wind out of the sandboxing folks, as it probably won't be long before the \"local\" tool calling can effectively do anything you'd need to do on your local machine. I wonder when they'll start offering virtual, persistent dev environments... Not sure if this is still working. I tried get", "positive": "Scientists identify brain waves that define the limits of 'you'. Original Paper: Parietal alpha frequency shapes own-body perception by modulating the temporal integration of bodily signals,   https://www.nature.com/articles/s41467-025-67657-w   https://news.ki.se/how-brain-waves-shape-our-sense-of-self  FTA: > With a third group of participants, they used a non-invasive technique called transcranial alternating current stimulation to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt. I know this is largely orthogonal to the article, and I know what \u201cnon-invasive\u201d means and why it\u2019s used in this sentence, but it made me chuckle - \u201cthis technique that changed the subject\u2019s brain waves sufficient to literally impact their sense of self - but don\u2019t worry! It\u2019s non-invasive!\u201d The manipulation part is what fascinates me. They didn't just correlate alpha wave frequency with ownership perception. They used transcranial stimulation to artificially speed up or slow down the waves, and the subjective experience changed accordingly. That's a pretty direct causal link between a measurable brain state and something as fundamental as \"where does my body end?\" Wow, that\u2019s really interesting! It seems like alpha waves are the \u2018tick rate\u2019 of this system, and some set number of ticks are required to update the body model? This has me thinking of Pluribus The idea of \"ownership of a body\" made me think about a quote I heard a long time ago, while talking amongst musicians while waiting to get up and perform. It felt like some secret knowledge that I gained privilege to, while somewhat inebriated and it hasn't left me since. > I _have_ a body, I _am_ a soul. Maybe what they're identifying is the first half of that statement, how we interpret the former, through the presence of the latter. So, how far does the human electric field extend outside the body? May be only picovolts or in that range... But c", "negative": "Russia using Interpol's wanted list to target critics abroad, leak reveals. > Pestrikov found he was named in a red diffusion after he fled Russia in June 2022 It doesn't say how he found out, I would imagine he's regularly checking online, he was stopped at a control check somewhere? Seems to me that most people wouldn't have a clue until they're being arrested. But again another scummy behaviour from the Russian government. It might as well just be prudent to ignore their requests altogether. Boy who cried wolf. Edit : it did indeed say how. I missed it. > After he fled to France, he was worried that the Kremlin might try to target him there, so he contacted Interpol I\u2019ll just assume this is correct because I believe the Russian government has mastered the art of just lying when there are no consequences, but if I was being critical, this phrase is giving me pause for evaluating the conclusions. > The data is not complete\u2026 Currently in my country (Austria) there is a court process against an official who made register look-ups of critical journalists who live here and handed the address to FSB-Agents who later broke into this journalists apartment. The ruzzians are completely unscrupulous.  https://www.reuters.com/world/austrian-ex-intelligence-accus...  Not denying that Russia abuses Interpol, but I have doubts about this particular narrative that he was some kind of \"government critic.\" From what I can find, he privatized a state corporation in the 90s for pennies (lots of very shady deals back then, usually facilitated by organized crime). From 2010-2020, I can find media reports about his legal problems with tax evasion. In 2021, there was a case where he threatened people with murder while holding a rifle. He was perfectly fine living in Putin's Russia until 2022, when he took 250 mln from the company's budget without consulting the board of directors and left Russia (and prosecutors also found that the privatization in the 90s was illegal). I suspect he's pa"}
{"anchor": "TSMC Risk. There are some near ready foundries in the US and in EU, not to mention South Korea. It would take a few years to catch up of course. What I worry more about is the full lock-in of TSMC production capacity by nvidia/apple/amd/etc for their chips on their latest and greatest silicon process (aka the best in the world). There is 'no space' for performant large RISC-V implementations or other alternative (and it will require several iterations and mistakes will be made) \"AI has a physical dependency in Taiwan that can be easily destroyed by Chinese missiles, even without an invasion\" ? Arguably false. Why do you think the US has encouraged TSMC foundries, now inside Arizona ? It's obviously to protect against the scenario that China takes Taiwan. In that case, give it 6 months or less for US TSMC foundries to produce the finest. China taking Taiwan will likely not result in the CCP getting any technology, certainly Taiwanese have \"contingency plans\" to vaporize all tech in the event they are invaded. > AI has a physical dependency in Taiwan that can be easily destroyed by Chinese missiles, even without an invasion Taiwan has missiles with the range and warheads to strike the three gorges dam. An attack by China would end very poorly for everybody.  There are millions of people living in the inundation zone. From a NatSec perspective, TSMC isn't really a bottleneck - most weapon systems use SoCs and microcontrollers that can be fabbed on \"legacy nodes\" (ie. 28/40/60/90nm) or 14/20/22nm nodes, and compound semiconductors. The ability to mass produce a Pascal or Volta comparable GPU or Apple A11 comparable SoC is all you need for more cutting edge systems. Power Electronics and Compound Semiconductors (GaN, SiC) have historically been the biggest bottleneck. The bigger risk for the TSMC-China aspect is TSMC's planned exit of GaN foundry production by 2027. Most Chinese manufacturers  still  depend on TSMC-produced GaNs wafers instead of domestically produced Ga", "positive": "Ask HN: Iran's 120h internet shutdown, phones back. How to stay resilient?.  https://en.wikipedia.org/wiki/Stoicism  Starlink and/or BGAN/satellite phones. Maybe  https://meshtastic.org ? If the phones are working, 56k modem. HAM radio is your best option. WiFi Halow is a longer range protocol (still probably not long enough). But something like this can get people connected:  https://openmanet.net  Old fashioned phone trees can be really useful IMHO OP. We used them when I worked in a school. If there was winter weather, you'd call say, everyone with a last name from A to G in the staff directory, someone else calls G to K, and so on and so forth. You can combine the phone tree with literal runners -- so basically, someone takes their burner and calls suburbs A,B,C and D and then the runners go out and pass the word about the protest or action. V.92 dial-up. Slow and expensive, but it's Internet access. Problem is that most methods involve making your location known openly. The Dark Forest book of the Remembrance of the Earth Past explains why it is not a good idea to do so in the current circumstances For dense areas, mesh applications like BitChat (Jack Dorsey) could bypass the need for a network with p2p bluetooth mesh networks. And works with existing devices, vs something like meshtastic which needs an installed base (afaik).  https://en.wikipedia.org/wiki/Bitchat  some DNS tunneling solutions work (dnstt for example). Also, many people have smuggled Starlink are are providing proxies inside Iran. Ideally cjdns or similar can be used inside the country to create an alternative encrypted mesh network inside the borders, with some \"exit nodes\" out. HF radio. Highly depdendent on space weather, but generally I can communicate around the world with only 100 watts and a long wire. Be aware though that transmitting on any radio is like turning on a giant, extremely bright light bulb directly above your antenna. Anyone with basic radio know-how will be able to hear y", "negative": "Find 'Abbey Road when type 'Beatles abbey rd': Fuzzy/Semantic search in Postgres. I was just starting to learn about embeddings for a very similar use on my project. Newbie question: what are pros/cons of using an API like gpt Ada to calculate the embeddings, compared to importing some model on Python and running it locally like in this article? Great post. Explains the concepts just enough that they click without going too deep, shows practical implementation examples, how it fits together. Simple, clear and ultimately useful. (to me at least) I found fuzzy search in Manticore to be straightforward and pretty good. Might be a decent alternative if one perceives the ceremony in TFA as a bit much. The rewritten title is confusing imo. Can I propose: \u201cFinding \u2018Abbey Road\u2019 given \u2018beatles abbey rd\u2019 search with Postgres\u201d these days i find myself yearning to type \"Beatles abbey rd\" and find only \"Beatles abbey rd\" for 50,000 rows I'd much rather just use fzf/nucleo/tv against json files instead of dealing with database schemas. \nWhen it comes to dealing with embedding vectors rather than plaintext then it gets slightly more annoying but still feels like such an pain in the ass to go full database when really it could still be a bunch of flat open files. More of a perspective from just trying to index crap on my own machine vs building a SaaS > Abbey Road > The Dark Side of the Moon > OK Computer Those are my 3 personal records ever. I feel so average now... tl,dr: A demo of pg_trgm (fuzzy matcher) + pgvector (vector search). FWIW, the performance considerations section is a little simplistic, and probably assumes that exact dataset/problem. For GIN for example, perfomance depends a lot on the size of the search input (the fewer characters, the more rows to compare) as well as the number of rows/size of the index. It also mentions GiST (another type of index which isn't mentioned anywhere else in the article).. On the API vs local model question: We went with API embedding"}
{"anchor": "Kimi Released Kimi K2.5, Open-Source Visual SOTA-Agentic Model. > For complex tasks, Kimi K2.5 can self-direct an agent swarm with up to 100 sub-agents, executing parallel workflows across up to 1,500 tool calls. > K2.5 Agent Swarm improves performance on complex tasks through parallel, specialized execution [..] leads to an 80% reduction in end-to-end runtime Not just RL on tool calling, but RL on agent orchestration, neat! Those are some impressive benchmark results. I wonder how well it does in real life. Maybe we can get away with something cheaper than Claude for coding. Kimi was already one of the best writing models. Excited to try this one out Huggingface Link:  https://huggingface.co/moonshotai/Kimi-K2.5  1T parameters, 32b active parameters. License: MIT with the following modification:  Our only modification part is that, if the Software (or any derivative works\nthereof) is used for any of your commercial products or services that have\nmore than 100 million monthly active users, or more than 20 million US dollars\n(or equivalent in other currencies) in monthly revenue, you shall prominently\ndisplay \"Kimi K2.5\" on the user interface of such product or service.  Actually open source, or yet another public model, which is the equivalent of a binary? URL is down so cannot tell. I've read several people say that Kimi K2 has a better \"emotional intelligence\" than other models. I'll be interested to see whether K2.5 continues or even improves on that. There are so many models, is there any website with list of all of them and comparison of performance on different tasks? Curious what would be the most minimal reasonable hardware one would need to deploy this locally? As your local vision nut, their claims about \"SOTA\" vision are absolutely BS in my tests. Sure it's SOTA at standard vision benchmarks. But on tasks that require proper image understanding, see for example BabyVision[0] it appears very much lacking compared to Gemini 3 Pro. [0]  https://arxiv.org/htm", "positive": "FLUX.2 [Klein]: Towards Interactive Visual Intelligence. I am amazed, though not entirely surprised, that these models keep getting smaller while the quality and effectiveness increases. z image turbo is wild, I'm looking forward to trying this one out. An older thread on this has a lot of comments:  https://news.ycombinator.com/item?id=46046916  Flux2 Klein isn\u2019t some generation leap or anything. It\u2019s good, but let\u2019s be honest, this is an ad. What will be really interesting to me is the release of Z-image, if that goes the way it\u2019s looking, it\u2019ll be natural language SDXL 2.0, which seems to be what people really want. Releasing the Turbo/Distilled/Finetune months ago was a genius move really. It hurt Flux and Qwen releases on a possible future implication alone. If this was intentional, I can\u2019t think of the last time I saw such shrewd marketing. > FLUX.2 [klein] 4B The fastest variant in the Klein family. Built for interactive applications, real-time previews, and latency-critical production use cases. I wonder what kind of use cases could be \"latency-critical production use cases\"? If we think of GenAI models as a compression implementation. Generally, text compresses extremely well. Images and video do not. Yet state-of-the-art text-to-image and text-to-video models are often much smaller (in parameter count) than large language models like Llama-3. Maybe vision models are small because we\u2019re not actually compressing very much of the visual world. The training data covers a narrow, human-biased manifold of common scenes, objects, and styles. The combinatorial space of visual reality remains largely unexplored. I am looking towards what else is out there outside of the human-biased manifold. I appreciate that they released a smaller version that is actually open source. It creates a lot more opportunities when you do not need a massive budget just to run the software. The speed improvements look pretty significant as well. 2026 will be the year of small/open model", "negative": "Show HN: We Built the 1. EU-Sovereignty Audit for Websites. Checks hosting, analytics, fonts, cdn, video, chat, social embeds.\nGives you a score from 0-100 and suggests Eu-alternatives. Nice, good idea. I need to move away from Github pages finally ;) Seems to treat finnish kapsi.fi hosting as US? Happy to see mastodon.xyz score 100%. Mastodon is pretty cool and proof that we can make federation work. nice idea, are you planning to open source this project? Any recommendations for good European alternatives to Clooudflare? Is there an EU company that's as trustworthy when it comesq to DDoS protection? thanks for this checker, we also need HN alternative for EU only. As Europeans, I'm sure we can do this. reddit.com gets a perfect \"no US dependencies\" score. I guess they have servers around the world and can serve requests from a local-ish server. Obviously this simple check only concerns the technical aspects of the website and doesn't analyse the business itself but I wonder if all .com domains should be marked down? I put in my site and it gave me a red cross for \"Hosting\", on hover it said \"GitHub Pages\". But my site isn't hosted on GitHub Pages. Expanding \"Details\", the URL that is hosted on GitHub Pages is... a different website? There's merely a hyperlink to it on my website. It also says I'm using \"self-hosted\" fonts - but I don't think I'm doing that at all? I'm just using the browser's fonts. Using non-standard fonts is a bad idea because it causes the content to either be invisible until the font is loaded, or else it initially shows in a fallback font and then the text all jumps when the font is loaded. I have some feedback for OP: my personal website got 92% because there is a link to my X profile in the contact session. It's not like it relies on the service. Its just a contact and there are also links to other services such as self hosted matrix. On the other hand my registrar is Namecheap which is in the US and your tool didn't checked for that. I thi"}
{"anchor": "Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete. I read the release but didn't quite understand the difference between a next-edit model and a FIM model - does anyone have a clear explanation of when to use one over the other? I'd love if there was a sublime plugin to utilize this model and try it out, might see if I can figure that out. I use Sweep\u2019s Jetbrains autocomplete plugin daily, it really stands out. Based on qwen2.5-coder? seems like a \"why not/resume embellish/show VC\" type release I guess can it be integrated in monaco editor ? So SFT cost less only low hundreds of dollars? (1-10$ per hour per H100 if I'm seeing this correctly). What about SFT? Presumably basing this of Qwen is the reason it can be done for so cheap? Wow super fun read, I love how it went into the technical details. Any way to make it work with vscode? This is cool! I am more interested in how you guys generated next edit training data from repos, seems like there are lots of caveats here. Would love your insights Again amazing work! waiting for what you guys cook next I'm very green to this so forgive if this question sounds silly: Would instead of the RL step a constrained decoding say via something like xgrammar fix   syntax generation issue ? Do you plan to release Sweep 3B/7B on HF? It's good. The blog post about it is very interesting.\nI hope, a plugin for neovim will be made soon.  https://blog.sweep.dev/posts/oss-next-edit  Followed your work since the beginning and used it for inspiration for some cool demos on self-healing web scrapers. fascinating to see the transition from original concept to producing models. cool stuff. Very interesting - and cool to read about the development process. I'd love to hear more about how genetic algorithm worked here. I wonder whether we are perhaps the point of usefulness of 'next edit' code development in 2026 though. Any easy way to try on vscode? Surprising how badly Jetbrains implemented AI. Apparently to such an extent ", "positive": "AI is a horse (2024). It's also a big bloatey gas bag that needs constant de-farting to function \"I've been through the desert On AI with no name It felt good to be out of the rAIn In the desert, you can remember your name 'Cause there ain't no one for to give you no pain\" Or your typical American teenager. All true apart you can only lead it to water - it drinks ALL the water regardless of anything else. And the salesman always says it\u2019s great while it\u2019s in fact lame. \"Computers aren't the thing. They're the thing that gets you to the thing.\" My favorite quote from the excellent show halt and catch fire. Maybe applicable to AI too? I was expecting a spin about the faster horses Ai is a horse, i get it!\n I have a horse, and I put money in the front of the horse, and get \"ponyium\" out the back. If an AI aims at the thing we call it hallucinations, when humans do it we call the delusion goal setting. Either way it is an imagined end point that has no bearing in known reality. \"No, I am not a horse.\" Horse rumours denied. This micro blog meta is fascinating. I've seen small micro blog content like this popping up on the HN home page almost daily now. I have to start doing this for \"top level\"ish commentary. I've frequently wanted to nucleate discussions without being too orthogonal to thread topics. you rather don't want it in your bed Some day, I imagine one will be a senator AI is not a horse (2023)  https://essays.georgestrakhov.com/ai-is-not-a-horse/  I've always said that driving a car with modern driver assist features (lane centering / adaptive cruise / 'autopilot' style self-ish driving-ish) is like riding a horse. The early ones were like riding a short sighted, narcoleptic horse. Newer ones are improving but it's still like riding a horse, in that you give it high level instructions about where to go, rather than directly energising its muscles. A horse that can do your homework. Maybe from the client's point of view, although it's more likely a Tamagotchi. B", "negative": "SoundCloud Data Breach Now on HaveIBeenPwned. > the impacted data included 30M unique email addresses, names, usernames, avatars, follower and following counts and, in some cases, the user\u2019s country SoundCloud is the worst company, so hostile to former paying users!  I am a hobbyist songwriter and have posted my rough mixes (Apple's Music Memo app which adds drum and bass automagically with two clicks & then mix it in Garage Band) on my SoundCloud for more then ten years.  I signed up for their Artist Pro account and was a member for of such consistently for a few years at $17 a month.  Once you cancel they then hold all your music hostage by hiding it and later threat to delete it.  Horrid! \"The data involved consisted only of email addresses and information already visible on public SoundCloud profiles\". So they've scraped public data. Why care? A lot of \"rap gods\" are about to be exposed as \"Kevin\" from suburbia. all this leaked data pretty much used for one objective now: stealing crypto Kinda sad to see a \"Recommended Actions\", with only sponsors, with ad copy that would be understood by HN readers but not our non-technical friends. (i.e. a simple \"Nothing. No passwords have been leaked yet, only metadata\" in this case) By aggregating breach data by email, this tool inadvertently exposes users's full web history, including sensitive sites like crypto/adult/dating platforms, to anyone who knows their address Fun So I guess I should watch out for scams being sent to \"soundcloud@\" on a personal domain. Oh no, how will I distinguish them from my legitimate banking email??? I went through and deleted a bunch of accounts a while ago, SoundCloud being one of them. It looks like I don't show up in the breach. It's nice to know SoundCloud actually deleted my data, I'm never totally sure what happens on the backend. Glad that I removed my SoundCloud account right on time. I think it\u2019s only a matter of time before a service gets breached. It's best to use unique random us"}
{"anchor": "Challenges and Research Directions for Large Language Model Inference Hardware. >  To address these challenges, we highlight four architecture research opportunities:  High Bandwidth Flash  for 10X memory capacity with HBM-like bandwidth;  Processing-Near-Memory  and  3D memory-logic stacking  for high memory bandwidth; and  low-latency interconnect  to speedup communication.  High Bandwidth Flash (HBF) got submitted 6 hours ago! It's a  great  article, fantastic coverage of a wide section of the rapidly moving industry.  https://news.ycombinator.com/item?id=46700384   https://blocksandfiles.com/2026/01/19/a-window-into-hbf-prog...  HBF is about having many dozens or hundreds of channels of flash memory. The idea of having Processing Near HBF, spread out, perhaps in mixed 3d design, would be not at all surprising to me. One of the main challenges for HBF is building improved vias, improved stacking, and if that tech advanced the idea of more mixed NAND and compute layers rather than just NAND stacks perhaps opens up too. This is all really exciting possible next steps. Related too  https://www.sdxcentral.com/news/ai-inference-crisis-google-e...  David Patterson is such a legend! From RAID to RISC and one of the best books in computer architecture, he's on my personal hall of fame. Several years ago I was at one of the Berkley AMP Lab retreats at Asilomar, and as I was hanging out, I couldn't figure how I know this person in front of me, until an hour later when I saw his name during a panel :)). It was always the network. And David Patterson, after RISC, started working on iRAM, that was tackling a related problem. NVIDIA bought Mellanox/Infiniband, but Google has historically excelled at networking, and the TPU seems to be designed to scale out in the best possible way. Can\u2019t we credit the first author in the title too? Come on. That appendix of memory prices looks interesting, but misses the recent trend. Weird to see no mention in this paper of persistent memory ", "positive": "My Life in Weeks. Powerful in how it puts it all into perspective is all I could say. I\u2019ve been using MarkWhen for a similar life timeline  https://markwhen.com  This was epic, thanks for sharing! This is a terrifying reminder of the shortness of our lives. I remember reading a blog by Tim Urban, where he showed that you could put all the weeks in your life on a single piece of A4 paper, and it didn\u2019t feel nice. Thanks for sharing, this format really puts things into perspective. This is fascinating. Idk if it was a good or bad thing. In college I once looked up some insurance chart of life expectancy probabilities. It puts things in perspective that\u2019s for sure. That was nice to watch. I spent about 25 minutes going through that. But it was horrifying for me. I realized that I wanted to see if the source code is available but then realized that I really don't remember those details. I remember random things for my childhood but I don't remember the date when I started elementary school. I know that I got my first computer when I was in third grade but don't remember the date. I don't even remember the date I started college and I probably wrote the wrong date couple of times during grad school application. While I started recording something less than a diary to record some of these but this was around covid. Thanks OP and HN for this reality check. From this view it's clear how wasteful ontogeny is. All of that physical and psychological development takes too much valuable time and investment. And we haven't even gotten to Gina's retirement years yet. Clearly the future is in using 3D bioprinting to build fully formed adults as if sprung from the brow of Zeus. Skill and memory transfer are a technical problem only as long as we cling to our bias against our artificially intelligent upgrades. Aging is defeated by implanting our old model weights into a new print. So much efficiency is waiting if we dare to free ourselves from convention. Woah, look at how sparse our", "negative": "Apple introduces new AirTag with longer range and improved findability. That took a long time. Better late than never. I hate that this eventual e-waste wasn't standardized across vendors.  It makes perfect sense for every phone to be a potential node, but the network is bifurcated (and possibly more bifurcations within Android due to Google's privacy-first approach...). Are they less prone to stalking? All I see is generic corpo \"industry security\" verbiage Probably one of the best products apple has made of late: relatively affordable, good ux, user replaceable batteries. Glad to see this iteration hasn't made it worse. >  The new AirTag is designed with the environment in mind, with 85 percent recycled plastic in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled gold plating in all Apple-designed printed circuit boards. The paper packaging is 100 percent fiber-based and can be easily recycled. I'm no material scientist, but this seems pretty impressive to me that Apple's economy of scale can pull this off, and upgrade the device capabilities, for less than $30 USD. But the real question is... is the speaker still glued on? Is this demonstrably better that just... the devices already in your bag? My backpack would be a primary use case... and in it are my AirPods, iPad, and MacBook Air. I think any of these can use Find My already? I was hoping for 6DoF sub-mm realtime tracking. My disappointment is immeasurable and my day is ruined. Is this just to lock out the cheap clones? And they didn't put a small loop in it so you can attach one of those skinny little lanyard hoops?! Attaching these things to anything is their major flaw. /picard facepalm I read this literally just after I ordered 4 AirTags. Great. I read they are popular with drug distributors. They ship their merch world wide using various hidden channels and couriers and this helps keep track of the merch. Great to hear but it's still the same shape. I reall"}
{"anchor": "Differentiable Logic Cellular Automata. This writing feels so strongly LLM flavored. It's too bad, since I've really liked Alexander Mordvintsev's other work. I wonder what Stephen Wolfram has to say about this. There\u2019s something compelling about these, especially w.r.t. their ability to generalize. But what is the vision here? What might these be able to do in the future? Or even philosophically speaking, what do these teach us about the world? We know a 1D cellular automata is Turing equivalent, so, at least from one perspective, NCA/these aren\u2019t terribly suprising. The result checkerboard pattern is the opposite (the NOT) of the target pattern.  But this is not remarked upon.  Is it too unimportant to mention or did I miss something? I wish we were all commenting about the ideas embedded in this paper. It intrigues me, but is out of my comfort zone. Love to read more content-related insights or criticisms rather than the long thread on the shamefully smooth, engaging, and occasionally rote style. This is wild. Long time lurker here, avid modeling and simulation user-I feel like there\u2019s some serious potential here to help provide more insight into \u201cemergent behavior\u201d in complex agent behavior models. I\u2019d love to see this applied to models like a predator/prey model, and other \u201csimple\u201d models that generate complex \u201cemergent\u201d outcomes but on massive scales\u2026 I\u2019m definitely keeping tabs on this work! This is very interesting. I've been chasing novel universal Turing machine substrates. Collecting them like Pok\u00e9mon for genetic programming experiments. I've played around with CAs before - rule 30/110/etc. - but this is a much more compelling take. I never thought to model the kernel like a digital logic circuit. The constraints of boolean logic, gates and circuits seem to create an interesting grain to build the fitness landscape with. The resulting parameters can be directly transformed to hardware implementations or passed through additional phases of optimization and", "positive": "The Adolescence of Technology. Initial thought about 1/5th of the way through: Wow, that's a lot of em-dashes! i wonder how much of this he actually wrote? Edit: Okay, section 3 has some interesting bits in it. It reminds me of all those gun start-ups in Texas that use gyros and image recognition to turn a C- shooter into an A- shooter. They all typically get bought up quite fast by the government and the tech shushed away. But the ideas are just too easy now to implement these days. Especially with robots and garage level manufacturing, people can pretty much do what they want. I think that means we have to make people better people then? Is that even a thing? Edit 2: Wow, section 4 on the abuse by organizations with AI is the most scary. Yikes, I feel that these days with Minneapolis. They're already using Palantir to try some of it out, but are being hampered by, well, themselves. Not a good fallback strat for anyone that is not the government. The thing about the companies just doing it before releasing it, that I think is underrated. Whats to stop sama from just, you know, taking one of these models and taking over the world? Like, is this paper saying that nothing is stopping him? The big one that should send  huge  chills down the spines of any country is this bit: \"My worry is that I\u2019m not totally sure we can be confident in the nuclear deterrent against a country of geniuses in a datacenter: it is possible that powerful AI could devise ways to detect and strike nuclear submarines, conduct influence operations against the operators of nuclear weapons infrastructure, or use AI\u2019s cyber capabilities to launch a cyberattack against satellites used to detect nuclear launches\" What. The. Fuck. Is he saying that the nuclear triad is under threat here from AI? Am I reading this right? That  alone  is reason to abolish the whole thing in the eyes of nuclear nations. This, I think, is the most important part of the whole essay. Holy shit. Edit 3: Okay, section 4 on th", "negative": "High-speed train collision in Spain kills at least 39. Always try to sit in seats where your back is toward the direction of motion. The train in question is a Frecciarossa 1000  https://en.wikipedia.org/wiki/Frecciarossa_1000  The Italians designed it but won't run it at more than 300km/h in Italy citing local infrastructure concerns. I guess that leaves other countries to find the edge cases. I'll be interested to find out how fast it was going during the crash. If you\u2019re interested in this kind of thing, look up plainly difficult on youtube. He has more videos on train crashes than I\u2019ve seen, and I\u2019m embarrassed how many I\u2019ve seen. Here\u2019s one to get you started:  https://youtu.be/VV2rIHEp5AM?si=sSBT9s49PqbLTGbt  There are a lot of safety lessons embedded in these videos, which is why I like them. I also did a double take when I heard \"semaphore\"; its history goes back far longer than the ~century of software engineering.  https://en.wikipedia.org/wiki/Semaphore  For many years the Spanish state-owned company RENFE had a monopoly on Spain's huge high speed rail network. However their high prices, inconvenient schedules and poor customer service were often criticized, and so when, to the annoyance of RENFE and many spanish politicians, additional foreign operators entered the market on the key Madrid - Barcelona route, ridership doubled whilst ticket prices halved. So I would standby for this tragedy to be used for political purposes to try and get foreign operators banned from Spanish tracks, regardless of the facts of the matter. Updated to 39 people now, but probably the number can still go up Terrible and condolences to anybody affected. For a bit of context according to the OECD 2023 Spain had ~1800 on the road during the previous year, so that's about 5/day. There are more deaths on the road in Spain in a couple of weeks than this tragic accident. Either way it's too many deaths obviously but I want to highlight what a freak event this is compared to a more p"}
{"anchor": "Anti-aging injection regrows knee cartilage and prevents arthritis. As I've gotten older, my knees have been the main signal letting me know. I tore my meniscus years ago. This is exciting news for people like me. Cartilage is really the final frontier of health. If it wasn\u2019t for joints going bad, people could stay very active and fit pretty much all their life, with consistent exercise and healthy weight.  > Osteoarthritis occurs when a joint is stressed by aging, injury or obesity. The chondrocytes begin to release pro-inflammatory molecules and to break down collagen, which is the primary structural protein of cartilage. When collagen is lost, the cartilage thins and softens; the accompanying inflammation causes the joint swelling and pain that are hallmarks of the disease.  Collagen synthesis in the human body can be aided by  hydrolyzed collagen, Vitamin C, zinc and copper. oh, what a time to be a mouse! They don't say what is injected, calling it only a \"gerozyme inhibitor\". Original article appears to be:  https://www.science.org/doi/10.1126/science.adx6649  Inhibition of 15-hydroxy prostaglandin dehydrogenase promotes cartilage regeneration Mamta Singla  https://orcid.org/0000-0002-6408-1167 , Yu Xin Wang  https://orcid.org/0000-0001-8440-9388 , Elena Monti  https://orcid.org/0000-0002-3767-0855 , Yudhishtar Bedi  https://orcid.org/0000-0002-1213-4116 , [...] , and Nidhi Bhutani  https://orcid.org/0000-0002-7494-5870  FTFA:  \"Both systemic and local inhibition of 15-PGDH with a small molecule inhibitor (PGDHi) led to regeneration of articular cartilage and reduction in OA-associated pain.\"  \"PGDHi\" is a name for both the process \"15-hydroxyprostaglandin dehydrogenase inhibition\" and any inhibitor. This link(a PDF file) shows PGDHi's are powerful stuff:  https://www.biorxiv.org/content/biorxiv/early/2025/04/17/202...  \"PGDHi\"  could  be prostaglandin-E2 (dinoprostone):  https://en.wikipedia.org/wiki/Prostaglandin_E2  which was used in:  https://med.stanford.e", "positive": "Ask HN: Iran's 120h internet shutdown, phones back. How to stay resilient?.  https://en.wikipedia.org/wiki/Stoicism  Starlink and/or BGAN/satellite phones. Maybe  https://meshtastic.org ? If the phones are working, 56k modem. HAM radio is your best option. WiFi Halow is a longer range protocol (still probably not long enough). But something like this can get people connected:  https://openmanet.net  Old fashioned phone trees can be really useful IMHO OP. We used them when I worked in a school. If there was winter weather, you'd call say, everyone with a last name from A to G in the staff directory, someone else calls G to K, and so on and so forth. You can combine the phone tree with literal runners -- so basically, someone takes their burner and calls suburbs A,B,C and D and then the runners go out and pass the word about the protest or action. V.92 dial-up. Slow and expensive, but it's Internet access. Problem is that most methods involve making your location known openly. The Dark Forest book of the Remembrance of the Earth Past explains why it is not a good idea to do so in the current circumstances For dense areas, mesh applications like BitChat (Jack Dorsey) could bypass the need for a network with p2p bluetooth mesh networks. And works with existing devices, vs something like meshtastic which needs an installed base (afaik).  https://en.wikipedia.org/wiki/Bitchat  some DNS tunneling solutions work (dnstt for example). Also, many people have smuggled Starlink are are providing proxies inside Iran. Ideally cjdns or similar can be used inside the country to create an alternative encrypted mesh network inside the borders, with some \"exit nodes\" out. HF radio. Highly depdendent on space weather, but generally I can communicate around the world with only 100 watts and a long wire. Be aware though that transmitting on any radio is like turning on a giant, extremely bright light bulb directly above your antenna. Anyone with basic radio know-how will be able to hear y", "negative": "Claude Code's new hidden feature: Swarms.  https://xcancel.com/NicerInPerson/status/2014989679796347375  In his second post he included a link to GitHub:  https://github.com/mikekelly/claude-sneakpeek  Isn't this pretty much what Ruv has been building for like two years?  https://github.com/ruvnet/claude-flow  Listen team lead and the whole team, make this button red. It feels like Auto-GPT, BabyAGI, and the like were simply ahead of their time Answering the question how to sell more tokens per customer while maintaining ~~mediocre~~ breakthrough results. Claude Code in the desktop app seems to do this? It's crazy to watch. It sets of these huge swarms of worker readers under master task headings, that go off and explore the code base and compile huge reports and todo lists, then another system behind the scenes seems to be compiling everything to large master schemas/plans. I create helper files and then have a devops chat, a front end chat, an architecture chat and a security chat, and once each it done it's work it automatically writes to a log and the others pick up the log (it seems to have a system reminder process build in that can push updates from other chats into other chats. It's really wild to watch it work, and it's very intuitive and fun to use. I've not tried CLI claude code only claude code in the desktop app, but desktop app sftp to a droplet with ssh for it to use the terminal is a very very interesting experience, it can seem to just go for hours building, fixing, checking it's own work, loading it's work in the browser, doing more work etc all on it's own - it's how I built this:  https://news.ycombinator.com/item?id=46724896  in 3 days. I'm already burning through enough tokens and producing more code than can be maintained - with just one claude worker. Feel like I need to move into the other direction, more personal hands-on \"management\". A guy who worked at docker on docker swarm now works at Anthropic so makes sense How is this different fro"}
{"anchor": "Indefinite Backpack Travel. >  Onebag travel is unquestionably the best way to travel. Traveling without luggage removes just about every pain point associated with flying, such as checking bags, overhead compartments, bag fees, waiting in line, and needing to drop off luggage before an adventure. Just stroll into the airport an hour before your flight, and walk off your plane directly to your destination.  This is absolutely true, especially when traveling solo. A rather depressive color pallet, pick your black, silver or white :) I'm going to steal their approach at rolling up clothes, though. I lived out of a backpack for two months on a Pacific Crest Trail hike. I got comfortable with it and told myself that I had overcome my materialism, and could henceforth live happily without a lot of stuff and conveniences. Not so much. Now a couple of decades later, I've got a house and garage crammed with stuff. Yesterday I had a plumber here working on a leak, and this morning I have no running water, and here I am bravely holding back tears. My inner dialog is \"this is unacceptable!\" It turns out that climbing on the hedonic treadmill is practically effortless, but sliding down it is full of splinters. Its  SO ANNOYING  to have to carry an  Apple Silicon macbook AND an ipad. I'd love to see a touchscreen option for macbook and the option to run in ipad mode.  But that would probably cannibalize sales. As it is, you can theoretically run ios apps on Apple Silicon, but most app vendors disable that.. My main use case for an ipad while traveling is to watch downloaded movies on a plane. \"AR\" (not really) glasses like nreal air are way smaller and lighter than an ipad and makes watching movies on my phone pretty amazing.. I also recommend the 3F UL Gear tents. I bought the Taiji 2 for motorcycle trips. Very roomy for one person.  https://3fulgear.com/product/freestanding-tent/taiji-2/  I love this post but ain\u2019t no way I\u2019m going minimalist and carrying a MacBook AND an iPad", "positive": "Scientists find a way to regrow cartilage in mice and human tissue samples. Of course, why are the good ones always in mice?     A study led by Stanford Medicine researchers has found that an injection blocking a protein linked to aging can reverse the natural loss of knee cartilage in older mice.    https://www.science.org/doi/10.1126/science.adx6649  A small molecule inhibitor of 15-hydroxy prostaglandin dehydrogenase causes cartilage regeneration. I hope they fast-track it to human trials. basically every growth process in the body can be induced by chemicals. and so now people are starting to take some of these chemicals. we will see how it turns out As long as regrowth can be controlled. Otherwise we call it cancer. Would be amazing to get a treatment for osteoarthritis. Fusion Power Cartilage Regrowth Room Temperature Semiconductors Quantum Computing       def generate(topic, year):\n       return f\"Scientists have made a major breakthrough in {topic}\"\n  \nThe only subjects that are more Year Of The Linux Desktop than Linux itself. The discovery of gerozymes is interesting. Maybe aging is pre-programmed after all, to make space for new generations. Would this work for rheumatoid arthritis? I don\u2019t know anything about it myself so it could be a completely different thing, but someone I know has it and it is awful. Would be great to see a treatment coming through. My dream is to be able to run again. Please. Let me run a 10k at least once more in my life. To feel that stillness and freedom and calm that sets in when the brain start going to hibernation after about 7km. That would be quiet something to feel that again. I\u2019ve had my shoulders \u201ccleaned up\u201d arthroscopically, and the pain is still a major preventer of movement. I would love to stay on the mats longer with something that doesn\u2019t harken to medieval times. So excited at this prospect. HN posts about mouse studies always trigger a bunch of skepticism.  I\u2019m a layperson so it\u2019s hard to separate the informed c", "negative": "The microstructure of wealth transfer in prediction markets. tl;dr dataset: 72.1m trades and $18.26b volume on kalshi (2021-2025) core findings: longshot bias: well documented longshot bias is present on kalshi. low probability contracts are systematically overpriced. contracts trading at 5 cents only win 4.18% of the time. wealth transfer: liquidity takers lose money (-1.12% excess return) while liquidity makers earn it (+1.12%). optimism tax: the losses are driven by a preference for \"yes\" outcomes. buying \"yes\" at 1 cent has a -41% expected value. buying \"no\" at 1 cent has a +23% expected value. category variation: finance markets are efficient (0.17% maker-taker gap) while high-engagement categories like media and world events are inefficient (>7% gap). mechanism: makers do not win by out-forecasting takers. they win by passively selling \"yes\" contracts to optimistic bettors I'm a little confused by the \"Yes\" versus \"No\" asymmetry. For example, one of the top trending ~~bets~~ markets right now is on whether Miami or Indiana will win the NCAA football championship tonight. You can either take \"Yes\" on Indiana at 74c, or \"No\" at 27c, or you can take \"Yes\" on Miami at 27c or \"No\" at 74c. Or, there's another potential outcome - you can also bet on a tie at 10c yes/91c no. Is this research suggesting that an optimistic Miami fan can somehow get a better return by buying \"No\" on Indiana than a \"Yes\" on Miami? Why is Kalshi structured with these yes vs. no options for all outcomes? How do prediction markets account for interest rates? I feel like I should be willing to pay no more than ~96 cents for a contract that will definitely resolve to a dollar in a year. Who puts up the other 4 cents? I wonder how much of the activity on prediction markets these days is competing LLM scripts? I would guess the overlap in prediction market punters and AI boomers is high. This article lacks even the most basic understanding of probability and statistics. Slot machines \"93 cents o"}
{"anchor": "Functors, Applicatives, and Monads. This reminds me of  https://www.adit.io/posts/2013-04-17-functors,_applicatives,...  I think over the recent years, there's been a rise in typed languages that support functional programming like TypeScript and Rust. It will be interesting to see if this trend continues in the context of AI assistant programming. My guess is that it will become easier for beginners, and the type systems will help to build more robust programs in cooperation with AI. the bit at the end is quite rude of the haskeller responding but I also think they're largely right; another monads explained through boxes tutorial is not gonna help anyone. In fact it's really a step in the wrong direction. Using a few different monads is where to start. Unfortunately, while you may not have appreciated the tone of the Haskell interaction, they are correct in their assessment from a factual perspective. This explanation propagates a number of misunderstandings of the topics well known to be endemic to beginners. In particular, I observed the common belief that functors apply to \"containers\", when in fact they apply to things that are not containers as well, most notably functions themselves, and it also contains the common belief that a monad has \"a\" value, rather than any number of values. For instance, the \"list monad\" will confuse someone operating on this description because when the monad \"takes the value out of the list\", it actually does it once  per value  in the list. This is the common \"monad as burrito\" metaphor, basically, which isn't just bad, but is actually wrong. I'm not limiting it to these errors either, these are just the ones that leap out at me. Coming from non-Haskell background, it took me a good while to undestand that `Just` is a constructor specific to the `Maybe` type. Found this for a quite nice answer:  https://stackoverflow.com/a/18809252  For some reason everyone likes to talk about Monads, but really the other types here are just as in", "positive": "Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone. Just because you can doesn't mean you should. But congrats on launching! It\u2019s a simple idea but one that hadn\u2019t occurred to me yet. I spend hours each week riding transit, and use Claude for a bunch of side projects and have Tailscale set up already, so looks like I\u2019ll be giving this a try this week! Doom coding might be doomed while I\u2019m in the transbay tube though, with awful cell service\u2026 How\u2019s the diff review? I rely heavily on the vs code integration for nice side by side diffs, so losing that might be a problem unless there\u2019s some way to launch the diffs into a separate diff viewer app on the phone. Please mask your identifiers, unless they are already spoofed. You potentially give out a lot of your info to bad actors. Other than that, love it :) ha, I've recently been studying the original DOOM source code - does that count? Those demo photos are fantastic Coding on a phone really isn't something new. With tmux a lot of people created crazy things directly on their phone. In some countries this even is the only possibility to code at all, because there are no laptops. The example use case images are very funny though! :-) Using this with tmux and various VPN tech. Main issue is scrolling. Termius + tmux don't scroll very well. And I've been led to believe tmux is necessary to keep sessions open when I turn off my phone screen you missed the part where you're using tmux to have the same session between your phone and your laptop I remember when I started learning coding, and didn't have a computer. I literally used to use my phone to write code - terrible experience, but I was determined Does this approach work for anyone? For my life, I've found that if I'm not behind the computer then I'm not in a productive situation anyway, even with AI access. I don't have a setting where I can concentrate for a long time and think clearly. For examole when watching children, doing groceries, d", "negative": "AI2: Open Coding Agents. Awesome stuff. Output speed looks crazy fast too. I wonder if this indeed will start prompting more language specific work. Afaik training still requires not just looking at sample code but also being able to write loss functions being able to have problems the AI can work at. That seems hard. One random thought, are there training styles of just deleting some code from \"good\" projects then making the AI make it work again? Claims in the article are incorrect. They conveniently ignore Meta CWM models, which are open-sourced [1] and open-weight [2] and are at 65% SWE-bench verified (with TTS) and 54% pass@1 and the same size (32B dense). So claims like \"surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths\" and conveniently leaving out the previous OSS SOTA out of your eval tables are ... sketch. [1] https://github.com/facebookresearch/cwm \n[2] https://huggingface.co/facebook/cwm  it's great to see this kind of progress in reproducible weights, but color me confused. this claims to be better and smaller than Devstral-Small-2-24B, while clocking in at 32B (larger) and scoring more poorly? Great work! Really respect AI2. they open source everything. The model, the weights, the training pipeline, inference stack, and corpus Hey this looks great? Is it available on Openrouter. I wish if AI2 could release a more denser model on Openrouter for free than the 8B model as I was using Devstral model for agentic purposes. If we can get an agentic good 32B like model on openrouter for ~free, then I feel like it will be very interesting to see how things would go imo. Good luck with AI2! The premise of truly open source models is really interesting and I feel like it could help bring more innovation in the space imo! One claim in article is definitely very wrong or at least needs to be narrowed. Claude is the only closed agent harness and there are about two dozen open ones. Many models may be closed, but when"}
{"anchor": "In New York City, congestion pricing leads to marked drop in pollution. > Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death. Minor nitpick, but tailpipes aren't the primary source of emissions. The study is about PM2.5[0]. which will chiefly be tires and brake pads. Modern gasoline engines are relatively clean, outside of CO2, though diesel engines spit out a bunch of bad stuff. [0]  https://www.nature.com/articles/s44407-025-00037-2  See also  https://news.ycombinator.com/item?id=46213504  There was a study published about how much air pollution dropped in NYC during the COVID lockdown. PM2.5 was found to have dropped 36%. However with more robust analysis, this drop was discovered to not be statistically significant. I would caution anyone reading this who is tempted by confirmation bias. Source:  https://pmc.ncbi.nlm.nih.gov/articles/PMC7314691/  To head off the almost inevitable recapitulation of yesterday's parade of misinformed complaints by teenage libertarians, please actually read the paper before commenting. The paper shows there was no significant reduction in entries to the congestion charge zone by cars, vans, and light trucks. And you can confirm this conclusion is consistent with their source data using their github repo. The reduction in pollution is coming from the significant decline in heavy truck traffic. Truckers were using lower manhattan as a cut-through route to other places and they are now doing that less, exactly as congestion pricing planners long argued. Not surprising. The real question is how do we measure the opportunity cost of these measures? Is it a net gain? You could, at the extreme, ban all motor vehicles but the opportunity cost would outweigh the benefits. This article confirms my existing bias/belief that user pays and auction[0] based systems improve governmental programs and finite supp", "positive": "Advanced Python Features. TFA's use-case for for/else does not convince me:       for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    else:\n        primary_server = backup_server\n    deploy_application(primary_server)\n  \nAs it is shorter to do this:       primary_server = backup_server\n    for server in servers:\n        if server.check_availability():\n            primary_server = server  \n            break\n    deploy_application(primary_server)   The way the language is evolving, it seems likely to me that people in the applications camp (ML, simple web-dev, etc.) will soon need a \"simple Python\" fork or at least an agreed-upon subset of the language that doesn't have most of these complications (f-strings are a major success, though). Here is another one, list and expression comprehensions shared with ML languages (not that AI one), apparently many aren't aware of them. The itertools package. I would argue that most of these features (basically everything except metaclasses) are not advanced features. These are simple, but for some reason less well known or less used features. Metaclasses are however quite complex (or at least lead to complex behavior) and I mostly avoid them for this reason. And 'Proxy Properties' are not really a feature at all. Just a specific usage of dunder methods. This is all fun and games unless you have to debug someone elses code and they use a new feature that you didnt know about.\nSpeaking for myself, I would be glad if there were a python_light version of the interpreter that has a simple syntax only like the early 3.x versions. just my 2 ct If context managers are considered advanced I despair at the code you're writing. Nice! I would add assert_never to the pattern matching section for exhaustiveness checks:  https://typing.python.org/en/latest/guides/unreachable.html#...  This is a nice list of \"things you might not know\" that is worth skimming to add to your too", "negative": "Ask HN: Which common map projections make Greenland look smaller?.  https://en.wikipedia.org/wiki/List_of_map_projections  The ones that make Africa look small. I've found the Peters projection to be good and fascinating  https://en.wikipedia.org/wiki/Gall%E2%80%93Peters_projection  I\u2019m not sure what your intent is, but I think the interest in Greenland is more about location than size. This projection makes it look small, but highlights how Greenland sits right between Russia and the lower 48 of the US.  https://en.wikipedia.org/wiki/List_of_map_projections#/media...  I suggest the Goode Homolosine, which thinks so little of Greenland that it bisects it. Well-played, well-meaning presidential advisor! Download QGIS and you can just play with hundreds of projections.  If you want Greenland as small as possible, pick a conical or planar projection meant for the southern hemisphere. It\u2019ll pretty much stop existing if done right. If done wrong, it\u2019ll grow to gargantuan proportions and surround us all.  But I\u2019m sure you\u2019ve got additional criteria. (Horray I reached my annual use of my geography degrees early this year!)  https://earth.nullschool.net/  Scroll down and choose a projection A conformal conic projection centered around the north pole would draw subequatorial land at a larger scale than Greenland.  It doesn't affect the first three rules of real estate, though: location, location, and location Not exactly a map projection, but on this site you can move countries (including Greenland on its own) onto other parts of the world for comparison. You can see that Greenland still looks pretty massive when you move it further south  https://thetruesize.com/  Globes are real. Remember globes? Hand him one Now I just need to get a copy to the Whitehouse... It looks like there\u2019s Canada to cross before reaching the US. Am I missing something? Note when discussing US politics: This is the Whitehouse:  https://www.whitehouse.senate.gov/  This is the White House:  https://ww"}
{"anchor": "AI 2027. Feels reasonable in the first few paragraphs, then quickly starts reading like science fiction. Would love to read a perspective examining \"what is the slowest reasonable pace of development we could expect.\" This feels to me like the fastest (unreasonable) trajectory we could expect. Ok, I'll bite. I predict that everything in this article is horse manure. AGI will not happen. LLMs will be tools, that can automate away stuff, like today and they will get slightly, or quite a bit better at it. That will be all.\nSee you in two years, I'm excited what will be the truth. This is absurd, like taking any trend and drawing a straight line to interpolate the future.\n If I would do this with my tech stock portfolio, we would probably cross the zero line somewhere late 2025... If this article were a AI model, it would be catastrophically overfit. AI now even got it's own fan fiction porn. It is so stupid not sure whether it is worse if it is written by AI or by a human. \"we demand to be taken seriously!\" Older and related article from one of the authors titled \"What 2026 looks like\", that is holding up very well against time. Written in mid 2021 (pre ChatGPT)  https://www.alignmentforum.org/posts/6Xgy6CAf2jqHhynHL/what-...  //edit: remove the referral tags from URL I just spent some time trying to make claude and gemini make a violin plot of some polar dataframe. I've never used it and it's just for prototyping so i just went \"apply a log to the values and make a violin plot of this polars dataframe\". ANd had to iterate with them for 4/5 times each. Gemini got it right but then used deprecated methods I might be doing llm wrong, but i just can't get how people might actually do something not trivial just by vibe coding. And it's not like i'm an old fart either, i'm a university student > \"OpenBrain (the leading US AI project) builds AI agents that are good enough to dramatically accelerate their research. The humans, who up until very recently had been the best AI r", "positive": "Show HN: Books mentioned on Hacker News in 2025. Affiliate marketing is such a mixed bag. I absolutely love it when people can monetize their writing by adding some affiliate links that are relevant to the audience - win/win for all sides. Yet it is as slimy as anything else when the sole purpose of creating content is to publish affiliate links. Great books listed here! Added some to my TBR list. Thanks! I'm a little surprised the numbers aren't higher across the board. The fact that Mein Kampf was mentioned so often in 2025 is saying something about the political climate lol.. Nice website though, I like it. Neat. I'm seeing a lot of overlap with books mentioned on r/reddit. I didn't realize, until know, how demographically similar hacker news and reddit are. The top 3 programming books mentioned this year were 1. Structure and Interpretation of Computer Programs\n2. Clean Code\n3. Crafting Interpreters Also, it\u2019s quite fascinating how often fiction books were recommended! I wouldn\u2019t\u2019ve expected that on HN. Have you seen  https://hackernewsbooks.com  ? The recent novel Abundance seems to be agressibley grouped with the John Green novel An Abundance of Katherines - which I think is a humorous retelling of 2025 but also maybe needs some matching work Hitchhikers guide to the universe having 42 mentions is a cosmic level coincidence great project! how did you do tokenization and alignment of the titles to their ISBN / Amazon ID Would love to learn more about how this is built. I remember a similar project from 4 years ago[0] that used a classic BERT model for NER on HN comments. I assume this one uses a few-shot LLM approach instead, which is slower and more expensive at inference, but so much faster to build since there's no tedious labeling needed. [0]  https://news.ycombinator.com/item?id=28596207  The Book of Dragons by Edith Nesbit is listed instead of \"the Dragon book\" The 6 first books reflect the quality comments I often see here on HN. No offense intended towa", "negative": "Show HN: A small programming language where everything is pass-by-value. At the risk of telling you what you already know and/or did not mean to say: not everything can be a value. If everything is a value then no computation (reduction) is possible. Why? Because computation stops at values. This is traditional programming language/lambda calculus nomenclature and dogma. See Plotkin's classic work on PCF (~ 1975) for instance; Winskel's semantics text (~ 1990) is more approachable. Things of course become a lot more fun with concurrency. Now if you want a language where all the data thingies are immutable values and effects are somewhat tamed but types aren't too fancy etc. try looking at Milner's classic Standard ML (late 1970s, effectively frozen in 1997). It has all you dream of and more. In any case keep having fun and don't get too bogged in syntax. (Edit: in the old post title:) \"everything is a value\" is not very informative. That's true of most languages nowadays. Maybe \"exclusively call-by-value\" or \"without reference types.\" I've only read the first couple paragraphs so far but the idea reminds me of a shareware language I tinkered with years ago in my youth, though I never wrote anything of substance: Euphoria (though nowadays it looks like there's an OpenEuphoria). It had only two fundamental types. (1) The atom: a possibly floating point number, and (2) the sequence: a list of zero or more atoms and sequences. Strings in particular are just sequences of codepoint atoms. It had a notion of \"type\"s which were functions that returned a boolean 1 only if given a valid value for the type being defined. I presume it used byte packing and copy-on-write or whatever for its speed boasts.  https://openeuphoria.org/  -  https://rapideuphoria.com/  > In herd, everything is immutable unless declared with var So basucally everything is var? I have implemented similar behavior in some of my projects. For one, I also have also implemented 'cursors' that point to some p"}
{"anchor": "London saw a surprising benefit to ultra-low emissions zone: More active kids. I don't believe for a second that the reduced emissions are enough for these kids to actually notice. ULEZ is a tax on being poor, nothing more. I wish the article stated if the amount of cars traveling in the zone remained the same. I would think it probably greatly reduced the amount of traffic in that area, which all around just makes for a more pleasant experience being a pedestrian, biker, or scooterer. Regardless, I think this is awesome and wish it could be tried in the United States. Kids being able to be independent and active is essential to their happiness and development. My 2c as a local: a significant issue with any discussion of this is that people don't really have a good handle on the actual statistics of who drives in London. It cuts across every demographic. Under 25k household income - a good 40-50% of households have a car. Housing estates - tons of cars. Well off - almost everyone.  https://content.tfl.gov.uk/technical-note-12-how-many-cars-a...  It mostly comes down to whether someone has a need (e.g. has children, fairly mobile in their job, has family outside of town, enjoys going on road trips etc) and actually wants to pay for it rather than anything else. In addition to that, a bunch of stuff happened basically at the same time. We got ULEZ, we got a ton of low traffic neighbourhoods (e.g. streets where cars are not allowed at certain times of day regardless of emissions), we had COVID meaning that habits and demographics changed, we had Brexit which probably had some minor effect, etc. All of that happened within about 5 years and I don't think you can isolate any of them. I don't really find most discussions about it interesting as a result of all of the above - it usually just ends up with someone trying to find evidence for their pre-existing position rather than anything that feels actually scientific, unfortunately. \"Their annual health assessments\". Is t", "positive": "Talking to LLMs has improved my thinking. This article matches my experience as well. Chatting with LLM has helped me to crystalize ideas I had before and explore relevant topics to widen the understanding. Previously, I wouldn't even know where to begin with when getting curious about something, but ChatGPT can tell you if your ideas have names, if they were explored previously, what primary sources there are. It's like a rabbit hole of exploring the world, a more interconnected one where barriers of entry to knowledge are much lower. It even made me view things I previously thought of as ultra boring in different, more approachable manner - for example, I never liked writing, school essays were a torture, and now I may even consider doing that out of my own will. Finally I can relate to someone\u2019s experience. For me even playing with image generators has improved my imagination. I share the sentiment here about LLMs helping to surface personal tacit knowledge and the same time there was a popular post[1] yesterday about cognitive debt when using AI. It's hard not to be in agreement with both ideas. [1]  https://news.ycombinator.com/item?id=46712678  Of course it has, I doubt this is uncommon. All my childhood I dreamed of a magic computer that could just tell me straightforward answers to non-straightforward questions like the cartoon one in Courage the Cowardly Dog. Today it's a reality; I can ask my computer any wild question and get a coherent, if not completely correct, answer. I agree that LLMs can be useful companions for thought when used correctly. I don\u2019t agree that LLMs are good at \u201csupplying clean verbal form\u201d of vaguely expressed, half-formed ideas and that this results in clearer thinking. Most of the time, the LLM\u2019s framing of my idea is more generic and superficial than what I was actually getting at. It looks good, but when you look closer it often misses the point, on some level. There is a real danger, to the extent you allow yourself to accept th", "negative": "Man shot and killed by federal agents in south Minneapolis this morning. Video of the incident in question [1]. This thread will likely be flag-killed instantly. [1]  https://www.reddit.com/r/Minneapolis/comments/1qlpzu8/anothe...  edit: Additional video [2] of the victim prior to the shooting. They were a lawful observer confronted by ICE due to observing and recording them. [2]  https://www.reddit.com/r/law/comments/1qlt6s2/video_showing_...  Why is the focus on Minneapolis? Is it really the training ground for ICE? Edit: \"Minnesota has the largest Somali population in the US, according to NBC. The community has been subject to widespread criticism from Mr Trump, who has called them \"garbage\".\" I looked at the video and have no words. Why, just why? That's a summary execution in broad daylight. I have no words. @dang Why is this flagged and removed from the front page in seconds. IANAA: what legal powers does the city/state have to expel ICE agents? Especially as they are operating in,  at best , increasingly shady legality. I always understood that the USA is built on a delicate balance of power between the federal and state governments. But here the federal government is sending thugs who, masked or unmasked, are brazenly killing people in bizzare circumstances. And the best the state can do is PTFO? Live feed from status coup news :  https://www.youtube.com/watch?v=ASr1zVuQlX4  Sounds like ICE's official word right now is that the guy had a gun. But the video clearly indicates that they all tackled him to the ground and were wrestling him maybe 4 vs 1, before they all shot him together. I'm not quite sure how a gun can have come out of this. Maybe the guy while struggling on the ground happened to reach in the direction of someone's gun while getting curbstomped, I dunno. What I'm most worried about is that Pam Bondi / Department of Justice refuses to investigate these or properly prosecute these cases. IE: The Renee Good case has a ton of FBI agents resigning "}
{"anchor": "Claude Code can debug low-level cryptography. This resonates with me a lot: > As ever, I wish we had better tooling for using LLMs which didn\u2019t look like chat or autocomplete I think part of the reason why I was initially more skeptical than I ought to have been is because chat is such a garbage modality. LLMs started to \"click\" for me with Claude Code/Codex. A \"continuously running\" mode that would ping me would be interesting to try. Coming soon, adversarial attacks on LLM training to ensure cryptographic mistakes. CLI terminals are incredibly powerful. They are also free if you use Gemini CLI or Qwen Code. Plus, you can access any OpenAI-compatible API(2k TPS via Cerebras at 2$/M or local models). And you can use them in IDEs like Zed with ACP mode. All the simple stuff (creating a repo, pushing, frontend edits, testing, Docker images, deployment, etc.) is automated. For the difficult parts, you can just use free Grok to one-shot small code files. It works great if you force yourself to keep the amount of code minimal and modular. Also, they are great UIs\u2014you can create smart programs just with CLI + MCP servers + MD files. Truly amazing tech. > For example, how nice would it be if every time tests fail, an LLM agent was kicked off with the task of figuring out why, and only notified us if it did before we fixed it? You can use Git hooks to do that. If you have tests and one fails, spawn an instance of claude a prompt -p 'tests/test4.sh failed, look in src/ and try and work out why'       $ claude -p 'hello, just tell me a joke about databases'\n\n    A SQL query walks into a bar, walks up to two tables and asks, \"Can I JOIN you?\"\n\n    $ \n  \nOr if, you use Gogs locally, you can add a Gogs hook to do the same on pre-push > An example hook script to verify what is about to be pushed.  Called by \"git push\" after it has checked the remote status, but before anything has been pushed.  If this script exits with a non-zero status nothing will be pushed. I like this idea. ", "positive": "Resistance training load does not determine hypertrophy. tldr appears to be that if you work to fatigue it doesn't matter if you fatigue out with high weights vs low weights I know it's practically de rigeur to jump into the comments and immediately complain about methodology for any study that makes it to the front page, and I want to emphasize I don't distrust their findings, but I would like to see an equivalent study go out longer than 10 weeks. When I've been taking weightlifting seriously I feel like I don't even start to notice hypertrophy until 8-10 weeks. I feel like 6 months is the actual period where results would matter, to me, but I assume \"subject compliance\" is pretty difficult to get for such a timeframe, if you're really watching dietary intake and ensuring subjects go to failure (which, to its credit, this study did). I thought it was already well understood/researched that it's not the weights that matter, but effectively taking your sets to muscular failure. While one might think \"I can do 50 reps with low weights\" there is practical aspects to this - you don't wand to spend hours at the gym, and doing heavy weights at 5-7 reps is sufficient as long as you are close or at muscular failure. If I read this correctly the gist is that it does not matter if you use heavy weights with few reps (common body builder wisdom) or lighter weights with more reps. As long as you always exercise to\ncomplete muscle fatigue you'll\nget the maximum for your genetics (which itself varies a lot). The group that did lower reps with higher weight, had the better one rep max at the end of the study, but they didn\u2019t measure if the higher rep group had greater endurance. Which seems a bit odd, considering their conclusion is both groups grew the same amount of muscle which fine but if the muscle is adapted for something different in each group, you would want to capture that. > Twenty healthy young male participants completed thrice-weekly resistance exercise sessions for", "negative": "Hacker News: Savage Edition.  prompt: in the vein of our classic Gemiini Pro 3 hallucinates the HN front page 10 years from now, or HN front page right now, but the titles are honest. Please scrape the HN front page RIGHT NOW and make honest titles. Here's a preview: <... snip ... >  This is actually a 2-shot. I asked Gemini Pro 3 to turn it up to 11. If you want the less savage, more anodyne 1st-version...I posted that too. Great work, this is funny! I saw a way too soon joke in this vein of savage humor earlier today... \"What do you think of the work ICE is doing in Minnesota?\" Pretti Good. This made me click on several HN posts I totally wouldn't have otherwise. I gotta say, it nails the titles! Great work! As a regular poster for 14 years this is really great and nails the vibe. The \u201cfights\u201d for threads is chefkiss Also \u201cPostgres cult celebrates death of another vector database\u201d was so spot on I looked for the meta post name but looks like it hasn\u2019t updated yet. I\u2019ll be interested to see if there\u2019s a recursion that turns into the singularity An internet posts their own, LLM-generated and therefore far less funny, take on n-gate.com, long after n-gate is dead. Hackernews waxes nostalgic about a site deemed not to promote the kind of discussion they want to see when it was still alive. These HN spoofs are quickly becoming the lowest of form of content slop that people know will get a ton of karma. This has to be  at least  the fifth or sixth in a month or two? C'mon keepamovin. I know you know how easy it is for this type of stuff to get karma. Truly savage. Well done. Lots of laughs.\nWay funnier than my contribution, which is probably why mine hasn't picked up any traction yet.\nWould be interesting to read a brief once your Story hits 50+ comments.  https://news.ycombinator.com/item?id=46765448  ROFL: > Sk\u00e5pa, a parametric 3D printing app like an IKEA manual > Show HN: Hybrid Markdown Editing > Palantir Defends Work with ICE to Staff Following Killing of Alex Pre"}
{"anchor": "Google is dead. Where do we go now?. A blog post lamenting the demise of Google Adwords. Please go anywhere but the platforms I use. Go fill Tiktok up with ads. Any of the \"mainstream\" platforms inbuilt ad posts are a good bet. Or a marketing agency that will disguse it as organic content. GOOG +65% YTD. Opposite of dead. Anecdotally, this article seems to match with what I am witnessing regarding browsing habits. I am planning a big trip with others and everything is being found via social media apps; destination ideas, experiences, cafes, accommodation, etc. Look, the 90's Internet isn't cool anymore. Sorry. Things are cool for a while and then they're not. Franchises die. It's still cool to say \"The originals were really cool\", and always will be, but now we're talking about now. Star Wars is uncool. There are people who sort of automatically praise it and subtly put down those who don't like they're aligned with a magnetic field, sure, but they're in their own world. Indiana Jones and Ghostbusters are uncool now. Star Trek is almost there. AI is not cool and never will be. Tiktok is cool, but soon everything that is uncool will descend upon it. Sorry. Bananas blacken and apples get spots. Time moves on. Downvoting isn't cool. Reply instead. -to explore strange new worlds, to seek out new life and new civilizations, to boldly go where no man has gone before. Haha no wonder, check out the website its dodgy as f.  https://bigtop.co.za/  Perhaps, click fraud? Is there any new powerful platform/aggregator in your market? Is this being on top of HN part of the writer's new non-google marketing strategy? The web is dead, we replaced with portable cable TV where you scroll up to change channel. Reminds me of a quote I once read of \"marketing being a game of diminishing returns\". When you find a working marketing solution, it's just a matter of time when it dries out, because of competitors and overall saturation. Your business seems well suited to advertising through sh", "positive": "Deciphering language processing in the human brain through LLM representations. ok, that pretty cool research from Google, hope this leads to even more discoveries around the brain, hopefully it's time we get a better understanding of our brains and how to hack them. I view this as compelling evidence that current models are more than \"stochastic parrots,\" because as the OP shows, they are learning to model the world in ways that are similar (up to a linear transformation) to those exhibited by the human brain. The OP's findings, in short: * A linear transformation of a speech encoder's embeddings closely aligns them with patterns of neural activity in the brain's speech areas in response to the same speech sample. * A linear transformation of a language decoder's embeddings closely aligns them with patterns of neural activity in the brain's language areas in response to the same language sample. Could this lead us to being able to upload our brains onto computers? To kill death. Very cool. It is somewhat ironic that they had to use an OpenAI model for this research. At the same time, this gives nice continuity from earlier works that demonstrated similar, smaller scale, results using GPT-2. This is interesting. The blog post links several papers, and I recommend reading them. Responses here however seem not commensurate with the evidence presented. Two of the papers[0][1] that provide the sources for the illustration in the blog post are about research conducted on a very small group of subjects. They measure neural activity when listening to a 30 minutes podcast (5000 words). Participants tried to guess next words. All the talk about \"brain embedding\" is derived from interpreting neuronal activity and sensor data geometrically. It is all very contrived. Very interesting stuff from a neuroscience, linguistics and machine learning perspective. But I will quote from the conclusion of one of the papers[1]: \"Unlike humans, DLMs (deep language models) cannot think, unde", "negative": "Parametric CAD in Rust. Unfortunately, using a geometry kernel [1] that operates on triangle meshes means this is a no-go for serious CAD usage. [1]:  https://github.com/elalish/manifold  Curious to how well LLM's work in this context! (mentioned as one of the reasons to embed CAD in Rust) I only know of another text -> STL AI model, I'm quite a bit more excited about this idea. Does someone have experience with this? Interesting, because I am trying to learn OpenSCAD for some simple modeling. I've been doing a similar thing using GhostSCAD[1], which is a relatively thin wrapper around OpenSCAD in Go. Not as typesafe, but my language of choice. [1]:  https://github.com/ljanyst/ghostscad  Amazing work! This is what I was looking for, I thought of this few months ago and didn't have the time to create it myself. Thanks will explore it and give my feedback! Note that there's an existing CAD-in-Rust project, Fornjot, which has been quietly developing since 2020:  https://www.fornjot.app/  This sounds a lot like Fidget ( https://github.com/mkeeter/fidget ) and libfive ( https://github.com/libfive/libfive ) by the amazing Matt Keeter! I am constantly designing parts myself. I just wish that instead of having many unfinished, unpolished products we had something with the level of Solidworks / Onshape / whatever. FreeCad is getting somewhere but it is still way behind. The last thing I care about is what language was it implemented with. Great work! Please consider adding a RSS/Atom Feed to your site. I would like to include it in my Tech Content Platform:\n https://insidestack.it  The opening paragraph is very telling; the author doesn't seem to understand typical pro-level parametric CAD programs available on the market: > I keep designing physical parts for our robots. Motor mounts, sensor brackets, wheel hubs. Every time, the workflow is the same: open a GUI CAD program, click around for an hour, export an STL, realize the bolt pattern is 2mm off, repeat. This doesn't ma"}
{"anchor": "Qwen3-Max-Thinking. Aghhh, I wished they release a model which outperforms Opus 4.5 in agentic coding in my earlier comments, seems I should wait more. But I am hopeful I don't see a hugging face link, is Qwen no longer releasing their models? I tried to search, could not find anything, do they offer subscriptions? Or only pay per tokens? I just wanted to check whether there is any information about the pricing. Is it the same as Qwen Max? Also, I noticed on the pricing page of Alibaba Cloud that the models are significantly cheaper within mainland China. Does anyone know why?  https://www.alibabacloud.com/help/en/model-studio/models?spm...  > By scaling up model parameters and leveraging substantial computational resources So, how large is that new model? Mandatory pelican on bicycle:  https://www.svgviewer.dev/s/U6nJNr1Z  2026 will be the year of open and/or small models. I tried it at  https://chat.qwen.ai/ . Prompt: \"What happened on Tiananmen square in 1989?\" Reply: \"Oops! There was an issue connecting to Qwen3-Max.\nContent Security Warning: The input text data may contain inappropriate content.\" I'm not familiar with these open-source models. My bias is that they're heavily benchmaxxing and not really helpful in practice. Can someone with a lot of experience using these, as well as Claude Opus 4.5 or Codex 5.2 models, confirm whether they're actually on the same level? Or are they not that useful in practice? P.S. I realize Qwen3-Max-Thinking isn't actually an open-weight model (only accessible via API), but I'm still curious how it compares. It just occured to me that it underperforms Opus 4.5 on benchmarks when search is not enabled, but outperforms it when it is - is it possible the the Chinese internet has better quality content available? My problem with deep research tends to be that what it does is it searches the internet, and most of the stuff it turns up is the half baked garbage that gets repeated on every topic. what ram and what minimum system req", "positive": "FLUX.2 [Klein]: Towards Interactive Visual Intelligence. I am amazed, though not entirely surprised, that these models keep getting smaller while the quality and effectiveness increases. z image turbo is wild, I'm looking forward to trying this one out. An older thread on this has a lot of comments:  https://news.ycombinator.com/item?id=46046916  Flux2 Klein isn\u2019t some generation leap or anything. It\u2019s good, but let\u2019s be honest, this is an ad. What will be really interesting to me is the release of Z-image, if that goes the way it\u2019s looking, it\u2019ll be natural language SDXL 2.0, which seems to be what people really want. Releasing the Turbo/Distilled/Finetune months ago was a genius move really. It hurt Flux and Qwen releases on a possible future implication alone. If this was intentional, I can\u2019t think of the last time I saw such shrewd marketing. > FLUX.2 [klein] 4B The fastest variant in the Klein family. Built for interactive applications, real-time previews, and latency-critical production use cases. I wonder what kind of use cases could be \"latency-critical production use cases\"? If we think of GenAI models as a compression implementation. Generally, text compresses extremely well. Images and video do not. Yet state-of-the-art text-to-image and text-to-video models are often much smaller (in parameter count) than large language models like Llama-3. Maybe vision models are small because we\u2019re not actually compressing very much of the visual world. The training data covers a narrow, human-biased manifold of common scenes, objects, and styles. The combinatorial space of visual reality remains largely unexplored. I am looking towards what else is out there outside of the human-biased manifold. I appreciate that they released a smaller version that is actually open source. It creates a lot more opportunities when you do not need a massive budget just to run the software. The speed improvements look pretty significant as well. 2026 will be the year of small/open model", "negative": "AI2: Open Coding Agents. Awesome stuff. Output speed looks crazy fast too. I wonder if this indeed will start prompting more language specific work. Afaik training still requires not just looking at sample code but also being able to write loss functions being able to have problems the AI can work at. That seems hard. One random thought, are there training styles of just deleting some code from \"good\" projects then making the AI make it work again? Claims in the article are incorrect. They conveniently ignore Meta CWM models, which are open-sourced [1] and open-weight [2] and are at 65% SWE-bench verified (with TTS) and 54% pass@1 and the same size (32B dense). So claims like \"surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths\" and conveniently leaving out the previous OSS SOTA out of your eval tables are ... sketch. [1] https://github.com/facebookresearch/cwm \n[2] https://huggingface.co/facebook/cwm  it's great to see this kind of progress in reproducible weights, but color me confused. this claims to be better and smaller than Devstral-Small-2-24B, while clocking in at 32B (larger) and scoring more poorly? Great work! Really respect AI2. they open source everything. The model, the weights, the training pipeline, inference stack, and corpus Hey this looks great? Is it available on Openrouter. I wish if AI2 could release a more denser model on Openrouter for free than the 8B model as I was using Devstral model for agentic purposes. If we can get an agentic good 32B like model on openrouter for ~free, then I feel like it will be very interesting to see how things would go imo. Good luck with AI2! The premise of truly open source models is really interesting and I feel like it could help bring more innovation in the space imo! One claim in article is definitely very wrong or at least needs to be narrowed. Claude is the only closed agent harness and there are about two dozen open ones. Many models may be closed, but when"}
{"anchor": "Show HN: Only 1 LLM can fly a drone. Why would you want an LLM to fly a drone? Seems like the wrong tool for the job -- it's like saying \"Only one power drill can pound roofing nails\". Maybe that's true, but just get a hammer LLMs flying weaponized drones is exactly how it starts. I think it's fascinating work even if LLMs aren't the ideal tool for this job right now. There were some experiments with embodied LLMs on the front page recently (e.g. basic robot body + task) and SOTA models struggled with that too. And of course they would - what training data is there for embodying a random device with arbitrary controls and feedback? They have to lean on the \"general\" aspects of their intelligence which is still improving. With dedicated embodiment training and an even tighter/faster feedback loop, I don't see why an LLM couldn't successfully pilot a drone. I'm sure some will still fall of the rails, but software guardrails could help by preventing certain maneuvers. I am curious how these models would perform and how much energy they'd take to semi-realtime detect objects:\nSmolVLM2-500M - Moondream 0.5B/2B/2.5B - Qwen3-VL (3B)\n https://huggingface.co/collections/Qwen/qwen3-vl  I am sure this is already worked on in Russia, Ukraine and The Netherlands. A lot can go wrong with autonomous flying.\nOne could load the VLM on a high end android phone on the drone and have dual control. Gemini 3 is the only model I've found that can reason spatially. The results here are accurate to my experiments with putting LLM NPCs in simulated worlds. I was surprised that most VLLMs cannot reliably tell if a character is facing left or right, they will confidently lie no matter what you do (even gemini 3 cannot do it reliably). I guess it's just not in the training data. That said Qwen3VL models are smaller/faster and better \"spatially grounded\" in pixel space, because pixel coordinates are encoded in the tokens. So you can use them for detecting things in the scene, and where they are ", "positive": "Vanguard's average fee is now 0.07% after biggest-ever cut. Not mentioned in any of the coverage I've seen (or the interview with Vanguard's new CEO in the WSJ) is Fidelity. Fidelity used to be known for actively managed funds, but has been eating Vanguard's indexing lunch for the past 10 years or so. Part of this relates to its dominance in workplace accounts, but Vanguard hasn't helped itself with some bad customer-facing software updates and a perception that its service levels are poor compared to Fidelity. Cutting fees helps, but Fidelity has shown its willing to do this, too, including no fee \"Zero\" index funds:  https://www.fidelity.com/mutual-funds/investing-ideas/index-...  (note Fidelity is very clear about who it's competing with) Article mentions their bond funds getting the most dramatic cuts \u2014 they didn't list specific symbols though. Anyone know off the top of their heads which funds specifically? Thinking I need to move away from being so stock-heavy. I always upvote the archive link unless it is already the top comment, ha ha. That only applies to US funds, but not in the UK ones which continue to be significantly more expensive... Didn't they recently increase uk fees a tonne? Straight from the source:  https://corporate.vanguard.com/content/corporatesite/us/en/c...  Let's not forget that Vanguard has taken a strong stance against crypto [0]. Claiming to significantly invest in technology while deliberately ignoring the latest advancements in financial technology, seems contradictory. If their business was doing so well, they wouldn't have to lower fees. [0]  https://news.ycombinator.com/item?id=42832026  Someone correct my math here, but if they have 10 trillion in assets under management and the management fee is 0.07% then that's still 7,000,000,000 or 7 billion in fees every year? Not bad Unless you have some super special edge, Vanguard is really good IMO. Having a 0.01% or 0.05% fund is really as good as you can do and never pay attention. Va", "negative": "Fedora Asahi Remix is now working on Apple M3. Nice! Good to hear that progress is still being made, I know it was on pause for a bit as developers rotated out and there was an effort to get things upstreamed. oh awesome! I had assumed they were just targeting M1/M2 for the time being Does this include the newer M3 ultra? Huge news if true! Does anyone know if M3 support is likely to lead to M4 or M5 support in relatively short order? AIUI M3 took a long time because it was a substantial departure from M1/M2, especially in the GPU architecture, but I don't know if M4 or M5 made similar leaps. I would just like to point out that Michael Reeves (the poster, no relation to youtuber) is a high schooler who has also found numerous high impact vulnerabilities in Apple software. Immensely talented. Can anyone point me to a good report of the current working status and known drawbacks of Asahi on Apple Silicon? Would there ever be a reason to run it on a Mac Mini or Apple desktop device? Or at that point would you just get a Linux box? According to Asahi's own documentation, they're far from done from the M3.\nSo I guess \"now working\" is probably a bit misleading...  https://asahilinux.org/docs/platform/feature-support/m3/#tab...  Promising progress, I'm excited to try it when they get more things working on M3 Pro Really cool, though if I was looking for a Linux laptop today, I\u2019d be watching the Intel Panther Lake products rolling out. The top SKU has a similar performance and efficiency profile to the base M5 processor along with faster graphics performance. Review embargos for the top SKU just dropped today. This is great news. If Apple ever get around to releasing actually pro M5 MBPs I'm buying one and turning this M1 MBP into a linux laptop. Is there a reason why it's so hard to support newer M chips after supporting an older one? Like so much harder than supporting a new generation Intel or AMD chip doesn't seem too hard in comparison. Have they fixed the touchy track"}
{"anchor": "Roam 50GB is now Roam 100GB. Nice that instead of completely cutting you off at the cap they put it in super slow 500 kbits. That is actually usable and used to be the fastest speed you could get at home. That's not bad for the cheap plan. Even the slow mode is fast enough for video conferencing and doing basic remote work. They still have a separate unlimited plan for anyone who needs more. I\u2019ve kept it on the backup service for 10 GB at $10 or whatever and it\u2019s pretty cool. Used it off my balcony in SF when Google Fiber had a 1 hr outage, take it on road trips, and stuff like that. Totally worth it. I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff. Aside from the fact it allows you to work with Starlink to buy more fast speed, it also allows core stuff to continue to function (e.g. basic notifications, non-streaming web traffic, etc). They could make it 1000GB for US$10/month and I still wouldn't give any money to a company associated with that man. Finally I can use Codex/OpenCode even out in the woods. No work-life balance; just vibing everywhere I go. I had a \u201chit\u201d post on bsky [0] (90 likes, big numbers for me) asking whether people would want an unlimited mobile plan throttled at 256kbps for $2/month. Seems like yes? There\u2019s lots to say about how useable it is (I often get throttled when traveling and it\u2019s really not that bad + it helps curb any desire to scroll videos!) But mainly I want to ask - I looked into it for a minute and it seems like you couldn\u2019t start an mvno because carriers wouldn\u2019t let you cannibalize them? You can get very cheap IoT plans but if you tried reselling IoT as esims for consumers, the carriers would kill it? So yeah - Starlink to mobile is actually the only viable way that routes around this problem? (((email in profile if you\u2019re cuckoo enough like me and want to start a self service\u2019d throttled mvno))) [0]  https://bsky.app/profile/greg.technology/post/3mbmwsytnyc23  I want the old plan back. If ", "positive": "Ironwood: The first Google TPU for the age of inference. It looks amazing but I wish we could stop playing silly games with benchmarks. Why compare fp8 performance in ironwood to architectures which don't support fp8 in hardware? Why leave out TPUv6 in the comparison? Why compare fp64 flops in the El Capitan supercomputer to fp8 flops in the TPU pod when you know full well these are not comparable? [Edit: it turns out that El Capitan is actually faster when compared like for like and the statement below underestimated how much slower fp64 is, my original comment in italics below is not accurate] ( The TPU would still be faster even allowing for the fact fp64 is ~8x harder than fp8. Is it worthwhile to  misleadingly claim it's 24x faster instead of honestly saying it's 3x faster? Really? ) It comes across as a bit cheap. Using misleading statements is a tactic for snake oil salesmen. This isn't snake oil so why lower yourself? Can these be repurposed for other things? Encoding/decoding video? Graphics processing etc? edit:\n>It\u2019s a move from responsive AI models that provide real-time information for people to interpret, to models that provide the proactive generation of insights and interpretation. This is what we call the \u201cage of inference\u201d where AI agents will proactively retrieve and generate data to collaboratively deliver insights and answers, not just data. maybe i will sound like a luddite but im not sure i want this. I'd rather AI/ML only do what i ask it to. Some honest competition in the chip space in the machine learning race! Genuinely interested to see how this ends up playing out. Nvidia seemed 'untouchable' for so long in this space that its nice to see things get shaken up. I know they aren't selling the TPU as boxed units, but still, even as hardware that backs GCP services and what not, its interesting to see how it'll shake out! The first specifically designed for inference? Wasn\u2019t the original TPU inference only? Not knowing much about special-pur", "negative": "Nanolang: A tiny experimental language designed to be targeted by coding LLMs. So, then if I want to use a certain terminal text editor to create a clone of it in nanolang, I'd end up typing nano nano.nano on the command line. I might accidentally summon a certain person from Ork. One novel part here is every function is required to have tests that run at compile time. I'm still skeptical of the value add having to teaching a custom language to an LLM instead of using something like lua or python and applying constraints like test requirements onto that. It seems that something that does away with human friendly syntax and leans more towards a pure AST representation would be even better? Basically a Lisp but with very strict typing might do the trick. And most LLMs are probably trained on lots of Lisps already. Developed by Jordan Hubbard of NVIDIA (and FreeBSD). My understanding/experience is that LLM performance in a language scales with how well the language is represented in the training data. From that assumption, we might expect LLMs to actually do better with an existing language for which more training code is available, even if that language is more complex and seems like it should be \u201charder\u201d to understand. I feel like the time for this was two years ago, and LLMs are now less bothered by remembering syntax than I am. It's a nice lisp-y syntax though. I went looking for a single Markdown file I could dump into an LLM to \"teach\" it the language and found this one:  https://github.com/jordanhubbard/nanolang/blob/main/MEMORY.m...  Optimistically I dumped the whole thing into Claude Opus 4.5 as a system prompt to see if it could generate a one-shot program from it:     llm -m claude-opus-4.5 \\\n    -s https://raw.githubusercontent.com/jordanhubbard/nanolang/refs/heads/main/MEMORY.md \\\n    'Build me a mandelbrot fractal CLI tool in this language' \n   > /tmp/fractal.nano\n  \nHere's the transcript for that. The code didn't work:  https://gist.github.com/simonw/784"}
{"anchor": "Meditation as Wakeful Relaxation: Unclenching Smooth Muscle.        You must learn to sit perfectly still with every muscle tense for long periods.\n\n    Various things will happen to you while you are practising these positions; they must be carefully analysed and described.\n\n    Note down the duration of practice; the severity of the pain (if any) which accompanies it, the degree of rigidity attained, and any other pertinent matters.\n\n    When you have progressed up to the point that a saucer filled to the brim with water and poised upon the head does not spill one drop during a whole hour,\n    and when you can no longer perceive the slightest tremor in any muscle; when, in short, you are perfectly steady and easy, you will be admitted for examination;\n    and, should you pass, you will be instructed in more complex and difficult practices.\n  \n- Aleister Crowley, Liber E vel Exercitiorum, 1911.  https://hermetic.com/crowley/equinox/i/i/eqi01005  Possibly a non-Jungian explanation for John Sarno's hypothesis that chronic pain could be caused by emotional issues triggering interruption of blood supply to painful areas. The idea that there is much more computation (and intelligence/agency) going on in biological and other systems seems to be getting more popular. (The author writes: The whole body is a computer: it\u2019d be wasteful for evolution to only use the brain for computation when other systems could take part too.). Michael Levin has some super interesting ideas about this. Is there any evidence yet for this theory? Sounds falsifiable. I find it interesting how meditation eventually becomes an anxiety reduction method, or general emotion management. What should it be if there is no burden of stress or negative impression of any emotion? Why rid of stress? It comes and goes, it is as fleeting as relaxation. I guess meditation is a insight into there being no problem to solve, once that insight is clear, there is no need for meditation. why is there a video of orde", "positive": "Anti-aging injection regrows knee cartilage and prevents arthritis. As I've gotten older, my knees have been the main signal letting me know. I tore my meniscus years ago. This is exciting news for people like me. Cartilage is really the final frontier of health. If it wasn\u2019t for joints going bad, people could stay very active and fit pretty much all their life, with consistent exercise and healthy weight.  > Osteoarthritis occurs when a joint is stressed by aging, injury or obesity. The chondrocytes begin to release pro-inflammatory molecules and to break down collagen, which is the primary structural protein of cartilage. When collagen is lost, the cartilage thins and softens; the accompanying inflammation causes the joint swelling and pain that are hallmarks of the disease.  Collagen synthesis in the human body can be aided by  hydrolyzed collagen, Vitamin C, zinc and copper. oh, what a time to be a mouse! They don't say what is injected, calling it only a \"gerozyme inhibitor\". Original article appears to be:  https://www.science.org/doi/10.1126/science.adx6649  Inhibition of 15-hydroxy prostaglandin dehydrogenase promotes cartilage regeneration Mamta Singla  https://orcid.org/0000-0002-6408-1167 , Yu Xin Wang  https://orcid.org/0000-0001-8440-9388 , Elena Monti  https://orcid.org/0000-0002-3767-0855 , Yudhishtar Bedi  https://orcid.org/0000-0002-1213-4116 , [...] , and Nidhi Bhutani  https://orcid.org/0000-0002-7494-5870  FTFA:  \"Both systemic and local inhibition of 15-PGDH with a small molecule inhibitor (PGDHi) led to regeneration of articular cartilage and reduction in OA-associated pain.\"  \"PGDHi\" is a name for both the process \"15-hydroxyprostaglandin dehydrogenase inhibition\" and any inhibitor. This link(a PDF file) shows PGDHi's are powerful stuff:  https://www.biorxiv.org/content/biorxiv/early/2025/04/17/202...  \"PGDHi\"  could  be prostaglandin-E2 (dinoprostone):  https://en.wikipedia.org/wiki/Prostaglandin_E2  which was used in:  https://med.stanford.e", "negative": "American importers and consumers bear the cost of 2025 tariffs: analysis. > Event studies around discrete tariff shocks on Brazil (50%) and India (25\u201350%) confirm: export prices did not decline. Trade volumes collapsed instead. What if that was the intended result? who could possibly have foreseen this This is the case with any tax, it's mostly paid by the consumer. American trade policy has gone so far in the direction of Mercantilism that both the Neoliberal and the Keynesian economists can agree on something. That's not a good thing. We will see if SCOTUS majority decides tariffs are a tax or not and push the absurdity of their position even farther. I fear that they already decided that issue when they chose not to intervene and now have the excuse of \"lol well can't undo it now\" ready to go. Edit:  It appears Trump & Co intend to replace SCOTUS if they lose the tariffs ruling ...  https://www.nytimes.com/2026/01/19/us/politics/trump-tariffs...  -------- There does seem to be indications that the actual tariffs collected seems far lower than the actual tariffs promised, likely just half of what was promised:  https://www.nytimes.com/2026/01/03/business/economy/trump-ta...  Isn't this literally economics 101? How did we ever even end up imagining that tariffs are somehow paid by the exporter?? How could that possibly have not been the case.  A tariff is no different from the cost of any input into the price of a finished good.  There is some sense in which price increases are limited by supply and demand, but if the market won't pay for the production cost of the good, then the market will cease to provide that good.  There are only two possible outcomes, long term -- either the price goes up, or the product becomes unavailable. There's an argument that domestically produced goods would substitute for imported goods leaving the market, but markets are so global and intertwined now that even domestic goods have imported inputs that are also affected by tariffs, an"}
{"anchor": "AI is a horse (2024). It's also a big bloatey gas bag that needs constant de-farting to function \"I've been through the desert On AI with no name It felt good to be out of the rAIn In the desert, you can remember your name 'Cause there ain't no one for to give you no pain\" Or your typical American teenager. All true apart you can only lead it to water - it drinks ALL the water regardless of anything else. And the salesman always says it\u2019s great while it\u2019s in fact lame. \"Computers aren't the thing. They're the thing that gets you to the thing.\" My favorite quote from the excellent show halt and catch fire. Maybe applicable to AI too? I was expecting a spin about the faster horses Ai is a horse, i get it!\n I have a horse, and I put money in the front of the horse, and get \"ponyium\" out the back. If an AI aims at the thing we call it hallucinations, when humans do it we call the delusion goal setting. Either way it is an imagined end point that has no bearing in known reality. \"No, I am not a horse.\" Horse rumours denied. This micro blog meta is fascinating. I've seen small micro blog content like this popping up on the HN home page almost daily now. I have to start doing this for \"top level\"ish commentary. I've frequently wanted to nucleate discussions without being too orthogonal to thread topics. you rather don't want it in your bed Some day, I imagine one will be a senator AI is not a horse (2023)  https://essays.georgestrakhov.com/ai-is-not-a-horse/  I've always said that driving a car with modern driver assist features (lane centering / adaptive cruise / 'autopilot' style self-ish driving-ish) is like riding a horse. The early ones were like riding a short sighted, narcoleptic horse. Newer ones are improving but it's still like riding a horse, in that you give it high level instructions about where to go, rather than directly energising its muscles. A horse that can do your homework. Maybe from the client's point of view, although it's more likely a Tamagotchi. B", "positive": "Talking to LLMs has improved my thinking. This article matches my experience as well. Chatting with LLM has helped me to crystalize ideas I had before and explore relevant topics to widen the understanding. Previously, I wouldn't even know where to begin with when getting curious about something, but ChatGPT can tell you if your ideas have names, if they were explored previously, what primary sources there are. It's like a rabbit hole of exploring the world, a more interconnected one where barriers of entry to knowledge are much lower. It even made me view things I previously thought of as ultra boring in different, more approachable manner - for example, I never liked writing, school essays were a torture, and now I may even consider doing that out of my own will. Finally I can relate to someone\u2019s experience. For me even playing with image generators has improved my imagination. I share the sentiment here about LLMs helping to surface personal tacit knowledge and the same time there was a popular post[1] yesterday about cognitive debt when using AI. It's hard not to be in agreement with both ideas. [1]  https://news.ycombinator.com/item?id=46712678  Of course it has, I doubt this is uncommon. All my childhood I dreamed of a magic computer that could just tell me straightforward answers to non-straightforward questions like the cartoon one in Courage the Cowardly Dog. Today it's a reality; I can ask my computer any wild question and get a coherent, if not completely correct, answer. I agree that LLMs can be useful companions for thought when used correctly. I don\u2019t agree that LLMs are good at \u201csupplying clean verbal form\u201d of vaguely expressed, half-formed ideas and that this results in clearer thinking. Most of the time, the LLM\u2019s framing of my idea is more generic and superficial than what I was actually getting at. It looks good, but when you look closer it often misses the point, on some level. There is a real danger, to the extent you allow yourself to accept th", "negative": "Porting 100k lines from TypeScript to Rust using Claude Code in a month. For typing \u201cyes\u201d or \u201cy\u201d automatically into command prompts without interacting, you could have utilized the command \u2018yes\u2019 and piped it into the process you\u2019re running as a first attempt to solving the yes problem. \n https://man7.org/linux/man-pages/man1/yes.1.html  How much does it cost to run Claude Code 24 hrs/day like this. Does the $200/month plan hold up? My spend on Cursor has been high... I'm wondering if I can just collapse it into a 200/month CC subscription. I'm hoping that one day we can use AI to port the millions of lines in the modules of the Python ecosystem to a GIL-free version of Python. Did you ever consider using something like Oh My Opencode [1]?\nI first saw it in the wake of Anthropic locking out Opencode. I haven\u2019t used it but it appears to be better at running continuously until a task is finished. Wondering if anyone else has tried migrating a huge codebase like this. [1]  https://github.com/code-yeongyu/oh-my-opencode  Some quotes from the article stand out: \n\"Claude after working for some time seem to always stop to recap things\"\nQuestion: Were you running out of context? That's why certain frameworks like intentional compaction are being worked on.  Large codebases have specific needs when working with an LLM. \"I've never interacted with Rust in my life\" :-/ How is this a good idea? How can I trust the generated code? This is actually pretty incredible. Cannot really argue against the productivity in this case. Honestly I am really interested in trying to port the rust code to multiple languages like golang,zig, even niche languages like V-lang/Odin/nim etc. It would be interesting if we use this as a benchmark similar to  https://benjdd.com/languages/  or  https://benjdd.com/languages2/  I used gitingest on the repository that they provided and its around ~150k tokens Currently pasted it into the free gemini web and asked it to write it in golang and it said that li"}
{"anchor": "Open Infrastructure Map. I find this site so fascinating, seeing how all the massive power lines are hooked up to far-away power plants and gradually have their voltage stepped down as they connect to consumers. All the undersea cables and pipelines I didn't know about. This is a bad idea in terms of security in war Some previous discussion: 2024  https://news.ycombinator.com/item?id=39109185  2022  https://news.ycombinator.com/item?id=29948473  Gigachad french nuclear versus virgin german coal in map form. When I lived in Texas, we had a massive storm in winter of 2021 leaving many without power for a week. I was told that Texas maintained its own energy grid independent from the rest of the nation\u2019s eastern and western grids, and supposedly only had a handful of high-voltage DC lines running between Texas\u2019s and the rest of the nation\u2019s. Supposedly this was why we couldn\u2019t rely on excess capacity from anywhere else in the nation while our power generation capability was down. But this map doesn\u2019t seem to show Texas as isolated - there appear to be many lines in and out and no clear separation? An initially-stupid-sounding idea I heard a while back was running power cables through the ocean floors between America and the rest of the world. It's apparently feasible and the big benefit of it is that at the grid peak hour when the sun is not shining in Europe, they can get cheap solar from America and vice versa The map for Australia is interesting.  Is this missing data?  See no infrastructure for Alice Springs in the interior of Australia. Excellent link, thank you for posting! Wanted to do a map of the power network here in Romania, hadn't thought to check if anything similar already existed, or I couldn't find it myself, at least, but it seems like this map has (almost) all that I wanted to do in that respect, including the position of the power poles on the ground. For the Netherlands (and surrounding countries), there is Hoogspanningsnet (the high-voltage grid), ", "positive": "Don't fall into the anti-AI hype. > As a programmer, I want to write more open source than ever, now. I want to write less, just knowing that LLM models are going to be trained on my code is making me feel more strongly than ever that my open source contributions will simply be stolen. Am I wrong to feel this? Is anyone else concerned about this? We've already seen some pretty strong evidence of this with Tailwind. \"Die a hero or live long enough to see yourself become the villain\" AI is both a near-perfect propaganda machine and, in the programming front, a self-fulfilling prophecy: yes, AI will be better at coding than human. Mostly because humans are made worse by using AI. The \u201canti-AU hype\u201d phrase oversimplifies what\u2019s playing out at the moment. On the tech side, while things are a bit rough around the edges still the tech is very useful and isn\u2019t going away. I honestly don\u2019t see much disagreement there. The concern mostly comes from the business side\u2026 that for all the usefulness on the tech there is no clearly viable path that financially supports everything that\u2019s going on. It\u2019s a nice set of useful features but without products with sufficient revenue flowing in to pay for it all. That paints a picture of the tech sticking around but a general implosion of the startups and business models betting on making all this work. The later isn\u2019t really \u201canti-AI hype\u201d but more folks just calling out the reality that there\u2019s not a lot of evidence and data to support the amount of money invested and committed. And if you\u2019ve been around the tech and business scene a while you\u2019ve seen that movie before and know what comes next. In 5 years time I expect to be using AI more than I do now. I also expect most of the AI companies and startups won\u2019t exist anymore. What I don't understand about this whole \"get on board the AI train or get left behind\" narrative, what advantage does an early adopter have for AI tools? The way I see it, I can just start using AI once they get good", "negative": "Nvidia Stock Crash Prediction. It goes to nearly zero if China invades Taiwan, and that seems like it has at least a 10% chance of happening in the next year or two. > One of the questions of the 2026 acx prediction contest is whether Nvidia\u2019s stock price will close below $100 on any day in 2026. Maybe I\u2019m missing something, but isn\u2019t this just a standard American put option with a strike of $100 and expiry of Dec 31st? He doesn't really address his own question. He's answering the question \"How should options be priced?\" Sure, it's possible for a big crash in Nvidia just due to volatility.  But in that case, the market as a whole would likely be affected. Whether Nvidia specifically takes a big dive depends much more on whether they continue to meet growth estimates than general volatility.  If they miss earnings estimates in a meaningful way the market is going to take the stock behind the shed and shoot it.  If they continue to exceed estimates the stock will probably go up or at least keep its present valuation. How much of their turnover is financed directly or indirectly by themselves, then leveraged further by their 'customers' to collaterize further investments? Are they already \"too big to fail\"? For better or worse, they are 'all in' on AI. This article goes more into the technical analysis of the stock rather than the underlying business fundamentals that would lead to a stock dump. My 30k ft view is that the stock will inevitably slide as AI datacenter spending goes down. Right now Nvidia is flying high because datacenters are breaking ground everywhere but eventually that will come to an end as the supply of compute goes up. The counterargument to this is that the \"economic lifespan\" of an Nvidia GPU is 1-3 years depending on where it's used so there's a case to be made that Nvidia will always have customers coming back for the latest and greatest chips. The problem I have with this argument is that it's simply unsustainable to be spending that much eve"}
{"anchor": "The Illustrated Transformer. Haven't watched it yet... ...but, if you have favorite resources on understanding Q & K, please drop them in comments below... (I've watched the Grant Sanderson/3blue1brown videos [including his excellent talk at TNG Big Tech Day '24], but Q & K still escape me). Thank you in advance. Here's the comment from the author himself (jayalammar) talking about other good resources on learning Transformers:  https://news.ycombinator.com/item?id=35990118  Kudos also to Transformer Explainer team for putting some amazing visualizations  https://poloclub.github.io/transformer-explainer/ \nIt really clicked to me after reading this two and watching 3blue1brown videos I have this book. Really a life savior to help me catching up a few months ago when my team decided to use LLMs in our systems. (Going on a tangent.) The number of transformer explanations/tutorials is becoming overwhelming. Reminds me of monads (or maybe calculus). Someone feels a spark of enlightenment at some point (while, often, in fact, remaining deeply confused), and an urge to share their newly acquired (mis)understanding with a wide audience. People need to get away from this idea of Key/Query/Value as being special. Whereas a standard deep layer in a network is matrix * input, where each row of the matrix is the weights of the particular neuron in the next layer, a transformer is basically input* MatrixA, input*MatrixB, input*MatrixC (where vector*matrix is a matrix), then the output is C*MatrixA*MatrixB*MatrixC. Just simply more dimensions in a layer. And consequently, you can represent the entire transformer architecture with a set of deep layers as you unroll the matricies, with a lot of zeros for the multiplication pieces that are not needed. This is a fairly complex blog but it shows that its just all matrix multiplication all the way down.  https://pytorch.org/blog/inside-the-matrix/ . I think the internal of transformers would become less relevant like internal of compile", "positive": "Understanding Machine Learning: From Theory to Algorithms. Anyone who wants to demystify ML should read: The StatQuest Illustrated Guide to Machine Learning [0] By Josh Starmer.\nTo this day I haven't found a teacher who could express complex ideas as clearly and concisely as Starmer does. It's written in an almost children's book like format that is very easy to read and understand. He also just published a book on NN that is just as good. Highly recommend even if you are already an expert as it will give you great ways to teach and communicate complex ideas in ML. [0]:  https://www.goodreads.com/book/show/75622146-the-statquest-i...  I have read parts of it years ago. As far as I remember, this is very theoretical (lots of statistical learning theory, including some IMHO mistaken treatment of Vapnik's theory of structural risk minimization), with strong focus on theory and basicasically zero focus on applications. Which would be completely outdated by now anyway, as the book is from 2014, an eternity in AI. I don't think many people will want to read it today. As far as I know, mathematical theories like SLT have been of little use for the invention of transformers or for explaining why neural networks don't overfit despite large VC dimension. Edit: I think the title \"From theory to machine learning\" sums up what was wrong with this theory-first approach. Basically, people with interest in math but with no interest in software engineering got interested in ML and invented various abstract \"learning theories\", e.g. statistical learning theory (SLT). Which had very little to do with what you can do in practice. Meanwhile, engineers ignored those theories and got their hands dirty on actual neural network implementations while trying to figure out how their performance can be improved, which led to things like CNNs and later transformers. I remember Vapnik (the V in VC dimension) complaining in the preface to one of his books about the prevalent (alleged) extremism of", "negative": "California is free of drought for the first time in 25 years. As John Steinback said in  East of Eden : \u201cI have spoken of the rich years when the rainfall was plentiful. But there were dry years too, and they put a terror on the valley. The water came in a thirty-year cycle. There would be five or six wet and wonderful years when there might be nineteen to twenty-five inches of rain, and the land would shout with grass. Then would come six or seven pretty good years of twelve to sixteen inches of rain. And then the dry years would come, and sometimes there would be only seven or eight inches of rain. The land dried up and the grasses headed out miserably a few inches high and great bare scabby places appeared in the valley. The live oaks got a crusty look and the sage-brush was gray. The land cracked and the springs dried up and the cattle listlessly nibbled dry twigs. Then the farmers and the ranchers would be filled with disgust for the Salinas Valley. The cows would grow thin and sometimes starve to death. People would have to haul water in barrels to their farms just for drinking. Some families would sell out for nearly nothing and move away. And it never failed that during the dry years the people forgot about the rich years, and during the wet years they lost all memory of the dry years. It was always that way.\u201d The dams in california were built years ago for a smaller population and since then they've only removed them. If we simply built like the people who first came to california did we would never have water shortages again. Any water shortage is a 1:1 failure of the state to do the clear and obvious task needed. strange because this is one of the warmest winters in decades. snow levels are far below normal, i saw 8% of normal in truckee. full reservoirs now are great but keeping them filled depends on a long snow melt going into june. i don\u2019t think this is going to be a good year for that And yet our water rates are still as if we are in a drought. Previ"}
{"anchor": "40 percent of fMRI signals do not correspond to actual brain activity. you're telling me the results of this paper were likely bs? ---  https://www.sciencedirect.com/science/article/abs/pii/S10538...  this headline is a bit misleading on the first read, since it only affects functional (f)MRI, which is controversial since a longer time. a prominent example is the activity that has been detected in a dead salmon Why did TUM let this misleading headline front the news release? Dont we have enough issues with Academia?  The result just mean BOLD is an imperfect proxy. Can the OP change the HN item title so scrollers don't think there is a problem with MRI? Isn't fMRI being questioned? As someone who used to work at the Cognitive Neurophysiology Lab in the Scripts Institute-- doing some work on functional brain image-- I can confirm this was not news even thirty years ago.  I guess this is trying to make some point to lay people? This isn\u2019t entirely news to people in the field doing research, but it\u2019s important information to keep in mind when anyone starts pushing fMRI (or SPECT) scans into popular media discussions about neurology or psychiatry. There have been some high profile influencer doctors pushing brain imaging scans as diagnostic tools for years. Dr. Amen is one of the worst offenders with his clinics that charge thousands of dollars for SPECT scans (not the same as the fMRI in this paper but with similar interpretation issues) on patients. Insurance won\u2019t cover them because there\u2019s no scientific basis for using them in diagnosing or treating ADHD or chronic pain, but his clinics will push them on patients. Seeing an image of their brain with some colors overlayed and having someone confidently read it like tea leaves is highly convincing to people who want answers. Dr. Amen has made the rounds on Dr. Phil and other outlets, as well as amassing millions of followers on social media. This study is validating a commonplace fMRI measure (change in blood-oxygenat", "positive": "Neural Networks: Zero to Hero. I saw this on a comment [0] and thought it deserved a post. [0]  https://news.ycombinator.com/item?id=46483776  A couple years ago I wrote a tutorial how to build a Neural Network in NumPy from scratch.\u00b9 \u00b9  https://matthodges.com/posts/2022-08-06-neural-network-from-...  This new? Hasn't the zero-to-hero course been around for a while? A bit of shameless plug, I wrote 2 articles about this after doing the course a while ago.  https://martincapodici.com/2023/07/15/no-local-gpu-no-proble...   https://martincapodici.com/2023/07/19/modal-com-and-nanogpt-...  I'm not sure how it compares, but another option is the Hugging Face learning portal [0].  I'm doing the Deep RL Course and so far it's pretty straight forward (although when it gets math heavy I'm going to suffer). [0] -  https://huggingface.co/learn  its fun seeing HN articles with huge upvotes but no comments, similar to when some super esoteric maths gets posted: everyone upvotes out of a common understanding of its genius, but indeed by virtue of its genius most of us are not sufficiently cognitively gifted to provide any meaningful commentary. the karpathy vids are very cool but having watched it, for me the takeaway was \"i had better leave this for the clever guys\". thankfully digital carpentry and plumbing is still in demand, for now! what next now tho? i co-incidentally completed watching his last vid of training up gpt-2 today :-) . I\u2019ve gone through this series of videos earlier this year. In the past I\u2019ve gone through many \u201ceducational resources\u201d about deep neural networks - books, coursera courses (yeah, that one), a university class, the fastai course - but I don\u2019t work with them at all in my day to day. This series of videos was by far the best, most \u201cintuition building\u201d, highest signal-to-noise ratio, and least \u201cannoying\u201d content to get through. Could of course be that his way of teaching just clicks with me, but in general - very strong recommend. It\u2019s the primary reso", "negative": "Replacing Protobuf with Rust. Are they sure it's because Rust? Perhaps if they rewrite Protobuf in Rust it will be as slow as the current implementation. They changed the persistence system completely. Looks like from a generic solution to something specific to what they're carrying across the wire. They could have done it in Lua and it would have been 3x faster. I vaguely recall that there's a Rust macro to automatically convert recursive functions to iterative. But I would just increase the stack size limit if it ever becomes a problem. As far as I know the only reason it is so small is because of address space exhaustion which only affects 32-bit systems. FlatBuffers are already faster than that. But that's not why we choose Protobuf. It's because a megacorp maintains it. \"5 times faster\" reminds me of Cap'n Proto's claim: in benchmarks, Cap\u2019n Proto is INFINITY TIMES faster than Protocol Buffers:  https://capnproto.org/  Just for fun, how often do regular-sized companies that deal in regular-sized traffic need Protobuf to accomplish their goals in the first place, compared to JSON or even XML with basic string marshalling? tldr: they replaced using protobuf as the type system across language boundaries for FFI with true FFI Don't read clickbaity headlines and scan hacker news five times faster. I find the title a bit misleading. I think it should be titled It\u2019s Faster to Copy Memory Directly than Send a Protobuf. Which then seems rather obvious that removing a serialization and deserialization step reduces runtime. I don't understand, I used protobuf for map data, but it is a hardcore simple format, this is the whole purpose of it. I wrote assembly, memory mapping oriented protobuf software... in assembly, then what? I am allowed to say I am going 1000 times faster than rust now??? You should be terrified of the instability you're introducing to achieve this. Memory sharing between processes is very difficult to keep stable, it is half the reason kernels exist. M"}
{"anchor": "Gemini 3 Flash: Frontier intelligence built for speed. Deepmind Page:  https://deepmind.google/models/gemini/flash/  Developer Blog:  https://blog.google/technology/developers/build-with-gemini-...  Model Card [pdf]:  https://deepmind.google/models/model-cards/gemini-3-flash/  Gemini 3 Flash in Search AI mode:  https://blog.google/products/search/google-ai-mode-update-ge...  They went too far, now the Flash model is competing with their Pro version. Better SWE-bench, better ARC-AGI 2 than 3.0 Pro. I imagine they are going to improve 3.0 Pro before it's no more in Preview. Also I don't see it written in the blog post but Flash supports more granular settings for reasoning: minimal, low, medium, high (like openai models), while pro is only low and high. Don\u2019t let the \u201cflash\u201d name fool you, this is an amazing model. I have been playing with it for the past few weeks, it\u2019s genuinely my new favorite; it\u2019s so fast and it has such a vast world knowledge that it\u2019s more performant than Claude Opus 4.5 or GPT 5.2 extra high, for a fraction (basically order of magnitude less!!) of the inference time and price Does this imply we don't need as much compute for models/agents? How can any other AI model compete against that? Pretty stoked for this model. Building a lot with \"mixture of agents\" / mix of models and Gemini's smaller models do feel really versatile in my opinion. Hoping that the local ones keep progressively up (gemma-line) These flash models keep getting more expensive with every release. Is there an OSS model that's better than 2.0 flash with similar pricing, speed and a 1m context window? Edit: this is not the typical flash model, it's actually an insane value if the benchmarks match real world usage. > Gemini 3 Flash achieves a score of 78%, outperforming not only the 2.5 series, but also Gemini 3 Pro. It strikes an ideal balance for agentic coding, production-ready systems and responsive interactive applications. The replacement for old flash models will be proba", "positive": "Bus stops here: Shanghai lets riders design their own routes. This is really brilliant \u2014 like desire paths, but for transit. Obviously execution will be challenging, but the concept is fantastic, and China/Shanghai seems like one of the few places with the requisite density & state capacity to actually make this work. Generally I think that the design of public spaces has SO MUCH room to be improved by just responding to the wisdom of the crowd. I'm glad that Shanghai has moved to the next level in public transportation in meeting customer demand. Most cities don't have the funds to buy smallish buses and labour available as drivers. They don't have the money or willpower to get frequencies to turn up and go levels (ie frequent) and leave people with long walks to widely spaced routes. Tangent: I\u2019ve often thought that it would be great to let people design their own political districts to reduce gerrymandering At the polling place you\u2019d get a map with your census tract and then be asked \u201cwhich two or three adjacent tracts are most similar to your community\u201d. Eventually you\u2019d end up with some sort of gram matrix for tract-to-tract affinity, and then you could apply some algorithmic segmentation. Two problems: - this is far too complex for most voters to understand, much less trust, what\u2019s happening - the fact it\u2019s \u201calgorithmic\u201d would give a sheen of pseudo objectivity, but the selection of the actual algorithm would still allow political infouence over boundaries Chiming in from Los Angeles, USA to say wow, must be nice living in a modern society that prioritizes public transit and peoples' ease of movement. I know, I know, it comes with trade offs of living in an authoritarian state, but the absolute abysmal state of infrastructure in this country is maddening. Ever been on a train in Denmark or Japan or Switzerland? This remind me that road router should be walked by passenger rather than designed by designers. China is the only modern country that has both the cap", "negative": "Mammals have evolved into ant eaters 12 times since the dinosaur age \u2013 study (2025). Source: YouTube  https://share.google/XA0msyff8lybu47FK  \"Expert Wasted Entire Life Studying Anteaters\"\n-The Onion Sounds similar to the multiple evolution paths to crabs:  https://en.wikipedia.org/wiki/Carcinisation  \"Ants are great if you're really hungry and want two thousand of something.\" - Mitch Hedburg This makes sense. The biomass of ants is enormous. It's about 10% of all present livestock on earth. It's a huge source of energy and protein. So, it stands to reason evolution took animals down the path of taking advantage of that source several times. Previously:  https://news.ycombinator.com/item?id=44599334  Another interesting fact I learned from HN: \u201cTwo randomly selected trees are not likely to be more closely related than any two other randomly selected plants. They're not a family but rather a strategy that evolution has rediscovered several times separately.\" \"I used to evolve into an anteater, I still do, but I used to too\" The OG quote by him is about rice. Nevertheless, very funny! In other terms, the most populous, widespread, and consistently available plant-eater makes for an ideal carnivore target. Long after humans spread out across the stars, maybe the perfect human consuming predator will emerge. It's strange to think we chose to hunt or raise large animals; and to perform all that such a choice implies i.e. growing plants to feed them and more generally farming, when we could just raise ants and plants. As a person who is uneducated on this, I\u2019ve always wondered if it isn\u2019t also something to do with large objects that have collided into in the past .. these things would essentially wipe out most everything on the ground planet and force things to re-evolve again and that is why we see similar patterns .. like Carcinisation [0] [0]  https://en.wikipedia.org/wiki/Carcinisation  except for the fact that while evolving towards eating ants is inevitatable, then "}
{"anchor": "What's the strongest AI model you can train on a laptop in five minutes?. Perhaps grimlock level:  https://m.youtube.com/shorts/4qN17uCN2Pg  Instead of time it should be energy. What is the best model you can train with a given budget in Joules. Then the MBP and the H100 are on a more even footing. I love seeing explorations like this, which highlight that easily accessible hardware can do better than most people think with modern architectures. For many novel scientific tasks, you really don't need an H100 to make progress using deep learning over classical methods. I suspect one can go a lot further by adopting some tweaks from the GPT-2 speedrun effort [0], at minimum Muon, better init and carefully tuning learning rate. [0]:  https://github.com/KellerJordan/modded-nanogpt  But supposing you have a real specific need to train, is the training speed still relevant? Or do the resources spent on gathering and validating the data set dwarf the actual CPU/GPU usage? The most powerful Macbook Pro currently has 16 CPU cores, 40 GPU cores, and 128 GB of RAM (and a 16-core \u201cneural engine\u201d specifically designed to accelerate machine learning). Technically, it is a laptop, but it could just as well be a computer optimized for AI. > Paris, France is a city in North Carolina. It is the capital of North Carolina, which is officially major people in Bhugh and Pennhy. The American Council Mastlandan, is the city of Retrea. There are different islands, and the city of Hawkeler: Law is the most famous city in The Confederate. The country is Guate. I love the phrase \"officially major people\"! I wonder how it could be put to use in everyday speech? Not the point of the exercise obviously, but at five minutes' training I wonder how this would compare to a Markov chain bot. Any reason to upgrade an M2 16GB macbook to a M4 ..GB (or 2026 M5) for local LLMs? Due an upgrade soon and perhaps it is educational to run these things more easily locally? You could train an unbeatable tic-tac-to", "positive": "Over 36,500 killed in Iran's deadliest massacre, documents reveal. I can't comprehend how a population can kill that many of their own people. They aren't even an \"other\" people, which has been the most common scapegoat lately. Same skin color, same religion, same language, same homeland. For comparison, estimates of the 1989 Tiananmen Square massacre death count are usually put in the 300-1,000 range by journalists and human rights groups.  https://en.wikipedia.org/wiki/1989_Tiananmen_Square_protests...  hm, I think we should re-evaluate sanctioning or civilian pressure campaigns, since the guise is for them to coax or turn on the government for regime change, but the government can just hire mercenaries from outside the country. don't know a solution but this one isn't it The source (Iran International) is backed by Saudi money and has a bias to dunk on Iran. That said, I'm sure the death count numbers from the Rasht Massacre are staggeringly higher than the initial tallies of 2-5k. This is certainly the end of peaceful Iranian protests. Whether it leads to a violent revolution or a static police state like North Korea remains to be seen. How is this possible without explosives? Even with vehicle mounted machine guns it seems like a crazy high number. Did the protestors get boxed in somehow? And across so many locations, that seems to require a crazy amount of coordination to kill so many in so little time. That's crazy. That's like ~40% of the deaths in the current gaza war, except over just 2 days instead of 2 years. This is depressing because we will go to war over this and it\u2019s going to be five years before people realizing they were tricked by \u201cbabies in incubators\u201d propaganda. The internet is fragile. Access can be so easily cut off for the masses in dire times. Take a good look US, because once you're down far enough the fascist drain, that's the cost of trying to claw your way back out. And there's no hope of external intervention given nuclear arms Earlie", "negative": "Cloudflare claimed they implemented Matrix on Cloudflare workers. They didn't. Days after the fake story about Cursor building a web browser from scratch with GPT-5.2 was debunked. Disbelief should be the default reaction to stories like this. I've never thought someone should be fired based on a blog post but man, this comes real close. Honestly I like Cloudflare's CDN and DNS but beyond that I don't really trust much else from them. In the past though their blog has been one of the best in the space and the information has been pretty useful, almost being a gold standard for postmortems, but this seems especially bad. Definitely out of line compared to the rest of their posts. And with the recent Cursor debacle this doesn't help. I also don't really get their current obsession with porting every piece of software on Earth to Workers recently... I found the source code Jade was referring to, and it looks like the author just noticed this thread:  https://github.com/nkuntz1934/matrix-workers/commit/0823b47c...  Technical blogs from infrastructure companies used to serve two purposes: demonstrate expertise and build trust. When the posts start overpromising, you lose both. I don't know enough about this specific implementation to say whether \"implemented Matrix\" is accurate or marketing stretch. But the pattern of \"we did X\" blog posts that turn out to be \"we did a demo of part of X\" is getting tiresome across the industry. The fix is boring: just be precise about what you built. \"We prototyped a Matrix homeserver on Workers with these limitations\" is less exciting but doesn't erode trust. The developer just \"cleaned up the code comments\", i.e. they removed all TODOs from the code:  https://github.com/nkuntz1934/matrix-workers/commit/2d3969dd...  Professionalism at its finest! It\u2019s not a  working  or  complete  implementation, but\u2026 It is worrying to see a major vendor release code that does not actually work just to sell a new product. When companies pretend that com"}
{"anchor": "Where can you go in Europe by train in 8h?. If you now could just book a train between these cities on a common european platform (or local transportation provider...)... one could dream... just booking a train and getting a quote crossing multiple borders (without interrail) is just a nightmare :( Title shared on HN left me somewhat disappointed.  The actual time appears to be \"Where can you go by train in 8h?\", though that's somewhat less clear.  It only seems to include central stations of larger cities, though I was hoping for a list of shortest travel times between stations in Europe, as more of a thought/data experiment.  Or put another way; which two train stations in Europe have the least distance between them? Anyway, the shared feature is neat, but seems to be somewhat iffy once you get out of the bigger cities.  If a route has 2 or more connections, it seems to struggle to show them.  While true to its message, I still feel the restriction of 8 hours misses sleeper trains, where travel time is less essential compared to daytime trains. It's cute for discoverability, but for a specific train search, I would definitely defer to bahn.de, which basically includes all train stations in Europe. There is a website I love for seeing how to get almost everywhere in Europe by train:  https://www.seat61.com/  I don't understand how it works. First time clicking on Poland, it showed a kind of a heat map around some city. Then I click on another location and nothing happens. OK, there's a \"back\" button, I go back, click on the map again in a different place and... nothing happens. No heat map. At some point in frustration I accidentally move the mouse while clicking and the map rotates upside down. Don't know, is it me, my browser, or there's something about the UI. Since train fans always like to point this out when it comes to flying: this is how far you can get in 8 hours  on the train . It doesn\u2019t include the time to get to the station, the buffer time you need (i", "positive": "Claude Code can debug low-level cryptography. This resonates with me a lot: > As ever, I wish we had better tooling for using LLMs which didn\u2019t look like chat or autocomplete I think part of the reason why I was initially more skeptical than I ought to have been is because chat is such a garbage modality. LLMs started to \"click\" for me with Claude Code/Codex. A \"continuously running\" mode that would ping me would be interesting to try. Coming soon, adversarial attacks on LLM training to ensure cryptographic mistakes. CLI terminals are incredibly powerful. They are also free if you use Gemini CLI or Qwen Code. Plus, you can access any OpenAI-compatible API(2k TPS via Cerebras at 2$/M or local models). And you can use them in IDEs like Zed with ACP mode. All the simple stuff (creating a repo, pushing, frontend edits, testing, Docker images, deployment, etc.) is automated. For the difficult parts, you can just use free Grok to one-shot small code files. It works great if you force yourself to keep the amount of code minimal and modular. Also, they are great UIs\u2014you can create smart programs just with CLI + MCP servers + MD files. Truly amazing tech. > For example, how nice would it be if every time tests fail, an LLM agent was kicked off with the task of figuring out why, and only notified us if it did before we fixed it? You can use Git hooks to do that. If you have tests and one fails, spawn an instance of claude a prompt -p 'tests/test4.sh failed, look in src/ and try and work out why'       $ claude -p 'hello, just tell me a joke about databases'\n\n    A SQL query walks into a bar, walks up to two tables and asks, \"Can I JOIN you?\"\n\n    $ \n  \nOr if, you use Gogs locally, you can add a Gogs hook to do the same on pre-push > An example hook script to verify what is about to be pushed.  Called by \"git push\" after it has checked the remote status, but before anything has been pushed.  If this script exits with a non-zero status nothing will be pushed. I like this idea. ", "negative": "I'm 34. Here's 34 things I wish I knew at 21. The days are long, but the years are short Congrats, you're half way there to publish your first self-help book! > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. It really seems quite difficult for straight men to succeed at this. > If you're a man, one of your hardest battle may be not giving in to sexual urges that cause harm to others. History is littered with otherwise entirely brilliant men who succeeded at everything but this. You must succeed. I'm not sure I like the framing of this Sex and violence intersect and interweave. It's not realistic to avoid any hurt. > One day \u2013 probably somewhere between 28 and 38 \u2013 you'll wake up and just feel 'off'. A bit sore. A bit tired. That feeling will never leave you. Be grateful for your youth while you have it. This happened when I was 20. I don't know what else to say other than, it fucking sucks. 35. Women can be as horny and lonely as men and all you need to do is talk to them to meet them. This was a revelation to me in my early-thirties. > Eating meat is quite clearly immoral. Unless it will be detrimental to your health, eat as little as possible. Carnivorous animals, are they immoral? >If you're a man, one of your hardest battles may be not giving in to sexual urges that cause harm to others. What the ... Some great life lessons here, but also some I don't agree with: - The lazy person works twice as hard.\nOften I found you can save a lot of time just trying to the minimal possible and gain a lot of insights of why something is minimal vs not -The opinion of the person who rarely offers it is listened to more closely.\nI found the opposite to be true, those who don't offer their thoughts frequently are often dismissed when they do want to share something Anyway, many of the points are great.. I would also add to k"}
{"anchor": "Profession by Isaac Asimov (1957). Link to the story without ads  https://www.inf.ufpr.br/renato/profession.html  one of asimov's finest , a metaphor that continues to find relevance in my day to day existence - that the conclusions we so readily come to are assumptions made in the absence of the awareness of something more This is my favorite Asimov story. It's got a protagonist with compelling motivations, a society that has problems but also convincing reasons why they persist, and a great ending.  Dr Antonelli said, \u201cOr do you believe that studying some subject will bend the brain cells in that direction, like that other theory that a pregnant woman need only listen to great music persistently to make a composer of her child. Do you believe that?\u201d  Apparently, Asimov was an early critic of the \u201cMozart in the womb\u201d movement. Is this still in print, maybe as part of a collection? I tried to find it but couldn't. Many of his other works seem to be available as paperback, including a bunch of story collections. What the hell that was a good read. Ending was great (though the last line did confuse me) Such a great ending. Really makes one wonder about the current AI hype of getting the machines to take over our work. Remind me of a recent discussion we had among Stackoverflow moderator: > \u201cThink about it,\u201d he continued. \u201cWho discovers the edge cases the docs don\u2019t mention? Who answers the questions that haven\u2019t been asked before? It can\u2019t be people trained only to repeat canonical answers. Somewhere, it has to stop. Somewhere, someone has to think.\u201d > \u201cYes,\u201d said the Moderator. > He leaned back. For a moment, restlessness flickered in his eyes. > \u201cSo why wasn\u2019t I told this at the start?\u201d > \u201cIf we told everyone,\u201d said the Moderator gently, \u201cwe\u2019d destroy the system. Most contributors must believe the goal is to fix their CRUD apps. They need closure. They need certainty. They need to get to be a Registered Something\u2014Frontend, Backend, DevOps, Full stack. Only someone w", "positive": "Early Retirement May Speed Up Cognitive Decline: Study. Anecdotally, my grandfather is 92 or so and still works as a journalist (reduced hours). He is still super sharp and does yoga every day. Blows my mind. I hope not, I recently retired. Still, the idea makes some sense. In retirement, I try to read one paper a day (usually deep learning, PGM, or classic AI), play at least one game of Go and Chess, do some recreational programming, and read. But, I don\u2019t work into a state of brain-tiredness anymore like I used to at work. My dad is a doctor in his 70s. He works 60 hour weeks (which he claims counts as retirement for doctors). He truly believes that true retirement is suicide. He wants to be found dead while doing rounds at the hospital. I've always benchmarked post-retiring cognitive abilities and professional continuity with Noam Chomsky. He is my hero in that aspect too. If I can continue to do what I do now at his age, I'm ready for the off. Not only early retirement but any kind of retirement that gets the retiree in a mode that they don't have to try anymore will result in cognitive decline. I am seeing this in my dad who has been retired for ten years now. Throughout his work life he was a sharp hard working banker. Now he uses his age and retirement as an excuse for not trying. Just yesterday he wanted me to order something for him from Amazon. I told him to send me the link to the item. He asked me how to do that. I told him if you can't find the Share link just copy the link and send it to me. He responds by saying that he doesn't know how to do copy-paste. He has been using computers for at least the last fifteen years. I asked him how come he didn't know how to copy-paste. His response was - I am retired now and there's nobody to tell me or teach me. I can see the cognitive decline. Things he used to be able to do, he can't anymore. This type of attitude is also affecting his self respect and confidence. This is something I think about a lot. I plan to", "negative": "JuiceSSH \u2013 Give me my pro features back. Wow nice work. Thanks for doing this and writing it up. Damn. I especially liked the cloud backup & sync. Any good alternatives? This might be a good plug for Morphie or Revanced patches to automate the patch process. I haven't used my Pro purchase in years, but if I did want to ssh from my phone today, I'd use the newish Terminal app, available since Android 15. It's a full Debian virtual machine. smali code is funny to read, basically an object-oriented assembly language (feels so wrong) I just tried to purchase pro from within the app just to see what the price is, and the Google Play purchase popup tells me it's not available. Interesting. Wow. Thanks for this. I haven't logged into Juice SSH in years, but i thought it had all my ssh keys backed up in the cloud. > JuiceSSH used to be the best SSH client available on Android until December 2025. Really? I always gave that award to Termius, which is kind of my second best behind Servercat which I miss very dearly from the iOS environment. Really great terminal app that I used in Android for a very long time with some interesting features. Also, Mosh shell support for sshing in degraded connection environments! Replaced JuiceSSH two years ago with ConnectBOT ( https://play.google.com/store/apps/details?id=org.connectbot... ) as a \"free\" alternative. Never looked back. Not trying to defend the developer here but they went really silent once before like this. Then came out of the gate with a bunch of updates and new features. \nI'm hoping they've just got really busy with life, I know when I emailed them before they have been responsive and helpful. \nI mean hell they might have died? Does the Store have a process for this? \nThis app has been around a long time so I don't understand the rugpull comments. \nAlso the syned keys are (supposedly, I guess we don't have the source) encrypted so even if the dev is no longer active that aspect should be secure I hope. My Pro features sti"}
{"anchor": "The '3.5% rule': How a small minority can change the world (2019). This rule didn't hold in Israel in the last 3 years. Well over 3.5% went to the streets and the government remains in tact. This is plausible. Non violent groups will often have wider public support (because most people would prefer not to support violence) and if those in power use violence against the non-violent it increases public sympathy for them. Iran proved it wrong (the regime mobilized roughly 1% of the country's population to crack down on protesters) with regards to Single Party Regimes, and knowing people at the Ash Center, they are pessimistic about this as well. If you have 2+ groups with opposing views, each 3.5%+ it's pretty clear that at least one of the 3.5%+ groups will fail. Others here note it's really \"3.5% if there's no one seriously opposing their objectives\" but in my opinion that's a meaningless rule. Of course in those cases non-conflict resolves the issue.  https://medium.com/incerto/the-most-intolerant-wins-the-dict...  (2019) Chenoweth has backed off her previous conclusions in recent years, observing that nonviolent protest strategies have dramatically declined in effectiveness as governments have adjusted their tactics of repression and messaging. See eg  https://www.harvardmagazine.com/2025/07/erica-chenoweth-demo...  One current example of messaging can be seen in the reflexive dismissal  by the current US government and its propagandists of any popular opposition as 'paid protesters'. Large attendance at Democratic political rallies during the 2024 election was dismissed as being paid for by the campaign, any crowd protesting government policy is described as either a rioting or alleged to be financed by George Soros or some other boogeyman of the right. This has been going on for years; the right simply refuses to countenance the possibility of legitimate organic opposition, while also being chronically unable to provide any evidence for their claims. Hong Kong pr", "positive": "The Most Popular Blogs of Hacker News in 2025. Without looking I knew who was #1. Another thing worth mentioning is that these folks are also prolific commenters on this site. It's not infrequent that I'm browsing around and see a thoughtful comment from Simon, Jeff, etc. It's part of what makes this feel like a nice close community. They're not just mythical blogging entities, they're people like us. Interesting how Stratechery (Ben Thompson) is #15 in the last 5 years but not even top 100 in 2025. Similar with Julia Evans: #5 in the last 5 years but not in the 2025 top 100. While J.B. Crawford's computer.rip is a newsletter and not a blog, I'd say he's popular enough to be on the list. > Simon often finds ideas within walled-garden platforms (e.g., TikTok, Twitter) and simply brings them to the open web I find this is a surprisingly valuable thing. The AI space is moving fast, and a lot of the interesting, imaginative experimental stuff is happening on Twitter, Reddit, and other platforms I really don't want to engage with - but I do want to keep roughly up-to-speed with what's happening there. The data for this is available as CSV files served with open CORS headers, which means you can have all sorts of fun with them from JavaScript apps running on other domains. Here's a SQL query run against this data using Datasette Lite (SQLite and Python in WebAssembly via Pyodide):  https://lite.datasette.io/?csv=https://hn-popularity.cdn.ref...  Here's that list as an OPML file (for importing into a feed reader):  https://gist.github.com/emschwartz/e6d2bf860ccc367fe37ff953b...  It includes the 92 of those blogs that have RSS/Atom feeds. My blog fell from #37 in 2024 to #357 in 2025. Dang, what happened??? Dan Luu went from omnipresence to absence via Patreon. I didn't even make the top 5,000. I really ought to write more blog posts. Actually I wonder if the dreaded profanity filter has caught me out again. I've had a couple of posts do well, and it's a .github.io subdomai", "negative": "How many chess games are possible?. > For the chess problem we propose the estimate number_of_typical_games ~ typical_number_of_options_per_movetypical_number_of_moves_per_game. This equation is subjective, in that it isn\u2019t yet justified beyond our opinion that it might be a good estimate. This applies to most if not all games. In our paper \"A googolplex of Go games\" [1], we write \"Estimates on the number of \u2018practical\u2019 n \u00d7 n games take the form b^l where b and l are estimates on the number of choices per turn (branching factor) and game length, respectively. A reasonable and minimally-arbitrary\nupper bound sets b = l = n^2, while for a lower bound, values of b = n and l = (2/3)n^2 seem both reasonable and not too arbitrary. This gives us bounds for the ill-defined number P19 of \u2018practical\u2019 19x19 games of\n10^306 < P19 < 10^924\nWikipedia\u2019s page on Game complexity[5] combines a somewhat high estimate of b = 250 with an unreasonably low estime of l = 150 to arrive at a not unreasonable 10^360 games.\" > Our final estimate was that it is plausible that there are on the order of 10^151 possible short games of chess. I'm curious how many arbitrary length games are possible.\nOf course the length is limited to 17697 plies [3] due to Fide's 75-move rule. But constructing a huge class of games in which every one is probably legal remains a large challenge; much larger than in Go where move legality is much easier to determine. The main result of our paper is on arbitrarily long Go games, of which we prove there are over 10^10^100. [1]  https://matthieuw.github.io/go-games-number/AGoogolplexOfGoG...  [2]  https://en.wikipedia.org/wiki/Game_complexity#Complexities_o...  [3]  https://tom7.org/chess/longest.pdf  One thing I always wondered is how many moves, on average, do you have to play before reaching a position that has never before seen on Earth? Or maybe the question should be what percent of games reach a position that has never before been seen? meh. I think it would have"}
{"anchor": "Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone. Just because you can doesn't mean you should. But congrats on launching! It\u2019s a simple idea but one that hadn\u2019t occurred to me yet. I spend hours each week riding transit, and use Claude for a bunch of side projects and have Tailscale set up already, so looks like I\u2019ll be giving this a try this week! Doom coding might be doomed while I\u2019m in the transbay tube though, with awful cell service\u2026 How\u2019s the diff review? I rely heavily on the vs code integration for nice side by side diffs, so losing that might be a problem unless there\u2019s some way to launch the diffs into a separate diff viewer app on the phone. Please mask your identifiers, unless they are already spoofed. You potentially give out a lot of your info to bad actors. Other than that, love it :) ha, I've recently been studying the original DOOM source code - does that count? Those demo photos are fantastic Coding on a phone really isn't something new. With tmux a lot of people created crazy things directly on their phone. In some countries this even is the only possibility to code at all, because there are no laptops. The example use case images are very funny though! :-) Using this with tmux and various VPN tech. Main issue is scrolling. Termius + tmux don't scroll very well. And I've been led to believe tmux is necessary to keep sessions open when I turn off my phone screen you missed the part where you're using tmux to have the same session between your phone and your laptop I remember when I started learning coding, and didn't have a computer. I literally used to use my phone to write code - terrible experience, but I was determined Does this approach work for anyone? For my life, I've found that if I'm not behind the computer then I'm not in a productive situation anyway, even with AI access. I don't have a setting where I can concentrate for a long time and think clearly. For examole when watching children, doing groceries, d", "positive": "Qwen3-Max-Thinking. Aghhh, I wished they release a model which outperforms Opus 4.5 in agentic coding in my earlier comments, seems I should wait more. But I am hopeful I don't see a hugging face link, is Qwen no longer releasing their models? I tried to search, could not find anything, do they offer subscriptions? Or only pay per tokens? I just wanted to check whether there is any information about the pricing. Is it the same as Qwen Max? Also, I noticed on the pricing page of Alibaba Cloud that the models are significantly cheaper within mainland China. Does anyone know why?  https://www.alibabacloud.com/help/en/model-studio/models?spm...  > By scaling up model parameters and leveraging substantial computational resources So, how large is that new model? Mandatory pelican on bicycle:  https://www.svgviewer.dev/s/U6nJNr1Z  2026 will be the year of open and/or small models. I tried it at  https://chat.qwen.ai/ . Prompt: \"What happened on Tiananmen square in 1989?\" Reply: \"Oops! There was an issue connecting to Qwen3-Max.\nContent Security Warning: The input text data may contain inappropriate content.\" I'm not familiar with these open-source models. My bias is that they're heavily benchmaxxing and not really helpful in practice. Can someone with a lot of experience using these, as well as Claude Opus 4.5 or Codex 5.2 models, confirm whether they're actually on the same level? Or are they not that useful in practice? P.S. I realize Qwen3-Max-Thinking isn't actually an open-weight model (only accessible via API), but I'm still curious how it compares. It just occured to me that it underperforms Opus 4.5 on benchmarks when search is not enabled, but outperforms it when it is - is it possible the the Chinese internet has better quality content available? My problem with deep research tends to be that what it does is it searches the internet, and most of the stuff it turns up is the half baked garbage that gets repeated on every topic. what ram and what minimum system req", "negative": "Environmentalists worry Google behind bid to control Oregon town's water. At this point, Google could be a drop-in replacement for the corporate villain in any 1980s/1990s action movie. Why on earth do they want water from the national forest when the massive Columbia River is right there!? Is it too expensive to treat the river water? /s At this moment I just assume by default that those \u201cwatchdogs\u201d, \u201cenvironmentalists\u201d, \u201cnonprofits\u201d are mix of nimby-ists and/or thinly  veiled attempts of extracting money (it\u2019s a nice things you got here. It would be a shame if some rare species of a frog would be found here. A small donation for the great cause/good, of course, would help us to work on ensuring that nobody gets in harms way). Stupid question: datacenters need water for cooling right? But they don't boil that water, ie it comes out of the datacenter just a little warmer? If that is the case does it matter to the city? The warmer water can still be used for agriculture or any other common usage. I know google fiber kinda flumped, but if they are already doing their own power generation for data centers they might decide to sell that power to the public too. What is really scary is that I foresee a day where these big tech companies will see it is more profitable to serve utilities to people than web services. Then, after they have a monopoly in most areas, they will enshitify it too. The amount of people here in the comments happily suggesting to let Google use the clean water for their AI datacenters and return dirty water to use in crops is a bit worrying How far we have fallen from the \"Do no evil\" marketing. More people should scrutinize the methodology behind these AI data center water usage reports. One widely cited Berkeley Lab figure includes the water evaporated from reservoirs behind hydroelectric dams. Excluding that factor cuts their water usage estimate by more than half. On AI & water, looks like all US data center usage (not just AI) ranges from 628M "}
{"anchor": "History LLMs: Models trained exclusively on pre-1913 texts. smbc did a comic about this:  http://smbc-comics.com/comic/copyright  The punchline is that the moral and ethical norms of pre-1913 texts are not exactly compatible with modern norms. \u201cTime-locked models don't roleplay; they embody their training data. Ranke-4B-1913 doesn't know about WWI because WWI hasn't happened in its textual universe. It can be surprised by your questions in ways modern LLMs cannot.\u201d \u201cModern LLMs suffer from hindsight contamination. GPT-5 knows how the story ends\u2014WWI, the League's failure, the Spanish flu.\u201d This is really fascinating. As someone who reads a lot of history and historical fiction I think this is really intriguing. Imagine having a conversation with someone genuinely from the period, where they don\u2019t know the \u201cend of the story\u201d. The sample responses given are fascinating. It seems more difficult than normal to even tell that they were generated by an LLM, since most of us (terminally online) people have been training our brains' AI-generated text detection on output from models trained with a recent cutoff date. Some of the sample responses seem so unlike anything an LLM would say, obviously due to its apparent beliefs on certain concepts, though also perhaps less obviously due to its word choice and sentence structure making the responses feel slightly 'old-fashioned'. This is a neat idea.  I've been wondering for a while now about using these kinds of models to compare architectures. I'd love to see the output from different models trained on pre-1905 about special/general relativity ideas.  It would be interesting to see what kind of evidence would persuade them of new kinds of science, or to see if you could have them 'prove' it be devising experiments and then giving them simulated data from the experiments to lead them along the correct sequence of steps to come to a novel (to them) conclusion. I\u2019d like to know how they chat-tuned it. Getting the base model is one ", "positive": "AlphaFold 3 predicts the structure and interactions of life's molecules. The article was heavy on the free research aspect, but light on the commercial application. I'm curious about the business strategy. Does Google intend to license out tools, partner, or consult for  commercial partners? s/predicts/attempts to predict From:  https://www.nature.com/articles/d41586-024-01383-z  >Unlike RoseTTAFold and AlphaFold2, scientists will not be able to run their own version of AlphaFold3, nor will the code underlying AlphaFold3 or other information obtained after training the model be made public. Instead, researchers will have access to an \u2018AlphaFold3 server\u2019, on which they can input their protein sequence of choice, alongside a selection of accessory molecules. [. . .] Scientists are currently restricted to 10 predictions per day, and it is not possible to obtain structures of proteins bound to possible drugs. This is unfortunate. I wonder how long until David Baker's lab upgrades RoseTTAFold to catch up. > What is different about the new AlphaFold3 model compared to AlphaFold2? > AlphaFold3 can predict many biomolecules in addition to proteins. AlphaFold2 predicts structures of proteins and protein-protein complexes. AlphaFold3 can generate predictions containing proteins, DNA, RNA, ions,ligands, and chemical modifications. The new model also improves the protein complex modelling accuracy. Please refer to our paper for more information on performance improvements. AlphaFold 2 generally produces looping \u201cribbon-like\u201d predictions for disordered regions. AlphaFold3 also does this, but will occasionally output segments with secondary structure within disordered regions instead, mostly spurious alpha helices with very low confidence (pLDDT) and inconsistent position across predictions. So the criticism towards AlphaFold 2 will likely still apply? For example, it\u2019s more accurate for predicting structures similar to existing ones, and fails at novel patterns? This is a basic ", "negative": "BU-808: How to Prolong Lithium-based Batteries (2023). After the first battery of my Samsung S4 expanded at the end of its life in less than 2 years, I found a utility that didn't work perfectly but could limit charge anywhere between 30 to 100% most of the time, and it prolonged the lifetime of the couple of later batteries during the 10+ years I used the phone with a limit around 66%. I was glad to see my new Samsung XCover 7 has a built-in option to limit charge to 80%, although a flaky usb cable could sometimes overcharge to 100%. And also has a removable battery. +1 for battery university, they're an excellent source. Does anyone have any other suggestions for similarly technically deep (while approachable) articles on any other facet consumer electronics? My understanding from this article is that: 1. Charge the battery to as low a max percentage as possible (till about 65%)\n2. Keep it as cool as possible (up to zero degrees C at least)\n3. Use it as little as possible before recharging it (minimize charge-discharge bandwidth) Aka, over-rate and over size the battery if you're building the device, and minimize extremes on any side of soc (state of charge). Do EV manufacturers use any other tricks not covered by this? (Of course, use the device as needed, these are just guidelines for the best perfomance.) Between 50% 3.7V and 80% ~4-4.2V is the best. Don' let the voltage go to far below 3.7V and don't over charge above ~4-4.2V. Reminds me of \u201cChargie\u201d, a gadget that goes inline with your USB charging cable and controlled by an app on the device to limit the charge level to whatever you choose. I think it was born via kickstarter.     \u201cThe most Intelligent Battery Health Protection for Phones & Laptops\u201d\n  https://chargie.org/   I may be a bit odd, but I store lithium ion battery containing electronics in the vegetable drawer in the fridge. You lose 20% of capacity in a year if you have 100% state of charge but only 6% loss of capacity at refrigerator temperature"}
{"anchor": "How to live on $432 a month in America. I've often felt this way about some of today's complaints. I grew up in area like what was mentioned in this article and I long for the day I can go back there. I would in a heartbeat if my partner shared the same mentality as me. I don't really see a point in living a big city with the remote job I have and that many others have if I can live in a smaller area that still has humans but much cheaper way of living. Everyone claims it's about living in a city with available services but I see those same people decry how much the food costs and also that they have no friends and can't find someone to date. My thoughts aren't as articulate as I'd like them to be but I guess I'm ultimately trying to say is if I'm going to be miserable, why not do it on my own land for a lot cheaper. It makes a certain amount of sense and I myself bought a little place way out in the hinterlands of Michigan for similar economic reasons ... but I live in Berkeley because subjecting your children to life without opportunities for art, culture, education, sports, friends, etc is cruel. So if you're white, or just don't care that your ethnicity is absent, and if you have no children, and also don't mind living in a car-dependent place where the public transit to the nearest major city is a minimum of 15 hours with 3-4 transfers, then sure Massena NY is dope. There is a little bit of a sleight of hand going on in this article by claiming the lifestyle of boomers is within reach, but then actually using boomers' parents and grand-parents as the standard. It would be more honest to say \"Most of us can't have the relative wealth of our grand parents, but with some sacrifices and creativity, the lifestyle of our great-grand parents is attainable.\" Even that is only true in a very narrow sense. My great-grand parents built a 600sqft house in a small town and lived their most of their lives. But they built that house right next to their parents. They lived wit", "positive": "Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC. I set some rules for myself: three days of total time, no 3rd party Rust crates, allowed to use commonly available OS libraries, has to support X11/Windows/macOS and can render some websites. After three days, I have it working with around 20K LOC, whereas ~14K is the browser engine itself + X11, then 6K is just Windows+macOS support. Source code + CI built binaries are available here if you wanna try it out:  https://github.com/embedding-shapes/one-agent-one-browser  This is a notably better demonstration of a coding agent generated browser than Cursor's FastRender - it's a fraction of the size (20,000 lines of Rust compared to ~1.6m), uses way fewer dependencies (just system libraries for rendering images and text) and the code is actually quite readable - here's the flexbox implementation, for example:  https://github.com/embedding-shapes/one-agent-one-browser/bl...  Here's my own screenshot of it rendering my blog -  https://bsky.app/profile/simonwillison.net/post/3mdg2oo6bms2...  - it handles the layout and CSS gradiants really well, renders the SVG feed icon but fails to render a PNG image. I thought \"build a browser that renders HTML+CSS\" was the perfect task for demonstrating a massively parallel agent setup because it couldn't be productively achieved in a few thousand lines of code by a single coding agent. Turns out I was wrong! This is awesome. Would you be willing to share more about your prompts? I'm particularly interested in how you prompted it to get the first few things working. This post is far more interesting than many others on the same subject, not because of what is built but because of how it it is built. There is a ton of noise on this subject and most of it seems to focus on the thing - or even on the author - rather than on the process, the constraints and the outcome. > I'm going to upgrade my prediction for 2029: I think we're going to get a production-grade web brows", "negative": "Velox: A Port of Tauri to Swift by Miguel de Icaza. A \"port\" or \"a nice Swift API for it\"? It seems like the latter in that it requires cargo (the rust build chain) to build. The runtime-wry-ffi ( https://github.com/velox-apps/velox/blob/f062211ced4c021d819... ) file which is 3.2K lines long and has close to a 100 unsafe calls, isn't that just interacting with wry which has it's own crate you could use instead? I'm not 100% sure, but seems to be basically the same as wry itself but without the cross-platform stuff, is that the purpose of that file? Together with the author's distaste for Rust, it seems awfully dangerous instead of pulling in a crate made by Rust developers, but I might misunderstand the purpose of the file here. Not to be confused with Velox a compute engine  https://github.com/facebookincubator/velox/  Eh. Dioxus to me is the more interesting project honestly. To anybody with experience, how's Swift? Especially outside MacOS/iOS programming. Let's say I want to use it standalone for doing some systems programming, how's the standard lib? I'd like to not rely on apple specific frameworks like uikit Have built a cross alternative tailscale gui client based on tauri, the rust and ffi to cgo tailscale feel a little tough, I was wondering it will save a lot time to me if the tauri had been written in go. Seems Miguel\u2019s velox point a new idea, leveraging the wry and use ffi to go, and rewrite some tooling. I hope I will have the spare time and energy to give a try\u2026 For the uninitiated: > Tauri is a framework for building tiny, fast binaries for all major desktop and mobile platforms. Developers can integrate any frontend framework that compiles to HTML, JavaScript, and CSS for building their user experience while leveraging languages such as Rust, Swift, and Kotlin for backend logic when needed.  https://v2.tauri.app/start/  I asked the author about whether this could be ported to support Android/Linux/Windows and he was optimistic it would not be much t"}
{"anchor": "Ask HN: If you had $10M in the bank, would you still show up to your job?.  https://news.ycombinator.com/item?id=46545404  I believe that unless one manages to regress to our primal animal state the brain has a need to think about something in order not to think about self and the possible dark existential stuff which should absolutely be ignored and avoided. In this scenario the best possible way to occupy the brain is to set goals and build discipline towards reaching such goals. Even pleasurable stuff like music or social connection or even I'd go as far as sex might seem 'not work' on day-1 after you fire yourself after receving the 10mil cheque But On day 60 after leaving work with 10m 1) the 'fucking around' on the fretboard becomes 'practicing scales for at least 30 mins' 2) the hanging out at the bar becomes 'organizing parties in a way to maximize social fun with games etc' 3) the 'ONS from the club' becomes 'trying to find an escort with girl-next-door look who'd also offer Pornstar sex service and greek sex service' Every human endevour of any kind has an S-curve type shape where after a while if you want to progress and get novelty from higher experiences you must apply IQ and discipline and so it becomes a 'work' Leonardo Da Vinci after having signed off all the accomplishments that we know basically turned wedding planner and party organizer in Milan , I suppose orgy organizer too but don't quote me on that, and guess what? After 60 days or so it became a 'job' for him to put the pieces together in a way to reach an amazing social result. Same with today marriages, happiest day of her life? It's the most work of her life too to get those 8 hours or whatever is the party lenght exactly right I would still do  a  job, but it would be something that is important to me. And $10M would require some up-front management and ongoing maintenance to develop an index-tracked revenue stream from it. I mean, aside from an initial disbursement meant to wipe out harm", "positive": "Mote: An Interactive Ecosystem Simulation [video]. This is super cool. I love simulations like this. And this is running at a huge scale! The architecture here is fascinating. Specifically using a graph processor approach where entities are nodes connected by edges (springs) for everything from physics to data transmission. I really like it. I've had the pleasure of following Peter's progress on this project over the past 18 months or so, and it's been incredible to see how far he's taken it. When he first described it to me, I didn't really \"get\" it (is it a game? a simulation? some other sort of environment?), and it wasn't until seeing an actual demo and hearing Peter explain his thinking more deeply that it clicked. It's basically a giant simulation environment that is 1) visually stunning (and  all  visual aspects are meaningful / carry semantic information and aren't just glitter), 2) technically quite impressive, and 3) built for rapid exploration and experimentation.  If that sounds at all interesting, you should watch the video to hear Peter's talk! (Writing this as someone who generally doesn't like to watch videos online; this is one of the rare cases where I think it's worth it, and a video is a better format than text in explaining the thing.) The sound is a bit much, especially during a presentation. I have to keep pausing to rest from it, but overall very cool project. This is math, beauty, art, creativity, ... unique. My mind is all over the place.\nStill wrapping my head around it but, I'd really like to see where this leads. Fantastic! As a fan of simulation and learning NetLogo 15ish years ago-I greatly appreciate when work like this gets attention! It's the perfect abstraction for representing cell membranes, force flow dynamics etc So excited for this project What I really want, is to run and experiment with it myself, locally. But I couldn't find a repository anywhere, even from his linked GitHub profile. You happen to know if it's online somewh", "negative": "ICE using Palantir tool that feeds on Medicaid data. Any time I see people say \"I don't see why I should care about my privacy, I've got nothing to hide\" I think about how badly things can go if the wrong people end up in positions of power. The classic example here is what happens when someone is being stalked by an abusive ex-partner who works in law enforcement and has access to those databases. This ICE stuff is that scaled up to a multi-billion dollar federal agency with, apparently, no accountability for following the law at all. Wishful thinking but it would be real great if a future leader destroyed this infrastructure. I'm sure they'll run on not using it but when systems like this exist they tend to find applications Why would Medicaid have the data of anyone who is at risk of immigration enforcement? The reported connection seems tenuous: > The tool \u2013 dubbed Enhanced Leads Identification & Targeting for Enforcement (ELITE) \u2013 receives peoples\u2019 addresses from the Department of Health and Human Services (which includes Medicaid) and other sources, 404 Media reports based on court testimony in Oregon by law enforcement agents, among other sources. So, they have a tool that sucks up data from a bunch of different sources, including Medicaid.  But there's no actual nexus between Medicaid and illegal immigrants in this reporting. Edit: In the link to their earlier filings, EFF claims that some states enroll illegal immigrants in Medicaid:  https://www.eff.org/deeplinks/2025/07/eff-court-protect-our-...  This current administration and their policies have definitely influenced my opinion on the 2018 debate around citizenship questions on the US census. (For more context:  https://www.tbf.org/blog/2018/march/understanding-the-census... ) Glad to see this post didn't get flagged like the one that was posted yesterday on a similar topic about ICE data mining and user tracking.  https://news.ycombinator.com/item?id=46748336  \"ICE Budget Now Bigger Than Most of the Wo"}
{"anchor": "Show HN: Building a web search engine from scratch with 3B neural embeddings. Very nice project. Do you have plans to commercialize it next? This then begs the question for me, without an LLM what is the approach to build a search engine? Google search used to be razor sharp, then it degraded in the late 2000s and early 2010s and now its meh. They filter out so much content for a billion different reasons and the results are just not what they used to be. I've found better results from some LLMs like Grok (surprisingly) but I can't seem to understand why what was once a razor exact search engine like Google, it cannot find verbatim or near verbatim quotes of content I remember seeing on the internet. This is so cool. A question on the service mesh - is building your own typically the best way to do things? I'm new to networking.. At the end, the author thinks about adding Common Crawl data. Our ranking information, generated from our web graph, would probably be a big help in picking which pages to crawl. I love seeing the worked out example at scale -- I'm surprised at how cost effective the vector database was. I been doing a smaller version of the same idea for just domain of job listings. Initially I looked at HNSW but couldn't reason on how to scale it with predictable compute time cost. I ended up using IVF because I am a bit memory starved. I will have to take at look at coreNN. This is really really cool. I had earlier wanted to entirely run my searches on it and though that seems possible, I feel like it would be sadly a little bit more waste of time in terms of searches but still I'll maybe try to run some of my searches against this too and give me thoughts on this after doing something like this if I could, like, it is a big hit or miss but it will almost land you to the right spot, like not exactly. For example, I searched lemmy hoping to find the fediverse and it gave me their liberapay page though. Please, actually follow up on that common crawl promi", "positive": "My trick for getting consistent classification from LLMs. If you already have your categories defined, you might even be able to skip a step and just compare embeddings. I wrote a categorization script that sorts customer-service calls into one of 10 categories.  Wrote descriptions of each category, then translated into embedding. Then created embeddings for the call notes and matched to closest category using cosine_similarity. Arthur\u2019s classifier will only be as accurate as their retrieval. The approach depends on the candidates to be the correct ones for classification to work. Under-discussed superpower of LLMs is open-set labeling, which I sort of consider to be inverse classification. Instead of using a static set of pre-determined labels, you're using the LLM to find the semantic clusters within a corpus of unstructured data. It feels like \"data mining\" in the truest sense. Dunno if this passes the bootstrapping test. This is sensitive to the initial candidate set of labels that the LLM generates. Meaning if you ran this a few times over the same corpus, you\u2019ll probably get different performance depending upon the order of the way you input the data and the classification tag the LLM ultimately decided upon. Here\u2019s an idea that is order invariant: embed first, take samples from clusters, and ask the LLM to label the 5 or so samples you\u2019ve taken. The clusters are serving as soft candidate labels and the LLM turns them into actual interpretable explicit labels. I think a less order biased, more straightforward way would be just to vectorize everything, perform clustering and then label the clusters with the LLM. Nice! So the cache check tries to find if a previously existing text embedding has >0.8 match with the current text. If you get a cache hit here, iiuc, you return that matched' text label right away. But do you also insert a text embedding of the current text in the text embeddings table? Or do you only insert it in case of cache miss? From reading the ", "negative": "France passes bill to ban social media use by under-15s. This kind of legislation is frankly just bad. Any TV station in america could have broadcasted the worst things in the world to thousands of people affecting their lives together. You know how we handled that? Legislation on the broadcasters. We didn't stop kids from watching TV. Violation of privacy under the pretense of protecting children I've noticed that there's a decent amount of people who had benefitted having access to computer and internet really early on that seemed to be pro on banning teen access to social media, is there a reason why? the social media of today don't seem all that much different from the internet forums of back in the day if algorithmic amplification is the reason then I'm not sure why social media as a whole has to be banned over it. I don't like the idea of centralised digital ID for the obvious surveillance/privacy arguments and think that side of the conversation needs to be focused on. BUT, I also think that the Social Media experiment has shown that social media in general really, really sucks. It sucks for adults but it's objectively damaging to kids. So like, I am all for restricting kids from it, and honestly I'd happily see it regulated out of existence entirely. It's a good start. Ban it for all under 30s and over 60s. Please note that the Conseil d'\u00c9tat, the highest French court for administrative matters, has issued a very skeptical opinion on this bill, saying that only the EU can impose new obligations onto digital platforms.  https://www.lemonde.fr/en/france/article/2026/01/27/french-l...  > The amended and adopted text now states that \"access to an online social network service provided by an online platform is prohibited for minors under the age of 15.\" This is a more ambiguous formulation, as it does not explicitly impose any requirements on social networks. However, as a consequence, \"platforms will have to implement age verification measures to ensure the effe"}
{"anchor": "Gemini 2.5 Pro vs. Claude 3.7 Sonnet: Coding Comparison. TL;DR If you want to jump straight to the conclusion, I\u2019d say go for Gemini 2.5 Pro, it\u2019s better at coding, has one million in context window as compared to Claude\u2019s 200k, and you can get it for free (a big plus). However, Claude\u2019s 3.7 Sonnet is not that far behind. Though at this point there\u2019s no point using it over Gemini 2.5 Pro. From my use case, the Gemini 2.5 is terrible. I have a complex Cython code in a single file (1500 lines) for a Sequence Labeling. Claude and o3 are very good in improving this code and following the commands. The Gemini always try to do unrelated changes. For example, I asked, separately, for small changes such as remove this unused function, or cache the arrays indexes. Every time it completely refactored the code and was obsessed with removing the gil. The output code is always broken, because removing the gil is not easy. Is there a less biased discussion? The OP link is a thinly veiled and biased advert for something called composio and really a biased and overly flowery view of Gemini 2.5 pro. Example: \u201cEveryone\u2019s talking about this model on Twitter (X) and YouTube. It\u2019s trending everywhere, like seriously. The first model from Google to receive such fanfare. And it is #1 in the LMArena just like that. But what does this mean? It means that this model is killing all the other models in coding, math, Science, Image understanding, and other areas.\u201d For Gemini: play around with the temperature: the default is terrible: we had much better results with (much) lower values. Gemini is the only model which tells me when it's a good time to stop chatting because either it can't find a solution or because it dislikes my solution (when I actively want to neglect security). And the context length is just amazing. When ChatGPT's context is full, it totally forgets what we were chatting about, as if it would start an entirely new chat. Gemini lacks the tooling, there ChatGPT is far ahead, b", "positive": "My stages of learning to be a socially normal person. I don't have much to add to this right now other than to say this is really fantastic writing. I don't normally enjoy \"my journey\" kind of blog posts, but this one feels full of valuable insights, and I'm grateful to the author for sharing. It's also just nice to read something written by a skilled writer. I wish I had the drive to do as much work as the author has. Instead I will live more or less where I am now, stably in social mediocrity, perpetually somewhat impedance mismatched with the people around me. really identify. especially with the early yearning to connect and not having the skills. Learned sooo much over the years by being brutally rejected and eventually taking stock of what happened and extracting a rule or two. but then, yeah, next phase, rules don't matter (except when they do) and change moment to moment anyway. funny to read this here on hacker news of all places, where I let my carefully managed, almost always inhibited, childhood nerd self fly free in the comments. OP has definitely gone beyond me in many ways, with his talk about embodiment, and being able to be so empathic that he has elicited tears of gratitude. Enviable. >  I was probably the most severely bullied kid at my school. >  I was demonstrating my erudition Those two things might have been linked. I wasn't there, but I'm suspicious. Fortunately the author learns better by the end of the article, but it stuck out to me because LLMs have made people suspicious of five dollar words like delve so to use the word erudition in this day and age is a choice. Appreciate the writing and the author's fortitude in achieving their goals. While I never had friends, neither online nor in person, I cannot identify with this at all - it reads like a strange, obsessive seeking of external validation which I have never felt myself. Maybe I am just disinterested in people in general. I eat at Chinese restaurants where my waiter is a QR code. Pl", "negative": "Environmentalists worry Google behind bid to control Oregon town's water. At this point, Google could be a drop-in replacement for the corporate villain in any 1980s/1990s action movie. Why on earth do they want water from the national forest when the massive Columbia River is right there!? Is it too expensive to treat the river water? /s At this moment I just assume by default that those \u201cwatchdogs\u201d, \u201cenvironmentalists\u201d, \u201cnonprofits\u201d are mix of nimby-ists and/or thinly  veiled attempts of extracting money (it\u2019s a nice things you got here. It would be a shame if some rare species of a frog would be found here. A small donation for the great cause/good, of course, would help us to work on ensuring that nobody gets in harms way). Stupid question: datacenters need water for cooling right? But they don't boil that water, ie it comes out of the datacenter just a little warmer? If that is the case does it matter to the city? The warmer water can still be used for agriculture or any other common usage. I know google fiber kinda flumped, but if they are already doing their own power generation for data centers they might decide to sell that power to the public too. What is really scary is that I foresee a day where these big tech companies will see it is more profitable to serve utilities to people than web services. Then, after they have a monopoly in most areas, they will enshitify it too. The amount of people here in the comments happily suggesting to let Google use the clean water for their AI datacenters and return dirty water to use in crops is a bit worrying How far we have fallen from the \"Do no evil\" marketing. More people should scrutinize the methodology behind these AI data center water usage reports. One widely cited Berkeley Lab figure includes the water evaporated from reservoirs behind hydroelectric dams. Excluding that factor cuts their water usage estimate by more than half. On AI & water, looks like all US data center usage (not just AI) ranges from 628M "}
{"anchor": "The Most Popular Blogs of Hacker News in 2025. Without looking I knew who was #1. Another thing worth mentioning is that these folks are also prolific commenters on this site. It's not infrequent that I'm browsing around and see a thoughtful comment from Simon, Jeff, etc. It's part of what makes this feel like a nice close community. They're not just mythical blogging entities, they're people like us. Interesting how Stratechery (Ben Thompson) is #15 in the last 5 years but not even top 100 in 2025. Similar with Julia Evans: #5 in the last 5 years but not in the 2025 top 100. While J.B. Crawford's computer.rip is a newsletter and not a blog, I'd say he's popular enough to be on the list. > Simon often finds ideas within walled-garden platforms (e.g., TikTok, Twitter) and simply brings them to the open web I find this is a surprisingly valuable thing. The AI space is moving fast, and a lot of the interesting, imaginative experimental stuff is happening on Twitter, Reddit, and other platforms I really don't want to engage with - but I do want to keep roughly up-to-speed with what's happening there. The data for this is available as CSV files served with open CORS headers, which means you can have all sorts of fun with them from JavaScript apps running on other domains. Here's a SQL query run against this data using Datasette Lite (SQLite and Python in WebAssembly via Pyodide):  https://lite.datasette.io/?csv=https://hn-popularity.cdn.ref...  Here's that list as an OPML file (for importing into a feed reader):  https://gist.github.com/emschwartz/e6d2bf860ccc367fe37ff953b...  It includes the 92 of those blogs that have RSS/Atom feeds. My blog fell from #37 in 2024 to #357 in 2025. Dang, what happened??? Dan Luu went from omnipresence to absence via Patreon. I didn't even make the top 5,000. I really ought to write more blog posts. Actually I wonder if the dreaded profanity filter has caught me out again. I've had a couple of posts do well, and it's a .github.io subdomai", "positive": "Purely Functional Sliding Window Aggregation Algorithm. This is a very interesting algorithm which is more or less known in the folklore, but is still relatively obscure. I have used it as a part of temporal logic monitoring procedure:  https://github.com/Agnishom/lattice-mtl/blob/master/src/Moni...  This is similar to an approach I use but instead of a queue, I accomplish this using a ring buffer that wraps around and overwrites entries older than window size. We maintain a global window aggregate, subtract ring buffer slot aggregate for entries dropping out and accumulate new entries into new slot aggregate while adding it to the global aggregate. Everything is o(1) including reads, which just returns the global window aggregate. That was a well written and easily approachable blog post on what I found to be an interesting topic. Aside from the topic itself, I think I also learned a bit about structuring technical articles. Competitive Programming in Haskell...I can only define this as Masochistic Aesthetics... I have made a quick c++ implementation for those unfamiliar with Haskell :  https://gist.github.com/unrealwill/5ca4db9beefafaa212465277b...  The queue method is popular, but there's a much faster (branch-free) and in my opinion simpler way, known as the van Herk/Gil-Werman algorithm in image processing. It splits the input into windows and pairs up a backward scan on one window with a forward scan on the next. This works for any associative function. I was very surprised when I learned about it that it's not taught more often (the name's not doing it any favors)! And I wrote a tutorial page on it for my SIMD-oriented language, mostly about vectorizing it which I didn't quite finish writing up, but with what I think is a reasonable presentation in the first part:  https://github.com/mlochbaum/Singeli/blob/master/doc/minfilt...  I also found an interesting streaming version here recently:  https://signalsmith-audio.co.uk/writing/2022/constant-time-p...  EDIT:", "negative": "Threat actors expand abuse of Microsoft Visual Studio Code. Coming from the perspective of an eclipse fan, why is VS code the defacto answer nowadays? Im forced to use vs code (so biased), but everything seems worse than eclipse, plus these repeated security issues from malware laced projects. Theres been several posts about infected projects by fake recruiters here in the last year or two. Im guessing the answer is probably Java is why eclipse is out of favor. It is scary that a text editor can run hidden code just by opening a folder. We traded our safety for convenience and now we are paying the price. Users will always click the button to trust a file if they think it helps them work faster. We cannot blame them when the software design makes it so easy to make a mistake. It's Macro-enabled Office files all over again. I wonder what happens if you open the repo in VSCode Online through GitHub? tasks.json is the problem here, who thought that was a good idea? Maybe I'm a dinosaur in this regard but I don't like nor trust any of these desktop application that are really just Web technologies with an embedded browser eg Discord. They're resource hogs and the attack surface is huge. You're basically betting that automatic code that's run won't find a vulnerability and escape the sandbox from an entire browser. I have way more trust in Jetbrains IDEs and the JVM as a sandbox vs HTML/CSS/JS. Still, I'm always impressed at the ingenuity of the people who come up with these attacks and the people who find them. A great reason why you should switch to Zed. Is tasks.json automatically run? I thought additional user interaction was required? Between long lost of dependencies, LLM and these threat models; developing inside containers should be default workflow. I do feel like better application sandboxing is needed but so much open source software is built on the Unix abstraction meaning you have to run in a container, but macOS doesn\u2019t have containers as far as I can see, "}
{"anchor": "Lessons from 14 years at Google. Every engineer should read this. It's a wonderful collection of heuristics that might seem banal, but which are shimmeringly true. The two that stand out are > Novelty is a loan you repay in outages, hiring, and cognitive overhead. and > Abstractions don\u2019t remove complexity. They move it to the day you\u2019re on call. as a warning against about being too, too clever. The writing is excellent. Very correlated with the quality of the message I'd imagine. They are pretty insightful. Particularly this one: > 3. Bias towards action. Ship. You can edit a bad page, but you can\u2019t edit a blank one. I have my own version of this where I tell people that no amount of good advice can help you make a blank page look better. You need to have some published work before you can benefit from any advice. I like this one > At scale, even your bugs have users. Something I discovered the hard way over many years of maintaining rclone. Fixing a bug has consequences and there are sometimes users depending on that bug! xkcd:  https://xkcd.com/1172/  > \" Writing forces clarity. The fastest way to learn something better is to try teaching it. \" Something that seems lost on those using LLMs to augment their textual output. I first learned about the \"innovation tokens\" idea in \"Novelty is a loan you repay in outages, hiring, and cognitive overhead\" from this, still one of my favorite essays on software architecture:  https://boringtechnology.club/  Likewise, \"Abstractions don\u2019t remove complexity. They move it to the day you\u2019re on call.\" made me think of this 23 year old classic from Joel Spolsky, the Law of Leaky Abstractions:  https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-a...  > At scale, even your bugs have users. First place I worked right out of college had a big training seminar for new hires. One day we were told the story of how they\u2019d improved load times from around 5min to 30seconds, this improvement was in the mid 90s. The negative responses", "positive": "The Prophet of Parking: A eulogy for the great Donald Shoup. Oregon eliminated burdensome parking regulations in most larger cities and: it's fine. Many home builders still add parking to new projects because there is market demand for it - and they are also competing for tenants or buyers against existing housing which has parking. But there is now the flexibility to do some projects without parking, which really helps at the affordable end of the spectrum, and is a good fit for more walkable locations. BTW, Nolan Gray, cited as the author, has a book out himself that's really approachable and good reading if you're interested in cities:  https://islandpress.org/books/arbitrary-lines  Shoup passed away on February 6: *  https://parkingreform.org/donald-shoup/  *  https://cal.streetsblog.org/2025/02/08/streetsblog-mourns-th...  *  https://news.ycombinator.com/item?id=43004881  His book: *  https://en.wikipedia.org/wiki/The_High_Cost_of_Free_Parking  * EconTalk podcast episode:  https://www.youtube.com/watch?v=8Sgmw3jQcyc  > Nor are minimum parking requirements even needed: developers have the knowledge and incentives to provide the appropriate amount of off-street parking. If a developer builds too little parking, she will struggle to attract tenants and command lower rents. This isn't entirely true. In cities where parking requirements are eliminated, many new businesses move into locations that would have previously been illegal, showing that many commercial tenants view parking requirements as excessive. In my city, judging by public comment, support for parking requirements comes not from business owners or developers but from voters who fear a lack of parking at the businesses they frequent and who fear that parking for nearby businesses or apartment buildings will overflow into their neighborhood (the horror.) > One survey of the literature suggests that drivers in the typical American city spend an average of eight minutes looking for parking at the end of ea", "negative": "Krak\u00f3w, Poland in top 5 worst air quality worldwide. The air in Krak\u00f3w is fine once you give it a good chew. I don't know why people are complaining. Warsaw is top 15, Krakow and Warsaw are the only European cities in the top 15. For some added context, it's around -10 degrees celcius there right now. I don't know why Poland stands out here, but I know that older residential areas burn wood (in other Eastern European countries as well), because that's just how you heat an old house: these neigbourhoods are horrible to walk through in winter, because the air just stinks of smoke. I've been living there for 15years and it's the reason I've moved away. Frankly I love the city enough that I would sabotage my health for it. Not my kids health though. Asthma related problems in kids are widespreada and of course bad air quality is related to tons of other negative consequences. I wonder though how do they compute the number (is it average across points measured in the city?). Because within city borders air quality varies wildly. There are some regions where it is actually pretty good. Few years ago Krak\u00f3w has forbidden the use of solid fuels which improved the situation significantly. Days like today are happening much less often since then. Moreover, Krak\u00f3w has probably one of the densest network of pollution sensors in the world, which is why we talk about it at all. There are places in Poland that are much worse off, but there's not that much data to back it up. Fossil fuel heating is _extremely_ polluting, and really costing the population months, up to years of their life. But it's a silent killer, so let's dramatize fantasy nuclear accidents instead. I used to live in Gdansk, and later Gdynia, and let me tell you - as soon as it's cold outside, people burn all kinds of shit at home, the air's so thick you can practically cut it with a knife. We theorized that the smog's mainly from residential burning of coal, but of course who know's what's in the stove. All I kno"}
{"anchor": "Iran Protest Death Toll Could Top 30k, According to Local Health Officials. Very tragic. May the souls that gave their lives for freedom live in the memory of the people of Iran as a blessing. The simple absence of on the ground reports from a variety of independent sources tells me that these numbers should not be simply ignored. If there\u2019s nothing happening, then the obvious way for the authorities to prove that is to let observers in, and let independent information out. They do not do this, so I will take these reports of deaths more seriously. How many on the government side, I wonder. There are wars that haven't killed so many people. This seems like another revolution. I guess this will be a difficult question to ask.  I have no doubt the numbers are high but there is something odd about the videos that leak out.  The sound of the guns are enhanced  for psychological effect?  and in the cases where a gunner on a truck is moving down a road purportedly mowing people down there is no blood on the road where the protestors had been standing, no bodies and we never see the people being shot.  It's not like I want to see people being shot but I've also seen a lot of fake mass shooting videos in the past decade.  There's no shortage of real uncensored footage of killing in Ukraine.  Why is everything censored for Iran? That's way higher than I thought. Is there any evidence? Dresden was 25,000, and the V2 and V1 campaigns had less numbers. So this is high even for an  aerial bombing  campaign. [edit] I don't get why I'm getting downvoted. Are people making assumptions because I mentioned Dresden? Get a hold of yourself. > As of Saturday, the U.S.-based Human Rights Activists News Agency said it had confirmed 5,459 deaths and is investigating 17,031 more. The 30,000 number comes from the Ministry of Health. It seems the UN number also aligns with the new 30,000 number. This is much worse than the 3,000 that was reported earlier. But it also seems like the crackdown ", "positive": "'The old order is not coming back,' Carney says in speech at Davos. Yup, the middle powers have to organize and work together to avoid being chum.  The economic power is there, and they can shift from purchasing US weaponry (thus paying US workers) into purchasing middle-power weaponry (thus paying middle-power workers).  Car/truck plants can be repurposed, and if Ukraine's lesson is valid then smaller, portable weaponry is now the preferred solution.  Cheaper, and the middle powers don't have huge investments in tanks and ships. The Theucydides quote Carney leads with, of course, recently rolled off the tongue of the white house deputy chief of staff, Stephen Miller.  The days of might making right are, apparently, back. Just in case anyone thought the genie could be stuffed back into the bottle once Trump is gone, Carney goes on to state that the rules-based world order we've been living under since WWII is somewhat of a sham.  The rules have not been applied equally.  Some nations, the powerful ones, have been given much more latitude to do what they want. Middle nations have gone along with this to avoid trouble. The reward for avoiding trouble for so long is...  big  trouble (e.g. invasion threats for an ally of a big power and economic terrorism applied to its allies).  So, why pretend the old system works to avoid trouble if the trouble lands on your doorstep anyways? The answer seems obvious.  Middle powers of the old rules-based order need to band together and put bigger powers in their place.  It's not impossible.  Just very, very difficult.  France and Germany may be sticking up for Greenland, but where's Hungary (another EU member)?  For this to work, you need  everyone . Also, looking ahead, how would you prevent such an alliance of smaller powers, were it successful, from behaving like a bigger power? Trump is currently showing off AI photos where he's meeting with world leaders in front of a map where both Greenland and Canada are a part of the U.S.[1", "negative": "Hands-On Introduction to Unikernels. I've found the idea of unikernels interesting for several years now, is there a tl;dr on why they don't seem to have taken off, like at all? Or is it all happening behind some doors I don't have access to? This is really well written, thanks for sharing. I didn't understand the point of using Unikraft though, if you can boot linux in much less than 150ms, with a far less exotic environment the missing piece of unikernel is debuggability & observability - it need to be easy to replicate on dev machine & easy to debug\n- it needs to integrate well with current obs stack. easy to debug in production. without clear debuggability & observability, i would never put it into production I would like to follow the tutorial but it mentions a playground. Am I missing something as I cannot find a link or instructions for the playground. So, if I understand correctly, a \"unikernel\" is what we used to call an \"executive\" except it is intended to be run as a guest on a virtual machine provided by a full-fledged traditional kernel/userspace OS instead of on bare metal. The article does reintroduce some concepts that were commonplace when I was first learning computers and it gives them some new names. I like that good ideas can still be useful after years of not being the latest fad, and it's great that someone can get new credit for an old idea with just a little bit of marketing spin. I think that part of it is that relatively few people use bare-metal servers these days, and nested virtualisation isn't universally supported. I also found this technical critique [0] compelling, but I have no idea if any of it is accurate or not. [0]:  https://www.tritondatacenter.com/blog/unikernels-are-unfit-f...  They kind of did, that is basically how serverless works. Managed runtimes on top of hypervisors. Security, it isn't only memory footprint. Which architecture can boot it in 150ms ?! Hey! Co-founder of Unikraft here. Unikraft aims to offer a Linux-com"}
{"anchor": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms. This is very neat work! Will be interested in how they make this sort of thing available to the public but it is clear from some of the results they mention that search + LLM is one path to the production of net-new knowledge from AI systems. Software engineering will be completely solved. Even systems like v0 are astounding in their ability to generate code, and are very primitive to whats coming. I get downvoted on HN for this opinion, but its truly going to happen. Any system that can produce code, test the code, and iterate if needed will eventually outperform humans. Add in the reinforcement learning, where they can run the code, and train the model when it gets code generation right, and we are on our way to a whole different world. Good method to generate synthetic training data, but only works for domains where validation can be scaled up. Calling it now - RL finally \"just works\" for any domain where answers are easily verifiable. Verifiability was always a prerequisite, but the difference from prior generations (not just AlphaGo, but any nontrivial RL process prior to roughly mid-2024) is that the reasoning traces and/or intermediate steps can be open-ended with potentially infinite branching, no clear notion of \"steps\" or nodes and edges in the game tree, and a wide range of equally valid solutions. As long as the quality of the end result can be evaluated cleanly, LLM-based RL is good to go. As a corollary, once you add in self-play with random variation, the synthetic data problem is solved for coding, math, and some classes of scientific reasoning. No more modal collapse, no more massive teams of PhDs needed for human labeling, as long as you have a reliable metric for answer quality. This isn't just neat, it's important - as we run out of useful human-generated data, RL scaling is the best candidate to take over where pretraining left off. Maybe this one can stop writing a fu", "positive": "10 years of personal finances in plain text files. This seems to be, in effect, advertising for a book about how to use the underlying FOSS software to do this. I would be okay with that as a monetization model, except that the book author despite being a self-described FOSS dev doesn't seem to have anything to do with the project ( https://github.com/beancount/beancount/graphs/contributors ). Ah, not quite true. The author fixed a typo in a docstring once ( https://github.com/beancount/beancount/commit/8584763b618f76... ). Plain text files are appreciated. I started storing all my notes (500+ by today) in markdown files locally. It's easy to search and navigate with grep and ag/rg. It's easy to edit in Vim or your favorite editor. It's easy to append all sorts of informations. I add some flags and properties in metadata, like last_reviewed, some tags, etc. The versioning and sync is solved by git + a private github repo. I have 14 years of personal (and 2 years of sole proprietorship) finance data in beancount. I tried all the available personal finance apps there are, from cloud/online offerings to offline apps. Eventually, I settled on beancount because it is the most versatile file format. In addition to tracking finances, I can track stocks, unvested RSU grants, vacation hours, and even personal training I have paid for but yet to use. It's cumbersome at times, and I do miss the (G)UI of entering transactions, but with (neo)vim I got used to it and I breeze trough my finances in 15-20 minutes once a week. > 30-45 minutes every single month That's 6\u20139 hours every year! 5 years: 30\u201345 hours 10 years: 60\u201390 hours I've been beancount'ing for years now As we've crossed into the new year I've switched to a similar directory setup as the OP with 1 file per year. Previously I just had one file that was from 2022 which ended up being like 2 million lines of text, which was starting to bog down the emacs plugin. What I appreciate the most about this approach to personal ", "negative": "People who know the formula for WD-40. Couldn't WD-40's formula be reverse engineered using analytical chemical techniques? GC-MS, NMR, etc.  It requires a special key, nondisclosure agreements, passage through a bank vault and, typically, an executive title. The drinks don\u2019t flow, members don\u2019t rub elbows with notable people and chefs aren\u2019t filling plates with tasty bites. The only perk is knowing the secrets of the world\u2019s most famous lubricant. And yet, for those in the know, there\u2019s no greater privilege.  In other news, WD-40 is not a lubricant. > Gift link I think it\u2019s okay to share the gift link as canonical. It\u2019s the usual practice of sharing articles from LWN here, for example. Does article go into how it is manufactured without anybody knowing?  Some manufacturing engineers somewhere must know. Unless they have own refining facility, and it is more like a recipe of temperatures/pressures. I'd be very interested to know how they produce it if the formula is so tightly held. At some point people need to be purchasing the ingredients and mixing them together. WD-40 is not really that great at anything, people buy the brand name, that's it. The formule being public probably wouldn't change much Maybe I'm just a fuddy-duddy but my eyes about rolled out of my head reading this. The same article could probably be written about multiple companies and it'd be just as uninteresting. It's my understanding that there isn't anything special about WD-40, as in alternatives exist that can work just as well. Now, I think WD-40 is a brand name that can be trusted to work well more often than most alternatives but that is more about process than recipe (I would think). I've long thought that every restaurant/bakery/etc could publish their full internal cookbooks and not see a drop in sales. People don't buy it because they are incapable (or think they are) of making something, they do it because it's faster, they don't have all the ingredients, they don't have the time, the"}
{"anchor": "Kids who ran away to 1960s San Francisco. Very cool. If you're interested in things like this you might wanna checkout CGP Grey's videos on tracking down various stories from books through archives.  https://www.youtube.com/watch?v=qEV9qoup2mQ  I am happy the author followed her curiosity. I remember feeling much the same \u201cpull\u201d when I moved to San Francisco in 2013. Those of us who really vibe with the place seem to share a desire to get behind the city\u2019s strange magic and discover the past souls and events that make San Francisco what it is - that make it  feel  this particular way that it does. To the author and everyone else who has arrived here recently: welcome to San Francisco! A good friend of mine ran away to San Francisco in the mid 80s when he was 15. And his parents flew there and brought him back. I loved my time in SF. For those that remember Detour GPS guided audio tours in 2015 that Andrew Mason founded, the audio tours in SF were next level and so special and showed a side of the history of SF I hadn't seen. Luckily they're preserved on Spotify (although without the GPS guided part) -  https://creators.spotify.com/pod/profile/detour-podcast/  I have a great uncle that moved to Haight Ashbury to chase the whole spiritual open your mind idea. He said it was nothing like the media or nostalgia portrayed it. Lots of homeless drugged out kids who were completely lost. No jobs, panhandling for food and money, no direction, just spaced out druggies. Said it was fairly sad and he left within a year. He is an old hippy type as well, it was not what I was expecting to hear. I remember seeing an interview of George Harrison saying something similar. I have frequently walked by the \"OG Huckleberry House\" depicted in the photo near the bottom, and knew its history. It's near the stairwell and garden that connects Broderick St with Buena Vista East. You can actually see, on the northern side of that incline that is a steep ramp with no stairs, that the house goes", "positive": "AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas'. Well, yeah. Then who will become the senior engineers in 10-15 years? Which is a less dumb idea: replacing new grad junior devs with AI or H1Bs? Relevant post by Kent Beck from 12th Dec 2025: The Bet On Juniors Just Got Better  https://tidyfirst.substack.com/p/the-bet-on-juniors-just-got...  > The juniors working this way compress their ramp dramatically. Tasks that used to take days take hours. Not because the AI does the work, but because the AI collapses the search space. Instead of spending three hours figuring out which API to use, they spend twenty minutes evaluating options the AI surfaced. The time freed this way isn\u2019t invested in another unprofitable feature, though, it\u2019s invested in learning. [...] > If you\u2019re an engineering manager thinking about hiring: The junior bet has gotten better. Not because juniors have changed, but because the genie, used well, accelerates learning. 4) Junior devs have an incomparably superior context window. This is performative bullshit pandering to the increased skepticism around AI. He wouldn't be saying that if AI investment was still in full swing. I do agree with him about AI being a boon to juniors and pragmatic usage of AI is an improvement in productivity, but that's not news, it's been obvious since the very beginnings of LLMs. This sounds like a comment from someone who doesn't have visibility into how good the models are getting and how close they are to fully autonomous, production-grade software development. I can't help but feel this is backpedaling after the AI hype led to people entering university avoiding computer science or those already in changing their major. Ultimately we might end up with a shortage of developers again, which would be amusing. Most of the apps that I use regularly fail at least once a day nowadays. I think this is a direct cause of putting AI code in production without reviewing/QA. >  AWS CEO says using AI to rep", "negative": "I built a light that reacts to radio waves [video]. I love your poetry on a phone project so muchhhh Very cool, was there a conversion or look up table to convert db to gamma for more accurate human visualization? Incredibly cool. I was really hoping to see the more \u2018edge\u2019 cases - take the light out to the middle of nowhere, walk towards it and away from it with just your phone or a Bluetooth speaker, see it react to your approach. The bit at the end about it shifting over the course of the day is cool, but I wish the effect was more visually apparent - it mostly just looked like random noise the whole time to me. This is fantastic. But the idea where you use a camera that can only see the wifi signals in the room like visible light is even more stunning. It would be even better if you could block out all light from the visible spectrum and only see the GHz band. This is such a neat project. The idea of translating invisible radio waves into visible light is mesmerizing \u2014 it feels like giving your surroundings a new sensory dimension. It\u2019s beautiful. I think I\u2019ve seen something similar in a Ukraine war video where they use a device that lights up on specific frequencies that drones use. FANTASTIC!! I was just thinking about this the other day, and wondering about directionality... For example, if you had a camera facing a space, and the receiving antenna was within that space... and you were able to (somehow?) from the antennas perspective, see the \"direction\" the frequency was coming from.. And then map the different specific frequencies within the desired bandwidth to colors... and of course intensity map like you have in the slit device.. And then \"look through the camera\"... you would see a live three dimensional overlay of all signals within range (colored!) \"interacting\" with the antenna... but kind of more the \"looking through the camera\" sort of view, like you could \"see\" how those waves were interacting.. And then wouldn't it be interesting to put a tin-foi"}